"course","url","campus","department","thesis_type","title","authors","main_advisor","committee","pt_abstract","en_abstract","auth_keywords","cnpq_area","language","publisher","affil_accronym","access_type","uri","defense_date","document_url","second_title","second_advisor"
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/11641","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Classificação de produtos em Notas Fiscais Eletrônicas usando descrições textuais não estruturadas","('Maria Tatiane Medeiros dos Santos',)","('Thales Miranda de Almeida Vieira',)","('Krerley Irraciel Martins Oliveira', 'Adriano Oliveira Barbosa')","Este trabalho apresenta uma análise acerca da viabilidade do uso de algoritmos de aprendizagem de máquina para a classificação de itens de produtos de Nota Fiscal Eletrônica (NFE), se baseando nas descrições textuais dos produtos para os atribuir às unidades comerciais correspondentes. A base de dados selecionada foi a base de dados de NFE disponibilizada pelo Ministério Público do Estado da Paraíba (MPPB). Esta pesquisa tem o objetivo de contribuir com a busca de soluções para o desafio de definir exatamente qual produto está sendo descrito e qual a quantidade que foi comercializada em uma NFE, e assim auxiliar em uma possível fiscalização automatizada dos preços. Para realizar a classificação, primeiro foi realizada uma rotulação manual de uma amostra dos dados, classificando-as quanto à unidade de medida. Essa amostra foi utilizada no treinamento de dois modelos para realizar a classificação da descrição do produto: uma solução tradicional a nível de palavras, adotado como baseline; e uma solução mais a nível do estado da arte baseado em redes neurais recorrentes, a nível de caracteres. Realizamos uma comparação do desempenho dessas duas abordagens.","This work presents an analysis about the feasibility of using machine learning algorithms to product item classification in Electronic Invoices (NFE), based on the textual descriptions of the products to associate them with the corresponding commercial units. The database used in this work was extracted from a NFE database made available by Public Ministry of Paraiba (MPPB). This research has as purpose to contribute to the challenge of defining exactly which product is being described and what quantity was sold in an NFE, and thus help in a possible automated price inspection. To the classification, first was performed a manual labeling of a data sample, classifying them with the matching unit of measurement. This sample was used in the training of two models to perform a product description classification: a traditional word-based solution, adopted as baseline; and a state-of-the-art character-based solution based on recurrent neural networks. We perform a comparison of the performance of these two approaches.","('Aprendizagem de máquina', 'Processamento de linguagem natural', 'Redes neurais recorrentes', 'Machine learning', 'Natural language processing', 'Recurrent neural network')","Engenharia de Software","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/11641","2023-01-13","https://www.repositorio.ufal.br/bitstream/123456789/11641/1/Classifica%c3%a7%c3%a3o%20de%20produtos%20em%20Notas%20Fiscais%20Eletr%c3%b4nicas%20usando%20descri%c3%a7%c3%b5es%20textuais%20n%c3%a3o%20estruturadas.pdf","",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/11642","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Bio-inspired optimization applied to synthetic ECG models for generating cardiac arrhythmias","('Rafael Monteiro Laranjeira',)","('Thiago Damasceno Cordeiro',)","('Álvaro Alvares de Carvalho César Sobrinho', 'Eduardo Moraes de Miranda Vasconcellos')","O eletrocardiograma (ECG) é um procedimento essencial para a detecção de diversos problemas cardíacos. Com o avanço do desenvolvimento dos algoritmos de aprendizado profundo, torna-se cada vez mais interessante a construção de classificadores de doenças cardiovasculares a partir do sinal de ECG e muitos desses algoritmos apresentam um alto desempenho. Entretanto, o principal desafio ainda persiste: as bases de dados contendo sinais de ECG são caras e muitas vezes com pouca variedade e anotações de especialistas da área. Esse trabalho introduz uma nova metodologia para gerar sinais de ECG sintéticos utilizando um modelo matemático e um algoritmo bio-inspirado para estimar os parâmetros deste mesmo modelo. O principal objetivo é expandir o modelo matemático original para que ele seja capaz de reproduzir as mais diversas arritmias cardíacas utilizando sinais reais como referencia. Os parâmetros do modelo são definidos para cada onda e são obtidos por um processo de otimização que consiste em minimizar a diferença entre sinal sintético gerado e o sinal real. Os resultados mostram que a metodologia proposta é capaz de estimar os parâmetros do modelo sintético utilizando funções gaussianas para cada onda e consegue se adaptar para diversas outras doenças cardiovasculares.","The Electrocardiogram (ECG) is an essential and straightforward procedure used to detect cardiac abnormalities. With the development of deep learning algorithms, the focus of many works is on the design of automatic ECG disorders detection algorithms, and many of them have achieved very high accuracy. The main challenge is still the same: clinical ECG datasets are expensive, and there are no sufficient expert annotations. This work introduces a new methodology for generating synthetic ECG signals using a mathematical model and a bio-inspired algorithm to estimate the model’s parameters. The objective is to expand the original model to reproduce different cardiac arrhythmias using ECG records as a reference. The model’s parameters are different for each selected ECG wave and are obtained by minimizing the difference between the ECG recordings and the synthetic ones. The results show that the proposed methodology is able to estimate the synthetic ECG model parameters using Gaussian functions for each ECG wave and is highly adaptable to different cardiac diseases.","('Eletrocardiografia', 'Evolução diferencial', 'Otimização de processos', 'Modelo de ECG sintético', 'Arritmias cardíacas', 'PhysioNet', 'Algoritmos', 'Algoritmos evolucionários', 'Algoritmos bio-inspirados', 'Doenças cardiovasculares', 'Eletrocardiografia', 'Differential evolution', 'Process optimization', 'Synthetic ECG Model', 'Cardiac arrhythmias', 'Algorithms', 'Evolutionary algorithms', 'Bio-inspired algorithms', 'Cardiovascular diseases')","Engenharia de Software","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/11642","2023-02-03","https://www.repositorio.ufal.br/bitstream/123456789/11642/1/Bio-inspired%20optimization%20applied%20to%20synthetic%20ECG%20models%20for%20generating%20%20cardiac%20arrhythmias.pdf","Otimização Bio-inspirada Aplicada à Modelos Sintéticos de ECG para Geração de Arritmias Cardíacas","('Erick de Andrade Barboza',)"
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/11640","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Squalo – um framework de ASV para coleta de lixo","('Hyago Procopio Brito',)","('Glauber Rodrigues Leite',)","('Ícaro Bezerra Queiroz de Araújo', 'José Henrick Viana Ramalho')","A água é um recurso precioso para a humanidade, mas, desde muito tempo, vem sofrendo com a poluição, desde produtos químicos, lixo sólido até os mais diversos tipos de resíduos. Devido a isso, se faz necessário monitorar e proteger esse recurso. Neste estudo, usando uma tecnologia de prototipação 3D, uma proposta de veículo autônomo de superfície (ASV) foi desenvolvida. Esse veículo é capaz de coletar lixo na superfície da água ao mesmo tempo em que coleta dados utilizando sensores. Entretanto, o projeto de robôs envolve tarefas de programação complexas, como sensoriamento, percepção, navegação e controle, além de problemas relacionados a eletrônica, mecânica e instrumentação. No domínio das aplicações marítimas, a simulação física, como a flutuação na água é uma especificidade, também complexa. Um framework robótico foi desenvolvido para dar suporte ao desenvolvimento de experimentação dos algoritmos em um ambiente de simulação confiável. O ciclo de vida do framework é descrito do seguinte modo: Dadas as coordenadas do resíduo, o controlador recebe os dados para processamento e computa a navegação para chegar ao destino, gerando comandos de força a serem aplicados a cada motor do veículo. Como prova de conceito, um MPC (Model Predictive Controller ) não linear foi implementado utilizando as funções do framework, provendo métricas de controle padrão para testar diferentes configurações.","Water is a precious resource for humankind, but for a long time, it has suffered from pollution from chemical products and solid waste to various types of residues. Because of that, it became necessary to monitor and protect this resource. In this study, using 3D prototyping technology, an autonomous surface vehicle (ASV) design was proposed. This vehicle can collect waste on the water surface and acquire data from water with sensors. However, along with problems concerning electronics, mechanics, and instrumentation, robot design involves complex programming tasks, such as sensing, perception, navigation, and control. Furthermore, simulated physics like water floating are specific to the domain. A robotic framework was developed to support the development and experimentation of such algorithms in a reliable simulation environment. The framework lifecycle is described as follows: Given the waste coordinates, the controller receives the data to process and compute the navigation to reach the destination, generating force commands to be applied in each engine of the vehicle. As concept proof, a nonlinear MPC (Model Predictive Controller) was implemented using the framework functions, providing standard control metrics to test different configurations.","('Veículo autônomo', 'Framework', 'Simulação robótica', 'Autonomous vehicle', 'Robotic simulation')","Engenharia de Software","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/11640","2022-12-12","https://www.repositorio.ufal.br/bitstream/123456789/11640/1/Squalo%20%e2%80%93%20um%20framework%20de%20ASV%20para%20coleta%20de%20lixo.pdf","Squalo -an ASV framework for garbage collection",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/10690","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Redes neurais artificiais para a estimativa do sinal de saída de amplificadores ópticos considerando sinais de entrada inclinados","('José Carlos Pinheiro Filho',)","('Erick de Andrade Barboza',)","('Ícaro Bezerra Queiroz de Araújo', 'Tiago Figueiredo Vieira')","Comunicação por redes ópticas é a principal maneira de suprir a quantidade de tráfego de dados que nos últimos anos só cresce. Os sistemas de comunicação ópticos precisam ser robustos para condições dinâmicas de funcionamento para assim obter o melhor sinal de transmissão. Para que a rede óptica seja adaptável é necessário que possua dispositivos autônomos. Os amplificadores ópticos são dispositivos importantes para estabelecer uma comunicação óptica, para tornar esse dispositivo autônomo é necessário estimar como o sinal é alterado ao passar pelo mesmo. Estudos foram realizados para a estimativa do sinal na saída do amplificador óptico, entretanto apenas dados de caracterização de sinais planos foram considerados, o que difere do que acontece em um cenário real. Neste trabalho são propostos modelos baseados em redes neurais artificiais para realizar a estimativa do sinal de potência de saída do amplificador óptico, utilizando dados de caracterização com sinais não planos. Os resultados mostraram que o modelo anterior, proposto com sinais planos, não tem um bom desempenho quando apresentado a dados de sinais não planos. Com os resultados foi possível observar que os modelos que utilizam todo o espectro de entrada, obtiveram um resultado melhor do que os que consideram os canais isoladamente. O modelo com melhor resultado alcançou 0, 15dB na mediana da distribuição do erro médio, uma redução de 2, 14 comparado ao modelo proposto anteriormente. Além disso, ao otimizar o modelo com melhor resultado foi possível obter uma mediana abaixo de 2,5dB em cenários de cascata de amplificadores com mais de 20 dispositivos.","Optical Communication is the main way to supply the amount of data traffic that only grows in the last years. Optical communication systems need to be robust for dynamic operating conditions to obtain the best transmission signal. For the optical network to be adaptable it is necessary to have autonomous devices. Optical amplifiers are important devices for establishing optical communication, to make this device autonomous it is necessary to estimate how the signal is modified when passed through it. The studies were realized to estimate the signal at the output of the optical amplifier, although only flat signal characterization data were considered, which differs from what happens in a real scenario. In this work, models based on artificial neural networks are proposed to estimate the output power signal of the optical amplifier, using characterization data with non-fiat signals. The results showed that the previous model, proposed with flat signals, does not perform well with data from non-flat signals. With the results it was possible to observe that the models that use the entire signal spectrum, obtained a better result than those that consider the isolated channels. The model with the best result reached 0.15dB in the median of the medium erro distribution, a reduction of 2.14 compared to the model previously proposed. In addition, by optimizing the model with the best result, it was possible to obtain a median below 2.5dB, with amplifier cascade scenarios with more than 20 devices.","('Amplificadores ópticos', 'Comunicações ópticas', 'Redes neurais artificiais', 'Artificial neural network', 'Regression', 'Optical amplifier', 'Optical signal')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/10690","2020-12-18","https://www.repositorio.ufal.br/bitstream/123456789/10690/1/Redes%20neurais%20artificiais%20para%20a%20estimativa%20do%20sinal%20de%20sa%c3%adda%20de%20amplificadores%20%c3%b3pticos%20considerando%20sinais%20de%20entrada%20inclinados.pdf","",""
"Sistemas de Informação","https://www.repositorio.ufal.br/handle/123456789/14032","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","A utilização de tecnologias da informação para potencializar o aprendizado através da metodologia de sala de aula invertida","('Handrik Palmeira Magalhães',)","('Ranilson Oscar Araújo Paiva',)","('Almir Pereira Guimarães', 'Petrúcio Antônio Medeiros Barros')","O presente trabalho tem como principal objetivo identificar as ferramentas computacionais mais utilizadas no contexto da abordagem pedagógica da Sala de Aula Invertida (SAI), bem como verificar se o uso destas ferramentas traz melhorias dentro dessa abordagem. Para isso realizamos uma revisão sistemática de literatura (RSL) com intuito de obter informações que possam satisfazer os objetivos citados. Durante a pesquisa foram selecionados 131 artigos científicos, dos quais 38 foram escolhidos após as fases de seleção e após a aplicação dos critérios de inclusão, exclusão e de qualidade dos artigos, foram adotados apenas 24 artigos. Após análise, pudemos observar que a maioria dos artigos foram publicados nos anos de 2021 e 2022 (62,5%) em revistas que apresentam conceito Qualis A1 ou A2 (42,9%), com uma predominância de publicações nacionais (54,2%). Como resultado pudemos averiguar que, dos autores que informaram as ferramentas utilizadas, o Moodle foi a ferramenta mais utilizada na fase de estudos preliminares (29,2%) e na fase avaliativa (29,2%), enquanto que o Google Meet foi a ferramenta mais utilizada na fase de encontros e discussões (25,0%). Quanto ao resultado da avaliação de melhora com o uso dessas ferramentas, mais da metade dos autores (54,2%), mostraram evidências de melhoras significativas com o uso desta ferramentas.","The main objective of this work is to identify the most used computational tools in the context of the Flipped Classroom (SAI) pedagogical approach, as well as to verify whether the use of these tools brings improvements within this approach. To this end, we carried out a systematic literature review (RSL) in order to obtain information that could satisfy the aforementioned objectives. During the research, 131 scientific articles were selected, of which 38 were chosen after the selection phases and after applying the inclusion, exclusion and article quality criteria, only 24 articles were adopted. After analysis, we were able to observe that the majority of articles were published in 2021 and 2022 (62.5%) in journals that present a Qualis A1 or A2 concept (42.9%), with a predominance of national publications (54.2 %). As a result, we were able to ascertain that, of the authors who reported the tools used, oodle was the most used tool in the preliminary studies phase (29.2%) and in the evaluationphase (29.2%), while Google Meet was the most used tool in the meetings and discussions phase (25.0%). Regarding the results of the assessment of improvement with the use of these tools, more than half of the authors (54.2%) showed evidence of significant improvements with the use of these tools.","('Sala de aula invertida', 'Sistemas de informação', 'Tecnologia da informação e da comunicação', 'Aplicativos (Programas de computador)', 'Flipped classroom', 'Information Systems', 'Information and communication technology', 'Applications (Computer Programs)')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/14032","2023-12-18","https://www.repositorio.ufal.br/bitstream/123456789/14032/1/A%20utiliza%c3%a7%c3%a3o%20de%20tecnologias%20da%20informa%c3%a7%c3%a3o%20para%20potencializar%20o%20aprendizado%20atrav%c3%a9s%20da%20metodologia%20de%20sala%20de%20aula%20invertida.pdf","","('Ibsen Mateus Bittencourt Santana Pinto',)"
"Sistemas de Informação","https://www.repositorio.ufal.br/handle/123456789/17704","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Uso de sistemas de informação no combate à pandemia de Covid-19: uma revisão sistemática","('Ana Flávia Gomes da Silva Carvalho',)","('Alexandre Paes dos Santos',)","('Rômulo Nunes de Oliveira', 'Petrúcio Antônio Medeiros Barros')","Durante a pandemia de COVID-19, a utilização de Sistemas de Informação (SI) no Brasil foi crucial para a gestão da saúde pública, permitindo o monitoramento eficiente da doença e a comunicação eficaz entre profissionais e a população. Iniciativas como o Conecte SUS, o ESUS e plataformas de telemedicina facilitou o atendimento e o controle da pandemia, apesar dos desafios enfrentados. A experiência adquirida com esses sistemas fortaleceu a infraestrutura de saúde e pode servir como base para a preparação para futuras crises sanitárias. Este estudo teve como objetivo geral realizar uma revisão sistemática sobre o uso de Sistemas de Informação no combate à pandemia de COVID-19, destacando como esses sistemas contribuíram para a gestão da saúde pública no Brasil. Para isso, foram analisadas publicações científicas sobre o uso de Sistemas de Informação durante a pandemia de COVID-19, empregando uma estratégia de busca detalhada em bases de dados e seguindo passos meticulosos para assegurar a seleção dos estudos mais pertinentes e confiáveis. Após interpretação dos resultados, concluiu-se que a implementação eficaz de SI foi indispensável para melhorar a resposta à pandemia e gerenciar os desafios associados à saúde pública. Esses sistemas tanto ajudaram na coordenação das ações de resposta como melhoraram a capacidade de análise e previsão de tendências epidemiológicas, o que é vital para enfrentar emergências sanitárias.","During the COVID-19 pandemic, the use of Information Systems (IS) in Brazil has been crucial for public health management, enabling efficient monitoring of the disease and effective communication between professionals and the population. Initiatives such as Connect SUS, E-SUS and telemedicine platforms have facilitated care and control of the pandemic, despite the challenges faced. The experience gained with these systems has strengthened the health infrastructure and can serve as a basis for preparing for future health crises. The general objective of this study was to carry out a systematic review of the use of Information Systems in combating the COVID-19 pandemic, highlighting how these systems have contributed to public health management in Brazil. To this end, scientific publications on the use of Information Systems during the COVID-19 pandemic were analyzed, employing a detailed database search strategy and following meticulous steps to ensure the selection of the most pertinent and reliable studies. After interpreting the results, it was concluded that the effective implementation of IS was indispensable for improving the response to the pandemic and managing the associated public health challenges. These systems both helped to coordinate response actions and improved the ability to analyze and forecast epidemiological trends, which is vital for dealing with health emergencies.","('Sistemas de informação', 'Pandemia da Covid-19', 'Saúde pública', 'Information systems', 'Covid-19 pandemic', 'Public health')","Sistemas de Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/17704","2024-12-19","https://www.repositorio.ufal.br/bitstream/123456789/17704/1/Uso%20de%20sistemas%20de%20informa%c3%a7%c3%a3o%20no%20combate%20%c3%a0%20pandemia%20de%20Covid-19%3a%20uma%20revis%c3%a3o%20sistem%c3%a1tica.pdf","",""
"Sistemas de Informação","https://www.repositorio.ufal.br/handle/123456789/14028","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Revisão sistemática sobre evidências de boas e más práticas no contexto do ensino remoto emergencial (ERE)","('Otávio José Costa de Albuquerque Júnior',)","('Ranilson Oscar Araújo Paiva',)","('Almir Pereira Guimarães', 'Petrúcio Antônio Medeiros Barros')","O ensino remoto emergencial foi o nome dado ao período de adaptação do ensino presencial para uma modalidade de ensino que utilizava em sua maior parte, tecnologia da informação para o desenvolvimento de atividades educacionais que necessitavam ter continuidade durante o período da pandemia do COVID-19, devido a urgência e obrigatoriedade de haver um distanciamento social visando o bem da saúde pública. O presente trabalho apresenta uma revisão sistemática da literatura a respeito das evidências de boas e más práticas que foram evidenciadas cientificamente durante o período acima mencionado. Como resultado das pesquisas iniciais 165 artigos foram encontrados e após a remoção de artigos duplicados e com a aplicação da seleção de estudos, critérios de inclusão e exclusão e análise de qualidade, restaram 33 artigos válidos para o presente trabalho. Nos resultados encontrados após a questão de pesquisa ficou evidente que as principais práticas são baseadas em melhorar a infraestrutura básica (54,54%) para os alunos conseguirem ter um acesso estável as plataformas de ensino e também ficou bastante evidente, que é necessário haver um letramento digital para professores e alunos, pois muitos relatos foram classificados como negativos durante o período em razão da falta de preparo de professores e alunos (24,24%) para lidar com a tecnologia da informação disponível. Ficou explícito que as plataformas de comunicação, Google Meet (54,54%), Whatsapp (33,33%) e Zoom (36,36%) foram essenciais para manter o contato frequente entre professores e alunos. Os fatos acima elucidados visam trazer para próximos pesquisadores, informações que sejam importantes em uma futura transição de ensino presencial para ensino remoto e também a reformulação de matrizes curriculares, buscando tornar a tecnologia da informação sempre mais presente no dia a dia de estudantes, professores e pesquisadores.","Emergency remote teaching was the name given to the period of adaptation from face-to-face teaching to a teaching modality that used mostly information technology for the development of educational activities that needed to be continued during the COVID-19 pandemic, due to the urgency and need for social distancing to protect public health. This work presents a systematic review of the literature on the evidence of good and bad practices that were scientifically evidenced during the aforementioned period. As a result of the initial searches, 165 articles were found and after the removal of duplicate articles and with the application of the study selection, inclusion and exclusion criteria and quality analysis, 33 articles were valid for this work. In the results found after the research question, it was evident that the main practices are based on improving the basic infrastructure (54.54%) for students to have stable access to teaching platforms and it was also quite evident that there is a need for digital literacy for teachers and students, as many reports were classified as negative during the period due to the lack of preparation of teachers and students (24.24%) to deal with the available information technology. It was clear that the communication platforms, Google Meet (54.54%), Whatsapp (33.33%) and Zoom (36.36%) were essential to maintain frequent contact between teachers and students. The facts elucidated above aim to bring to future researchers information that is important in a future transition from face-to-face teaching to remote teaching and also the reformulation of curricular matrices, seeking to make information technology increasingly present in the daily lives of students, teachers and researchers.","('Ensino remoto emergencial', 'Ensino online emergencial', 'Ensino híbrido emergencial e práticas', 'Emergency remote teaching', 'Emergency online teaching', 'Emergency hybrid teaching and Practices')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/14028","2023-12-21","https://www.repositorio.ufal.br/bitstream/123456789/14028/1/Revis%c3%a3o%20sistem%c3%a1tica%20sobre%20evid%c3%aancias%20de%20boas%20e%20m%c3%a1s%20pr%c3%a1ticas%20no%20contexto%20do%20ensino%20remoto%20emergencial%20%28ERE%29.pdf","","('Ibsen Mateus Bittencourt Santana Pinto',)"
"Sistemas de Informação","https://www.repositorio.ufal.br/handle/123456789/14812","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","A percepção docente e discente através do ensino remoto em tempos de pandemia COVID-19: estudo de caso em duas cidades no sertão alagoano","('Farley Marcos Machado Rocha',)","('Olival de Gusmão Freitas Júnior',)","('Fábio Paraguaçu Duarte da Costa', 'Marcus de Melo Braga')","Este trabalho visa apresentar e discutir dados sobre a percepção dos docentes e discentes em duas escolas do sertão alagoano frente ao distanciamento social imposto pela pandemia do COVID-19 desde o final do ano de 2019. Tendo em vista a mudança repentina na maneira de se viver e se comportar imposta pela quarentena após o anuncio do ministério da saúde que sugeriu a substituição das aulas presenciais por aulas remotas em março de 2020, nas mais distintas áreas, e principalmente na educação, busca-se entender através desse trabalho de pesquisa, qual foi o impacto causado na educação levando em consideração o que diz a ONU onde 9 em cada 10 alunos estão fora do ambiente escolar, de que forma as escolas aderiram a modalidade de ensino remoto emergencial, e em alguns casos educação a distância como estratégia e quais são os resultados do uso dessa nova metodologia sabendo que o ensino remoto, por mais importante que seja no atual contexto, tem limitações e não atendem a todos os alunos da mesma maneira e com a mesma eficiência. Os recursos metodológicos escolhidos para este estudo foram à observação participante, a fim de perceber como é construído o ensino e a entrevista estruturada com professores e alunos da rede pública e privada do ensino básico nas instituições de duas cidades circunvizinhas do sertão de Alagoas, sendo elas Santana do Ipanema uma das mais importantes do sertão, e Olho D’Água das Flores, ambas com números muito parecidos na educação. Justifica-se a realização desse estudo com base no pressuposto de que apesar de ser uma modalidade que surgiu há bastante tempo, muitas são as dificuldades encontradas pelos envolvidos na pesquisa quanto ao uso, eficácia, e adaptação. Os resultados obtidos demonstraram que o ensino a distância tenta reduzir os efeitos negativos do distanciamento social, mas que ainda precisa passar por um processo de aceitação e entendimento por parte do aluno, além de uma formação continuada por parte do professor.","This work aims to present and discuss data about the perception of teachers and students in two schools in the backlands of Alagoas in view of the social distance imposed by the pandemic of COVID-19 since the end of 2019. In view of the sudden change in the way of living and behave imposed by the quarantine after the announcement of the Ministry of Health that suggested the replacement of face-to-face classes with remote classes in March 2020, in the most different areas, and mainly in education, we seek to understand through this research work, what was the impact on education taking into account what the UN says, where 9 out of 10 students are outside the school environment, how schools have joined the emergency remote teaching modality, and in some cases distance education as a strategy and what are the results of using this new methodology knowing that remote education, however important it may be in the current context, has limitations and does not serve all students of same way and with the same efficiency. The methodological resources chosen for this study were participant observation, in order to understand how teaching and structured interviews with teachers and students from the public and private network of basic education are built in the institutions of two cities surrounding the sertão of Alagoas, namely Santana do Ipanema, one of the most important in the sertão, and Olho D'Água das Flores, both with very similar numbers in education. It is justified to carry out this study based on the assumption that despite being a modality that emerged a long time ago, there are many difficulties encountered by those involved in the research regarding use, effectiveness, and adaptation. The results obtained showed that distance learning tries to reduce the negative effects of social distance, but that it still needs to go through a process of acceptance and understanding on the part of the student, in addition to continuing education on the part of the teacher.","('Ensino remoto', 'COVID-19', 'Estudantes – Percepção', 'Aprendizagem', 'Remote teaching', 'Students – Perception', 'Learning')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/14812","2020-01-01","https://www.repositorio.ufal.br/bitstream/123456789/14812/1/A%20percep%c3%a7%c3%a3o%20docente%20e%20discente%20atrav%c3%a9s%20do%20ensino%20remoto%20em%20tempos%20de%20pandemia%20COVID-19%20es.pdf","","('Wanderson Rubian Martins Rodrigues',)"
"Sistemas de Informação","https://www.repositorio.ufal.br/handle/123456789/15039","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Uma proposta de implantação do método SCRUM em uma empresa de tecnologia","('Samuel das Chagas Macena',)","('Arturo Hernández-Domínguez',)","('Olival de Gusmão Freitas Júnior', 'Marcus de Melo Braga')","Este trabalho apresenta uma proposta de implantação do Scrum gradualmente com foco em diminuir o impacto da adoção do framework em uma organização que atua com desenvolvimento de software e que possui uma cultura organizacional conservadora. Iniciar o processo de implantação do framework enfatizando os princípios ágeis, os pilares e os valores do Scrum para os envolvidos pode ser um fator determinante para alcançar os resultados almejados por uma organização. Os valores apresentados pelos criadores do Scrum, Ken Schwaber e Jeff Sutherland, divergem por muitas vezes de uma cultura organizacional já bem estabelecida, o que pode tornar o processo de implantação mais complexo e demorado. Um estudo de caso é feito em torno de uma estratégia gradual: capacitação de pessoas, formação de Time Scrum em um projeto piloto e expansão de aprendizado para demais times. A partir das lições aprendidas, são sugeridos passos seguintes da implantação voltados para a essência do desenvolvimento ágil. Na busca por dominar o método, a organização passa por dificuldades para engajar seus colaboradores na transição de uma cultura organizacional para um modelo adaptativo. Mas também colhe benefícios, como melhor interação entre desenvolvedores e melhor entrega de valor para os clientes. Conclui-se que a adoção do framework segue duas definições dadas pelos autores do Scrum: simples de entender e difícil de dominar. Para adoção, uma organização deve estabelecer boas estratégias de implantação gradual considerando sua realidade e deve constantemente avaliar os feedbacks coletados para garantir que o Scrum esteja sendo implantado com base na essência do desenvolvimento ágil de software.","This work presents a proposal to implant Scrum gradually with a focus on reducing the impact of adopting the framework in an organization that works with software development and that has a conservative organizational culture. Starting the process of implementing the framework emphasizing the agile principles, pillars and values of Scrum for those involved can be a determining factor in achieving the results desired by an organization. The values presented by the creators of Scrum, Ken Schwaber and Jeff Sutherland, often differ from an already well-established organizational culture, which can make the deployment process more complex and time-consuming. A case study is carried out around a gradual strategy: training people, forming a Scrum Team in a pilot project and expanding learning to other teams. Based on the lessons learned, the following implementation steps are suggested, focusing on the essence of agile development. In the quest to master the method, the organization experiences difficulties in engaging its employees in the transition from na organizational culture to an adaptive model. But it also reaps benefits, such as better interaction between developers and better delivery of value to customers. It is concluded that the adoption of the framework follows two definitions given by the Scrum authors: simple to understand and difficult to master. For adoption, na organization must establish good gradual deployment strategies considering its reality and must constantly evaluate the feedbacks collected to ensure that Scrum is being implemented based on the essence of agile software development.","('Empresa de tecnologia', 'Scrum (Desenvolvimento de software)', 'Engenharia de software', 'Metodologias ágeis', 'Technology company', 'Scrum (Software Development)', 'Software engineering', 'Agile methodologies')","Sistemas de Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/15039","2020-08-06","https://www.repositorio.ufal.br/bitstream/123456789/15039/1/Uma%20proposta%20de%20implanta%c3%a7%c3%a3o%20do%20m%c3%a9todo%20SCRUM%20em%20uma%20empresa%20de%20tecnologia.pdf","A proposal to implatation the SCRUM method in a technology company",""
"Sistemas de Informação","https://www.repositorio.ufal.br/handle/123456789/11598","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","R-PARTNER: um sistema para apoio à realização de experimentos com design do tipo pré-teste e pós-teste em ambientes online de aprendizagem","('Leonardo Ulisses Lima de Holanda',)","('Ranilson Oscar Araújo Paiva',)","('Rafael de Amorim Silva', 'André Luís Alice Raabe')","O uso de práticas educacionais baseadas em evidência vem ganhando relevância considerável em países no exterior. Essa tendência vem acompanhada do desenvolvimento de um aparato de pesquisa responsável por gerar e avaliar evidências científicas. Para a geração de evidências, um dos métodos mais convincentes são os experimentos controlados. Entretanto, tais experimentos são caros e difíceis de realizar. No contexto brasileiro, a pesquisa educacional que utiliza experimentos controlados é pouco expressiva, o que enfraquece a geração de evidências capazes de basear novas práticas educacionais. Neste cenário, o presente trabalho propõe um sistema capaz de apoiar a realização de experimentos com design do tipo pré-teste e pós-teste em ambientes online de aprendizagem, buscando oferecer melhores condições para a realização destes experimentos. Um experimento foi conduzido para avaliar a percepção dos usuários sobre o sistema. Os resultados foram analisados estatisticamente e sugerem percepções positivas dos usuários em relação às métricas de facilidade de uso, utilidade e baixo custo de tempo do sistema. Conclui-se que o sistema é capaz de apoiar a realização de experimentos com design do tipo pré-teste e pós-teste.","The use of evidence-based practices in education is gaining traction in foreign countries. This trend has been accompanied by the development of a research apparatus responsible for generating and evaluating scientific evidence. To generate evidence, one of the most convincing methods is controlled experiments. However, such experiments are expensive and difficult to carry out. In the Brazilian context, educational research that uses controlled experiments is modest, which weakens the generation of evidence on which to base new educational practices. In this scenario, the present work proposes a system to manage experiments with pretest and posttest designs in online learning environments, seeking to offer better conditions for conducting these experiments. An experiment was conducted to evaluate the user's perception of the system. The results were statistically analyzed and suggest positive user perceptions regarding the system's metrics of ease of use, usefulness, and low time cost. It is concluded that the system is capable of supporting pre-test and post-test design experiments.","('Experimentos científicos', 'Práticas baseadas em evidências', 'Pesquisa educacional -Software', 'Experiments', 'Evidence-based practices', 'Educational research software', 'Pretest-posttest design', 'Educational Research -Software')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/11598","2022-12-19","https://www.repositorio.ufal.br/bitstream/123456789/11598/1/R-PARTNER%3a%20um%20sistema%20para%20apoio%20%c3%a0%20realiza%c3%a7%c3%a3o%20de.pdf","R-PARTNER: a system to support the conducting of experiments with pretest and posttest design in online learning environments",""
"Sistemas de Informação","https://www.repositorio.ufal.br/handle/123456789/15026","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Uma ferramenta para análise de sentimento para o Twitter","('Michelle Bernardino da Silva',)","('Rodolfo Carneiro Cavalcante',)","('Rômulo Nunes de Oliveira', 'Petrúcio Antônio Medeiros Barros')","O crescimento das redes sociais proporcionou algumas vantagens, dentre as quais podemos destacar o compartilhamento de informações entre os usuários em um curto espaço de tempo. A postagem de opiniões sobre diferentes eventos que estão em alta no momento é comum entre os usuários das redes sociais, tendo como consequência um volume crescente de dados diariamente. No entanto, toda essa informação gerada por meio destas postagens pode ser de grande utilidade, se a mesma for tratada corretamente gerando assim um conhecimento que poderá ser utilizado em diversas áreas. Este trabalho apresenta um estudo sobre análise de sentimento, mais especificamente, tendo como base de estudo a rede social Twitter, por esta conter recursos que facilitam a coleta de dados. Para a composição do trabalho utilizou-se um dataset (conjunto de dados) contendo informações que foram coletadas do Twitter por pessoas que trabalham para o governo de Minas Gerais, ou seja, as postagens dos usuários, conhecidas como tweets. Esses dados passaram por um processamento de linguagem natural a fim de remover stopwords (palavras irrelevantes para o sentido de determinada informação) e caracteres indesejados. Foi utilizado o algoritmo de aprendizagem de máquina Naive Bayes para classificação de sentimento em postagens. A ferramenta utilizada apresentou, apesar de ser utilizada uma base de teste simples, uma acurácia satisfatória de 86,85% na fase de teste. Posteriormente a ferramenta foi utilizada nos tweets recuperados e também mostrou-se bastante usual, conseguindo fazer a predição de todos os tweets recuperados.","The growth of social networks has provided some advantages among which we can highlight the sharing of information among users in a short space of time. The posting of opinions on different events that are currently on the rise and common among users of social networks results in a growing volume of data on a daily basis.However, this information generated through these posts can be very useful if they are treated correctly, thus generating knowledge that can be used in different areas. This article presents a study on sentiment analysis, more specifically based on the social network Twitter because it contains resources that facilitate data collection. For the composition of the work, a dataset was used with data collected from Twitter by people who work for the government of Minas Gerais, that is, the users' posts, known as tweets, that data went through a natural language processing in order to remove stopwords and unwanted characters. The Naive Bayes machine learning algorithm was used to classify sentiment in posts. The tool used presented, despite being used a simple test base, a satisfactory accuracy of 86.85% in the test phase. Subsequently, the tool was used in retrieved tweets and also proved to be quite usual, managing to predict all retrieved tweets.","('Mineração de textos', 'Mineração de dados', 'Mineração de opinião', 'Aprendizado de máquina', 'Processamento de linguagem natural', 'Twitter (Rede social on-line)', 'Análise de sentimento', 'Text mining', 'Data mining', 'Opinion mining', 'Machine learning', 'Natural language processing', 'Twitter (Online social network)', 'Sentiment analysis')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/15026","2020-12-23","https://www.repositorio.ufal.br/bitstream/123456789/15026/1/Uma%20ferramenta%20para%20an%c3%a1lise%20de%20sentimento%20para%20o%20Twitter.pdf","",""
"Sistemas de Informação","https://www.repositorio.ufal.br/handle/123456789/11597","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","O pensamento computacional como apoio pedagógico para professores em laboratórios de informática","('Aleph da Silva Lima',)","('Alan Pedro da Silva',)","('Ranilson Oscar Araújo Paiva', 'Ivo Augusto Andrade Rocha Calado')","Este trabalho tem como objetivo compreender como utilizar o pensamento computacional como apoio pedagógico para os professores na sala de aula, a existência dos laboratórios de informática na escola, observar como acontece à utilização do laboratório de informática pelos professores em sua prática pedagógica e a inclusão digital de professores e alunos, a falta de conhecimento dos professores para utilizar o Pensamento Computacional e o laboratório de informática com uma metodologia voltada para gerar novos conhecimentos em suas disciplinas, tendo em vista que apesar de algumas escolas possuírem esses laboratórios, observamos que esse despreparo inviabiliza a obtenção dos resultados almejados. A metodologia foi voltada para o estudo de caso, com professores de uma escola da rede municipal da cidade de Mata Grande, através de um questionário semiestruturado. Os dados foram avaliados de forma quantitativa e qualitativa. O resultado aponta para a necessidade de capacitação para os professores sobre o Pensamento Computacional, e que os mesmos detenham esse conhecimento e possam utilizá-lo em sua prática pedagógica.","This work aims to understand how to use computational thinking as pedagogical support for teachers in the classroom, the existence of computer labs at school, observe how teachers use the computer lab in their pedagogical practice and digital inclusion of teachers and students, the lack of knowledge of teachers to use Computational Thinking and the computer lab with a methodology aimed at generating new knowledge in their disciplines, considering that although some schools have these laboratories, we observe that this unpreparedness makes unfeasible obtaining the desired results. The methodology was focused on the case study, with teachers from a municipal school in the city of Mata Grande, through a semi-structured questionnaire. The data were evaluated quantitatively and qualitatively. The result points to the need for training for teachers on Computational Thinking, and that they retain this knowledge and can use it in their pedagogical practice.","('Pensamento computacional', 'Informática – Estudo e ensino', 'Laboratórios de informática', 'Prática pedagógica', 'Computational thinking', 'Computer science', 'Informatics – Study and teaching')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/11597","2019-03-21","https://www.repositorio.ufal.br/bitstream/123456789/11597/1/O%20pensamento%20computacional%20como%20apoio%20pedag%c3%b3gico%20para%20professores%20em%20laborat%c3%b3rios%20de%20inform%c3%a1tica.pdf","","('Denys Fellipe Souza Rocha',)"
"Sistemas de Informação","https://www.repositorio.ufal.br/handle/123456789/13310","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Doe.se, uma plataforma digital para facilitar a oferta e procura de trabalho voluntário","('Sandney Farias da Santos',)","('Olival de Gusmão Freitas Júnior',)","('Giseldo da Silva Néo', 'Wanderson Rubian Martins Rodrigues')","A oferta de trabalho voluntário e a procura por voluntários são processos importantes para a sociedade, mas podem ser difíceis de realizar de forma eficiente e eficaz. Neste contexto, uma plataforma digital para facilitar a oferta e procura de trabalho voluntário se destaca como uma solução prática, útil e inovadora. Tendo em vista esse cenário, o presente trabalho teve como objetivo desenvolver uma plataforma digital, a Doe.se, para facilitar a oferta e procura de vagas de trabalho voluntário, auxiliando assim as organizações a encontrarem o apoio de que precisam e permitindo que as pessoas possam encontrar vagas de trabalho voluntário de acordo com seus interesses e habilidades. Para o desenvolvimento da plataforma, foi utilizado a metodologia ágil Scrum no gerenciamento do projeto. As tecnologias utilizadas para o desenvolvimento do back-end foram: Java 17, SpringBoot 3.0.0, PostgreSQL, Lombok, JPA, JavaBeanValidation e Flyway Database Migration. Para o desenvolvimento do front-end, utilizou-se o Angular em conjunto com o Angular Material. Com a construção da plataforma Doe.se, criou-se as condições para facilitar a oferta e procura de trabalho voluntário, constituindo uma iniciativa promissora, com o potencial de promover um maior engajamento da sociedade em causas sociais e ambientais.","The supply of volunteer work and the search for volunteers are important processes for society, but they can be difficult to carry out efficiently and effectively. In this context, a digital platform to facilitate the supply and demand of volunteer work stands out as a practical, useful and innovative solution. In view of this scenario, the present work aimed to develop a digital platform, Doe.se, to facilitate the supply and demand for volunteer work vacancies, thus helping organizations to find the support they need and allowing people to find volunteer work vacancies according to their interests and skills. For the development of the platform, the agile Scrum methodology was used in project management. The technologies used for the development of the back-end were: Java 17, SpringBoot 3.0.0, PostgreSQL, Lombok, JPA, JavaBeanValidation and Flyway Database Migration. For the development of the front-end, Angular was used together with Angular Material. With the construction of the Doe.se platform, conditions were created to facilitate the supply and demand of volunteer work, constituting a promising initiative, with the potential to promote greater engagement of society in social and environmental causes.","('Sistemas de informação', 'Empreendedorismo social', 'Trabalho voluntário', 'Web -desenvolvimento', 'Negócios de impacto', 'Java', 'Impact business', 'Social entrepreneurship', 'Volunteer work', 'Web development')","Sistemas de Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/13310","2023-08-09","https://www.repositorio.ufal.br/bitstream/123456789/13310/1/Doe.se%2c%20uma%20plataforma%20digital%20para%20facilitar%20a%20oferta%20e%20procura%20de%20trabalho%20volunt%c3%a1rio.pdf","",""
"Sistemas de Informação","https://www.repositorio.ufal.br/handle/123456789/13469","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Complementariedade da carga horária presencial utilizando o ensino remoto no contexto brasileiro","('Laudemi José de Oliveira',)","('Ranilson Oscar Araújo Paiva',)","('Almir Pereira Guimarães', 'Petrúcio Antônio Medeiros Barros')","Através de uma Revisão Sistemática de Literatura (RSL), utilizando a Plataforma Evidências -Módulo Sumarize, o presente trabalho visa identificar como o ensino remoto pode ser utilizado como complemento da carga horária do ensino presencial, de forma a enriquecer o aprendizado dos estudantes do ensino fundamental e médio e para melhoramento da qualidade do aprendizado do estudante. Através dessa metodologia, adotamos um protocolo da revisão sistemática de literatura e criamos strings de busca para procurar nas plataformas digitais. Como resultados, percebemos que mais da metade das publicações em revistas científicas (63,3%) foram publicadas em 2021, seguida por 2022 (16,7%) e 2020 (16,7%) e finalmente em 2019 (3,3%).10% (3 artigos) apresentaram as TDICs (Tecnologias Digitais da Informação e Comunicação) que são usadas para complementar o ensino presencial. 10% (3 artigos) apresentaram como as TDICs são utilizadas para complementar o ensino presencial. Apenas 1 artigo apontou evidências de efetividade das TDICS. Somente 2 artigos apresentaram quais técnicas foram utilizadas pelos professores para a utilização do ensino remoto. Para quais as plataformas utilizadas para o uso do ensino híbrido, apenas 3 artigos foram identificados, reportando as seguintes plataformas: aplicativos para videoconferências (Zoom, Google Hangouts, Skype); E-mails; WhatsApp; ambientes virtuais de aprendizagem – AVA; salas de aula virtuais (Google Classroom, Google Meet, Google Forms, Google Jamboard, Google Docs, Google Slides), SIGAA, Moodle, além do uso de ferramentas assíncronas, como os fóruns (espaços de discussão) dos AVA, correio eletrônico, questionários, planilhas, agendas, vídeo-aulas, porta-arquivos virtuais (Google Drive, Dropbox, outros) e outros. Concluímos que as respostas encontradas não foram suficientes para responder todas as perguntas desta pesquisa. O que nos leva a identificar uma ausência de trabalhos/pesquisas que possam substanciar nossas questões de pesquisa e que, possivelmente, tenha maiores estudos sobre a temática da complementariedade da carga horária para as escolas brasileiras.","Through a Systematic Literature Review (RSL), using the Evidence Platform -Sumarize Module, this work aims to identify how remote teaching can be used as a complement to the in-person teaching workload, in order to enrich the learning of teaching students elementary and secondary education and to improve the quality of student learning. Through this methodology, we adopted a systematic literature review protocol and created search strings to search on digital platforms. As a result, we noticed that more than half of the publications in scientific journals (63.3%) were published in 2021, followed by 2022 (16.7%) and 2020 (16.7%) and finally in 2019 (3.3%).10% (3 articles) presented TDICs (Digital Information and Communication Technologies) that are used to complement face-to-face teaching. 10% (3 articles) presented how TDICs are used to complement face-to-face teaching. Only 1 article showed evidence of the effectiveness of TDICS. Only 2 articles presented which techniques were used by teachers to use remote teaching. Regarding the platforms used for the use of hybrid teaching, only 3 articles were identified, reporting the following platforms: applications for video conferencing (Zoom, Google Hangouts, Skype); Emails; Whatsapp; virtual learning environments – VLE; virtual classrooms (Google Classroom, Google Meet, Google Forms, Google Jamboard, Google Docs, Google Slides), SIGAA, Moodle, in addition to the use of asynchronous tools, such as VLE forums (discussion spaces), electronic mail, questionnaires , spreadsheets, diaries, video lessons, virtual folders (Google Drive, Dropbox, others) and others. We concluded that the answers found were not sufficient to answer all the questions in this research. Which leads us to identify a lack of work/research that can substantiate our research questions and that, possibly, have further studies on the topic of complementary workload for Brazilian schools.","('Ensino complementar', 'Carga horária complementar', 'Ensino remoto', 'Tecnologia digital da informação e da comunicação', 'Complementary teaching', 'Complementary credit hours', 'Digital information and communication technology', 'Remote teaching')","Sistemas de Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/13469","2023-10-31","https://www.repositorio.ufal.br/bitstream/123456789/13469/1/Complementariedade%20da%20carga%20hor%c3%a1ria%20presencial%20utilizando%20o%20ensino%20remoto%20no%20contexto%20brasileiro.pdf","","('Ibsen Mateus Bittencourt Santana Pinto',)"
"Sistemas de Informação","https://www.repositorio.ufal.br/handle/123456789/13848","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Barreiras e desafios na implementação do pensamento computacional e da computação desplugada em ambientes de ensino público: uma revisão sistemática da literatura","('Milton dos Santos Ferreira Filho',)","('Alexandre Paes dos Santos',)","('Petrúcio Antônio Medeiros Barros', 'Ricardo Alexandre Afonso')","O presente trabalho monográfico propõe uma revisão sistemática da literatura para investigar as barreiras e desafios enfrentados por professores e alunos na implementação do Pensamento Computacional e da Computação Desplugada em ambientes escolares públicos no Brasil, estando relacionadas às palavras-chave: Pensamento Computacional e Computação Desplugada, contextualiza-se a importância dessas abordagens no atual cenário educacional. Destaca-se a relevância do Pensamento Computacional no desenvolvimento de habilidades cognitivas, raciocínio lógico e resolução de problemas, bem como a inclusão da Computação Desplugada como estratégia para tornar esses conceitos acessíveis a diferentes realidades, independentemente da infraestrutura tecnológica disponível. Ao oferecer insights sobre estratégias para superar tais desafios, este estudo visa contribuir para a melhoria da implementação das habilidades nas redes públicas de ensino básico e fundamental. Sugere-se a promoção de programas de capacitação continuada para professores, o desenvolvimento de materiais didáticos adequados, a criação de parcerias com instituições que possam fornecer suporte técnico e a promoção de abordagens flexíveis que permitam a adaptação desses conceitos às particularidades de cada ambiente educacional. Por meio desta RSL (revisão sistemática da literatura), busca-se consolidar conhecimentos existentes, oferecendo subsídios para aprimorar práticas pedagógicas meio à introdução das ciências da computação, visando preparar professores e alunos para os desafios e oportunidades do mundo digital, promovendo uma educação mais inclusiva e alinhada às demandas contemporâneas.","This monographic work proposes a systematic review of the literature to investigate the barriers and challenges faced by teachers and students in the implementation of Computational Thinking and Unplugged Computing in public school environments in Brazil, being related to the keywords: Computational Thinking and Unplugged Computing, the importance of these approaches in the current educational scenario is contextualized. The relevance of Computational Thinking in the development of cognitive skills, logical reasoning and problem solving stands out, as well as the inclusion of Unplugged Computing as a strategy to make these concepts accessible to different realities, regardless of the available technological infrastructure. By offering insights into strategies to overcome such challenges, this study aims to contribute to improving the implementation of skills in public primary and secondary education networks. It is suggested that continuing training programs for teachers be promoted, the development of appropriate teaching materials, the creation of partnerships with institutions that can provide technical support and the promotion of flexible approaches that allow the adaptation of these concepts to the particularities of each educational environment. Through this RSL (systematic literature review), we seek to consolidate existing knowledge, offering subsidies to improve pedagogical practices through the introduction of computer sciences, aiming to prepare teachers and students for the challenges and opportunities of the digital world, promoting a more comprehensive education. inclusive and aligned with contemporary demands.","('Pensamento computacional', 'Computação desplugada', 'Rede de ensino público', 'Computational thinking', 'Unplugged computing', 'Public education network')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/13848","2023-11-20","https://www.repositorio.ufal.br/bitstream/123456789/13848/1/Barreiras%20e%20desafios%20na%20implementa%c3%a7%c3%a3o%20do%20pensamento%20computacional%20e%20da%20computa%c3%a7%c3%a3o%20desplugada%20em%20ambientes%20de%20ensino%20p%c3%bablico_uma%20revis%c3%a3o%20sistem%c3%a1tica%20da%20literatura.pdf","Barriers and challenges in implementing computacional thinking and unplugged computing in public education environments: a systematic review of literature",""
"Sistema de Informação","https://www.repositorio.ufal.br/handle/123456789/12473","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Sistemas e aplicações para autistas: uma revisão sistemática sobre soluções para pessoas atípicas","('Maria Simone Mônica Costa de Moraes',)","('Rômulo Nunes de Oliveira',)","('Petrúcio Antônio Medeiros Barros', 'Ítalo Carlo Lopes Silva')","A Tecnologia Assistiva, através dos diferentes tipos de Sistemas, tem como objetivo auxiliar as pessoas com necessidades especiais, dando-lhes suporte para realização das atividades diárias. As pessoas com Transtorno do Espectro Autista possuem uma alteração do neurodesenvolvimento. Entre as dificuldades dos Autistas está a comunicação. É fundamental compreender como os Sistemas e recursos tecnológicos podem auxiliar no desenvolvimento intelectual dos Autistas. Com esse propósito foi realizada uma revisão sistemática sobre o tema proposto. Foram analisados 15 artigos, obtidos nas bases de dados nacionais, Periódicos CAPES e Google Acadêmico. Os estudos e pesquisas sobre Sistemas e recursos, como software e APPs, vêm sendo realizados com o objetivo de buscar informações, alternativas para o desenvolvimento intelectual/cognitivo e aprendizado dos Autistas. A pesquisa apresentou resultado para a Tecnologia Assistiva, através da Comunicação Alternativa e Aumentativa, Jogos como apoio pedagógico. Outros estudos reuniram diretrizes para implementação das técnicas e práticas para acessibilidade na web , sites, aplicativos, navegadores e outras ferramentas. Além de recursos, de baixa, média e alta tecnologia. Com base nos resultados, percebe-se efeitos positivos, por meio dos diferentes tipos de recursos da Tecnologia Assistiva utilizados pelos Autistas.","Assistive Technology, through different types of Systems, aims to help people with special needs, giving them support to carry out daily activities. People with Autistic Spectrum Disorder have a change in neurodevelopment. communication. It is essential to understand how systems and technological resources can help in the intellectual development of autistic people. For this purpose, a state-of-the-art study on the proposed theme was carried out. 15 articles were analyzed, obtained from national databases, CAPES journals and Google Scholar. Studies and research on Systems and resources, such as software and APPs, have been carried out with the aim of seeking information, alternatives for the intellectual/cognitive development and learning of Autistic people. The research presented results for Assistive Technology, through Alternative and Augmentative Communication, Games as a pedagogical support, studies that gathered guidelines for the implementation of techniques and practices for accessibility on the web, websites, applications, browsers and other tools. In addition to resources, low, medium and high technology. Based on the results, positive effects are perceived through the different types of Assistive Technology resources used by Autistic people.","('Pessoas atípicas', 'Comunicação alternativa', 'Aplicações web', 'Tecnologia assistiva', 'Transtorno autístico', 'Atypical people', 'Alternative communication', 'Applications web', 'Assistive technology', 'Autistic Disorder')","Sistemas de Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/12473","2023-04-19","https://www.repositorio.ufal.br/bitstream/123456789/12473/1/Sistemas%20e%20aplica%c3%a7%c3%b5es%20para%20autistas%3a%20uma%20revis%c3%a3o%20sistem%c3%a1tica%20sobre%20solu%c3%a7%c3%b5es%20para%20pessoas%20at%c3%adpicas.pdf","Systems and applications for autistic people: a systematic review of solutions for atypical people",""
"Sistema de Informação","https://www.repositorio.ufal.br/handle/123456789/10271","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Sistematizando a seleção de recursos educacionais online para a prática da matemática para o 9º ano","('Rafael Alan Fagundes Santos',)","('Ranilson Oscar Araújo Paiva',)","('Alan Pedro da Silva', 'Diego Dermeval de Medeiros da Cunha Matos')","A educação online tem crescido significativamente nas últimas décadas em todo o mundo, alterando a forma de visualizar o ensino-aprendizagem para novos olhares. Neste contexto, a aprendizagem não se prende exatamente ao ambiente presencial de ensino, mas pode acontecer em qualquer lugar, com isso, surgem sistemas de educação online que auxiliam alunos e professores, provendo recursos educacionais (vídeos, textos, questões, etc.). Contudo, tais recursos educacionais são limitados ou, na maioria das vezes, não estão facilmente acessíveis, cabendo ao professor o papel de procurá-los e adequá-los ao contexto de seus cursos. Entretanto, isso agrega mais uma tarefa ao professor além das atividades e preocupações com o ensino, com a gestão de seus cursos e com a aprendizagem de seus estudantes. O objetivo desse trabalho é apoiar professores a escolher recursos educacionais online relevantes para a aprendizagem de estudantes do ensino fundamental. Como resultado, percebeu-se que o método aplicado na seleção dos recursos educacionais foi eficaz. O uso dos recursos online é positivo e deve ser aplicado em sala de aula, embora precisem ser selecionados utilizando uma metodologia adequada e mesmo que o uso destes recursos exija um treinamento específico por parte das escolas, para que orientem os estudantes para um melhor aproveitamento de seus dispositivos móveis.","Online education has grown significantly in the last decades around the world, changing the way of viewing teaching-learning for new looks. In this context, learning is not exactly about the face-to-face teaching environment, but it can happen anywhere. With this, online education systems that help students and teachers, providing educational resources (videos, texts, questions, etc.), arise. However, such educational resources are limited or, for the most part, not easily accessible, with the teacher having the role of searching for them and adapting them to the context of their courses. However, this adds yet another task to the teacher in addition to the activities and concerns with teaching, the management of their courses and the learning of their students. The objective of this work is to support teachers in choosing online educational resources relevant to the learning of elementary students. As a result, we noticed a better performance in the applied tests of the students who made use of the online resources to study the discipline. The use of online resources is positive and should be applied in the classroom, even if the use of these resources requires specific training by the schools, so that they guide students to make better use of their mobile devices.","('Educação a distância', 'Recursos tecnológicos', 'Ensino de matemática', 'Online education', 'Online resources for studying mathematics', 'Systematization of online resources')","Sistemas de Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/10271","2019-08-21","https://www.repositorio.ufal.br/bitstream/123456789/10271/1/Sistematizando%20a%20sele%c3%a7%c3%a3o%20de%20recursos%20educacionais%20online%20para%20a%20pr%c3%a1tica%20da%20matem%c3%a1tica%20para%20o%209%c2%ba%20ano.pdf","Systematizing the selection of online educational resources for the practice of mathematics for the 9th year","('Jário José dos Santos Júnior',)"
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/12147","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","wQuestions -um gerador e gerenciador de atividades para professores","('William Philippe Lira Bahia',)","('Ranilson Oscar Araújo Paiva',)","('Dalgoberto Miquilino Pinho Júnior', 'Rafael de Amorim Silva')","A elaboração de atividades e provas consome considerável parcela de tempo dos professores. Essa constatação é oriunda de pesquisas acadêmicas, reportagens e estudos governamentais, e é amparada por leis que limitam ou desincentivam que o professor trabalhe em casa além da carga horária contratual. Com o objetivo de utilizar a tecnologia para mitigar esse problema, este trabalho tem como objetivo desenvolver uma ferramenta que ajudará o professor a gerar atividades/provas automaticamente e mais rapidamente em comparação ao seu método tradicional. A ferramenta, nomeada de wQuestions, é um sistema online desenvolvido com React e Node.js, totalmente gratuito e de fácil utilização. Os resultados obtidos com os testes foram promissores.","Thisworkhasitsorigininthatteacherswastetoomuchtimemanuallymakingactivitiesandtests for their students. This fact is based on research, papers, andgovernmentinvestigations.Aswell based on laws that try not to encourage teachers to work more than the hours under contract. In order to solve this problem, this paper aims to develop one tool that will help teachers automatically andfastergeneratetests/activitiescomparedtotheirusualmethod.Thetool,named as wQuestions, is an online system developed with React and Node.js, totally free and easy to use. The obtained results were auspicious.","('Provas', 'Atividades', 'Automação', 'wQuestions(Software)', 'Evidence', 'Activities', 'Automation')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/12147","2022-08-31","https://www.repositorio.ufal.br/bitstream/123456789/12147/1/wQuestions%20-%20Um%20gerador%20e%20gerenciador%20de%20atividades%20para%20professores.pdf","",""
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/10326","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Occupancy detection in intelligent environments based on low-cost wireless sensor networks and machine learning techniques","('Hyuri da Silva Maciel',)","('André Luiz Lins de Aquino',)","('Leonardo Viana Pereira', 'Geymerson dos Santos Ramos')","As cidades inteligentes de forma ideal deveriam utilizar os sistemas computacionais para inferir a intenção do usuários, reduzindo ao máximo a necessidade da intervenção humana para a configuração dos ambientes. Para isto é necessário a criação de aplicações computacionais que sejam cada vez mais adaptáveis e flexíveis, melhorando os serviços dos ambientes inteligentes de forma contínua e transparentes. Neste trabalho apresentamos uma rede de sensores que detecta a ocupação dos ambiente e atua no sistema de iluminação e refrigeração de forma inteligente. Também foram inseridos outliers nos dados com intuito de validar as técnicas de classificação em a realização de um pré-processamento nos dados.","The smart cities, ideally, can use computer systems who perceive the intention of users, decreasing the need for human intervention to configure the environments. For this, it is necessary to create computational applications that are increasingly adaptable and flexible, improving the services of intelligent environments in a continuous and transparent. In this work, we present a wireless sensor network that detects the occupation in the environment and acts in the lighting and cooling system in an intelligent. Also, some outliers were added to the data in order to validate the results of the classification techniques and check their performance on noise data.","('Redes de sensores sem fio', 'Aprendizagem de máquina', 'Ocupação do ambiente (Computação)', 'Wireless Sensor Network', 'Machine Learning', 'Occupation')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/10326","2021-02-24","https://www.repositorio.ufal.br/bitstream/123456789/10326/1/Occupancy%20detection%20in%20intelligent%20environments%20based%20on%20low-cost%20wireless%20sensor%20networks%20and%20machine%20learning%20techniques.pdf","",""
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/10217","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Modelagem assíncrona do Page Rank","('Matheus Inacio Batista Santos',)","('André Luiz Lins de Aquino',)","('Leonardo Viana Pereira', 'Geymerson dos Santos Ramos')","Neste trabalho, apresentamos uma solução distribuída exata para o problema de classiﬁcação dos vértices mais populares de um grafo. Nos últimos anos, a quantidade de links WWW tem se tornado cada vez maior, então algoritmos sequenciais ou apenas paralelos não são mais viáveis, pois são executados em apenas uma máquina. Neste artigo, redesenhamos o algoritmo PageRank, proposto pelos fundadores do Google, para que funcione de forma eﬁciente em clusters de máquinas. Trazendo uma proposta inovadora em relação a literatura com a modelagem assíncrona. A solução usa o middleware Java Cá & Lá (JCL) e foi testada em um dos líderes do setor -o Apache GraphX. Os resultados usando instâncias aleatórias e reais demonstraram que nossa solução, chamada JCL PageRank, foi 10x mais rápida que o GraphX. Realizamos experimentos com máquinas de poder computacional diferentes, desde as conﬁgurações mais simples à conﬁgurações mais robustaz de clusters diferentes e os resultados de tempo de execução foram semelhantes. Ambas as soluções JCL e GraphX calculam os valores PageRank para todos os vértices de um grafo, portanto, sem aproximações. O cálculo personalizado PageRank também é executado pelas soluções GraphX e JCL PageRank.","In this work, we present an exact distributed solution for the problem of ranking the most popular vertices of a graph. In recent years, the amount of WWW links has become increasing, so sequential or just parallel algorithms are no longer feasible as they run on just one machine. In this work, we redesign the PageRank algorithm, proposed by Google’s founders, so that it runs efﬁciently under machine clusters. Bringing an innovative proposal in relation to the literature with asynchronous modeling. The solution uses the Java Cá & Lá (JCL) middleware and it has been tested against one of the industry leaders-the Apache GraphX. The results using synthetic and real instances demonstrated that our solution, named JCL PageRank, was 10x faster than GraphX. We have performed experiments with small and big machines in two different cluster conﬁgurations and the runtime results were similar. Both JCL and GraphX solutions calculate the PageRank values for all vertices of a graph, thus without approximations. Personalized PageRank calculus is also performed by both GraphX and JCL PageRank solutions.","('Pagerank (Algoritmo)', 'Sistemas distribuídos', 'Assíncrona', 'Distributed systems', 'asynchronous')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/10217","2021-08-23","https://www.repositorio.ufal.br/bitstream/123456789/10217/1/Modelagem%20ass%c3%adncrona%20do%20Page%20Rank.pdf","",""
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/12617","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Um operador de cruzamento baseado na preservação dos blocos de construção","('José Rubens da Silva Brito',)","('Roberta Vilhena Vieira Lopes',)","('Evandro de Barros Costa', 'Andrilene Ferreira Maciel')","Neste trabalho, foi introduzido um operador genético de cruzamento baseado na preservação dos blocos de construção que existem entre os cromossomos pais. Esse operador é utilizado no lugar do operador genético de cruzamento de um ponto de corte no algoritmo genético de Holland, onde ocorre a preservação dos blocos de construção que existem nos pais em seus filhos, com o propósito de resolver problemas de otimização. O algoritmo genético com o operador proposto, é comparado como o mesmo algoritmo considerando o cruzamento de um ponto e dois pontos de cortes. Esses três operadores foram testados sobre dois problemas de otimização, caixeiro viajante e OneMax. Para avaliar o desempenho do operador de cruzamento proposto em relação ao operador de cruzamento genético de um ponto de corte, onde serão realizados dois tipos de análise: convergência do algoritmo genético e qualidade dos cromossomos encontrados. Ao fim dos testes, foram analisados os resultados obtidos pelo operador proposto com um ponto de corte, e com dois pontos, e o operador genético de cruzamento de um ponto de corte do algoritmo genético de Holland.","n this work, a genetic crossover operator based on the preservation of the building blocks that exist between the parent chromosomes has been introduced. This operator is used in place of the genetic crossover operator of a cutoff point in Holland's genetic algorithm, where the preservation of the building blocks that exist in the parents in their children occurs, with the purpose of solving optimization problems. The genetic algorithm with the proposed operator, is compared with the same algorithm considering one cross cut point and two cut points. These three operators were tested on two optimization problems, traveling salesman and OneMax. To evaluate the performance of the proposed crossover operator compared to the genetic one-cutting point cross operator, where two types of analysis will be performed: convergence of the genetic algorithm and quality of the chromosomes found. At the end of the tests, the results obtained by the proposed operator with one cutoff point, and with two points, and the genetic crossover operator of one cutoff point of Holland's genetic algorithm were analyzed.","('Algoritmos genéticos', 'Algoritmo de Holland', 'Operador de cruzamento', 'Teoria dos schemata', 'Genetic Algorithms', ""Holland's algorithm"", 'Crossover operator', 'Schemata theory')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/12617","2022-07-14","https://www.repositorio.ufal.br/bitstream/123456789/12617/1/Um%20operador%20de%20cruzamento%20baseado%20na%20preserva%c3%a7%c3%a3o%20dos%20blocos%20de%20constru%c3%a7%c3%a3o.pdf","A crossing operator based on the preservation of building blocks",""
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/12655","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Métodos de integração entre ESP8266 e assistente virtual Alexa","('Leonardo Alexandre Ferreira da Silva',)","('João Raphael Souza Martins',)","('Glauber Rodrigues Leite', 'Tiago Alves de Almeida')","O avanço da automação no âmbito residencial tem proporcionado um crescimento em novas tecnologias e estudos acerca da popularização e acessibilidade do tema. A plataforma NodeMCU ESP8266 vem ganhando espaço no cenário de prototipagem e projetos, se mostrando uma excelente concorrente da já conhecida plataforma Arduino. Neste trabalho, é proposto um estudo de caso entre dois métodos de integração para ESP8266 e a assistente virtual da Amazon, Alexa, utilizando um dispositivo Echo Dot como hub de comunicação. Estes elementos estarão conectados à internet via WIFI, possibilitando assim um controle de uma carga conectada ao ESP8266 através de um comando de voz. Para o estudo de caso são abordadas as aplicações Blynk e Voiceflow, no primeiro método de integração e a biblioteca espalexa no segundo. Como cargas a serem acionadas são utilizados dois leds que representarão dispositivos de iluminação e climatização no ambiente doméstico. Um sensor de temperatura é utilizado para controle e acionamento secundário de uma das cargas. Tendocomoprincipalobjetivooestudodepossibilidadesdeacionamentoporcomando de voz de uma carga qualquer conectada ao ESP8266, visando um contexto de acessibilidade, uma vez que, o controle por comando de voz oferece maior comodidade e facilidade a pessoas com condições impeditivas de locomoção ou visuais, por exemplo. Por fim é apresentado um comparativo entre os métodos aplicados.","The advancement of automation in the residential field has provided a growth of new technologies and studies on the popularization and accessibility of the subject. The NodeMCUESP8266platformhasbeengainingspaceintheprototypingandprojectscenario, proving to be an excellent competitor to the already known Arduino platform. This article proposes a case study between two methods of integrating the ESP8266 and Amazon’s virtual assistant, Alexa, using an Echo Dot device as a communication hub. These elements are connected to the Internet via WIFI, allowing control of a load connected to the ESP8266 by voice command. by voice command. The case study uses the Blynk and Voiceflow applications in the first integration method and the espalexa library in the second. The loads to be controlled are two LEDs representing lighting and air conditioning devices for the home environment. A temperature sensor is used for control and secondary activation of one of the loads. The main goal is to study the possibilities of voice command activation of any load connected to the ESP8266, aiming at an accessibility context, since voice command offers greater convenience and ease for people with mobility or visual impairments, for example.","('Automação residencial', 'ESP8266 (Microcontrolador)', 'Alexa (Assistente virtual)', 'Inteligência artificial', 'Home automation', 'ESP8266 (Microcontroller)', 'Alexa (Virtual Assistant)', 'Artificial Intelligence')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/12655","2023-06-01","https://www.repositorio.ufal.br/bitstream/123456789/12655/1/M%c3%a9todos%20de%20integra%c3%a7%c3%a3o%20%20entre%20ESP8266%20%20e%20assistente%20virtual%20Alexa.pdf","",""
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/9121","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Explicação em sistema de apoio à decisão baseado em grafos do conhecimento: uma revisão sistemática","('Romário Oliveira Pantaleão',)","('Evandro de Barros Costa',)","('Thales Miranda de Almeida Vieira', 'Patrick Henrique da Silva Brito')","Com o advento dos sistemas de apoio à decisão que fazem uso de técnicas de inteligência artificial, na linha dos sistemas baseados em conhecimento, incluindo os sistemas de recomendação, constatou-se um crescimento no número de tarefas de tomada de decisão de forma completamente automática, ou seja, passam a ser executadas por sistemas de software. Neste sentido, facilidades de explicação passaram a ser uma característica requerida em algumas aplicações, a exemplo de aplicações no domínio da medicina, dentre outras. Algumas aplicações também são desenvolvidas oferecendo facilidades de explicação para itens recomendados. Por conta desse interesse em explicações, recentemente começou-se o investimento em pesquisa e desenvolvimento de sistemas de recomendação baseados em grafos de conhecimento, que tem propriedades de enriquecer os detalhes das entidades de um grafo e extrair relações importantes que podem enriquecer tais explicações. Apesar da importância dessas aplicações, ainda se constata pouco material que facilite a compreensão de como essas facilidades de explicação têm sido concebidas, desenvolvidas e usadas. Assim, o objetivo do presente trabalho é contribuir para reduzir a mencionada lacuna, provendo um arcabouço que organize o conhecimento no tema explicação em sistemas baseados em conhecimento que usam grafos de conhecimento, verificando como grafos de conhecimento são aplicados a esses sistemas, observando os propósitos de explicações (explanações), focalizando: como o grafo de conhecimento é incorporado a sistemas existentes, como explanações são geradas com a ajuda de GC, além de como serão apresentadas aos usuários e avaliadas. Para tanto, realizou-se uma revisão sistemática da literatura, motivada por algumas questões de pesquisa, visando identificar os estudos primários, seguindo um pré-definido protocolo formal de revisão. Neste estudo, considerou-se quatro bibliotecas (repositórios) digitais, com artigos publicados até janeiro de 2022, onde de 41 artigos recuperados, 19 artigos foram selecionados após avaliação de qualidade com base na aplicação de critérios de exclusão e inclusão. A partir deles foram destacadas as técnicas mais utilizadas que buscam resolver o problema da completude em GC, ou seja, inferir fatos desconhecidos baseados nos dados existentes no GC. Também foram destacados os tipos de incorporação dos grafos aos sistemas existentes. Ao avaliar as formas mais comuns de avaliação das explicações geradas, notou-se uma falta de material referente as gerações e avaliações das mesmas. Apesar dos artigos envolverem o tema explicações, é notado um foco maior na geração e avaliação das recomendações e deixam um pouco a desejar no quesito explicações.","With the advent of decision support systems that make use of artificial intelligence techniques, along the lines of knowledge-based systems, including recommendation systems, there has been an increase in the number of completely automatic decision-making tasks, that is, They are executed by software systems. In this regard, explanation facilities have become a required feature in some applications, such as applications in the field of medicine, among others. Some applications are also developed offering explanation facilities for recommended items. Because of this interest in explanations, investment in research and development of recommendation systems based on knowledge graphs has recently started, which have properties of enriching the details of the entities of a graph and extracting important relationships that can enrich such explanations. Despite the importance of these applications, there is still little material that facilitates the understanding of how these explanation facilities have been conceived, developed and used. Thus, the objective of the present work is to contribute to reduce the aforementioned gap, providing a framework that organizes knowledge on the topic of explanation in knowledge based systems that use knowledge graphs, verifying how knowledge graphs are applied to these systems, observing the purposes of explanations, focusing on: how the knowledge graph is embedded into existing systems, how explanations are generated with the help of KG, and how They will be presented to users and evaluated. Therefore, a systematic literature review was carried out, motivated by some research questions, aiming to identify the primary studies, following a pre-defined formal review protocol. In this study, four digital libraries (repositories) were considered, with articles published until January 2022, where from 41 articles retrieved, 19 articles were selected after quality assessment based on the application of exclusion and inclusion criteria. From them, the most used techniques that seek to solve the problem of completeness in KG were highlighted, that is, infer unknown facts based on existing data in the KG. The embedding of graphs into existing systems were also highlighted. When evaluating the most common forms of evaluation of the generated explanations, it was noticed a lack of material referring to the generations and evaluations of the same. Although the articles involve the topic of explanations, there is a greater focus on the generation and evaluation of recommendations and they leave a lot to be desired in terms of explanations.","('Grafos de conhecimento', 'Sistema de recomendação explicável', 'Sistemas de aconselhamento', 'Sistemas de recuperação da informação', 'Revisão sistemática da literatura', 'Knowledge graphs', 'Explainable recommendation system', 'Advice-giving systems', 'Information retrieval systems', 'Systematic review')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/9121","2022-03-04","https://www.repositorio.ufal.br/bitstream/123456789/9121/3/Explica%c3%a7%c3%a3o%20em%20sistema%20de%20apoio%20%c3%a0%20decis%c3%a3o%20baseado%20em%20grafos%20do%20conhecimento%3a%20uma%20revis%c3%a3o%20sistem%c3%a1tica.pdf","Explanation in decision support system based on knowledge graphs: a systematic review","('Robério José Rogério dos Santos',)"
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/12097","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Levantamento e avaliação de funções score para algoritmo minimax em batalhas Pokémon","('Lucas Albuquerque Lisboa',)","('Roberta Vilhena Vieira Lopes',)","('Evandro de Barros Costa', 'George Darmiton da Cunha Cavalcanti')","O mercado de games tem ganhado cada vez mais destaque no mundo, sendo Pokémon uma de suas principais franquias. Nesse sentido, a concepção de estratégias para tomada de decisão nos agentes de Inteligência Artificial é uma preocupação constante dos desenvolvedores. Assim, este trabalho visa avaliar funções score para o algoritmo Minimax aplicado a batalhas pokémon, com o intuito de verificar quais abordagens obtêm melhores resultados. Com o uso de ferramentas, como Pokemon Showdown e Poke-env, diversas simulações foram realizadas para testar o desempenho das propostas apresentadas na literatura. Ao final dos experimentos, apesar do baixo número de propostas, foi possível constatar que funções de evolução as quais tinham como base a diferença percentual dos Pontos de Vida entre jogadores obtiveram melhores resultados nos experimentos, bem como as que continham um sistema de pontuação para status e efeitos.","The gaming market has gained more and more prominence in the world, with Pokémon being one of its main franchises. This way, the design of strategies for decision making in Artificial Intelligence agents is a constant concern of developers. So, this work aims to evaluate score functions for the Minimax algorithm applied to pokémon battles, in order to verify which approaches obtain better results. Using tools such as Pokemon Showdown and Poke-env, several simulations were performed to test the performance of the proposals presented in the literature. At the end of the experiments, despite the low number of proposals, it was possible to verify that evolution functions which were based on the percentage difference of Life Points between players obtained better results in the experiments, as well as those that contained a scoring system for status and effects.","('Games', 'Pokémon (Jogo)', 'Inteligência artificial', 'Minimax', 'Game theory', 'Artificial intelligence', 'Decision making')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/12097","2022-05-26","https://www.repositorio.ufal.br/bitstream/123456789/12097/1/Levantamento%20e%20avalia%c3%a7%c3%a3o%20de%20fun%c3%a7%c3%b5es%20score%20para%20algoritmo%20minimax%20em%20batalhas%20Pok%c3%a9mon.pdf","Survey and evaluation of score functions for minimax algorithm in Pokemon battles",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/10336","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Uso de séries temporais para previsão de irradiação solar","('Gregory Albertt Santos Carvalho',)","('Ícaro Bezerra Queiroz de Araújo',)","('João Raphael Souza Martins', 'Winnie de Lima Torres')","O planejamento eficiente e o processo de tomada de decisão relacionados às usinas de energia solar fotovoltaicas exigem cada vez mais um conhecimento acurado da irradiância solar. A análise de séries temporais aplicada a dados climatológicos tem atraído um interesse especial nos últimos anos, visto que o clima interfere diretamente em muitas atividades econômicas. Este trabalho tem como objetivo desenvolver e analisar o uso de modelos de séries temporais SARIMA para previsão de irradiância solar a partir dos dados de uma estação meteorológica localizada em Maceió-AL. Com base nos dados de irradiância,foiaplicadoométododeprevisãoBox-Jenkinsparaidentificarummodelomatemático. Para a estimação dos parâmetros do modelo foi utilizado o método da máxima verossimilhança. Para seleção dos modelos mais adequados foram utilizadas métricas bem definidas, como o erro médio quadrático (MSE). Como consequência, foi possível realizar a previsão do dia seguinte à série temporal estudada e avaliá-la com métodos de análise de erros. Finalmente, neste trabalho foi possível descrever e implementar técnicas de predição nas séries temporais com dados coletados, possibilitando um estudo de caso real, onde foi possível concluir que os modelos construídos são satisfatórios para previsão do dia seguinte a partir das métricas e limites estabelecidos.","Efficientplanninganddecision-makingprocessesrelatedtophotovoltaicsolarpowerplants increasingly demand an accurate knowledge of solar irradiance. The analysis of time series applied to climatological data has attracted special interest in recent years, since the climate directly interferes in many economic activities. This work aims to develop and compare models of SARIMA time series to forecast solar irradiance, based on data from a meteorological station located in Maceió-AL. Based on the irradiance data, the Box-Jenkins forecast method was applied to identify a mathematical model. To estimate the model parameters, the maximum likelihood method was used. To select the most appropriate models, well-defined metrics were used,such as the mean square error (MSE). Hence,it was possible to make the forecast for the day ahead of the studied time series and evaluate it with error analysis methods. Finally, in this work it was possible to describe and implement prediction techniques in the time series with collected data, enabling a real case study, where it was possible to conclude that the models built are satisfactory for forecasting a day ahead from the established metrics and limits","('Séries temporais', 'Modelo SARIMA', 'Irradiância solar', 'Box-Jenkins')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/10336","2020-09-15","https://www.repositorio.ufal.br/bitstream/123456789/10336/1/Uso%20de%20s%c3%a9ries%20temporais%20para%20previs%c3%a3o%20de%20irradia%c3%a7%c3%a3o%20solar.pdf","",""
"Computação gráfica","https://www.repositorio.ufal.br/handle/riufal/1056","Campus A.C. Simões","Instituto de Matemática","Dissertação","Visualização de malhas com adaptação de resolução e textura dependente do observador","('José Fábio Boia Porto',)","('Adelailson Peixoto da Silva',)","('Perfilino Eugenio Ferreira Junior', 'Dimas Martínez Morera')","Este trabalho trata do problema de visualização de malhas triangulares de modo que a geometria e a textura das mesmas possam ser calculadas adaptativamente de acordo com a posição do orientador. Como apenas as informações necessárias de malha tendem a permanecer, as principais aplicações envolvidas estão relacionadas à visualização de malhas em tempo real, as quais têm sido de grande interesse de pesquisa em diversas áreas científicas. Na adaptação da geometria da malha, sua resolução vai sendo localmente alterada através de inserção/remoção de vértices, arestas e faces, de acordo com a posição do observador, de modo que o número de polígonos preserve uma forma visual suave e bem próxima da malha original. Na adaptação da textura, o mapeamento de textura associado `a malha vai sendo adaptado `as mudança as de sua resolução de modo a reduzir ou eliminar as distorções de textura resultantes do colapso de vértices, arestas e faces","This work has the goal of explore the triangulated mesh visualization problem in order that geometry and texture information could be computed adaptively according to the view position. As only the essential information from the mesh is going to persist, the main applications involved are linked with real-time mesh visualization which concerns a large number of scientific areas. To adapt the mesh geometry, its resolution is being locally changed through the insertion/removal of vertices, edges and faces, view-dependent considering the number of polygons to preserve smooth forms near to the original mesh. In the texture adaptation, the texture map association of the mesh is being adapted to the resolution changes minimizing or eliminating the texture distortion resulting from the collapse of vertices, edges and faces","('Malhas adaptativas', 'reconhecimento visual de textura', 'Visualização volumétrica', 'Processamento de dados -Tempo real', 'Computação gráfica', 'Mesh adaptative', 'Recognition of visual texture', 'Visualization volumetric', 'Data')","Matemática","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/1056","2009-05-29","https://www.repositorio.ufal.br/bitstream/riufal/1056/1/Dissertacao_Jose%20Fabio%20Boia%20Porto_2009.pdf","View-mesh with adaptative resolution and view-dependent texture map",""
"Computação gráfica","https://www.repositorio.ufal.br/handle/riufal/1032","Campus A.C. Simões","Instituto de Matemática","Dissertação","Visualização da curvatura de objetos implícitos em um sistema extensável.","('Allyson Ney Teodosio Cabral',)","('Vinicius Moreira Mello',)","('Adelailson Peixoto da Silva', 'Ralph Costa Teixeira')","Neste trabalho, estudaremos a visualização da curvatura de superfícies definidas implicitamente por funções do tipo f:[0,1]³ [0,1], usando a técnica de lançamento de raios (ray casting). Como em geral conhecemos apenas valores amostrados de f, estudaremos um método de interpolação tricúbica, a fim de calcular as derivadas de segunda ordem precisamente. A implementação computacional deste trabalho foi desenvolvida na forma de módulos do framework de visualização e processamento de imagens Voreen, o qual se beneficia do poder de processamento das placas gráficas atuais para acelerar o processo de visualização.","In this work we study the curvature visualization problem on surfaces implicitly defined by functions f: [0,1]³ &#8594; [0,1], using the ray casting technique. As we usually know only sampled values of f, we study the tricubic interpolation method to compute second order derivatives accurately. This work's implementation was designed as modules to the framework for volume rendering and image processing named Voreen, that uses the processing capability of graphics cards to improve the rendering tasks.","('Curvatura', 'Visualização volumétrica', 'Interpolação tricúbica', 'B-spline', 'GPU', 'GLSL', 'Objetos implícitos', 'Volume Rendering', 'Tricubic interpolation', 'B-spline', 'GPU', 'GLSL', 'Implicit objects')","Matemática","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/1032","2010-02-11","https://www.repositorio.ufal.br/bitstream/riufal/1032/1/Dissertacao_AllysonNeyTeodosioCabral_2010.pdf","Curvature visualization of implicit objects in a extensible system.",""
"Computação gráfica","https://www.repositorio.ufal.br/handle/riufal/1044","Campus A.C. Simões","Instituto de Matemática","Dissertação","Teoremas de comparação em variedades Käler e aplicações","('Adina Rocha dos Santos',)","('Hilário Alencar da Silva',)","('Zhou Detang', 'Márcio Henrique Batista da Silva')","Nesta dissertação, apresentamos as demonstrações dos teoremas de comparação do Laplaciano para variedades Kähler completas Mm de dimensão complexa m com curvatura bisseccional holomorfa limitada inferiormente por &#8722;1, 1 e 0. As variedades a serem comparadas são o espaço hiperbólico complexo CHm, o espaço projetivo complexo CPm e o espaço Euclidiano complexo Cm, cujas curvaturas bisseccionais holomorfas são &#8722;1, 1 e 0, respectivamente. Além disso, como aplicação dos teoremas de comparação do Laplaciano, descrevemos a prova do Teorema de Comparação de Bishop-Gromov para variedades Kähler; obtemos uma estimativa para o primeiro autovalor &#955;1(M) do Laplaciano, isto é, &#955;1(M) &#8804; m2 = &#955;1(CHm); e mostramos que o volume de variedades Kähler, com curvatura bisseccional limitada inferiormente por 1, é limitado pelo volume de CPm. Os resultados citados acima foram provados em 2005 por Li e Wang no artigo Comparison Theorem for Kähler Manifolds and Positivity of Spectrum , publicado no Journal of Differential Geometry.","In this work we present the proofs of the Laplacian comparison theorems for Kähler manifolds Mm of complex dimension m with holomorphic bisectional curvature bounded from below by &#8722;1, 1, and 0. The manifolds being compared are the complex hyperbolic space CHm, the complex projective space CPm, and the complex Euclidean space Cm, which holomorphic bisectional curvatures are &#8722;1, 1, and 0, respectively. Moreover, as applications of the Laplacian comparison theorems, we describe the proof of the Bishop-Gromov comparison theorem for Kähler manifolds and obtain an estimate for the first eigenvalue &#955;1(M) of the Laplacian operator, that is, &#955;1(M) &#8804; m2 = &#955;1(CHm), and show that the volume of Kähler manifolds with holomorphic bisectional curvature bounded from below by 1 is bounded by the volume of CPm. The results cited above have been proved in 2005 by Li and Wang, in an article Comparison theorem for Kähler Manifolds and Positivity of Spectrum , published in the Journal of Differential Geometry.","('Geometria de variedades', 'Variedade Käler', 'Curvatura bisseccional holomorfa', 'Espaço hiperbólico complexo', 'Espaço projetivo complexo', 'Laplaciano -Autovalor', 'Geometry of manifolds', 'Käler manifold', 'Holomorphic bisectional curvature', 'Complex hyperbolic space', 'Complex projective space', 'Laplacian -Eigenvalue')","Matemática","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/1044","2011-03-25","https://www.repositorio.ufal.br/bitstream/riufal/1044/1/Dissertacao_Adina%20Rocha%20dos%20Santos_2011.pdf","Laplacian comparison of theorems for Käler manifolds and applications",""
"Computação gráfica","https://www.repositorio.ufal.br/handle/riufal/1031","Campus A.C. Simões","Instituto de Matemática","Dissertação","O Teorema de H. Hopf e as Inequações de Cauchy-Riemann","('Maria de Andrade Costa',)","('Hilário Alencar da Silva',)","('Fernando Codá dos Santos Cavalcanti Marques', 'Manfredo Perdigão do Carmo')","Em 1951, H. Hopf publicou em um prestigiado artigo um famoso resultado: Seja M uma superfície compacta de gênero zero imersa no espaço Euclidiano de dimensão três com curvatura m´edia constante. Então M é isométrica à esfera redonda. Neste trabalho descreveremos detalhadamente do ponto de vista matemático uma generalização do resultado obtido por H. Hopf, a qual será publicada na revista Communication in Analysis and Geometry em 2007, cujos autores são Hilário Alencar, Manfredo Perdigão do Carmo e Renato Tribuzy. Neste artigo, os pesquisadores classificaram as superfícies compactas de gênero zero imersas na variedade produto: superfícies com curvatura Gaussiana constante cartesiano o espaço Euclidiano de dimensão um e cuja diferencial da curvatura média satisfaz uma certa desigualdade envolvendo uma forma quadrática. Além disso, estudaremos uma extensão da classificação anterior no caso em que as superfícies estão imersas numa variedade Riemanniana simplesmente conexa, homogênea com um grupo de isometrias de dimensão quatro. Tais resultados foram obtidos recentemente por Hilário Alencar, Isabel Fernandez, Manfredo Perdigão do Carmo e Renato Tribuzy. Nas demonstrações destes teoremas foram usadas técnicas de Análise Complexa, fatos de Topologia e uma generalização do Teorema de H. Hopf obtida por Abresch e Rosenberg, publicado em Acta Mathematica em 2004.","","('Curvatura média', 'Esfera', 'Forma quadrática', 'Função holomorfa', 'Inequações de Cauchy-Riemman', 'Supefície de gênero zero')","Matemática","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/1031","2006-12-04","https://www.repositorio.ufal.br/bitstream/riufal/1031/1/O%20Teorema%20de%20H.%20Hopf%20e%20as%20Inequa%c3%a7%c3%b5es%20de%20Cauchy-Riemann.pdf","A theorem of H. Hopf and the Cauchy-Riemann inequality",""
"Computação gráfica","https://www.repositorio.ufal.br/handle/riufal/1020","Campus A.C. Simões","Instituto de Matemática","Dissertação","Teorema de Decomposição de Cheeger-Gromoll.","('Marcius Petrúcio de Almeida Cavalcante',)","('Hilário Alencar da Silva',)","('Enaldo Silva Vergasta', 'Fernando Codá dos Santos Cavalcanti Marques')","Demonstramos o Teorema de Decomposição de Cheeger-Gromoll, o qual garante que uma variedade Riemanniana completa ndimensional, com curvatura de Ricci não-negativa, que possui uma linha, pode ser decomposta isometricamente num produto Riemanniano de uma variedade (n-1 )-dimensional com o conjunto dos reais.","We demonstrate the Splitting Theorem due to Cheeger and Gromoll, which ensures that a complete Riemannian n-manifold which has nonnegative Ricci curvature and a line, can be split isometrically into the Riemannian product of real with a (n-1 )-manifold.","('Isometria', 'Fórmula de Weitzenbocil', 'Laplaciano', 'Decomposição de Cheeger-Gromoll', 'Funções de Busemann', 'Isometry', 'Weitzenbock&#1497', 's Formula', 'Laplacian', 'Splitting theorem of Cheeger-Gromoll', 'Busemann functions')","Matemática","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/1020","2007-12-14","https://www.repositorio.ufal.br/bitstream/riufal/1020/1/Dissertacao_Marcius%20Petrucio%20de%20A%20Cavalcante_2007.pdf","Cheeger-Gromoll Splitting theorem.",""
"Computação gráfica","https://www.repositorio.ufal.br/handle/riufal/1022","Campus A.C. Simões","Instituto de Matemática","Dissertação","O Teorema de Comparação de Volume de Bishop-Gromov","('Erikson Alexandre Fonseca dos Santos',)","('Marcos Petrucio de Almeida Cavalcante',)","('Antonio Caminha Muniz Neto', 'Fernando Enrique Echaiz Espinoza')","Nesta Dissertação, usamos o teorema de comparação do Laplaciano para demonstrar o teorema de comparação de volume de Bishop-Gromov, o qual assegura que, se as curvaturas de Ricci de uma variedade Riemanniana completa são maiores ou iguais a (n��1)k, k uma constante real, então, para todo p 2 M e para todo R > 0, o volume de uma bola centrada em p e de raio R é menor ou igual que o volume de uma bola geodésica de raio R na forma espacial de curvatura seccional constante k. Ademais, a igualdade ocorre se toda curvatura seccional ao longo de geodésicas ligando p e x, para planos contendo o vetor radial for constante e igual a k.","In this dissertation, we use the Laplacian comparison theorem to prove the comparison of volume Bishop-Gromov s theorem, which assures that if the Ricci curvatures of a complete Riemannian manifold are larger than or equal to (n -1)k, the volume of a ball with center in p and radius R is smaller than or equal to the volume of a geodesic ball with radius R in the space form of sectional constant curvature k, for all p 2 M and R > 0, where k 2 R. Moreover, equality occurs if all sectional curvature throughout geodesics connecting p and x, for plans which contain the radial vector, is constant and equal to k.","('Volume de uma região aberta e conexa', 'Fórmula de Weitzenböck', 'Teorema de comparação do Laplaciano', 'Teorema de comparação de volume de Bishop-Gromov', 'Volume of an open and connected region', 'Weitzenböck s formula', 'Laplacian comparison theorem', 'Comparison of volume Bishop-Gromov s theorem')","Matemática","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/1022","2009-02-27","https://www.repositorio.ufal.br/bitstream/riufal/1022/1/O%20Teorema%20de%20Compara%c3%a7%c3%a3o%20de%20Volume%20de%20Bishop-Gromov.pdf","Bishop-Gromov s theorem of comparison of volume",""
"Computação gráfica","https://www.repositorio.ufal.br/handle/riufal/1026","Campus A.C. Simões","Instituto de Matemática","Dissertação","O teorema de Alexandrov","('Gregorio Manoel da Silva Neto',)","('Hilário Alencar da Silva',)","('Marcos Petrucio de Almeida Cavalcante', 'Abdênago Alves de Barros')","O objetivo desta dissertação é apresentar uma demonstração de R. Reilly para o Teorema de Alexandrov. O teorema estabelece que As únicas hipersuperfícies compactas, conexas, de curvatura média constante, mergulhadas no espaço Euclidiano são as esferas. O teorema de Alexandrov foi provado por A. D. Alexandrov no artigo Uniqueness Theorems for Surfaces in the Large V, publicado em 1958 pela Vestnik Leningrad University, volume 13, número 19, páginas 5 a 8. Em sua demonstração, Alexandrov usou o famoso Princípio de Tangência, introduzido por ele no citado artigo. No ano de 1962, M. Obata demonstrou em Certain Conditions for a Riemannian Manifold to be Isometric With a Sphere, publicado pelo Journal of Mathematical Society of Japan, volume 14, páginas 333 a 340, que uma variedade Riemanniana M, compacta, conexa e sem bordo, é isométrica a uma esfera, desde que a curvatura de Ricci de M satisfaça determinada limitação inferior. Este teorema resolve o problema de encontrar as variedades que atingem a igualdade na estimativa de Lichnerowicz para o primeiro autovalor. Em 1977, R. Reilly, no artigo Applications of the Hessian Operator in a Riemannian Manifold, publicado no Indianna University Mathematical Journal, volume 23, páginas 459 a 452, demonstrou uma generalização do Teorema de Obata para variedades compactas com bordo. Como exemplo da técnica desenvolvida nesta demonstração, ele apresenta uma nova demonstração do Teorema de Alexandrov. Esta demonstração, bem como as técnicas envolvidas, são o objeto de estudo deste trabalho.","The goal of this dissertation is to present a R. Reilly's demonstration of the theorem of Alexandrov . The theorem states that The only compact hypersurfaces, conected, of constant mean curvature, immersed in Euclidean space are spheres. The theorem of Alexandrov was proved by A. D. Alexandrov in the article Uniqueness Theorems for Surfaces in the Large V, published in 1958 by Vestnik Leningrad University, volume 13, number 19, pages 5 to 8. In his demonstration, Alexandrov used the famous Principle of tangency, introduced by him in that article. In the year 1962, M. Obata shown in Certain Conditions for a Riemannian Manifold to be isometric With the Sphere, published by the Journal of Mathematical Society of Japan, volume 14, pages 333 to 340, that a Riemannian Manifold M, compact, connected and without boundary, is isometric to a sphere, since the Ricci curvature of M satisfies certain lower bound. This theorem solves the problem of finding manifolds that reach equality in the estimate of Lichnerowicz for the first eigenvalue. In 1977, R. Reilly, in the article Applications of the Hessian operator in a Riemannian Manifold, published in Indianna University Mathematical Journal, volume 23, pages 459 to 452, showed a generalization of the Obata theorem for compact manifolds with boundary. As an example of the technique developed in this demonstration, he presents a new demonstration of the theorem of Alexandrov. This demonstration, as well as the techniques involved are the object of study of this work.","('Geometria diferencial', 'Laplaciano', 'Hipersuperfícies', 'Curvatura média', 'Curvatura de Ricci', 'Alexandrov, teorema de', 'Obata, teorema de', 'Variedade riemanniana compacta', 'Differential geometry', 'Laplacian', 'Hypersurfaces', 'Mean curvature', 'Ricci Curvature', 'Alexandrov, theorem of', 'Obata, theorem of', 'Compact riemannian manifolds')","Matemática","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/1026","2009-08-04","https://www.repositorio.ufal.br/bitstream/riufal/1026/1/Dissertacao_GregorioManoeldaSilvaNeto_2009.pdf","The theorem of Alexandrov.",""
"Computação gráfica","https://www.repositorio.ufal.br/handle/riufal/1048","Campus A.C. Simões","Instituto de Matemática","Dissertação","Superfícies de curvatura média constante um no espaço hiperbólico","('Márcio Silva Santos',)","('Feliciano Marcílio Aguiar Vitório',)","('Marcos Petrucio de Almeida Cavalcante', 'Heudson Tosta Mirandola')","O ponto crucial do trabalho é a obtenção de uma representação holomorfa para superfícies de curvatura média um no espaço hiperbólico. Esta representação possui uma grande semelhança com a representação de Weierstrass para superfícies mínimas em R3: A partir disso, obteremos uma gama de resultados acerca da teoria de superfícies de curvatura média um, completas e de curvatura total finita em H3.","In this work the crucial point is to obtain a holomorphic representation for mean curvature one surfaces in hyperbolic space. This representation has a great resemblance to the Weierstrass representation for minimal surfaces in R3: From this, we obtain a range of results about the theory of mean curvature one surfaces complete and finite total curvature in H3.","('Espaço hiperbólico', 'Representação de Weierstrass', 'Superfícies mínimas', 'Hyperbolic space', 'Weierstrass representation')","Matemática","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/1048","2011-02-28","https://www.repositorio.ufal.br/bitstream/riufal/1048/1/Dissertacao_Marcio%20Silva%20Santos_2011.pdf","Surfaces of Constant mean curvature one in hyperbolic space",""
"Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/830","Campus A.C. Simões","Instituto de Computação","Dissertação","THÊMIS: um sistema para análise forense de DNA utilizando Redes Baysianas","('José Tenório César Costa',)","('Eliana Silva de Almeida',)","('Luiz Antonio Ferreira da Silva', 'Maurício Marengoni')","Desde meados da década de 80, a tipagem do DNA (DNA fingerprinting) tem revolucionado a ciência forense, provendo uma poderosa ferramenta de investigação, sendo atualmente bastante utilizada em estudos de paternidade. Os laboratórios que trabalham com a análise forense de DNA realizam quantidades cada vez maiores de estudos desse tipo, incitando o uso de sistemas de software que auxiliem essa análise. Dentre as características essenciais para softwares dessa magnitude, está a confiabilidade, haja vista a minuciosidade do estudo. Dessa forma, é interessante o uso de métodos formais na execução de tais estudos. Neste trabalho, é construído um sistema de software, denominado THÊMIS, que utiliza o ferramental das Redes Bayesianas como meio de representação do conhecimento acerca de estudos de paternidade, obtendo por meio de inferências os resultados requeridos pela genética forense no que tange ao cálculo do índice de Paternidade (IP)","Since the mid 80, DNA fingerprinting has revolutionized forensic science, providing a powerful tool for research, currently being widely used in studies of paternity. Laboratories that work with forensic analysis of DNA carry increasing amounts of such studies and encourage the use of software systems that help with this type of analysis. One of the requirements for software of this magnitude is reliability, considering the level of detail of the study. Thus, it is interesting the use of formal methods. In this work, a software system called THÊMIS is built. THÊMIS uses Bayesian Networks as knowledge representation about studies of paternity, using inferences to obtain the results required by the forensic genetics regarding the calculation of the Index of Paternity (IP)","('Bioinformatice', 'Forensic genetic', 'Forensic DNA', 'Computational modeling', 'Bayesian Newtworks', 'Bioinformática', 'Genética forense', 'DNA forense', 'Modelagem computacional', 'Redes Baysianas')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/830","2009-04-13","https://www.repositorio.ufal.br/bitstream/riufal/830/1/TH%c3%8aMIS%3a%20um%20sistema%20para%20an%c3%a1lise%20forense%20de%20DNA%20utilizando%20Redes%20Baysianas.pdf","THÊMIS: a software for DNA forensic analysis using Bayesian Networks","('Alejandro César Frery Orgambide',)"
"Computação gráfica","https://www.repositorio.ufal.br/handle/riufal/1051","Campus A.C. Simões","Instituto de Matemática","Dissertação","Um sistema de calibração de câmera","('Clarissa Codá dos Santos Cavalcanti Marques',)","('Adelailson Peixoto da Silva',)","('Luiz Carlos Pacheco Rodrigues Velho', 'Thomas Maurice Lewiner')","Um processo de calibração de câmera consiste no problema de determinar as características geométricas digitais e ópticas da câmera a partir de um conjunto de dados iniciais. Este problema pode ser dividido em três etapas: aquisição de dados iniciais, o processo de calibração em si e otimização. Este trabalho propõe o desenvolvimento de uma ferramenta de calibração baseada em uma arquitetura genérica para qualquer processo de calibração. Para este propósito, o sistema apresentado neste trabalho permite a personalização de cada etapa da calibração. A inclusão de novos métodos de calibração é realizada de forma dinâmica, permitindo assim maior integração e flexibilidade entre os módulos do sistema.","A camera calibration procedure corresponds to determine the digital geometric and optical characteristics of the camera from a known initial data set. This problem can be divided into three steps: a) acquisition of initial data; b) calibration process itself; and c) optimization. This work presents the development of a calibration tool based on a generic architecture for any calibration approach. For this aim, the presented system allows the personalization of each calibration step. In the proposed tool new calibration procedures are introduced dynamically, allowing a better integration between the modules of the system.","('Calibração de câmera', 'Geometria projetiva', 'Fotografia 3D.', 'Camera calibration', 'Geometry projective', '3D Photography.')","Matemática da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/1051","2007-02-05","https://www.repositorio.ufal.br/bitstream/riufal/1051/1/Dissertacao_Clarissa_Da_capa_ate_cap6.pdf","A camera calibration system",""
"Computação gráfica","https://www.repositorio.ufal.br/handle/riufal/1047","Campus A.C. Simões","Instituto de Matemática","Dissertação","Simplificação de malhas triangulares baseada no diagrama de Voronoi intrínseco","('Douglas Cedrim Oliveira',)","('Dimas Martínez Morera',)","('Adelailson Peixoto da Silva', 'Thales Miranda de Almeida Vieira', 'Thomas Maurice Lewiner')","Nesta dissertação, estudaremos o processo de simplificaçãoo de malhas triangulares, caracterizando-o com suas particularidades. Discutiremos uma adaptação para superfícies triangulares do método de simplificação baseado em uma cobertura de Voronoi proposto por Peixoto [2002]. Além disso, utilizaremos o método Fast Marching como uma nova métrica e diferentes estratégias para seleção de vértices da malha simplificada, como a seleção por curvatura. A simplificação ocorre a partir de um diagrama de Voronoi intrínseco à malha. Discutiremos algumas condições necessárias para que a partir do dual desse diagrama, obtenha-se uma malha sem singularidades que seja equivalente a malha original.","In this dissertation, we study the triangular mesh simplification process, describing its main characteristics. We discuss an adaptation for triangular meshes of a mesh simplification process based on Voronoi coverage proposed by Peixoto [2002]. Moreover, we use Fast Marching Method as a distance function over the mesh and some different strategies for simplified mesh vertices selection, like curvature based selection. The simplification process is done by constructing an intrinsic Voronoi diagram over the original mesh. We discuss some necessary conditions to obtain a mesh, as Voronoi dual, without any singularities and topologically equivalent to the original mesh.","('Simplificação de malhas', 'Simplificação de malhas triangulares', 'Diagrama de Voronoi intrínseco', 'Subamostragem de malhas', 'Mesh simplification', 'Triangular mesh simplification', 'Intrinsic Voronoi diagram', 'Mesh coarsening', 'Mesh subampling')","Matemática","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/1047","2011-02-24","https://www.repositorio.ufal.br/bitstream/riufal/1047/1/Dissertacao_Douglas%20Cedrim%20Oliveira_2011.pdf","Triangular mesh simplification based on intrinsic Voronoi diagram",""
"Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/826","Campus A.C. Simões","Instituto de Computação","Dissertação","Sistema de recomendação hídrido para bibliotecas digitais que suportam o protocolo OAI PMH","('Hélio Martins do Nascimento Júnior',)","('Evandro de Barros Costa',)","('Henrique Pacca Loureiro Luna', 'Guilherme Ataíde Dias')","O crescimento acelerado das tecnologias Web tem beneficiado pesquisadores e acadêmicos, pois as publicações de pesquisa podem ser acessadas eletronicamente tão logo elas tenham sido finalizadas e publicadas. Nesse contexto, surgem as Bibliotecas Digitais como um sistema de informação complexo que possui uma série de atividades que integram coleções, serviços e pessoas em suporte ao completo ciclo de criação, disseminação, acesso e preservação de dados, informação e conhecimento. No entanto, devido a enorme quantidade de conteúdo presente na Web, em particular nas Bibliotecas Digitais, usuários acabam se deparando com uma diversidade muito grande de opções, o que leva ao fenômeno conhecido como sobrecarga de informação. Com o objetivo de contribuir para amenizar ou até mesmo eliminar essas dificuldades, sistemas de recomendação para Bibliotecas Digitais têm sido propostos e desenvolvidos. Este trabalho segue essa direção, investigando soluções alternativas para alcançar mais qualidade nas indicações geradas por um sistema de recomendação na sua tarefa de ajudar os seus usuários. Para isso estudou-se as abordagens tratadas na literatura especializada sobre tais sistemas, propondo-se em seguida, um sistema de recomendação personalizada de artigos científicos para Bibliotecas Digitais. Tal sistema seguiu uma abordagem híbrida, procurando tirar proveito das características interessantes identificadas nas técnicas de filtragem e recomendação baseadas em conteúdo e colaborativa. Nesse sentido desenvolveu-se um engenho de recomendação híbrido que se utiliza de tecnologias padrão para a descrição de conteúdo (Padrão Dublin Core), comunicação com Bibliotecas Digitais (Protocolo OAI-PMH) e perfil do pesquisador (Currículo Lattes). Finalmente, avaliou-se o sistema proposto sobre uma base de dados do CiteSeer contendo artigos no formato Dublin Core, tendo os resultados preliminares mostrado-se satisfatórios melhorando a precisão na recomendação e a cobertura quando comparado com sistemas que implementam abordagens baseada em conteúdo e colaborativa isoladamente","The growth of Web technologies has benefited researchers and the academic community by supporting the access of electronic publications as soon as they have been finished and published. In this context, Digital Libraries emerges as complex information systems which are essential for disseminating and preserving data, information and knowledge. However, due to the high amount of content available on the Web, specially in Digital Libraries, users face many correlated options, what result in the phenomenon known as information overload. Aiming to decrease or even eliminate these diffculties, recommender systems for Digital Libraries have been proposed and developed. This work presents a personalized recommender system which presents alternative ways to achieve better query results. For this, the main existing approaches of automatic recommendation have been studied in order to identify extension points and points to be improved. The proposed recommender system follows a hybrid approach which combines filtering techniques, content-based recommendation and collaborative recommendation. A hybrid recommendation engine has been proposed, which uses standard technologies for content description (Dublin Core), for communication with Digital Libraries (OAI-PMH Protocol ), as well as the user profile extracted from the curriculum vitae Lattes. The proposed solution has been evaluated in the context of the CiteSeer database, which contains papers and articles in the Dublin Core format. The preliminary results has showed an improvement in the quality of recommendation, thus presenting a better precision and coverage, when compared with existing approaches based either on content-based recommendation or on collaborative recommendation","('Information filtering', 'Digital Libraries -Recommendation systems', 'Metadata', 'Artificial Inteligence', 'Digital libraries -User profile', 'Computational modeling', 'Bibliotecas digitais -Perfil do usuário', 'Bibliotecas digitais -Sistemas de recomendação', 'Metadados', 'Filtragem de informação', 'Inteligência artificial', 'Modelagem computacional')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/826","2008-12-22","https://www.repositorio.ufal.br/bitstream/riufal/826/1/Sistema%20de%20recomenda%c3%a7%c3%a3o%20h%c3%ad%c2%addrido%20para%20bibliotecas%20digitais%20que%20suportam%20o%20protocolo%20OAI%20PMH.pdf","Hibrid recommender system for digital libraries what supporting the protocol OAI PMH",""
"Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/829","Campus A.C. Simões","Instituto de Computação","Dissertação","Um sistema evolutivo de apoio a tomada de decisão: um estudo de caso em compra eletrônica.","('Genildo Nascimento dos Santos',)","('Roberta Vilhena Vieira Lopes',)","('Luís Cláudius Coradine', 'Robson do Nascimento Fidalgo')","O desempenho da manipulação dos dados por um sistema de apoio à decisão, em um ambiente de comércio eletrônico, pode ser considerado um processo complexo devido à grande quantidade de informação proveniente do mecanismo de busca adotado para aquisição de equipamentos eletroeletrônicos. Este processo poderá aumentar exponencialmente no decorrer do tempo devido ao crescimento que influenciará no tempo de resposta da execução das tarefas do mecanismo de busca para o usuário. Este trabalho propõe uma abordagem híbrida utilizando banco de dados e algoritmo genético baseado em tipos abstratos de dados, denominado GAADT, para reduzir a dimensionalidade dos dados providos em uma base de conhecimento e auxiliar nas negociações da obtenção de produtos.","The performance of data manipulation through a search engine in e-commerce systems using decision support systems can be considered a complex process due to lots of information and may grow exponentially, according to research performed by the user for acquisition of equipment electronics. The import information collected by the system may influence the time to answer during the course of the search engine in accordance with the user s request. This works proposes a hybrid approach using database and genetic algorithm based on abstract data types (GAADT), to reduce the data of database dimensionality and helpful in the selection of products","('Case-Based reasoning Systems', 'Artificial Intelligence', 'Genetic Algorithm', 'Sistemas baseado em casos', 'Inteligência artificial', 'Algoritmo genético')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/829","2009-11-09","https://www.repositorio.ufal.br/bitstream/riufal/829/1/DissertacaoGenildoNascimentodosSantos_2009.pdf","An evolutionary systems of decision support systems: a case study in electronic purchase.","('Evandro de Barros Costa',)"
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/16877","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Visual servoing em ambientes virtuais com Unity 3D","('Bruno Lemos de Lima',)","('Glauber Rodrigues Leite',)","('Allan de Medeiros Martins', 'Andressa Martins Oliveira', 'Ícaro Bezerra Queiroz de Araújo')","A implementação de algoritmos de visual servoing enfrenta desafios como a escassez de robôs físicos para experimentação e a complexidade na integração de sistemas. Este trabalho apresenta o desenvolvimento de um simulador em ambiente virtual para visualização e controle de robôs, focando na validação de algoritmos de controle visual. A simulação é implementada na plataforma Unity 3D, integrada ao ROS 2 por meio do pacote ROS-TCP-Connector, permitindo a troca de dados via protocolo TCP/IP. O simulador coleta dados da câmera acoplada ao efetuador do robô, como imagens RGB e mapas de profundidade, além de informações sobre o estado das juntas, incluindo posições, velocidades e esforços. Ele também possibilita o controle individual das juntas, promovendo flexibilidade no desenvolvimento de algoritmos. Embora o foco seja o visual servoing, o simulador é versátil e pode ser aplicado em outras abordagens de controle. Adicionalmente, foi desenvolvido um pacote ROS 2 contendo um algoritmo de visual servoing para controle automatizado do robô na simulação. A proposta oferece um ambiente para validar algoritmos de visual servoing em cenários simulados, contribuindo para o desenvolvimento de soluções na área de controle visual.","The implementation of visual servoing algorithms faces challenges such as the scarcity of physical robots for experimentation and the complexity of system integration. This work presents the development of a simulator in a virtual environment for robot visualization and control, focusing on validating visual control algorithms. The simulation is implemented on the Unity 3D platform, integrated with ROS 2 through the ROS-TCP-Connector package, enabling data exchange via the TCP/IP protocol. The simulator collects data from the camera attached to the robot’s end-effector, such as RGB images and depth maps, as well as joint state information, including positions, velocities, and efforts. It also allows individual joint control, promoting flexibility in algorithm development. Although the focus is on visual servoing, the simulator is versatile and can be applied to other control approaches. Additionally, a ROS 2 package containing a visual servoing algorithm was developed for automated robot control within the simulation. The proposal provides an environment to validate visual servoing algorithms in simulated scenarios, contributing to the development of solutions in the field of visual control.","('Visual servoing', 'Robótica', 'Unity 3D (Recurso eletrônico)', 'ROS 2 -Comutação por pacotes (Transmissão de dados)', 'ROS-TCP-Connector -Comutação por pacotes (Transmissão de dados)', 'Robotic Simulation', 'Unity 3D')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/16877","2024-12-06","https://www.repositorio.ufal.br/bitstream/123456789/16877/1/Visual%20servoing%20em%20ambientes%20virtuais%20com%20Unity%203D.pdf","",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/12976","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Utilização de modelos estocásticos para o planejamento de estratégias de políticas de manutenção em infraestruturas de refrigeração e de potência em sistemas de data centers","('Leonardo Silva Costa',)","('Almir Pereira Guimarães',)","('Petrúcio Antônio Medeiros Barros', 'Rômulo Nunes de Oliveira')","Com a ascensão de serviços baseados em Internet, surge uma demanda de funcionamento ininterrupto de sistemas de Data center, que são recursos de missão crítica projetados para suportar serviços diários tais como: computação em nuvem, além do acesso às redes sociais, ao comércio eletrônico e ao armazenamento de informações, forçando a disponibilização destes sistemas 24 horas por dia, 7 dias por semana, sob pena de grandes prejuízos, o que exige um dimensionamento correto de suas infraestruturas de comunicação, potência e refrigeração. Dessa forma, além de técnicas de redundância de hardware aplicadas a seus componentes, é de grande importância a adoção de estratégias corretas para o desenvolvimento de políticas de manutenção que possam assegurar esse funcionamento ininterruptamente. Neste trabalho, são utilizados os mecanismos de modelagem SPN e RBD na construção de modelos para a análise do impacto de diferentes políticas de manutenção, baseados nos diferentes níveis de SLA, sobre a disponibilidade estacionária das infraestruturas de refrigeração e de potência, considerando arquiteturas com diferentes níveis de redundância. Um estudo de caso foi elaborado para a análise da disponibilidade estacionária resultante de diversos cenários, que consideram diferentes estratégias de manutenção a partir das infraestruturas/arquiteturas estudadas através da aplicação dos modelos propostos.","With the rise of Internet-based services, there is a demand for uninterrupted operation of Data center systems, which are mission-critical resources designed to support daily services such as: cloud computing, in addition to accessing social networks, to electronic commerce and information storage, forcing the availability of these systems 24 hours a day, 7 days a week, under penalty of great losses, which requires a correct dimensioning of its communication, power and cooling infrastructures. Thus, in addition to hardware redundancy techniques applied to its components, it is of great importance to adopt correct strategies for the development of maintenance policies that can ensure uninterrupted operation. In this work, the modeling mechanisms SPN and RBD are used in the construction of models for the analysis of the impact of different maintenance policies, based on different levels of SLA, on the stationary availability of cooling and power infrastructures, considering architectures with different levels of redundancy. A case study was elaborated for the analysis of the stationary availability resulting from different scenarios, which consider different maintenance strategies from the infrastructures/architectures studied through the application of the proposed models.","('Datacenter', 'Políticas de manutenção', 'Modelos estocásticos', 'Maintenance policies', 'Stochastic models')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/12976","2023-08-24","https://www.repositorio.ufal.br/bitstream/123456789/12976/1/Utiliza%c3%a7%c3%a3o%20de%20modelos%20estoc%c3%a1sticos%20para%20o%20planejamento%20de%20estrat%c3%a9gias%20de%20pol%c3%adticas%20de%20manuten%c3%a7%c3%a3o%20em%20infraestruturas%20de%20refrigera%c3%a7%c3%a3o%20e%20de%20pot%c3%aancia%20em%20sistemas%20de%20data%20centers.pdf","",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/16425","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Treinamento e avaliação de redes neurais convolucionais (CNNs) para a identificação de comportamento canino em imagens","('Guilherme de Oliveira Monteiro Peixoto',)","('Thales Miranda de Almeida Vieira',)","('Adriano Oliveira Barbosa', 'Xu Yang')","O reconhecimento automático de ações em imagens pode transformar profundamente o modo como interagimos e cuidamos dos pets. Quando aplicado ao monitoramento da saúde canina, essa tecnologia tem o potencial de detectar sinais precoces de doenças ou desconforto, permitindo intervenções rápidas e eficazes. Este trabalho tem como objetivo desenvolver e validar um modelo de Rede Neural Convolucional (CNN) capaz de classificar, a partir de uma única imagem, se um cão está se coçando ou não. A ação de coçar, quando realizada excessivamente, pode ser um sinal de alergias alimentares ou ambientais, pulgas, carrapatos ou outros parasitas, além de condições de pele como dermatite e infecções. O modelo CNN-DATAUG-RELU-L2-DROPOUT foi projetado com uma arquitetura que utiliza camadas convolucionais com funções de ativação ReLU, regularização L2 e dropout. O modelo foi treinado e avaliado com um conjunto de dados coletado por uma empresa multinacional da França, que foi posteriormente anotado ao longo deste trabalho, alcançando uma acurácia de 87,83%, precisão de 90,23% e cobertura de 89,31%. Esses resultados indicam um bom desempenho em condições controladas. Embora modelos de reconhecimento de ações frequentemente utilizem sequências de frames, este estudo demonstra que a análise de frames individuais pode ser uma abordagem simples e eficaz.","Automatic action recognition can profoundly transform the way we interact with and care for pets. When applied to monitoring canine health, this technology has the potential to detect early signs of disease or discomfort, allowing for quick and effective interventions. This work aims to develop and validate a Convolutional Neural Network (CNN) model capable of classifying, from a single image, whether a dog is scratching or not. The scratching action, when performed excessively, can be a sign of food or environmental allergies, fleas, ticks, or other parasites, as well as skin conditions such as dermatitis and infections. The CNN-DATAUG-RELU-L2-DROPOUT model was designed with an architecture that utilizes convolutional layers with ReLU activation functions, L2 regularization, and dropout. The model was trained and evaluated on a specific dataset, achieving an accuracy of 87.83%, a precision of 90.23%, and a cobertura of 89.31%. These results indicate good performance under controlled conditions. Although action recognition models often use sequences of frames, this study demonstrates that analyzing individual frames can be a simple and effective approach.","('Redes neurais convolucionais (Computação)', 'Classificação de ações em vídeos', 'Saúde animal -Monitoramento', 'Aprendizado do computador', 'Convolutional neural networks', 'Action classification in videos', 'Animal health -Monitoring', 'Deep learning')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/16425","2024-12-06","https://www.repositorio.ufal.br/bitstream/123456789/16425/1/Treinamento%20e%20avalia%c3%a7%c3%a3o%20de%20redes%20neurais%20convolucionais%20%28CNNs%29%20para%20a%20identifica%c3%a7%c3%a3o%20de%20comportamento%20canino%20em%20imagens.pdf","",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/13566","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","A transformer-based architecture neural network approach to email message autocomplete","('Mateus Fernando Felismino da Silva Patriota',)","('Tiago Figueiredo Santos Neto',)","('Bruno Georgevich Ferreira',)","Este estudo tem como propósito o desenvolvimento e exploração de uma arquitetura de rede neural fundamentada em transformers, com o intuito de aprimorar a tarefa do preenchimento de mensagens de e-mail. O presente trabalho detalha o abrangente processo de concepção, treinamento e avaliação da referida arquitetura, ao mesmo tempo em que investiga o impacto de diversos hiperparâmetros e camadas. O enfoque central está voltado para a criação de um modelo transformer capaz de capturar as complexas interdependências de longo alcance inerentes às comunicações por e-mail. Antes de proceder com o treinamento, uma extensa etapa de limpeza dos dados é realizada. Considerando as restrições de recursos de hardware, a citada arquitetura é submetida à uma fase inicial de treinamento em um extenso conjunto de textos da web de acesso público. Isso é seguido por uma meticulosa avaliação em um conjunto de testes independente. Posteriormente, efetua-se o processo de ajuste fino utilizando um conjunto de dados específico relacionado ao contexto de mensagens eletrônicas, compreendendo e detalhando os efeitos de diferentes hiperparâmetros no desempenho do modelo refinado. Métricas de desempenho são apresentadas tanto antes quanto depois desse procedimento, permitindo uma comparação direta do impacto do ajuste fino na qualidade das respostas geradas. Desta forma, proporciona-se uma compreensão da aplicabilidade dos modelos do tipo transformer no contexto do preenchimento automático de e-mails, sendo possível compreender limitações, identificar áreas de melhoria, definição de parâmetros e desenvolvimento de base sólida para a implementação à nível de código desse tipo de tecnologia em aplicações de comunicação por e-mail.","This research endeavors to develop and investigate an innovative neural network architecture based on transformers, aiming to enhance the automatic completion of email messages. The study outlines the comprehensive process of architecture creation, training, and evaluation, while exploring the impact of diverse hyperparameters and layers. The central focus lies in crafting a transformer model proficient in capturing intricate long-range dependencies inherent in email communications. Prior to training, an extensive data cleansing procedure is executed. Given hardware resource constraints, the architecture undergoes preliminary training on a substantial corpus of publicly available web texts, followed by rigorous evaluation on an independent test dataset. Subsequent fine-tuning is performed on individualized user email data, accompanied by a thorough analysis of hyperparameter effects on the performance of the fine-tuned model. This analysis encompasses a comparative assessment of performance metrics both before and after the fine-tuning process. Through these objectives, this study aspires to study the construction of the architecture mentioned in relation to the email autocompletion mechanisms, taking advantage of the resources of neural networks based on transformers. In this way, an understanding of the applicability of transformer models in the context of email message generation is provided, allowing for the identification of limitations, areas of improvement, parameter tuning, and the development of a solid foundation for the code-level implementation of this technology in email communication applications.","('Redes neurais', 'Processamento de linguagem natural', 'Mensagens eletrônicas – Preenchimento', 'Neural networks', 'Natural Language Processing', 'Electronic messages – Filling', 'Transformers')","Ciência da Computação","eng","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/13566","2023-11-10","https://www.repositorio.ufal.br/bitstream/123456789/13566/1/A%20transformer-based%20architecture%20neural%20network%20approach%20to%20email%20message%20autocomplete.pdf","Uma abordagem de rede neural de arquitetura baseada em transformador para preenchimento automático de mensagem de e-mail","('Baldoíno Fonseca dos Santos Neto',)"
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/13319","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Sistema inteligente baseado em conhecimento para acompanhamento de pré-diabéticos","('Jacques Wolbeck Saraiva de Melo Godoy Amorim',)","('Leandro Dias da Silva',)","('Baldoíno Fonseca dos Santos Neto', 'Álvaro Alvares de Carvalho César Sobrinho')","No cenário atual, nota-se que as doenças metabólicas ganharam mais visibilidade para os pesquisadores e estudiosos da área da saúde, principalmente por essa temática abordada comprometer o estilo de vida da humanidade. O Diabetes Mellitus tipo 2 é uma dessas doenças crônicas que com o passar dos anos tem se tornado mais presente na vida dos seres humanos. Apesar de não ter cura, é possível reduzir a progressão da doença mediante a adoção de cuidados preventivos de saúde em fases anteriores ao seu desenvolvimento pleno. Neste trabalho é proposto, através de um sistema inteligente, o auxílio de pessoas que estejam no quadro de desenvolvimento ou que já possuem pré-diabetes. O objetivo é fornecer um acompanhamento contínuo dos indicativos da doença para um diagnóstico rápido, visando a possibilidade de prever ou até reverter um quadro de pré-diabetes. No que difere de quando se atinge o estágio do Diabetes, propriamente dito, onde apenas o controle da doença se torna a solução para evitar possíveis complicações. Este sistema inteligente, por meio de um aplicativo móvel, pode beneficiar principalmente pessoas que possuam dificuldade de acesso a profissionais para acompanhar sua condição de saúde de forma contínua.","In the current scenario, it is noted that metabolic diseases have gained more visibility for researchers and scholars in the area of health, mainly because this topic compromises humanity’s lifestyle. Type 2 Diabetes Mellitus is one of those chronic diseases that over the years has become more present in the lives of human beings. Although there is no cure, it is possible to reduce the progression of the disease by adopting preventive health care in stages prior to its full development. This work proposes, through an intelligent system, the help of people who are in the development stage or who already have prediabetes. The objective is to provide continuous monitoring of disease indicators for a quick diagnosis, aiming at the possibility of predicting or even reversing pre-diabetes. This differs from when the Diabetes stage itself is reached, where only controlling the disease becomes the solution to avoid possible complications. This intelligent system, through a mobile application, can mainly benefit people who have difficulty accessing professionals to monitor their health condition on an ongoing basis.","('Diabetes mellitus', 'Estado pré-diabético', 'Sistemas inteligentes', 'Aplicativos móveis', 'Intelligent system', 'Mobile Application')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/13319","2023-10-18","https://www.repositorio.ufal.br/bitstream/123456789/13319/1/Sistema%20inteligente%20baseado%20em%20conhecimento%20para%20acompanhamento%20de%20pr%c3%a9-diab%c3%a9ticos.pdf","Knowledge-based intelligent system for monitoring pre-diabetics",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/16418","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Solução integrada de engenharia de dados para gestão e análise, utilizando uma abordagem open source e de baixo custo","('Aldemir Melo Rocha Filho',)","('Erick de Andrade Barboza',)","('Jairo Raphael Moreira Correia de Souza', 'Baldoíno Fonseca dos Santos Neto')","A crescente geração de dados, impulsionada pela transformação digital e pela disseminação de tecnologias como a Internet das Coisas, exige soluções inovadoras e acessíveis para a gestão eficiente das informações. A democratização do acesso à análise de dados, por meio da adoção de tecnologias open source e de baixo custo, permite que organizações de todos os portes e setores extraiam informações valiosas para otimizar processos, tomar decisões mais assertivas e impulsionar o crescimento dos negócios. Ao combinar a escalabilidade e flexibilidade das soluções open source com a acessibilidade e o custo reduzido, essa abordagem possibilita que um número maior de negócios aproveite o potencial dos seus dados, impulsionando a inovação e a competitividade. Este trabalho apresenta a implementação de um ambiente de gestão de dados baseado em ferramentas de código aberto, visando criar uma solução eficiente e de baixo custo para a construção de um lakehouse. O estudo aborda a crescente necessidade de gerenciar grandes volumes de dados, propondo um ecossistema acessível para organizações de diversos setores, integrando as funcionalidades de um Data Lake e um Data Warehouse para permitir a coleta, organização e análise de dados de forma estruturada. Durante o desenvolvimento, um dos desafios foi integrar as diversas ferramentas open source, garantindo compatibilidade e segurança no processo de gerenciamento de dados. A abordagem modular adotada facilitou a configuração e automação das etapas, assegurando a integridade dos dados e otimizando o desempenho geral do ambiente, consolidando-se como uma solução eficaz para o armazenamento e processamento de grandes volumes de dados. Os resultados demonstram a viabilidade técnica e econômica do ambiente, o qual foi aplicado ao Sistema Eletrônico de Informações (SEI) como estudo de caso em questão. O ambiente permitiu a criação de uma infraestrutura confiável para a organização, armazenamento e processamento eficiente de dados, oferecendo uma base otimizada para suportar análises detalhadas e melhorar a gestão de informações. A comparação com o Azure Synapse, uma solução amplamente utilizada no mercado para gerenciamento de dados, evidenciou não apenas a economia significativa, mas também a capacidade do ambiente open source de oferecer uma solução robusta sem exigir altos investimentos, tornando-se uma alternativa viável para instituições com recursos limitados.","The increasing generation of data, driven by digital transformation and the spread of technologies like the Internet of Things, demands innovative and accessible solutions for efficient information management. The democratization of data analysis through the adoption of open source and low-cost technologies enables organizations of all sizes and sectors to extract valuable insights to optimize processes, make more accurate decisions, and drive business growth. By combining the scalability and flexibility of open-source solutions with accessibility and reduced costs, this approach allows a greater number of businesses to harness the potential of their data, fostering innovation and competitiveness. This work presents the implementation of a data management environment based on open-source tools, aiming to create an efficient and low-cost solution for building a lakehouse. The study addresses the growing need to manage large volumes of data, proposing an accessible ecosystem for organizations in various sectors, integrating the functionalities of both a Data Lake and a Data Warehouse to enable the collection, organization, and analysis of data in a structured manner. During the development, one of the challenges was integrating the various open-source tools, ensuring compatibility and security in the data management process. The modular approach adopted facilitated the configuration and automation of the stages, ensuring data integrity and optimizing the overall performance of the environment, consolidating itself as an effective solution for storing and processing large volumes of data. The results demonstrate the technical and economic feasibility of the environment, which was applied to the Electronic Information System (SEI) as a case study. The environment enabled the creation of a reliable infrastructure for the organization, storage, and efficient processing of data, providing an optimized foundation to support detailed analyses and improve information management. The comparison with Azure Synapse, a widely used solution in the market for data management, highlighted not only significant cost savings but also the ability of the open-source environment to offer a robust solution without requiring large investments, making it a viable alternative for institutions with limited resources.","('Gestão de dados', 'Código aberto', 'Democratização da informação', 'Armazenamento de dados', 'Processamento de dados', 'Análise de dados', 'Data management', 'Open source', 'Democratization of information', 'Data storage', 'Data processing', 'Data analysis', 'Data Warehouse')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/16418","2024-11-25","https://www.repositorio.ufal.br/bitstream/123456789/16418/1/Solu%c3%a7%c3%a3o%20integrada%20de%20engenharia%20de%20dados%20para%20gest%c3%a3o%20e%20an%c3%a1lise%2c%20utilizando%20uma%20abordagem%20open%20source%20e%20de%20baixo%20custo.pdf","",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/16341","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Transcrição automática de acordes: análise espectral e classificação","('Gabriel Paulino Farias da Silva',)","('Thiago Damasceno Cordeiro',)","('Glauber Rodrigues Leite', 'Jobson de Araújo Nascimento')","A transcrição de acordes é uma técnica com alto grau de dificuldade, mesmo para alguns músicos experientes. Dito isso, este trabalho possui como objetivo a apresentação do método de transcrição automática de acordes, avaliando diferentes técnicas de análise espectral para a identificação dos componentes de frequência do sinal e por meio da utilização de algoritmos de programação dinâmica para classificação dos acordes. Como resultado, verificou-se que a transformada Q constante e o algorítmo Viterbi, mostraram-se eficientes para a identificação das composições de menor complexidade, compostas por acordes maiores e menores, trazendo resultados satisfatórios para músicas mais complexas que apresentem acordes dissonantes. Por fim, o modelo utilizado, mesmo sem a apresentação de 100% da taxa de acertos para as músicas compostas por acordes dissonantes, mostrou-se como uma ferramenta formidável para auxiliar na transcrição de acordes, tanto para músicas simples quanto para as mais complexas.","Chord transcription is a technique with a high degree of difficulty, even for some experienced musicians. That said, this work aims to present the method for automatic transcription of chords, evaluating different spectral analysis techniques for identifying the frequency components of the signal and through the use of dynamic programming algorithms to classify chords. As a result, it was found that the constant Q transform and the Viterbi algorithm proved to be efficient for identifying less complex compositions, composed of major and minor chords, bringing significant results for more complex songs that feature dissonant chords. Finally, the model used, even without presenting a 100% hit rate for songs composed of dissonant chords, proved to be a formidable tool to assist in the transcription of chords, both for simple and more complex songs.","('Engenharia de Computação', 'Processamento de sinais', 'Análise espectral', 'Música', 'Transcrição automática de acordes', 'Transformada de Fourier', 'Transformada Q constante', 'Computer Engineering', 'Signal processing', 'Spectral analysis', 'Music', 'Automatic chord transcription', 'Fourier Transform', 'Constant-Q Transform')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/16341","2023-10-20","https://www.repositorio.ufal.br/bitstream/123456789/16341/1/Transcri%c3%a7%c3%a3o%20autom%c3%a1tica%20de%20acordes%3a%20an%c3%a1lise%20espectral%20e%20classifica%c3%a7%c3%a3o.pdf","",""
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/17090","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Um sistema para ranqueamento e previsão de similaridade entre vagas de emprego e candidatos","('Hellena Almeida Canuto',)","('André Luiz Lins de Aquino',)","('Fabiane da Silva Queiroz', 'Keila Barbosa Costa dos Santos')","Este trabalho explora o uso de aprendizado de máquina em sistemas de recomendação aplicados ao recrutamento, destacando o potencial de Graph Attention Networks (GATs) para modelar relações entre candidatos, vagas e empresas. Um modelo baseado em GATs foi desenvolvido e avaliado em um conjunto de dados real, focando nas tarefas de ranqueamento e predição de similaridade. Os resultados demonstraram desempenho superior do modelo em métricas globais e significativa eficiência computacional, com tempos de execução reduzidos em até quatro vezes no maior subconjunto de dados. Contudo, limitações, como a ausência de informações temporais e a abordagem de amostragem negativa aleatória, indicam oportunidades de aprimoramento. Este estudo contribui para o avanço de sistemas de recomendação no contexto laboral, oferecendo bases para futuras pesquisas que incorporem dados temporais e métodos mais criteriosos de treinamento.","This study explores the use of machine learning in recommendation systems applied to recruitment, highlighting the potential of Graph Attention Networks (GATs) to model relationships between candidates, job openings, and companies. A GAT-based model was developed and evaluated on a real dataset, focusing on ranking and similarity prediction tasks. The results demonstrated superior performance in global metrics and significant computational efficiency, with execution times reduced by up to fourfold in the largest dataset subset. However, limitations such as the absence of temporal information and the use of random negative sampling indicate opportunities for improvement. This research contributes to the advancement of re commendation systems in the recruitment context, providing a foundation for future studies that incorporate temporal data and more refined training methods.","('aprendizado de máquina', 'redes neurais de grafos', 'sistemas de recomendação', 'recrutamento laboral', 'mecanismo de atenção', 'machine learning', 'graph neural networks', 'recommendation systems', 'job recruitment', 'Graph Attention Networks')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/17090","2025-01-23","https://www.repositorio.ufal.br/bitstream/123456789/17090/1/Um%20sistema%20para%20ranqueamento%20e%20previs%c3%a3o%20de%20similaridade%20entre%20vagas%20de%20%20emprego%20e%20candidatos.pdf","",""
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/13461","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Uso de meta-aprendizado para avaliar a tunagem para o algoritmo Máquina de vetores de suporte","('Jadson Crislan Santos Costa',)","('Bruno Almeida Pimentel',)","('Roberta Vilhena Vieira Lopes', 'Diego Carvalho do Nascimento')","Aprendizagem de máquina é um dos campos de estudo da área da Inteligência Artificial, onde faz uso de algoritmos que realizam classificação e agrupamento de dados com o objetivo de extrair conhecimento para resolver um determinado problema. Os algoritmos de Aprendizagem de Máquina utilizam hiperparâmetros para melhorar seu funcionamento, sendo esses hiperparâmetros ajustáveis para se adaptar ao problema. A busca por esses hiperparâmetros pode ser um tanto complexa, principalmente quando for aplicado em bases de dados complexas. O presente trabalho compreende em utilizar a técnica de meta-aprendizado para predizer se existe uma real vantagens de melhorar os hiperparâmetros para o algoritmo de Máquina de vetores de suporte utilizando os algoritmos de Busca Aleatória, Busca em Grade, Algoritmo Genético e Otimização por enxame de partículas. Para mensurar os desempenho dos algoritmos, foi adotados métricas de desempenho de f1-score e tempo de execução, e aplicado teste de hipôtese 5x2CV pareado para comparar os algoritmos e Mann-Whitney para comparar as distribuíções de tempo, e com isso, os resultados indicam que o uso do algoritmo de Busca Aleatória tem uma performance satisfatória em bases não complexas, por outro lado, em bases complexas os hiperparâmetros default tem uma melhor eficácia, e para os resultados da utilização dos meta-aprendizes, os resultados mostram que eles obtiveram melhor desempenho em relação ao algoritmo de Linha de Base e melhoram os resultados quando o meta-aprendiz foi tunado.","Machine learning is one of the fields of study in the area of Artificial Intelligence, which uses algorithms that perform classification and clustering of data to extract knowledge to solve a given problem. Machine Learning algorithms use hyper-parameters to improve their performance, and these hyper-parameters are adjustable to adapt to the problem. The search for these hyper-parameters can be quite complex, especially when applied to complex databases. This work uses the meta-learning technique to predict if there is a real advantage of improving the hyper-parameters for the Support Vector Machine algorithm using the Random Search, Grid Search, Genetic Algorithm, and Particle Swarm Optimization. The results indicate that Random Search algorithm has satisfactory results on non-complex bases, and on complex bases, the default hyper-parameters have better efficiency., and for the results of using meta-learning, the results show that they had the best relationship with the baseline and improve the results when the meta-learning was fine-tuned.","('Aprendizagem de máquina', 'Hiperparâmetros', 'Máquina de vetores de suporte', 'Inteligência artificial', 'Machine learning', 'Hyperparameters', 'Suport vector machine')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/13461","2022-07-28","https://www.repositorio.ufal.br/bitstream/123456789/13461/1/Uso%20de%20meta-aprendizado%20para%20avaliar%20a%20tunagem%20para%20o%20algoritmo%20M%c3%a1quina%20de%20vetores%20de%20suporte.pdf","",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/13655","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Sistema preditivo de reprovação de alunos do ensino básico","('Bruna Damaris Ramos dos Santos',)","('Marcelo Costa Oliveira',)","('Andressa Martins Oliveira', 'Rafael Sampaio de Melo Fragoso')","Este trabalho apresenta os resultados do desenvolvimento de um sistema de predição de reprovação de alunos do Ensino Básico utilizando as notas de avaliações das escolas do Serviço Social da Indústria de Alagoas. O desempenho educacional é um fator essencial nas áreas da educação, assim, é importante o desenvolvimento de um sistema que pode indicar se o aluno está em risco de reprovação. O trabalho visou desenvolver modelos preditivos para predizer a probabilidade de reprovação em uma disciplina em cada marco avaliativo do ano, apresentando resultados com rótulos indicando se os alunos estão previstos como aprovados ou reprovados com a probabilidade associada. A identificação de alunos em risco pode orientar intervenções pedagógicas para melhorar o desempenho e evitar reprovações. Para desenvolvimento do sistema, foram aplicados algoritmos classifi cadores, os quais foram o K-vizinhos mais próximos, a árvore de decisão, o Random Forest e o eXtreme Gradient Boosting. Esses foram avaliados em questão de seu desempenho e conforme o funcionamento em relação à solução explorada. Para a avaliação, foram ado tadas as métricas da acurácia e o F1-Score, além de ser aplicado o teste de Mann-Whitney nos resultados das métricas a fim de apontar se são estatisticamente significativos. Diante disso, o K-vizinhos mais próximos não apresentou diferenças significativas com a árvore de decisão, mas foi distinto do Random Forest e eXtreme Gradient Boosting. Estatistica mente, o Random Forest e eXtreme Gradient Boosting superaram os demais. Além disso, a média aritmética foi empregada para sintetizar os resultados dos modelos criados e disso, o Random Forest e o eXtreme Gradient Boosting apresentaram os melhores resultados de desempenho. Assim, a versão final do sistema preditivo utiliza o algoritmo classificatório eXtreme Gradient Boosting para gerar modelos e realizar predições a partir dos dados existentes, onde a escolha do eXtreme Gradient Boosting baseou-se em seu desempenho consistente, menor dispersão em relação às médias obtidas e eficiência computacional. Os resultados obtidos a partir da abordagem escolhida foram satisfatórios, com o desempenho dos modelos gerados pelo eXtreme Gradient Boosting apresentando cerca de 86% de acurácia e F1-Score.","This paper presents the results of developing a student failure prediction system in Basic Education using the evaluation grades from schools affiliated with the Social Service of Industry in Alagoas. Educational performance is a crucial factor in the field of education, making it important to develop a system that can indicate if a student is at risk of failing. The aim of the study was to develop predictive models to estimate the probability of failure in a subject at each evaluation point throughout the year, presenting results with labels indicating whether students are predicted to pass or fail, along with the associated probability. Identifying students at risk can guide pedagogical interventions to improve performance and prevent failures. For the system development, classification algorithms, including K-Nearest Neighbors, Decision Tree, Random Forest, and eXtreme Gradient Boosting, were applied. They were evaluated in terms of performance and functionality concerning the explored solution. Evaluation metrics included accuracy and F1-Score, and the Mann-Whitney test was applied to metric results to determine statistical signi ficance. In this regard, K-Nearest Neighbors showed no significant differences from the Decision Tree but differed from the Random Forest and eXtreme Gradient Boosting. Sta tistically, the Random Forest and eXtreme Gradient Boosting outperformed the others. Additionally, the arithmetic mean was used to synthesize model results, with the Random Forest and eXtreme Gradient Boosting showing the best performance. Consequently, the final version of the predictive system uses the eXtreme Gradient Boosting classification algorithm to generate models and make predictions based on existing data. The choice of eXtreme Gradient Boosting was based on its consistent performance, lower dispersion in relation to obtained averages, and computational efficiency. The results obtained from the chosen approach were satisfactory, with the performance of models generated by eXtreme Gradient Boosting showing approximately 86% accuracy and F1-Score.","('Aprendizagem de máquina', 'Mineração de dados -Educação', 'Predição de reprovação', 'Machine learning', 'Data mining -Education', 'Educational Data Mining', 'Failure prediction')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/13655","2023-12-06","https://www.repositorio.ufal.br/bitstream/123456789/13655/1/Sistema%20preditivo%20de%20reprova%c3%a7%c3%a3o%20de%20alunos%20do%20ensino%20b%c3%a1sico.pdf","",""
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/15029","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Segurança na transmissão de dados : uma abordagem utilizando criptografia e esteganografia de imagem","('Ayrton Oliveira Ouriques',)","('Almir Pereira Guimarães',)","('Ranilson Oscar Araújo Paiva', 'Alexandre Paes dos Santos')","Este trabalho aborda a questão da proteção de dados no contexto moderno, onde a transmissão segura de dados é cada vez mais necessária devido ao rápido aumento na geração e compartilhamento de dados. A necessidade de proteger esses dados de ameaças externas e internas é fundamental para o funcionamento de ambientes de transmissão de dados. Neste contexto, o estudo se concentra na transmissão segura de dados por meio da combinação de técnicas de criptografia e esteganografia. Ele é iniciado com uma revisão dos fundamentos teóricos dessas áreas, destacando conceitos importantes como protocolos de comunicação, algoritmos criptográfico e métodos de ocultação esteganográficos. Em seguida, apresento o desenvolvimento de uma ferramenta prática de esteganografia de imagem, detalhando sua arquitetura, funcionamento e algoritmos utilizados. Foram realizados testes rigorosos para avaliar o desempenho da ferramenta, considerando métricas como MSE, PSNR, SSIM e capacidade de carga em diferentes tamanhos de imagem. Os resultados obtidos forneceram dados valiosos sobre a eficácia da esteganografia da ferramenta na proteção da confidencialidade dos dados e na integridade de sua comunicação digital. Concluí destacando o que foi descoberto nos testes e propondo direções para futuras pesquisas e desenvolvimentos da ferramenta.","This paper addresses the issue of data protection in the modern context, where secure data trans mission is increasingly necessary due to the rapid increase in data generation and sharing. The need to protect this data from external and internal threats is fundamental to the functioning of data transmission environments. In this context, the study focuses on secure data transmission through the combination of encryption and steganography techniques. It begins with a review of the theoretical foundations of these areas, highlighting important concepts such as communi cation protocols, cryptographic algorithms, and steganographic hiding methods. Next, I present the development of a practical image steganography tool, detailing its architecture, operation, and algorithms used. Rigorous tests were conducted to evaluate the performance of the tool, considering metrics such as MSE, PSNR, SSIM, and payload capacity across different image si zes. The results obtained provided valuable data on the effectiveness of the tool’s steganography in protecting data confidentiality and the integrity of its digital communication. I conclude by highlighting what was discovered in the tests and proposing directions for future research and development of my tool.","('Criptografia', 'Esteganografia de imagem', 'Processamento de imagem', 'Segurança da informação', 'Transmissão de dados', 'Cryptography', 'Image Steganography', 'Image Processing', 'Information Security', 'Data Transmission')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/15029","2024-04-04","https://www.repositorio.ufal.br/bitstream/123456789/15029/1/Seguran%c3%a7a%20na%20transmiss%c3%a3o%20de%20dados%20%20uma%20abordagem%20utilizando%20criptografia%20e%20esteganografia%20de%20imagem.pdf","",""
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/15456","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Uso de Lakehouses para um ambiente analítico espacial Big Data","('Felipe Ferreira Vasconcelos',)","('Fábio José Coutinho da Silva',)","('André Magno Costa de Araújo', 'Cristina Dutra de Aguiar')","A transformação digital impulsionou o surgimento de novas formas de coletar e armazenar dados. Inicialmente, surgiram Data Warehouses e Data Lakes para lidar com análises complexas, altos custos de armazenamento e a necessidade de escalabilidade. No entanto, o crescimento dos dados Big Data revelou limitações nessas arquiteturas, culminando no desenvolvimento de soluções como os Data Lakehouses, que combinam características dos Data Lakes e dos Data Warehouses. Os Lake houses oferecem umaa bordagem unificada para lidar com a diversidade e o grande volume de dados, mantendo baixos custos, alto desempenho analítico, flexibilidade e escalabilidade. Este trabalho analisa as limitações das arquiteturas de armazenamento atuais, destacando o suporte oferecido para dados Big Data e dados geoespaciais. A partir disso, constrói-se um ambiente Lakehouse baseado em tecnologias como o Delta Lake, para explorar o armazenamento e a análise de dados. Apresenta-se um estudo de caso real, onde é implementado um ambiente Lakehouse para armazenar e analisar dados geoespaciais do transporte público em quatro cidades brasileiras. Este trabalho contribui para entender as tendências em arquiteturas de dados, especialmente em cenários de análise de dados espaciais Big Data, facilitando a aplicação prática desses conceitos.","Digital transformation has driven the emergence of new ways of collecting and storing data. Initially, Data Warehouses and Data Lakes emerged to deal with complex analyses,high storage costs and the need for scalability. However,the growth of Big Data revealed limitations in these architectures, culminating in the development of solutions such as Data Lakehouses, which combine characteristics of both Data Lakes and Data Warehouses. Lakehouses offer a unified approach for dealing with diversity and large volumes of data while maintaining low costs, high analytical performance, flexibility and scalability. This work analyzes the limitations of current storage architectures, high lighting the support offered for Big Data and geospatial data. From this, a Lakehouse environment is built based on technologies such as Delta Lake, to explore data storage and analysis. It’s presented a real case study, where a t he Lake house environment simplemented to store and analyze geospatial data from public transportin four Brazilian cities. This work contributes to understanding trends in data architectures, especially in Spatial Big Data Analytics scenarios, facilitating the practical application of these concepts.","('Big data', 'Banco de dados', 'Data Lakehouse', 'Armazenamento de dados', 'Cidades Inteligentes', 'Dados – Computação', 'Big Data', 'Database', 'Data Lakehouse')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/15456","2024-06-17","https://www.repositorio.ufal.br/bitstream/123456789/15456/1/Uso%20de%20Lakehouses%20para%20um%20ambiente%20anal%c3%adtico%20espacial%20Big%20Data.pdf","",""
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/14168","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Segmentação semântica de imagens dermatoscópicas de lesões de pele utilizando aprendizado profundo","('Guilherme Volney Mota Amaral',)","('Thiago Damasceno Cordeiro',)","('Álvaro Alvares de Carvalho César Sobrinho', 'Valmir Macario Filho')","O câncer de pele é uma doença caracterizada pela formação de células malignas a partir dos melanócitos, que são células que dão cor à pele. Apesar de ser o tipo mais recorrente entre todos, o câncer de pele é extremamente tratável nos estágios iniciais da doença. Na dermatoscopia, não há ferramenta que auxilie os médicos a fechar o diagnóstico precoce da doença. Assim, este trabalho propõe uma ferramenta que utilize técnicas de aprendizagem de máquina (segmentação semântica) para otimizar o trabalho dos dermatoscopistas. A validação da ferramenta apontou resultado médio de 0,0971 na perda dice para o conjunto de treino e 0,1724 para o conjunto de validação, permitindo uma análise mais precisa da evolução de lesões de pele conforme o tempo. Apesar da ferramenta apresentar uma boa precisão do ponto de vista das técnicas de aprendizagem de máquina, ainda serão necessários ajustes para atender as expectativas de uma aplicação na área da medicina.","Skin cancer is a disease characterized by the formation of malignant cells from the melanocytes, which are cells that give color to the skin. Despite being the most recurrent type of all, skin cancer is extremely treatable in the early stages of the disease. In dermoscopy, there is no tool to help physicians to make an early diagnosis of the disease. Thus, this work proposes a tool that uses machine learning techniques (semantic segmentation) to optimize the work of dermatoscopists. The validation of the tool showed an average result of 0.0971 in the loss dice for the training set and 0.1724 for the validation set, allowing a more accurate analysis of the evolution of skin lesions according to time. Although the tool has good accuracy from the point of view of machine learning techniques, adjustments will still be needed to meet the expectations of an application in the medical field.","('Câncer de pele', 'Dermatoscopia', 'Aprendizagem de máquina', 'Segmentação semântica', 'Skin cancer', 'Dermoscopy', 'Machine Learning', 'Semantic segmentation')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/14168","2023-06-05","https://www.repositorio.ufal.br/bitstream/123456789/14168/1/Segmenta%c3%a7%c3%a3o%20sem%c3%a2ntica%20de%20imagens%20dermatosc%c3%b3picas%20de%20les%c3%b5es%20de%20pele%20utilizando%20aprendizado%20profundo.pdf","","('Elvys Alves Soares',)"
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/11411","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Riscos em projetos: uma análise aplicada em um projeto de correção textual","('Leonardo Pedrosa Leite',)","('Thiago Damasceno Cordeiro',)","('Edson Koiti Kudo Yasojima',)","O gerenciamento de riscos é uma parte importante do gerenciamento de projetos e envolve a identificação, análise e gerenciamento de possíveis ameaças ou oportunidades que possam afetar o projeto. Sendo importante para minimizar o impacto de possíveis eventos adversos e maximizar o potencial de eventos positivos, a fim de garantir o sucesso do projeto. É importante realizar uma investigação detalhada dos dados que envolvem o projeto, para analisá-los à procura dos riscos e oportunidades e então estudá-los de uma forma que disponibilize informações essenciais sendo possível tomar as melhores decisões de gerenciamento de riscos. Aplicar esse gerenciamento em cima da Plataforma Adaptativa de Avaliação e Diagnóstico Pedagógico de Textos, fez perceber que o aproveitamento gerado pela gestão de risco em um projeto traz um grande benefício, podendo otimizar todo trabalho e até um lucro não previsto.","Risk management is an important part of project management and involves the identification, analysis, and management of potential threats or opportunities that may affect the project. It is important to minimize the impact of potential adverse events and maximize the potential of positive events in order to ensure the success of the project. It is important to conduct a detailed investigation of the data involving the project, to analyze it in search of risks and opportunities, and then study it in a way that provides essential information and allows for the best risk management decisions to be made. Applying this management to the Adaptive Platform for Pedagogical Assessment and Text Diagnosis revealed that the benefits generated by risk management in a project bring great benefits, optimizing all work and even an unplanned profit.","('Gerenciamento de riscos', 'Gerenciamento de projetos', 'Matriz de probabilidade e impacto', 'Project Management', 'Risk Management', 'Quantitative Analysis', 'Probability and Impact Matrix')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/11411","2022-12-23","https://www.repositorio.ufal.br/bitstream/123456789/11411/1/Riscos%20em%20projetos%20-%20uma%20an%c3%a1lise%20aplicada%20em%20um%20projeto%20de%20corre%c3%a7%c3%a3o%20textual.pdf","","('Rodrigo Lisbôa Pereira',)"
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/13899","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Reconhecimento de entidades características para classificação de nódulos pulmonares em laudos médicos","('Lucas Agra de Omena',)","('Marcelo Costa Oliveira',)","('Baldoíno Fonseca dos Santos Neto', 'Thales Miranda de Almeida Vieira')","O câncer de pulmão é o tipo de doença neoplástica maligna mais mortífera, ocasionando 1.8 milhão de vítimas em 2020, em número absoluto sendo superior a soma do segundo e terceiro colocados (câncer colorretal e de fígado). Estudos mostram que o diagnóstico precoce da doença é fundamental para aumentar as chances de sucesso do tratamento, feito majoritariamente pela detecção de nódulos pulmonares através de tomografias computadorizadas (TC) de tórax. Os resultados desses exames são tipicamente armazenados de forma não estruturada, em formato de texto livre, depois de passar por um processo que contribui para a sua corrupção, como erros gramaticais, erros de digitação, ou até mesmo falta de convenção dos termos clínicos. Essa falta de estruturação dos dados cria um obstáculo desnecessário para o diagnóstico da doença, ao ser necessário buscar nesses resultados a presença de nódulos com características malignas. Com o objetivo de identificar e extrair as informações relevantes para o diagnóstico, foi treinado um modelo utilizando técnicas de deep-learning para fazer o reconhecimento de entidades, permitindo a identificação, em laudos textuais de TCs de tórax, dessas entidades cor respondentes às características nodulares. O método de definição das entidades in-loco levou em consideração que as entidades identificadas pelo modelo possibilitassem a classificação nódular de acordo com a diretriz internacional Lung-Rads. Definiu-se então seis entidades com o propósito de identificar quantidade, tipo, tamanho, local e características gerais dos nódulos além da presença de enfisema pulmonar. Para o treinamento do modelo foi utilizado a ferramenta spaCy, usando como base uma arquitetura de modelo de linguagem pré-treinado BERT, em português brasileiro, em que foi obtido uma medida F1 de 91,89%, utilizando um conjunto de dados com 600 documentos, cedidos pelo hospital Unimed Maceió e anotados manualmente como descrito na metodologia.","Lung cancer is the deadliest type of malignant neoplastic disease, causing 1.8 million victims in 2020. In absolute numbers, it is higher than the second and third leading types combined (colo rectal and liver cancer). Studies show that early diagnosis is crucial to increase the chances of successful treatment, primarily achieved through the detection of lung nodules via lung compu terized tomography (CT) scans. As a typical practice, the results of these scans are data stored in an unstructured, free text format, after passing through a storing process that contributes to its corruption, such as grammatical errors, typos, or even lack of convention of clinical terms. This lack of data structure creates an unnecessary obstacle for the disease diagnosis, as it is necessary to search in these results for the presence of nodules with malignant characteristics. Aiming for identifying and extracting relevant data for the disease diagnosis, a deep-learning model was trained to perform a named entity recognition task, enabling the retrieval of entities related to the nodules aspects from textual lung CT scan reports. The entities were defined taking in con sideration the characteristics needed to enable the classification according to the international Lung-Rads guideline. Six entities were defined to identify the quantity, type, size, location, and general characteristics of the nodules, as well as the presence of pulmonary emphysema. The spaCy framework was used to train the model, employing a BERT pre-trained language model architecture in Brazilian Portuguese. The model achieved a F1 score of 91.89% using a dataset of 600 documents provided by Unimed Maceio Hospital, manually annotated as described in the methodology.","('Medicina', 'Lung RADs', 'Processamento de linguagem natural', 'Aprendizagem de máquina', 'Aprendizagem profunda', 'Prova pericial', 'Transformers', 'Representação de Codificador Bidirecional para Transformadores', 'SpaCy (Framework)', 'healthcare', 'lung rads', 'nlp', 'machine learning', 'deep learning', 'NER', 'medical reports', 'transformers', 'bert', 'spacy')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/13899","2023-10-17","https://www.repositorio.ufal.br/bitstream/123456789/13899/1/Reconhecimento%20de%20entidades%20caracter%c3%adsticas%20para%20classifica%c3%a7%c3%a3o%20de%20n%c3%b3dulos%20pulmonares%20em%20laudos%20m%c3%a9dicos.pdf","",""
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/11160","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Uma proposta de software para apoio logístico a oficiais de justiça no cumprimento de diligências","('Myron David Lucena Campos Peixoto',)","('Erick de Andrade Barboza',)","('Baldoíno Fonseca dos Santos Neto', 'João Lucas Marques Correia')","Oficiais de justiça são funcionários públicos que exercem funções de grande importância para o poder judiciário brasileiro. Sabendo disto, devido a alta demanda ocasionada por um grande número de processos judiciais que surgem todos os dias nas diversas comarcas espalhadas pelo Brasil, esses profissionais acabam sendo sobrecarregados. Neste caso a utilização da tecnologia da informação como forma de apoio acaba sendo um fator decisivo para que estes profissionais desempenhem seu trabalho de forma eficiente. No entanto, atualmente apesar do judiciário brasileiro adotar o processo judicial eletrônico como padrão, e fornecer uma ferramenta para controlede diligências,não hánenhum apoiocomputacional queajude osoficiais logisticamente nocumprimentodoseudever.Todoplanejamentodedeslocamentoaosendereçosdasdiligências é realizado pelo oficial de justiça, planejamento este que toma tempo que poderia ser utilizado para empenho de outras tarefas. Neste trabalho apresentamos uma proposta de software que automatiza este planejamento de rotas, fornecendo sugestões de forma a maximizar a eficiência do oficial de justiça.","Judicial officers are civil servants who perform functions of great importance for the brazilian judiciary. Knowing this, due to the high demand caused by a large number of lawsuits that arise every day in the various districts spread throughout Brazil, these professionals end up being overloaded. In this case, the use of information technology as a form of support ends up being a decisive factor for these professionals to perform their work efficiently. However, despite the brazilian judiciary currently adopting the electronic judicial process as a standard, andprovidingatooltocontrolthediligence,thereisnocomputingsupportthathelpstheofficers logisticallyintheperformanceoftheirduty.Alltheplanningofthedisplacementtotheaddresses of the proceedings is done by the bailiff, planning that takes time that could be used for other tasks. In this paper we present a software proposal that automates this route planning, providing suggestions in order to maximize the efficiency of the process server.","('Oficial de justiça', 'Diligência', 'Poder judiciário', 'Roteamento', 'Software', 'Judicial Officers', 'Judiciary', 'Routes', 'Routing', 'Software')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/11160","2022-12-20","https://www.repositorio.ufal.br/bitstream/123456789/11160/1/Uma%20proposta%20de%20software%20para%20apoio%20log%c3%adstico%20a%20oficiais%20de%20justi%c3%a7a%20no%20cumprimento%20de%20dilig%c3%aancias.pdf","",""
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/13045","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Uma metaheurística para tratar a parcimônia em árvores filogenéticas","('Larissa da Silva Santos',)","('Roberta Vilhena Vieira Lopes',)","('Almir Pereira Guimarães', 'Maria Cristina Tenório Cavalcante Escarpini')","Na sociedade, existem diversos produtos com recursos alterados geneticamente, desde alimentos até tratamentos médicos. Seja para remover ou adicionar características em uma dada espécie, os pesquisadores precisam conhecer os graus de parentescos entre as espécies em estudo. Para compreender as relações de parentescos entre espécies é necessário representá-las na árvore filogenética, de acordo com suas características. Para construir uma árvore filogenética, são utilizados métodos por similaridade e por distância, ambos contém problemas de desempenho ou resultados conflitantes. No método por distância, é utilizado o Princípio de Parcimônia, este afirma que a árvore ideal teria a menor quantidade de modificações. Os algoritmos de construção de árvore filogenética apresentam problemas na parcimônia quando existem mais de uma espécie com a menor distância, o que limita o espaço de busca dos descendentes ou ascendentes das próximas espécies. É sugerida então uma metaheurística para solucionar este impasse, após modificações, definiu-se que classificando as espécies de três tipos de parcimônias por quantidade de vezes selecionadas junto com verossimilhança ajudam o Algoritmo de Wagner a sair de máximo globais ruins, tendo como resultado árvore mais realística.","In society, there are several products with genetically altered resources, from food to medical treatments. Whether to remove or add features in a given species, researchers need to know the degrees of relatedness between the species under study. To understand the kinship relationships between species, it is necessary to represent them in the phylogenetic tree, according to their characteristics. To build a phylogenetic tree, similarity and distance methods are used, both of which have performance problems or conflicting results. In the method by distance, the Principle of Parsimony is used, it is stated that the ideal tree would have the least amount of modifications. The phylogenetic tree construction algorithms present parsimony problems when there are more than one species with the shortest distance, which limits the search space for descendants or ancestors of close species. A metaheuristic is then suggested to solve this impasse, after modifications, to define that classifying the species of three types of parsimony by number of times selected together with likelihood helps Wagner’s Algorithm to get out of maximum global ruins, resulting in a tree more realist.","('Parcimônia', 'Filogenia', 'Relações familiares', 'Metaheurística', 'Biotecnologia', 'Algoritmo de Wagner', 'Computação evolutiva', 'Parsimony', 'Phylogeny', 'Family Relationships', 'Metaheuristics', 'Biotechnology', 'Wagner’s algorithm', 'Evolutionary computation')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/13045","2023-06-30","https://www.repositorio.ufal.br/bitstream/123456789/13045/1/Uma%20metaheur%c3%adstica%20para%20tratar%20a%20parcim%c3%b4nia%20em%20%c3%a1rvores%20filogen%c3%a9ticas.pdf","",""
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/11407","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Uma meta-heurística híbrida para o problema de cobertura de discos ponderados","('Luan Gustavo Alves Viana',)","('Rian Gabriel Santos Pinheiro',)","('Bruno Costa e Silva Nogueira', 'Bruno José da Silva Barros')","","","('Meta-heurística', 'Cobertura (Redes de computadores)', 'Discos ponderados', 'CMSA')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/11407","2022-07-28","https://www.repositorio.ufal.br/bitstream/123456789/11407/1/Uma%20meta-heur%c3%adstica%20h%c3%adbrida%20para%20o%20problema%20de%20cobertura%20de%20discos%20ponderados.pdf","",""
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/17126","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Qualidade de dados geoespaciais: uma análise de ferramentas sob a perspectiva da ISO 19157-1:2023","('José Rui Roque da Silva Fernandes',)","('Fábio José Coutinho da Silva',)","('Baldoíno Fonseca dos Santos Neto', 'João Paulo Clarindo dos Santos')","Ferramentas de qualidade de dados (FQDs) cumprem um papel importante para garantir confiabilidade aos procedimentos analíticos. No entanto, para lidar com dados geoespaciais, são necessários tratamentos e funcionalidades específicas. Padrões internacionais, como a ISO 19157-1:2023, estabelecem princípios e métricas para a avaliação de qualidade de dados geoespaciais. Este trabalho tem como objetivo realizar uma análise de FQDs, verificando a conformidade dessas ferramentas com os principais requisitos para a obtenção de métricas de qualidade de dados geoespaciais. Inicialmente, foi desenvolvida uma metodologia para o processo de busca, que retornou 34 FQDs. A partir de critérios de seleção, a busca foi refinada para um total de 15 FQDs, as quais foram analisadas quanto à conformidade aos requisitos identificados. Além disso, apresenta-se uma proposta de arquitetura para tratar os problemas identificados nestas FQDs.","Data quality tools (DQTs) play a crucial role in ensuring the reliability of analytical processes. However, specific treatments and functionalities are required when dealing with geospatial data. International standards, such as ISO 19157-1:2023, establish principles and metrics for assessing the quality of geospatial data. This work aims to perform an analysis of DQTs, verifying their compliance with the main requirements for obtaining geospatial data quality metrics. Initially, a methodology was developed for the search process, which returned 34 DQTs. Based on selection criteria, the search was refined to a total of 15 DQTs, which were analyzed for compliance with the identified requirements. In addition, an architecture proposal is presented to address the problems identified in these DQTs.","('Ferramentas de qualidade -ISO 19157', 'Qualidade de dados geoespaciais', 'Bases de dados abertas', 'Usabilidade', 'Padrões internacionais', 'Data quality', 'Geospatial data', 'ISO 19157', 'Quality tools', 'Comparative analysis', 'Open databases', 'Usability', 'Tool performance', 'Geospatial data standards')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/17126","2024-10-29","https://www.repositorio.ufal.br/bitstream/123456789/17126/1/Qualidade%20de%20dados%20geoespaciais_uma%20an%c3%a1lise%20de%20ferramentas%20sob%20a%20perspectiva%20da%20ISO%2019157-1_2023.pdf","",""
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/12933","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Previsão de empregos na construção civil em Alagoas utilizando séries temporais","('Lucas Ribeiro Raggi',)","('Thiago Damasceno Cordeiro',)","('Erick de Andrade Barboza', 'Marcelo Costa Oliveira')","A indústria da construção civil tem um papel fundamental na economia brasileira, contribuindo significativamente para o desenvolvimento socioeconômico e a empregabilidade. No estado de Alagoas, onde o setor é uma das principais forças econômicas, a empregabilidade vem sendo afetada por uma serie de fatores, incluindo mudanças na política econômica, crises financeiras e a pandemia de COVID-19. Este estudo propõe a previsão do saldo empregos na construção civil em Alagoas utilizando técnicas de previsão de séries temporais, a fim de ajudar instituições de formação técnica e profissional a alinharem seus programas de capacitação às demandas do setor e os formuladores de políticas no desenvolvimento de estratégias de emprego e educação mais eficazes. Os dados de emprego no setor foram obtidos a partir das bases RAIS e CAGED, ferramentas governamentais que coletam informações sobre admissões, demissões e empregos formais no Brasil. Diversos modelos de previsão, incluindo Suavização Exponencial Holt Winters, ARIMA, SARIMA, TBATS e Prophet, foram aplicados e comparados, com otimização de hiperparâmetros e validação cruzada realizadas para melhorar a precisão das previsões e avaliar o desempenho dos modelos. Os resultados destacam a Suavização Exponencial Holt Winters como a abordagem mais eficaz, alcançando um erro RMSE de 825.26, uma redução de 43.5% em relação ao método Prophet, amplamente utilizado na indústria. sugerindo que essa técnica clássica continua sendo uma ferramenta robusta e eficaz para prever a demanda de empregos no setor da construção civil. O estudo reconhece as limitações inerentes à abordagem univariada, que não leva em consideração variáveis exógenas, e sugere que pesquisas futuras explorem técnicas de modelagem que considerem tais variáveis. Em suma, esta pesquisa fornece um método confiável e eficaz para prever a demanda de empregos na construção civil, oferecendo orientações relevantes para empresas de construção, instituições de formação técnica e profissional, e formuladores de políticas.","The construction industry plays a crucial role in the Brazilian economy, significantly contributing to socioeconomic development and employability. In the state of Alagoas, where the sector is one of the main economic forces, employability has been affected by a series of factors, including changes in economic policy, financial crises, and the COVID-19 pandemic. This study proposes forecasting the balance of jobs in the construction industry in Alagoas using time series forecasting techniques, aiming to assist technical and professional training institutions in aligning their training programs with the sector’s demands and policymakers in developing more effective employment and education strategies. Employment data in the sector were obtained from the RAIS and CAGED databases, government tools that collect information about admissions, layoffs, and formal jobs in Brazil. Various forecasting models, including Holt Winters Exponential Smoothing, ARIMA, SARIMA, TBATS, and Prophet, were applied and compared, with hyperparameter optimization and crossvalidation performed to improve forecast accuracy and evaluate model performance. The results highlight Holt Winters Exponential Smoothing as the most effective approach, achieving an RMSE error of 825.26, a reduction of 43.5% compared to the widely used Prophet method, suggesting that this classic technique remains a robust and effective tool for predicting job demand in the construction sector. The study acknowledges the inherent limitations of the univariate approach, which does not take into account exogenous variables, and suggests that future research explore modeling techniques that consider such variables. In summary, this research provides a reliable and effective method for predicting job demand in the construction industry, offering relevant guidance for construction companies, technical and professional training institutions, and policymakers.","('Indústria de construção civil', 'Emprego – Construção civil – Alagoas', 'Previsão de séries temporais', 'Construction industry', 'Employment – Civil construction – Alagoas', 'Time series forecasting')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/12933","2023-07-18","https://www.repositorio.ufal.br/bitstream/123456789/12933/1/Previs%c3%a3o%20de%20empregos%20na%20constru%c3%a7%c3%a3o%20civil%20em%20Alagoas%20utilizando%20s%c3%a9ries%20temporais.pdf","","('Baldoíno Fonseca dos Santos Neto',)"
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/11408","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Replicando abordagem para geração automática de tratadores de exceção","('Eric dos Santos Coelho',)","('Baldoíno Fonseca dos Santos Neto',)","('Ícaro Bezerra Queiroz de Araújo', 'Rodrigo dos Santos Líma')","Neste trabalho, replicamos uma abordagem baseada em aprendizado profundo para tratamento automatizado de exceções, mas não conseguimos obter o mesmo desempenho relatado originalmente. O modelo foi implementado utilizando o código-fonte e o conjunto de dados disponibilizados pelo autor do trabalho original. Para realizar a abordagem foi utilizado o ambiente Google Colab, que fornece um runtime para executar scripts na linguagem Python. Utilizando a configuração da versão gratuita obtivemos uma redução de 0,56% na acurácia e de 0,12% no F1 -score, derivados de um aumento de 1,98% na sensibilidade e uma perda de 2,59% na precisão do modelo localizador de blocos try. Entretanto, o modelo gerador de blocos catch apresentou um ganho de 0,1% na acurácia e de 0,2% no BLEU score. Por fim, concluímos que as causas prováveis de tais divergências foram a configuração dos hiperparâmetros do modelo e as diferenças entre os ambientes utilizados.","In this work, we replicated an approach based on deep learning for automated exception handling, but we were unable to obtain the same performance originally reported. The model was implemented using the source code and data set provided by the author of the original work. To carry out the approach, the Google Colab environment was used, which provides a runtime to execute scripts in the Python language. Using the configuration of the free version, we obtained a reduction of 0.56% in accuracy and 0.12% in the F1 -score, resulting from an increase of 1.98% in sensitivity and a loss of 2.59% in model precision try block locator. However, the catch block generator model showed a gain of 0.1% in Accuracy and 0.2% in the BLEU score. Finally, we conclude that the probable causes of such divergences were the configuration of the model’s hyperparameters and the differences between the environments used.","('Tratamento de exceções (Computação)', 'Deep learning (Aprendizado do computador)', 'Engenharia de software', 'Reproducibility', 'Exception handling', 'Deep Learning', 'Machine Learning', 'Software engineering')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/11408","2023-01-19","https://www.repositorio.ufal.br/bitstream/123456789/11408/1/Replicando%20abordagem%20para%20gera%c3%a7%c3%a3o%20autom%c3%a1tica%20de%20tratadores%20de%20exce%c3%a7%c3%a3o.pdf","","('Jairo Raphael Moreira Correia de Souza',)"
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/17122","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Microscopy image analysis using deep metric learning: a study on the detection and classification of leishmania amastigotes and other parasites","('Carllos Eduardo Ferreira Lopes',)","('Fabiane da Silva Queiroz',)","('Raquel da Silva Cabral', 'Rodolfo Carneiro Cavalcante')","A Leishmaniose Visceral, uma forma grave da doença causada pelo parasita Leishmania donovani, é fatal em mais de 95% dos casos não tratados e afeta principalmente pessoas de baixa renda com acesso limitado a cuidados de saúde. O diagnóstico padrão envolve a identificação de amastigotas do parasita, que são pequenas e difíceis de encontrar, tornando o exame uma tarefa desafiadora que requer habilidade. Para ajudar os profissionais de saúde, este estudo propõe uma nova abordagem que combina aprendizagem métrica profunda com classificação supervisionada para a detecção rápida da leishmaniose visceral. A metodologia divide as imagens em pequenos fragmentos (patches) para melhorar a avaliação de quatro funções de perda, que ajudam uma Máquina de Vetores de Suporte (SVM) a diagnosticar a doença. Os resultados mostraram que a função Circle teve o melhor desempenho, com 98,3% de sensibilidade e 99,3% de especificidade. Além da leishmaniose, exploramos o desempenho em outras infecções parasitárias, como Babesia, Toxoplasma, Trypanosoma, Plasmodium e Schistosoma, que também apresentaram resultados impressionantes, com alta precisão e sensibilidade. Essa abordagem sugere que a inteligência artificial pode ser uma ferramenta valiosa para melhorar o diagnóstico de doenças tropicais negligenciadas, tornando-o mais acessível e eficiente.","Visceral Leishmaniasis, a severe form of the disease caused by the parasite Leishmania donovani, is fatal in over 95% of untreated cases and primarily affects low-income individuals with limited access to healthcare. The standard diagnosis involves identifying the parasite’s amastigotes, which are small and difficult to find, making the examination a challenging task that requires skill. To assist healthcare professionals, this study proposes a new approach that combines deep metric learning with supervised classification for the rapid detection of visceral leishmaniasis. The methodology divides images into small fragments (patches) to enhance the evaluation of four loss functions, which help a Support Vector Machine (SVM) diagnose the disease. The results showed that the Circle loss function performed best, with 98.3% sensitivity and 99.3% specificity. In addition to leishmaniasis, we explored the performance on other parasitic infections, such as Babesia, Toxoplasma, Trypanosoma, Plasmodium, and Schistosoma, which also demonstrated impressive results, with high precision and sensitivity. This approach suggests that artificial intelligence can be a valuable tool for improving the diagnosis of neglected tropical diseases, making it more accessible and efficient.","('Deteção de parasitas', 'Leishmaniose visceral', 'Aprendizagem profunda', 'Aprendizagem de métrica profunda', 'Redes neurais convolucionais', 'Parasite Detection', 'Visceral Leishmaniasis', 'Deep Metric Learning', 'Deep Learning', 'Convolutional Neural Networks', 'Binary Classification', 'Automated Disease Diagnosis', 'Multiclass Classification', 'Babesia', 'Toxoplasma', 'Trypanosoma', 'Plasmodium and Schistosoma')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/17122","2024-12-07","https://www.repositorio.ufal.br/bitstream/123456789/17122/1/Microscopy%20image%20analysis%20using%20deep%20metric%20learning_a%20study%20on%20the%20detection%20and%20classification%20of%20leishmania%20amastigotes%20and%20other%20parasites.pdf","",""
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/17408","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Meta-Aprendizagem para seleção de técnicas de redução de dimensionalidade em problemas de Big Data","('Daniel José da Silva',)","('Bruno Almeida Pimentel',)","('Ícaro Bezerra Queiroz de Araújo', 'Glauber Rodrigues Leite')","Universidades e indústrias produzem uma enorme quantidade de dados, muitas vezes caracterizados por alta dimensionalidade, o que pode afetar negativamente o desempenho de algoritmos de Aprendizagem de Máquina. A redução de dimensionalidade se torna uma solução fundamental para simplificar esses dados sem perder informações importantes, permitindo uma análise mais eficiente. No entanto, a escolha manual do algoritmo de redução de dimensionalidade mais adequado para cada conjunto de dados é um processo complexo e demorado. Com o objetivo de automatizar essa seleção, este trabalho propõe o desenvolvimento de um meta-aprendiz que possa prever qual algoritmo de redução de dimensionalidade será mais eficiente para um determinado conjunto de dados. Este trabalho aborda a seleção automatizada de algoritmos de redução de dimensionalidade em cenários de Big Data, utilizando meta-aprendizagem para aprender padrões entre os conjuntos de dados e os algoritmos que produzem os melhores resultados. A proposta é testar diferentes técnicas de redução de dimensionalidade e, por meio da construção de rankings comparativos, verificar se o modelo de recomendação de algoritmos consegue prever corretamente o algoritmo mais adequado.","Universities and industries generate vast amounts of data, often characterized by high dimensionality, which can negatively impact the performance of Machine Learning algorithms. Dimensionality reduction becomes a crucial solution to simplify these data without losing important information, allowing for more efficient analysis. However, manually selecting the most sui table dimensionality reduction algorithm for each dataset is a complex and time-consuming process. To automate this selection, this study proposes the development of a meta-learner capable of predicting which dimensionality reduction algorithm will be most efficient for a given dataset. This work focuses on the automated selection of dimensionality reduction algorithms in Big Data scenarios, utilizing meta-learning to identify patterns between datasets and the algorithms that yield the best results. The approach involves testing different dimensionality reduction techniques and, through the construction of comparative rankings, verifying whether the algorithm recommendation model can accurately predict the most suitable algorithm.","('Aprendizagem de máquina', 'Meta aprendizagem', 'Algoritmos', 'Inteligência artificial', 'Big data', 'Meta-learning', 'Algorithms', 'Data', 'Reduction', 'Machine Learning')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/17408","2024-11-28","https://www.repositorio.ufal.br/bitstream/123456789/17408/1/Meta-Aprendizagem%20para%20sele%c3%a7%c3%a3o%20de%20t%c3%a9cnicas%20de%20redu%c3%a7%c3%a3o%20de%20dimensionalidade%20%20em%20problemas%20de%20Big%20Data.pdf","",""
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/12903","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Melhorando o desempenho na classificação de imagens médicas: uma análise comparativa de técnicas de aumento de dados","('Phyllipe Matheus Bezerra Alves',)","('Marcelo Costa Oliveira',)","('Baldoíno Fonseca dos Santos Neto', 'Lucas Lins de Lima')","Os métodos de classificação e segmentação de imagens médicas baseados em redes neurais convolucionais (CNNs) possuem o estado da arte quando se trata de acurácia. No entanto, a escassez de dados médicos rotulados disponíveis para o treinamento supervisionado das CNNs pode comprometer sua performance. Para contornar essa limitação, os métodos de aumento de dados têm sido empregados com sucesso. Esses métodos consistem na aplicação de transformações nos dados de entrada, como rotação, translação, escala e espelhamento, a fim de gerar novas imagens sintéticas que possam enriquecer o conjunto de treinamento. Além disso, podem ser aplicadas a diferentes tipos de dados, incluindo aplicações com o uso de diferentes tipos de imagens médicas. O objetivo desse trabalho é analisar a eficácia de quatro métodos automáticos de aumento de dados: Método base, AugMix, RandAugment e TrivialAugment. Propõe-se assim, a análise da eficácia de um modelo de CNN na categorização de imagens de raio-x de pneumonia por COVID-19, em que o conjunto de dados está categorizado em quatro diferentes classes e será aumentado a partir de quatro cenários de aumento de dados diferentes, ao final dos treinamentos e validações os resultados foram comparados. Os resultados mostraram que o uso do método AugMix obteve o melhor resultado dentre os métodos avaliados, com F1-Score de 0.910368, cerca de 5% maior quando comparado ao método base. Seguido dos métodos RandAugment e TrivialAugment com valores de F1-Score de 0.896375 e 0.893653 respectivamente. Além disso, notou-se que em comparação com o método base, os métodos avaliados foram capazes de reduzir o overfitting do modelo, melhorando sua capacidade de generalização para novos casos. Espera-se que o resultado desse estudo possam contribuir para a melhor compreensão da importância do aumento de dados, auxiliar na escolha do melhor método de aumento de dados para o domínio de imagens de raio-x de pneumonia por COVID-19 e analisar o impacto de diferentes métodos automáticos de aumento de dados no desempenho de modelos supervisionados de classificação de imagens de pneumonia por COVID-19.","Classification and segmentation methods for medical image analysis based on convolutional neural networks (CNNs) have achieved state-of-the-art accuracy. However, the scarcity of labeled medical data available for supervised training of CNNs can compromise their performance. To overcome this limitation, data augmentation methods have been successfully employed. These methods involve applying transformations to the input data, such as rotation, translation, scaling, and mirroring, to generate synthetic images that enrich the training set. Additionally, they can be applied to different types of data, including applications involving various types of medical images. The objective of this study is to evaluate the effectiveness of four automatic data augmentation methods: Baseline, AugMix, RandAugment, and TrivialAugment. We aim to assess the performance of a CNN model in classifying X-ray images of COVID-19 pneumonia, utilizing a dataset divided into four distinct classes. The dataset will be augmented using four different data augmentation scenarios. Subsequently, the results obtained from the training and validation processes will be compared and analyzed. The results showed that the AugMix method achieved the best performance among the evaluated methods, with an F1-Score of 0.910368, approximately 5% higher than the baseline method. The RandAugment and TrivialAugment methods followed, with F1-Scores of 0.896375 and 0.893653, respectively. Furthermore, it was noticed that compared to the baseline method, the evaluated methods were able to reduce model overfitting, improving its generalization capability for new cases. It is expected that the results of this study will contribute to a better understanding of the importance of data augmentation, assist in selecting the best data augmentation method for the domain of COVID-19 pneumonia X-ray images, and analyze the impact of different automatic data augmentation methods on the performance of supervised classification models for COVID-19 pneumonia image analysis.","('Imagens médicas -Classificação', 'Redes neurais convolucionais', 'Aumento de dados', 'Aprendizagem profunda', 'Medical images -Classification', 'Convolutional neural networks', 'Data augmentation', 'Deep learning')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/12903","2023-06-19","https://www.repositorio.ufal.br/bitstream/123456789/12903/1/Melhorando%20o%20desempenho%20na%20classifica%c3%a7%c3%a3o%20de%20imagens%20m%c3%a9dicas%3a%20uma%20an%c3%a1lise%20comparativa%20de%20t%c3%a9cnicas%20de%20aumento%20de%20dados.pdf","",""
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/15041","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Uma matheurística Construct, Merge, Solve & Adapt para o problema da cadeia de caracteres mais próxima","('Emily Brito de Oliveira',)","('Rian Gabriel Santos Pinheiro',)","('Bruno Costa e Silva Nogueira', 'Bruno José da Silva Barros')","O Problema da Cadeia de Caracteres Mais Próxima (PCCP) é um problema de otimização combinatória que busca determinar uma string que mais se aproxima de um conjunto de strings de mesma dimensão. O PCCP faz parte de um conjunto de diversos problemas de otimização que envolvem comparação de strings e que encontram aplicações na Biologia Molecular. Este trabalho propõe um algoritmo Self-Adaptive Construct, Merge, Solve & Adapt (Adapt-CMSA) utilizando mecanismos da meta-heurística Tabu Search para resolver o PCCP. O CMSA é uma matheurística que explora características do problema para gerar uma sub-instância reduzida a partir da instância original, aplicando, em seguida, um algoritmo exato para resolvê-la. A versão self-adaptive do CMSA incrementa o algoritmo com mecanismos de auto-adaptação de seus parâmetros, tornando-o menos sensível à sua configuração em diferentes instâncias. Resultados experimentais em instâncias artificiais e reais demonstram que a abordagem proposta apresenta um desempenho significativamente superior em relação aos métodos heurísticos recentes propostos na literatura. O valor ótimo é encontrado na maioria das instâncias e o gap médio é consideravelmente reduzido. Além disso, são realizadas análises estatísticas com objetivo de avaliar a importância dos componentes do algoritmo no seu bom desempenho.","The Closest String Problem (CSP) is a combinatorial optimization problem that seeks to determine a string that best approximates a set of strings with the same length. The CSP is part of a set of optimization problems involving string comparison, with applications in Molecular Biology. This work proposes a Self-Adaptive Construct, Merge, Solve & Adapt (Adapt-CMSA) algorithm using mechanisms from Tabu Search metaheuristic to solve the CSP. CMSA is a matheuristic that explores the problem characteristics to generate a reduced sub-instance of the original problem instance, subsequently employing an exact solver for its resolution. The self-adaptive version of CMSA enhances the algorithm with mechanisms for automatic adaptation of its parameters, making it less sensitive to its configuration across different instances. Experimental results on artificial and real instances demonstrate that the proposed approach significantly outperforms recent heuristic methods proposed in the literature. The optimal value is found in the majority of instances, and the average gap is considerably reduced. Additionally, statistical analyses are conducted to assess the importance of the algorithm’s components in its good performance.","('Meta-heurísticas', 'Problema da cadeia de caracteres mais próxima', 'Construct, Merge, Solve & Adapt', 'Busca tabu', 'Auto-adaptação', 'Metaheuristics', 'Matheuristics', 'Closest String Problem', 'CMSA', 'Tabu Search', 'Self-adaptation')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/15041","2024-04-15","https://www.repositorio.ufal.br/bitstream/123456789/15041/1/Uma%20matheur%c3%adstica%20Construct%2c%20Merge%2c%20Solve%20%26%20Adapt%20para%20o%20problema%20da%20cadeia%20de%20caracteres%20mais%20pr%c3%b3xima.pdf","",""
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/13046","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Mapeamento sistemático sobre a utilização de sistemas de planejamento de recursos empresariais","('Ramon Basto Callado Lima Lopes',)","('Ricardo Alexandre Afonso',)","('Roberta Vilhena Vieira Lopes', 'Alexandre Paes dos Santos', 'Tácito Trindade de Araújo Tiburtino Neves')","Com o constante e grande avanço da tecnologia, necessidade de suprir as demandas dos mais diversos ramos de venda e o incansável desejo dos empresários por atender a essa necessidade para obter uma maior margem de lucro, a utilização de sistemas que elevam a performance e resultados da corporação, para isso torna-se necessário a utilização de softwares que tenham esse propósito. Assim, este trabalho apresenta um mapeamento sistemático sobre a utilização de sistemas de planejamento de recursos empresariais (ERP) e sua importância para as empresas. Apresenta uma análise de artigos científicos relacionados aos fatores de sucesso e fracasso na implementação de sistemas ERP. Os resultados indicam que a utilização de sistemas ERP trazem diversos benefícios nos processos de negócios das empresas para os mais diversos departamentos, desde que o projeto seja feito com controle e um ótimo gerenciamento entre ambas as partes responsáveis pela implantação, mas que a implementação desses sistemas também apresenta desafios e fatores críticos de sucesso que devem ser considerados. O trabalho contribui para a compreensão da importância dos sistemas ERP e para a identificação de tendências e desafios na área.","With the constant and significant advancement of technology, the need to meet the demands of various sales sectors, and the relentless desire of entrepreneurs to address this need in order to achieve a higher profit margin, the use of systems that enhance corporate performance and results becomes necessary. To achieve this, the use of software with this purpose is essential. Thus, this work presents a systematic mapping of the use of Enterprise Resource Planning (ERP) systems and their importance for businesses. It provides an analysis of scientific articles related to the success and failure factors in the implementation of ERP systems. The results indicate that the use of ERP systems brings various benefits to business processes across different departments, provided that the project is executed with control and excellent management by both parties responsible for implementation. However, the implementation of these systems also presents challenges and critical success factors that must be considered. This work contributes to understanding the importance of ERP systems and identifying trends and challenges in the field.","('Sistema ERP -Implantação', 'Sistema ERP -Benefícios', 'ERP System -Implementation', 'ERP System -Benefits')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/13046","2023-08-31","https://www.repositorio.ufal.br/bitstream/123456789/13046/1/Mapeamento%20sistem%c3%a1tico%20sobre%20a%20utiliza%c3%a7%c3%a3o%20de%20sistemas%20de%20planejamento%20de%20recursos%20empresariais.pdf","",""
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/15384","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Making websites more accessible for blind people with automatic HTML code transformations","('Ana Lúcia da Silva Ferreira',)","('Márcio de Medeiros Ribeiro',)","('Elvys Alves Soares', 'Erick de Andrade Barboza')","A Lei Brasileira de Inclusão (LBI) exige acessibilidade em todos os websites, visando a inclusão digital, mas apenas 0,46% dos sites brasileiros atendem plenamente a esses requisitos. Apesar da eficácia das ferramentas atuais em identificar barreiras de acessibilidade, como a falta de descrições alternativas para imagens e informações de idioma, essenciais para usuários cegos que dependem de leitores de tela, elas não oferecem soluções automatizadas para corrigir tais problemas. Este trabalho propõe uma solução inovadora por meio de um catálogo preliminar e um plugin para o IDE Visual Studio Code, projetados para aprimorar a acessibilidade dos websites, detalhando transformações específicas no código HTML e facilitando sua implementação de maneira prática. A eficácia dessa abordagem foi validada em um estudo empírico que envolveu avaliações de acessibilidade online e a percepção de oito indivíduos cegos, mostrando uma redução significativa nos erros críticos de acessibilidade e confirmando o reconhecimento das melhorias pelos participantes. Este avanço representa um passo importante na direção de uma web mais inclusiva, oferecendo soluções práticas para superar as lacunas de acessibilidade e promover um acesso igualitário às informações e serviços digitais para todos os usuários, em especial para aqueles que dependem de leitores de tela.","The Brazilian Inclusion Law (LBI) requires accessibility on all websites, aiming for digital inclusion, but only 0.46% of Brazilian websites fully meet these requirements. Despite the effectiveness of current tools in identifying accessibility barriers, such as the lack of alternative image descriptions and language information, essential for blind users who rely on screen readers, they do not offer automated solutions to correct such problems. This work proposes an innovative solution through a preliminary catalog and a plugin for the Visual Studio Code IDE, designed to improve the accessibility of websites, detailing specific transformations in the HTML code and facilitating their practical implementation. The effectiveness of this approach was validated in an empirical study that involved online accessibility assessments and the perception of eight blind individuals, showing a significant reduction in critical accessibility errors and confirming the participants’ recognition of improvements. This advancement represents an important step towards a more inclusive web, offering practical solutions to overcome accessibility gaps and promote equal access to information and digital services for all users, especially those who depend on screen readers.","('WEB (Linguagem de programação) -Acessibilidade', 'Experiência do usuário -Cegos', 'Tecnologia de leitor de tela', 'Ferramentas de acessibilidade para cegos', 'Tecnologias assistivas', 'Web Accessibility', 'User Experience of Blind Individuals', 'Screen Reader Technology', 'Accessibility Tools for the Blind', 'Assistive Technologies')","Ciência da Computação","eng","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/15384","2024-03-08","https://www.repositorio.ufal.br/bitstream/123456789/15384/1/Making%20websites%20more%20accessible%20for%20blind%20people%20with%20automatic%20HTML%20code%20transformations.pdf","",""
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/14243","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","A Importância da criação de uma ferramenta de conscientização de segurança da informação","('Evérton Borges da Silva',)","('Leonardo Viana Pereira',)","('André Lages Freitas', 'Jorge Artur Peçanha de Miranda Coelho')","A cada dia surgem novos tipos de ataques cibernéticos e ameaças digitais, precisamos que a cada dia se encontrem soluções para combater essas pragas digitais também. O número de pessoas utilizando a Internet cresce a cada ano, é dever dos profissionais de segurança e daqueles que tem conhecimento trazer conscientização para esses usuários e tornar a rede mundial de computadores um lugar mais seguro. Não é proteger da Internet é proteger na Internet. O desenvolvimento de ferramentas de conscientização é importante para a propagação do conhecimento. E ainda mais importante é ter conversas sobre segurança da informação dentro de casa, no escritório e na roda de amigos. Continuem atentos e vigilantes!","Every day new types of cyber attacks and digital threats appear, we need each day to find solutions to combat these digital pests as well. The number of people using the Internet grows every year, it is the duty of security professionals and those who have knowledge to bring awareness to these users and make the worldwide computer network a safer place. It is not protecting from the Internet is protecting on the Internet. The development of awareness tools is important for the propagation of knowledge. And even more important is having conversations about information security indoors, in the office and in the friends wheel. Stay alert and vigilant!","('Segurança da informação', 'Interfaces de usuário (Sistemas de computação)', 'Phishing (Crime por computador)', 'Aquisição de conhecimento', 'Information security', 'User Interfaces (Computer Systems)', 'Phishing (Computer Crime)', 'Knowledge acquisition')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/14243","2022-08-16","https://www.repositorio.ufal.br/bitstream/123456789/14243/1/A%20Import%c3%a2ncia%20da%20Cria%c3%a7%c3%a3o%20de%20uma%20Ferramenta%20de.pdf","The importance of creating an information security awareness tool",""
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/11159","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Introduzindo MLOps: reconhecimento de placas de licença de caminhões","('Warley Vital Barbosa',)","('Tiago Figueiredo Vieira',)","('Ícaro Bezerra Queiroz de Araújo', 'Bruno Georgevich Ferreira')","Grande parte dos projetos de Machine Learning (ML) não chegam a produção. Há vários desafios enfrentados no que tange o gerenciamento de dados e modelos, logo não há soluções universais. O novo paradigma de Machine Learning Operations (MLOps) foi criado justamente para abordar esses desafios e tornar o ciclo de vida do desenvolvimento de modelos de aprendizado de máquina mais eficiente e eficaz. Portanto, neste trabalho, foram introduzidos os principais conceitos de MLOps através da apresentação de uma solução de Optical Character Recognition (OCR) com modelos de detecção de objetos para a tarefa de Automatic License Plate Recognition (ALPR) já validada na indústria. Algumas ferramentas de MLOps foram também introduzidas de forma a exemplificar os principais conceitos de MLOps na prática. Os resultados mostraram a facilidade na criação e manutenção pipelines de dados, bem como deixam claro como tais processos são flexíveis o suficiente para que o fluxo de dados seja replicável, com o mínimo de mudanças, em contextos similares, como OCR de códigos vagões ou containers. Por fim, também foram detalhadas atividades que podem ser adicionadas no workflow para que as operações de desenvolvimento e implantação de modelos de ML sejam mais completas.","Most Machine Learning (ML) projects do not reach production. Several challenges are faced when managing data and models, so there are no universal solutions. The new paradigm of Machine Learning Operations (MLOps) was created precisely to address these challenges and make the lifecycle of the development of machine learning models more efficient and effective. Therefore, in this work, the main concepts of MLOps were introduced through the presentation of an Optical Character Recognition (OCR) solution with object detection models for the Automatic License Plate Recognition (ALPR) task already validated in the industry. Some MLOps tools were also introduced to exemplify the main concepts of MLOps in practice. The results showed the ease of creating and maintaining data pipelines and making it clear how flexible such processes are so that the data flow is replicable, with minimal changes, in similar contexts, such as OCR of wagon or container codes. Finally, it was detailed which activities can be added to the workflow so that the operations of developing and deploying ML models are more complete.","('Aprendizado do computador', 'Software de Aprendizado do computador', 'Reconhecimento automático', 'Sinais e placas de sinalização', 'Reconhecimento de caracteres ópticos', 'Machine Learning', 'Machine Learning Operations', 'Machine Learning Software Systems', 'Automatic License Plate Recognition', 'Optical Character Recognition')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/11159","2022-12-19","https://www.repositorio.ufal.br/bitstream/123456789/11159/1/Introduzindo%20MLOps%20%20reconhecimento%20de%20placas%20de%20licen%c3%a7a%20de%20caminh%c3%b5es.pdf","",""
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/17259","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Jigas de teste em protótipos de circuito impresso: estudo de método e desenvolvimento de uma IDE","('Arquimedes Vinícius Pereira de França Moura',)","('Erick de Andrade Barboza',)","('Rodrigo José Sarmento Peixoto', 'Vergilio Torezan Silingardi Del Claro')","Este trabalho apresenta um estudo sobre jigas de teste aplicada a placas de circuito impresso (PCB) e propõe uma prova de conceito integrada que visa facilitar e simplificar o desenvolvimento de cadernos de teste através de uma IDE. São consideradas as PCB que possuem pontos de teste em sua superfície superior e/ou inferior. Jigas de teste são essenciais para a verificação e validação de circuitos eletrônicos, garantindo que os componentes funcionem conforme especificações técnicas. A IDE desenvolvida busca facilitar a validação de circuitos, bem como depurações de lógica de programa, a partir da variação de nível de sinais digitais nos pontos de teste de uma PCB. Através do estudo das soluções atuais, são avaliadas as principais funcionalidades e a viabilidade técnica da solução proposta. Os resultados demonstram que a IDE desenvolvida tem o potencial de facilitar a implementação de testes de hardware em protótipos, através da adição de uma camada de abstração entre a jiga física e a jiga lógica, reduzindo o tempo de desenvolvimento da mesma, destacando-se como um complemento para o setor de validação de hardware.","This work presents a study on test jigs applied to printed circuit boards (PCBs) and proposes an integrated proof of concept aimed at facilitating and simplifying the development of test plans through an IDE. The focus is on PCBs with test points on their upper and/or lower surfaces. Test jigs are essential for the verification and validation of electronic circuits, ensuring that components function according to technical specifications. The developed IDE seeks to streamline circuit validation and program logic debugging by analyzing variations in digital signal levels at the PCB test points. Through the study of current solutions, the main functionalities and technical feasibility of the proposed solution are evaluated. The results demonstrate that the developed IDE has the potential to simplify the implementation of hardware tests on prototypes by adding a layer of abstraction between the physical jig and the logical jig, reducing its development time and standing out as a valuable complement to the hardware validation sector.","('Jiga de teste', 'Placas de circuito impresso', 'Validação de hardware', 'Automação de testes', 'Test Jigs', 'Printed Circuit Board', 'Test Automation', 'IDE', 'Hard-ware validation')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/17259","2024-12-05","https://www.repositorio.ufal.br/bitstream/123456789/17259/1/Jigas%20de%20teste%20em%20prot%c3%b3tipos%20de%20circuito%20impresso_estudo%20de%20m%c3%a9todo%20e%20desenvolvimento%20de%20uma%20IDE.pdf","",""
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/12808","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Injeção de ruído em serviços de aprendizagem de máquina na nuvem","('Lucas de Oliveira Amorim',)","('Baldoíno Fonseca dos Santos Neto',)","('Marcelo Costa Oliveira', 'Erick de Andrade Barboza')","A aplicação de Machine Learning as a Service (MLaaS) para a análise de sentimentos é um elemento crucial no panorama tecnológico atual, impactando diversas áreas, desde o marketing digital até a pesquisa acadêmica. Este estudo concentrou-se na exploração de como a injeção de ruído em dados de texto afeta o desempenho desses serviços, utilizando como exemplos os serviços oferecidos por três grandes provedores: Microsoft, Amazon e Google. O objetivo principal desta pesquisa foi avaliar a robustez e confiabilidade dessas plataformas frente a vários tipos de ruídos induzidos através da biblioteca NlpAug. As métricas de desempenho, em particular a F-measure, foram analisadas detalhadamente e os resultados obtidos foram comparados entre os diferentes serviços. Os resultados obtidos demonstraram uma queda linear na F-measure à medida que o nível de ruído nos dados aumentava. Embora a Amazon e a Google tenham apresentado um desempenho ligeiramente superior em relação à Microsoft, todas sofreram uma redução significativa de performance à medida que os níveis de ruído aumentavam. Este estudo evidencia a importância de estratégias robustas de pré-processamento e limpeza de dados ao implementar soluções de machine learning. Além disso, foi observado que certos tipos de ruído, como erros de digitação, OCR e substituição aleatória de caracteres, causam uma piora da performance dos modelos de análise de sentimentos comparado a outros. Concluindo, esta pesquisa fornece insights fundamentais sobre a necessidade de um entendimento mais aprofundado das capacidades e limitações dos serviços de MLaaS, a fim de utilizá-los de forma mais efetiva em aplicações reais. Além disso, abre caminho para futuras investigações que podem explorar a robustez desses serviços em relação a outros tipos de dados e tarefas de machine learning.","The application of Machine Learning as a Service (MLaaS) for sentiment analysis is a critical element in today’s technological landscape, impacting various areas from digital marketing to academic research. This study focused on exploring how the injection of noise into text data affects the performance of these services, using as examples the services offered by three major providers: Microsoft, Amazon, and Google. The primary goal of this research was to evaluate the robustness and reliability of these platforms against various types of noise induced through the NlpAug library. Performance metrics, particularly the F-measure, were analyzed, and the results obtained were compared among the different services. The results demonstrated a linear drop in the F-measure as the noise level in the data increased. Although Amazon and Google showed slightly superior performance compared to Microsoft, all suffered a significant performance decrease as noise levels increased. This study highlights the importance of robust pre-processing and data cleaning strategies when implementing machine learning solutions. Moreover, it was observed that certain types of noise, such as typographical errors, OCR, and random character substitution, worsens the performance of sentiment analysis models compared to others. In conclusion, this research provides essential insights into the need for a deeper understanding of the capabilities and limitations of MLaaS services in order to use them more effectively in real applications. Furthermore, it paves the way for future investigations that may explore the robustness of these services in relation to other types of data and machine learning tasks.","('Machine Learning as a Service (MlaaS)', 'Análise de sentimentos', 'Ruído em dados de texto', 'Robustez de modelos', 'Sentiment analysis', 'Text noise injection', 'Model reliability', 'Noise in text data')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/12808","2023-07-17","https://www.repositorio.ufal.br/bitstream/123456789/12808/1/Inje%c3%a7%c3%a3o%20de%20ru%c3%addo%20em%20servi%c3%a7os%20de%20aprendizagem%20de%20m%c3%a1quina%20na%20nuvem.pdf","",""
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/17271","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Improving kinship verification using face age transformation","('Matheus Levi Rodrigues Aidano',)","('Tiago Figueiredo Vieira',)","('Bruno Georgevich Ferreira', 'Warley Vital Barbosa')","Verificação facial de parentesco, a tarefa de determinar relações familiares com base em imagens faciais, tem ganhado atenção significativa nos últimos anos devido às suas aplicações em áreas como mídias sociais, forense e genealogia. No entanto, verificar parentesco com precisão continua sendo um problema desafiador, especialmente ao se considerar as variações de idade entre os membros da família. Esta dissertação explora o potencial de usar técnicas de Transformação de Idade Facial, especificamente através de Generative Adversarial Networks (GANs), para melhorar a precisão dos modelos de verificação de parentesco. Este trabalho envolve o desenvolvimento de um modelo de transformação de idade baseado em GAN que pode simular o processo de envelhecimento em imagens faciais. Ao aumentar as bases de dados de parentes com essas imagens faciais transformadas pela idade, buscamos aprimorar a robustez e a confiabilidade dos sistemas de verificação de parentesco. Os resultados experimentais indicam que a incorporação de imagens faciais transformadas pela idade no processo de verificação de parentesco leva a uma representação mais precisa das relações familiares, especialmente em casos onde as diferenças de idade são acentuadas. Este trabalho contribui para o campo emergente de verificação de parentesco ao elaborar uma abordagem inovadora que aproveita o poder das GANs para progressão de idade, oferecendo uma direção promissora para pesquisas futuras e aplicações práticas.","Kinship verification, the task of determining family relationships based on facial images, has gained significant attention in recent years due to its applications in areas such as social networks, forensics, and genealogy. However, accurately verifying kinship remains a challenging problem, particularly when accounting for variations in age between family members. This thesis explores the potential of using Face Age Transformation techniques, specifically through Generative Adversarial Networks (GANs), to improve the accuracy of kinship verification models. This work involves developing a GAN-based age transformation model that can simulate the aging process in facial images. By augmenting kinship datasets with these age-transformed images, we aim to enhance the robustness and reliability of kinship verification systems. Experimental results indicate that incorporating age-transformed facial images into the kinship verification process leads to a more accurate representation of familial relationships, particularly in cases where age differences are pronounced. This work contributes to the growing field of kinship verification by elaborating a novel approach that leverages the power of GANs for age progression, offering a promising direction for future research and practical applications.","('Reconhecimento facial (Computação)', 'Visão Computacional', 'Redes neurais (Computação)', 'Redes generativas adversariais', 'Parentesco -Percepção facial', 'Face age transformation', 'Kinship Recognition', 'Generative Adversarial Network', 'Convolutional Neural Network', 'Computer Vision')","Ciência da Computação","eng","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/17271","2024-12-13","https://www.repositorio.ufal.br/bitstream/123456789/17271/1/Improving%20kinship%20verification%20using%20face%20age%20transformation.pdf","Melhorando a verificação de parentesco utilizando transformação de idade facial",""
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/11405","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Estudo comparativo da aplicação de modelos de propagação para a localização em ambientes indoor utilizando dispositivos Bluetooth Low Energy","('Dayvson Cassiano Sales',)","('Fábio José Coutinho da Silva',)","('Erick de Andrade Barboza', 'Roberta Vilhena Vieira Lopes')","A crescente utilização de smartphones e o avanço de técnicas de localização permitiram o surgimento de diversas aplicações que se utilizam de tecnologias como GPS, BLE e Wi-Fi para diferentes finalidades. Para aplicações outdoor, o GPS é o mais familiar e utilizado. Porém, para ambientes indoors outras tecnologias precisam ser utilizadas por conta das características deste tipo de ambiente. Nesse contexto, as tecnologias BLE e Beacons juntamente com Modelos de Propagação são utilizados para ajudar a determinar localização dentro de um ambiente. Este trabalho teve o objetivo de comparar os três modelos de propagação indoor: Log-Distance, ITU e Distance-Partitioned com relação a sua acurácia aplicado a um conjunto de dados. Com os resultados, foi possível observar os modelos estão tecnicamente empatados, então, o DistancePartitioned poderia ser a melhor opção por ter menos parâmetros.","The growing use of smartphones and the advancement of location techniques allowed the emergence of several applications that use technologies such as GPS, BLE, and Wi-Fi for different purposes. For outdoor applications, GPS is the most familiar and used. However, other technologies need to be used for indoor environments due to the characteristics of this type of environment. In this context, BLE and Beacons technologies along with Propagation Models are used to help determine the location within an environment. This work aims to compare the three indoor propagation models: Log-Distance, ITU, and Distance-Partitioned with respect to their performance applied to a dataset. The results showed that the models were technically tied, so the Distance-Partitioned should be the best option due to a smaller number of parameters among the three.","('Received Signal Strength Indication', 'Modelos de propagação (Eletromagnetismo)', 'Bluetooth Low Energy', 'Beancons', 'Propagation Models', 'Bluetooth Low Energy')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/11405","2022-11-25","https://www.repositorio.ufal.br/bitstream/123456789/11405/1/Estudo%20comparativo%20da%20aplica%c3%a7%c3%a3o%20de%20modelos%20de%20propaga%c3%a7%c3%a3o%20para%20a%20localiza%c3%a7%c3%a3o%20em%20ambientes%20indoor%20utilizando%20dispositivos%20Bluetooth%20Low%20Energy.pdf","",""
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/15378","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Gestic: uma ferramenta para gestão de atividades extensionistas","('Thiago Emmanuel Gomes Rodrigues',)","('Olival de Gusmão Freitas Júnior',)","('Arturo Hernández-Domínguez', 'Giseldo da Silva Néo')","Entende-se que a excelência organizacional pode ser alcançada por meio do exercício do conhecimento, de forma a orientar a tomada de decisões e de técnicas de gestão dinâmica para maximizar o desenvolvimento corporativo e a compreensão dos fluxos de processos internos e externos. Alinhado a isto, a gestão da informação revela-se como um alicerce fundamental para uma organização, pois fomenta a capacidade de promover o uso estratégico dos dados, a eficiência operacional e a modernização tecnológica, uma vez que os sistemas digitais desempenham o papel de estruturar e gerir a informação de forma eficaz. O curso de Ciência da Computação da Universidade Federal de Alagoas tem em sua grade curricular as Atividades Curriculares de Extensão, que representam 10% da carga horária curricular total do curso e promovem a interdisciplinaridade educacional no processo de formação dos alunos do Instituto de Computação. Neste contexto, o Sistema Integrado de Gestão de Atividades Acadêmicas é utilizado como principal software de apoio à gestão das atividades gerais e de extensão, porém não fornece informações atualizadas sobre os projetos. Da mesma forma, o endereço eletrônico do Instituto de Computação, na seção de extensões, não possui informações atualizadas sobre os projetos e apresenta contextos incompletos para suporte do conhecimento do corpo discente, o que promove a desorganização institucional; dificuldade no acompanhamento das atividades e do processo de melhorias internas. Assim, este trabalho tem como objetivo a criação do GestIC, uma ferramenta de apoio à gestão de atividades extensionistas capaz de gerenciar projetos de extensão e gerar conhecimento para auxiliar o corpo administrativo, docente e discente do Instituto de Computação e demais cursos da Universidade Federal de Alagoas.","It is understood that organizational excellence can be achieved through the exercise of knowledge, guiding decision-making and dynamic management techniques to maximize corporate development and understanding of internal and external process flows. Aligned with this, information management proves to be a fundamental foundation for an organization, as it fosters the ability to promote the strategic use of data, operational efficiency, and technological modernization, since digital systems play the role of structuring and managing information effectively. The Computer Science course at the Federal University of Alagoas includes Extension Curricular Activities in its curriculum, representing 10% of the total curriculum hours of the course, promoting educational interdisciplinarity in the training process of the students at the Computing Institute. In this context, the Integrated System for Academic Activities Management is used as the main software to support general and extension activities management, but it does not provide updated information about the projects. Similarly, the Computing Institute's website, in the extension section, lacks updated information about the projects and presents incomplete contexts to support the knowledge of the student body, which promotes institutional disorganization; difficulty in monitoring activities and internal improvement processes. Thus, this work aims to create GestIC, a tool to support the management of extension activities capable of managing extension projects and generating knowledge to assist the administrative, teaching, and student body of the Computing Institute and other courses at the Federal University of Alagoas.","('Gestão do conhecimento', 'Gestão da informação', 'Desenvolvimento de software', 'Extensão universitária – Atividade complementar', 'Knowledge Management', 'Information Management', 'Software Development', 'Complementary Extension Activities')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/15378","2024-03-22","https://www.repositorio.ufal.br/bitstream/123456789/15378/1/Gestic_uma%20ferramenta%20para%20gest%c3%a3o%20de%20atividades%20extensionistas.pdf","",""
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/12857","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Estudo de aplicabilidade de técnicas de processamento de linguagem natural em petições iniciais","('Ana Geórgia de Souza Silva Gama Pereira',)","('André Lages Freitas',)","('Leonardo Viana Pereira', 'Orivaldo Vieira de Santana Júnior')","Este trabalho teve como objetivo estudar a aplicação de algoritmos de processamento de linguagem natural (NLP) na classificação de petições iniciais do sistema jurídico brasileiro. Foram explorados os algoritmos Doc2Vec e BERT, com a finalidade de analisar sua eficácia e comparar seus desempenhos. A metodologia envolveu etapas de pré-processamento dos dados, treinamento e avaliação dos modelos. Os resultados foram avaliados utilizando métricas como precisão, acurácia e matriz de confusão. O modelo BERT demonstrou uma precisão de 85% na classificação de documentos, enquanto o modelo Doc2Vec apresentou resultados moderados. A importância do pré-processamento dos dados e a influência da dimensionalidade também foram discutidas. Além disso, foi destacada a necessidade de recursos computacionais adequados para a análise de modelos de linguagem grandes. Esses resultados contribuem para a compreensão do desempenho dos algoritmos de NLP na classificação de petições iniciais e podem auxiliar na seleção e implementação de modelos adequados em diferentes contextos jurídicos.","This study aimed to investigate the application of natural language processing (NLP) algorithms in the classification of initial petitions in the Brazilian legal system. The Doc2Vec and BERT algorithms were explored to analyze their effectiveness and compare their performances. The methodology involved data preprocessing, model training, and evaluation stages. The results were assessed using metrics such as precision, accuracy, and confusion matrix. The BERT model demonstrated an 85% precision in document classification, while the Doc2Vec model showed moderate results. The importance of data preprocessing and the influence of dimensionality were also discussed. Additionally, the need for adequate computational resources for analyzing large language models was emphasized. These findings contribute to understanding the performance of NLP algorithms in classifying initial petitions and can assist in selecting and implementing suitable models in various legal contexts.","('Processamento de linguagem natural (Computação)', 'Algoritmos -Doc2Vec', 'Algoritmos -BERT', 'Petições (Direito)', 'Natural Language Processing (Computing)', 'Algorithms -Doc2Vec', 'Algorithms -BERT', 'Doc2Vec algorithms')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/12857","2023-06-14","https://www.repositorio.ufal.br/bitstream/123456789/12857/1/Estudo%20de%20aplicabilidade%20de%20t%c3%a9cnicas%20de%20processamento%20de%20linguagem%20natural%20em%20peti%c3%a7%c3%b5es%20iniciais.pdf","Applicability study of natural language processing techniques in initial petitions",""
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/10684","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Explorando métricas de código para a detecção de Long Envious Methods","('Audrey Emmely Rodrigues Vasconcelos',)","('Baldoíno Fonseca dos Santos Neto',)","('Ícaro Bezerra Queiroz de Araújo', 'Jairo Raphael Moreira Correia de Souza')","Atualmente os projetos estão em constante evolução para introduzir novas funcionalidades e adaptá-las a diferentes contextos de execução. Com isso, alguns problemas na qualidade do projeto de software podem ser introduzidos, podendo estar relacionados à presença de anomalias de código, geralmente chamadas de code smells ou bad smells em inglês, que são estruturas pobres de código. As anomalias são categorizadas em tipos e alguns desses tipos são Long Method, quando um método tem várias linhas de código, e Feature Envy, quando um método geralmente usa recursos de outras classes. Como a identificação manual dessas anomalias de código é custosa, várias ferramentas de anomalias de código foram propostas. Essas ferramentas utilizam estratégias de detecção baseadas em métricas de código, mas elas focam na remoção de uma única anomalia e um estudo recente indicou que um elemento de código pode ter duas ou mais anomalias de código. Assim, esses elementos podem estar com suas métricas degradadas e os limiares utilizados por essas ferramentas não são suficientes para indicar a gravidade deles. Essa monografia visa explorar métricas de código de métodos que são Long Method e Feature Envy. Esses métodos são chamados de Long Envious Method, um novo tipo de anomalia que pode ser causado por excessivas linhas de código e a implementação de duas ou mais funcionalidades. O objetivo é explorar quais métricas de código podem ser usadas para a identificação desse método. Mais de 8.000 instâncias de anomalias de código foram investigadas em três projetos de software, onde 4.707 (54%) são Long Methods e 3.910 (45.3%) métodos são Long Envious Methods. Ou seja, Long Envious Methods são frequentes e muitas vezes as ferramentas não conseguem detectá-los. Pode-se observar também que as métricas cyclomaticComplexity (complexidade do código), NumberOfCatchStatements (tratamento de exceções) e couplingIntensity (acoplamento do código fonte) têm uma diferença significativa entre Long Envious Methods e Long Methods. Por fim, conclui-se que essas métricas podem ser usadas para a identificação de Long Envious Methods.","Currently, projects are constantly evolving to introduce new features and adapt them to different execution contexts. With this, some problems in the quality of the software project can be introduced, which may be related to the presence of code anomalies, usually called code smells or bad smells in English, which are poor code structures. Anomalies are categorized into types and some of these types are Long Method, when a method has several lines of code, and Feature Envy, when a method often uses features from other classes. As manual identification of these code anomalies is costly, several code anomaly tools have been proposed. These tools use detection strategies based on code metrics, but they focus on removing a single anomaly and a recent study indicated that a code element can have two or more code anomalies. Thus, these elements may have their metrics degraded and the thresholds used by these tools are not sufficient to indicate their severity. This monograph aims to explore code metrics of methods that are Long Method and Feature Envy. These methods are called the Long Envious Method, a new type of anomaly that can be caused by excessive lines of code and the implementation of two or more features. The goal is to explore which code metrics can be used to identify this method. More than 8000 instances of code anomalies were investigated in three software projects, where 4707 (54%) are Long Methods and 3910 (45.3%) methods are Long Envious Methods. That is, Long Envious Methods are frequent and tools often fail to detect them. It can also be seen that the metrics cyclomaticComplexity, NumberOfCatchStatements and couplingIntensity have a significant difference between Long Envious Methods and Long Methods. Finally, it is concluded that these metrics can be used to identify Long Envious Methods.","('Anomalias de código', 'Software -Qualidade', 'Métricas de código', 'Code smells', 'Software quality', 'Code metrics', 'Detection tools')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/10684","2023-01-18","https://www.repositorio.ufal.br/bitstream/123456789/10684/1/Explorando%20m%c3%a9tricas%20de%20c%c3%b3digo%20para%20a%20detec%c3%a7%c3%a3o%20de%20Long%20Envious%20Methods.pdf","Exploring Code Metrics For Detecting Long Envious Methods","('Ana Carla Gomes Bibiano',)"
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/11412","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Uma ferramenta para demarcação de áreas de interesse e monitoramento em tempo real de pessoas usando aprendizado profundo","('David Silva Alexandre',)","('Thales Miranda de Almeida Vieira',)","('Marcelo Costa Oliveira',)","Identificar pessoas é um problema relevante da área de Detecção de Objetos. Mais recentemente, surgiram técnicas para realizar essas detecções em tempo real, utilizando Redes neurais e Aprendizado profundo. Essas técnicas têm como grande vantagem a rapidez e a precisão com que conseguem classificar seres humanos em uma cena, o que são propriedades indispensáveis em aplicações de monitoramento por vídeo. Soluções baseadas em Aprendizado Profundo possuem uma ampla gama de aplicações. Desde que as Redes Neurais começaram a ser aplicadas com sucesso na área de Aprendizado Supervisionado, abordagens que fazem seu uso estão alcançando resultados a nível de estado da arte na solução de problemas de classificação(como reconhecimento de fala, sensoriamento remoto, dentre outros). Essas tecnologias podem ser combinadas com outras técnicas para resolver problemas geométricos do mundo real, como por exemplo monitorar a localização de um usuário usando óculos de realidade virtual. Nesse trabalho, relatamos o processo de desenvolvimento de uma ferramenta que detecta pessoas e infere se elas estão em uma área demarcada ou não. Esse programa visa possibilitar o monitoramento em tempo real de regiões customizadas pelo usuário, podendo ser utilizado para diversas finalidades. O sistema foi implementado na linguagem de programação Python que, além de fornecer praticidade, também possui uma vasta usabilidade de bibliotecas, métodos e funções muito utilizadas atualmente na área de Visão Computacional. Também utilizamos um modelo pré-treinado da Yolov5 para detectar pessoas com mais confiança e rapidez.","The identification of people is a relevant problem in the area of Object Detection. More recently, techniques have emerged to perform these detections in real time, using Neural Networks and Deep Learning. These techniques have the great advantage of being able to quickly and accurately classify persons in a scene, which are indispensable properties in video monitoring applications. Deep Learning based solutions have a wide range of applications. Since Neural Networks began to be successfully applied in the area of Supervised Learning, approaches that make use of them are achieving state-of-the-art results in solving classification problems (such as speech recognition, remote sensing, among others). These technologies can be combined with other techniques to solve real-world geometric problems, such as tracking a user’s location using virtual reality glasses. In this work, we report the process of developing a tool that detects people and infers whether they are in a demarcated area or not. This program aims to enable real-time monitoring of regions customized by the user, and can be used for various purposes. The system was implemented in the Python programming language, which provide practicality and also has a vast usability of libraries, methods and functions that are currently used in the area of Computer Vision. We also use a pre-trained Yolov5 model to detect people more confidently and quickly.","('Detecção de objetos (Aprendizado profundo)', 'Processamento eletrônico de dados em tempo real', 'Python (Linguagem de programação de computador)', 'Object Detection', 'Real Time Application', 'Python language')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/11412","2022-08-09","https://www.repositorio.ufal.br/bitstream/123456789/11412/1/Uma%20ferramenta%20para%20demarca%c3%a7%c3%a3o%20de%20%c3%a1reas%20de%20interesse%20e%20monitoramento%20em%20tempo%20real%20de%20pessoas%20usando%20aprendizado%20profundo.pdf","","('Eduarda Tatiane Caetano Chagas',)"
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/11410","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Um estudo comparativo entre técnicas de aprendizado de máquina para classificação de intenções, em um contexto de diálogos no e-commerce de roupa","('Gabriel Barbosa Pereira',)","('Evandro de Barros Costa',)","('Robério José Rogério dos Santos', 'Priscylla Maria da Silva Sousa')","Ao longo dos últimos anos é perceptível como os agentes de conversação, tais como os chatbots e os assistentes virtuais, foram cada vez mais integrados na vida do ser humano. Ao analisarmos especificamente o setor de e-commerce, é possível ver como esse tipo de tecnologia está realmente incorporada ao mesmo, trazendo benefícios para o usuário final. Com o passar do tempo essas tecnologias foram evoluindo e graças a inteligência artificial, o processo de entrega de valor foi sendo refinado. A classificação de intenções é uma das etapas mais importantes na construção de um agente de conversação moderno. Através do classificador de intenções, o chatbot consegue identificar e classificar automaticamente cada enunciado inserido pelo usuário em intenções, gerando conhecimento de valor. Este trabalho propõe uma abordagem de um classificador de intenções para enunciados em um diálogo no contexto do e-commerce de moda. Para atingir o objetivo, foi realizado um estudo comparativo entre vários modelos de aprendizado de máquina comumente utilizados para essa finalidade. Resultados indicaram que o modelo de aprendizado de máquina SVC é o que demonstra melhor desempenho frente a outros modelos na classificação de intenções para diálogos no e-commerce de roupa.","Over the past years, it has been noticeable how conversational agents, such as chatbots and virtual assistants, have been increasingly integrated into human life. By explicitly analyzing the e-commerce sector, it is possible to see how this type of technology is incorporated, bringing benefits to the final user. Over time these technologies have evolved and thanks to artificial intelligence, the process of generating value has been refined. Intent classification is one of the most important steps in building a modern conversational agent. Through the intent classifier, the chatbot can automatically identify and classify each statement entered by the user into intents, generating valuable knowledge. This work proposes an intention classifier approach for utterances in a dialogue in the context of fashion e-commerce. To achieve the objective, a comparative study was carried out between several machine learning models commonly used for this purpose. Results indicated that the SVC machine learning model is the one that demonstrates the best performance compared to other models in the classification of intentions for dialogues in e-commerce clothing.","('Chatbots', 'E-commerce', 'Classificação de intenção', 'Aprendizagem de máquina', 'Intent classifier', 'Machine learning', 'Fashion e-commerce')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/11410","2022-12-20","https://www.repositorio.ufal.br/bitstream/123456789/11410/1/Um%20estudo%20comparativo%20entre%20t%c3%a9cnicas%20de%20aprendizado%20de%20m%c3%a1quina%20para%20classifica%c3%a7%c3%a3o%20de%20inten%c3%a7%c3%b5es%2c%20em%20um%20contexto%20de%20di%c3%a1logos%20no%20e-commerce%20de%20roupa.pdf","","('Thales Miranda de Almeida Vieira',)"
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/13988","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Evaluation of deep metric learning methods for the diagnosis of human visceral leishmaniasis","('Yanka Raíssa Ribeiro da Silva',)","('Fabiane da Silva Queiroz',)","('André Luiz Lins de Aquino', 'Raquel da Silva Cabral')","A Leishmaniose Visceral, um tipo grave causado pelo complexo de parasitos Leishmania donovani, é fatal em mais de 95% dos casos não tratados e afeta predominantemente a população baixa renda, com acesso limitado a assistência médica. O exame parasitológico é o padrão ouro para o diagnóstico da LV; consiste na inspeção visual de amastigotas do parasita com cerca de 2-4 µm de diâmetro, o que pode rapidamente tornar-se uma tarefa exaustiva e exigir um nível de competência elevado. Visando auxiliar os profissionais de saúde, este estudo propõe uma abordagem alternativa que une aprendizagem métrica profunda a classificação supervisionada para a detecção rápida e precisa da leishmaniose visceral humana. A abordagem propõe divi dir as imagens em conjunto de fragmentos (patches) para facilitar o discernimento durante a avaliação de quatro funções de perda de aprendizagem métrica profunda, visando a extração de características utilizadas por uma Máquina de Vetores de Suporte (SVM) para diagnosticar a leishmaniose visceral. Esse processo foi avaliado minuciosamente usando métricas relevantes como o Coeficiente de Correlação de Matthew (MCC), sensibilidade e especificidade, que revelaram que a função Circle supera o desempenho de outras funções com 98,3% de sensibilidade, 99,3% de especificidade e 97,7% de MCC. Em resumo, todas as funções avaliadas apresentaram um bom desempenho nas avaliações quantitativas, sugerindo que a aplicação da inteligência artificial no diagnóstico médico oferece benefícios consideráveis, sspecialmente ao auxiliar os médicos de forma economicamente eficiente na detecção rápida e precisa de doenças tropicais negligenciadas.","Visceral Leishmaniasis, a severe type caused by the Leishmania donovani parasite complex, is fatal in over 95% of untreated cases and predominantly affects the poor and vulnerable with limited healthcare access. Parasitological processes are the gold standard for diagnosing VL; they entail direct icroscopic inspection of amastigotes about 2–4 µm in diameter, which can quickly become a time-consuming, exhausting task and require an expert skill level. Aiming to assist physicians, this study proposes an alternative approach combining deep metric learning with supervised classification for the rapid and reliable detection of human visceral leishmani asis. The suggested methodology segments images into patches for discernability during the evaluation of four deep metric learning loss functions to extract features, which are utilized by a Support Vector Machine (SVM) for the diagnosis of visceral leishmaniasis. This process was thoroughly assessed using key metrics like the Matthew Correlation Coefficient (MCC), sensitivity, and specificity, which revealed that Circle loss outperforms other losses with 98.3% sensitivity, 99.3% specificity, and 97.7% MCC. Overall, all of the functions evaluated erfor med well in quantitative assessments, implying that AI’s application to medical diagnostics offers considerable benefits, particularly in cost-effectively assisting physicians in rapidly and accurately detecting neglected tropical diseases.","('Detecção de parasitas', 'Leishmaniose visceral', 'Aprendizagem profunda', 'Redes neurais', 'Classificação binária', 'Diagnóstico automático de doenças', 'Parasite Detection', 'Visceral Leishmaniasis', 'Deep Metric Learning', 'Deep Learning', 'Convolutional Neural Networks', 'Binary Classification', 'Automatic Disease')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/13988","2023-12-15","https://www.repositorio.ufal.br/bitstream/123456789/13988/1/Evaluation%20of%20deep%20metric%20learning%20methods%20for%20the%20diagnosis%20of%20human%20visceral%20leishmaniasis.pdf","",""
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/16466","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Identificação e interpretação de debates feministas no Instagram brasileiro: uma abordagem com BERTopic e LLaMA","('Thalia Barbosa Marques de Almeida',)","('André Luiz Lins de Aquino',)","('Fabiane da Silva Queiroz', 'Sheyla Christine Santos Fernandes')","Este trabalho investiga a identificação e interpretação de temas feministas abordados por perfis brasileiros no Instagram, utilizando técnicas de Processamento de Linguagem Natural (PLN) e modelagem de tópicos. Com o objetivo de analisar discussões recorrentes e suas variações, o estudo aplicou a técnica BERTopic para modelagem de tópicos e o modelo de linguagem de grande escala (LLM) LLaMA para enriquecer a interpretação dos temas identificados. A coleta de dados abrangeu mais de 11 mil postagens de seis perfis feministas, e o pré-processamento foi realizado em Python, utilizando a biblioteca spaCy para tokenização, lematização e remoção de stopwords. A modelagem resultou em 90 tópicos, entre os quais se destacaram temas como vi-olência doméstica, direitos reprodutivos, saúde mental e autonomia do corpo, refletindo debates atuais e relevantes no contexto brasileiro. Para validar a interpretação dos tópicos, um expe-rimento comparativo foi conduzido, avaliando a consistência entre as respostas humanas e as interpretações geradas pelo LLaMA. Embora as métricas de similaridade lexical apresentassem baixa correspondência, o BERTScore indicou uma alta similaridade semântica, sugerindo que o LLaMA capturou o significado dos temas com precisão, confirmando a hipótese alternativa de que técnicas de PLN e LLMs podem identificar e interpretar temas feministas no Instagram de forma eficaz. A relevância desta pesquisa reside em sua contribuição para o campo da aná-lise de discussões sociais em redes digitais, oferecendo uma abordagem estruturada e inovadora para entender debates feministas em uma plataforma de grande alcance como o Instagram. Os resultados reforçam a importância de técnicas de PLN e de modelos de linguagem de grande es-cala na interpretação de temas sociais complexos, proporcionando uma base sólida para estudos futuros sobre o impacto das redes sociais na conscientização e promoção de mudanças sociais.","This study investigates the identification and interpretation of feminist themes addressed by Brazilian profiles on Instagram, using Natural Language Processing (NLP) techniques and to-pic modeling. Aiming to analyze recurring discussions and their variations, the study applied the BERTopic technique for topic modeling and the large language model (LLM) LLaMA to enrich the interpretation of identified themes. Data collection covered over 11,000 posts from six feminist profiles, and preprocessing was conducted in Python using the spaCy library for tokenization, lemmatization, and stopword removal. The modeling identified 90 topics, in-cluding prominent themes such as domestic violence, reproductive rights, mental health, and bodily autonomy, reflecting current and relevant debates within the Brazilian context. To vali-date topic interpretation, a comparative experiment was conducted, evaluating the consistency between human responses and interpretations generated by LLaMA. Although lexical simila-rity metrics showed low correspondence, the BERTScore indicated high semantic similarity, suggesting that LLaMA effectively captured the meaning of the topics, thus confirming the alternative hypothesis that NLP techniques and LLMs can accurately identify and interpret fe-minist themes on Instagram. The relevance of this research lies in its contribution to the field of social discourse analysis on digital networks, offering a structured and innovative approach to understanding feminist debates on a widely accessible platform like Instagram. The results un-derscore the importance of NLP techniques and large language models in interpreting complex social themes, providing a solid foundation for future studies on the impact of social media on awareness and the promotion of social change.","('Redes Sociais.', 'Feminismo', 'Processamento de Linguagem Natural (PLN', 'BERTopic – LlaMA', 'Modelagem de Tópicos', 'Feminism', 'Topic Modeling', 'BERTopic', 'LLaMA', 'Large Language Models (LLMs)', 'Instagram', 'Natural Language Processing (NLP)', 'Social Media')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/16466","2024-11-22","https://www.repositorio.ufal.br/bitstream/123456789/16466/1/Identifica%c3%a7%c3%a3o%20e%20Interpreta%c3%a7%c3%a3o%20de%20Debates%20Feministas%20no%20Instagram%20Brasileiro%20Uma%20abordagem%20com%20BERTopic%20e%20LLaMA.pdf","",""
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/17125","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Desenvolvimento de um verificador de acessibilidade web de varredura completa","('Jonathas Patrick Hermenegildo de Azevedo',)","('Fábio José Coutinho da Silva',)","('Maria Cristina Tenório Cavalcante Escarpini', 'Thiago Damasceno Cordeiro')","A acessibilidade digital é um requisito essencial para garantir a inclusão de pessoas com deficiência no ambiente online, mas ainda enfrenta desafios significativos devido à falta de conformidade de muitos websites com as diretrizes internacionais, como as Web Content Accessibility Guidelines (WCAG). Este trabalho tem como objetivo desenvolver o FullScan Accessibility Checker, uma aplicação gratuita e automatizada capaz de avaliar a acessibilidade de todas as páginas de um website, proporcionando uma visão abrangente sobre seu nível de conformidade. Como estudo de caso, a ferramenta foi aplicada em websites de museus virtuais, revelando que a maioria dos sites apresenta um nível intermediário de acessibilidade, com falhas recorrentes em áreas essenciais como textos alternativos para imagens e navegação intuitiva. Esses resultados evidenciam a importância de ferramentas automatizadas para diagnosticar e corrigir problemas de acessibilidade, promovendo um ambiente digital mais inclusivo. O FullScan Accessibility Checker se destacou como uma solução eficaz, contribuindo para a detecção de problemas e auxiliando no processo de correção dos mesmos.","Digital accessibility is an essential requirement to ensure the inclusion of people with disabilities in the online environment, yet it still faces significant challenges due to the lack of compliance of many websites with international guidelines, such as the Web Content Accessibility Guidelines (WCAG). This study aims to develop the FullScan Accessibility Checker, a free and automated application capable of assessing the accessibility of all pages of a website, providing a comprehensive overview of its compliance level. As a case study, the tool was applied to virtual museum websites, revealing that most of them exhibit an intermediate level of accessibility, with recurring issues in critical areas such as alternative text for images and intuitive navigation. These findings highlight the importance of automated tools in diagnosing and addressing accessibility issues, fostering a more inclusive digital environment. The FullScan Accessibility Checker proved to be an effective solution, contributing to the detection of accessibility barriers and supporting the process of their resolution.","('Acessibilidade web', 'Verificadores de acessibilidade', 'Wcag', 'Web crawler', 'Museus virtuais', 'Web accessibility', 'Accessibility checkers', 'Accessibility evaluation methods', 'Virtual museums')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/17125","2024-12-20","https://www.repositorio.ufal.br/bitstream/123456789/17125/1/Desenvolvimento%20de%20um%20verificador%20de%20acessibilidade%20web%20de%20varredura%20completa.pdf","",""
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/11633","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Desenvolvimento de um modelo de algoritmo genético para otimização do custo na fase de transporte logístico do pequeno empreendedor","('José Eraldo dos Santos Neto',)","('Roberta Vilhena Vieira Lopes',)","('Rafael de Amorim Silva', 'Evandro de Barros Costa')","Os Algoritmos Genéticos são algoritmos meta-heurísticos de busca, que simulam o processo evolutivo descrito na Teoria da Evolução de Charles Darwin. De acordo com a teoria, os indivíduos com melhores adaptações ao ambiente são aqueles que sobrevivem. Assim, essa ideia foi aplicada no cenário da computação por John H. Holland, que em 1975 criou um modelo de computação baseado na evolução biológica para solucionar problemas de otimização. A simplicidade do seu algoritmo permitiu buscar soluções aproximadas para problemas NP (NãoPolinomiais), tentando encontrar uma solução ótima, mas sem garantias de que a solução encontrada seja a melhor. A busca da solução do problema é construída por meio de uma série de funções que ele definiu como operadores genéticos: criação de população, seleção dos mais adaptados, combinação, mutação e substituição. A cada processo, é criada uma população descendente que pode ser a solução potencial, mas que passará pela etapa de avaliação da função objetivo até que uma solução satisfatória seja encontrada. Devido a sua flexibilidade e capacidade de solucionar problemas, os algoritmos genéticos podem ser utilizados em diversas áreas do conhecimento, incluindo a Teoria dos Jogos, Inteligência Artificial, finanças, Ciência de Dados e Engenharias, com a otimização de processos, modelos e aprendizado. No Brasil, os microempreendedores e pequenas empresas enfrentam desafios significativos no setor logístico, reflexo da falta de investimento por parte do governo, baixo capital para planejamentos estratégicos e infraestrutura deficiente. Isso resulta no aumento dos custos de operações, sobretudo na fase do transporte de mercadorias. Dessa forma, este trabalho busca aplicar o conceito de algoritmos genéticos para o desenvolvimento de um modelo computacional evolutivo que auxilie na redução dos custos operacionais logísticos de pequenos empreendedores, na fase de transporte de mercadorias.","Genetic algorithms are metaheuristic search algorithms that simulate the evolutionary process described in Charles Darwin's theory of evolution. According to the theory, individuals with better adaptations to the environment are the ones that survive. Thus, this idea was applied to the computing scenario by John H. Holland, who in 1975 created a computational model based on biological evolution to solve optimization problems. The simplicity of his algorithm allowed for approximate solutions to NP (non-polynomial) problems to be found, attempting to find an optimal solution, but without guarantees that the solution found will be the best. The search for the problem solution is constructed through a series of functions that he defined as genetic operators: population creation, selection of the fittest, combination, mutation, and substitution. At each process, a descendant population is created that could be the potential solution, but it will go through the objective function evaluation stage until a satisfactory solution is found. Due to its flexibility and problem-solving ability, genetic algorithms can be used in various fields of knowledge, including Game Theory, Artificial Intelligence, finance, Data Science, and Engineering, optimizing processes, models, and learning. In Brazil, microentrepreneurs and small businesses face significant challenges in the logistics sector, reflecting the lack of government investment, low capital for strategic planning, and deficient infrastructure. This results in increased operational costs, particularly in the transportation phase of goods. Thus, this work aims to apply the concept of genetic algorithms to the development of an evolutionary computational model that assists in reducing the logistics operational costs of small entrepreneurs in the transportation phase of goods.","('Algoritmos genéticos', 'Otimização', 'Modelo computacional', 'Logística', 'Genetic algorithms', 'Logistics', 'Optimization', 'Small entrepreneur')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/11633","2023-04-26","https://www.repositorio.ufal.br/bitstream/123456789/11633/1/Desenvolvimento%20de%20um%20modelo%20de%20algoritmo%20gen%c3%a9tico%20para%20otimiza%c3%a7%c3%a3o.pdf","",""
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/17701","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Desenvolvimento de um verificador de acessibilidade web de varredura completa","('Jonathas Patrick Hermenegildo de Azevedo',)","('Fábio José Coutinho da Silva',)","('Maria Cristina Tenório Cavalcante Escarpini', 'Thiago Damasceno Cordeiro')","A acessibilidade digital é um requisito essencial para garantir a inclusão de pessoas com deficiência no ambiente online, mas ainda enfrenta desafios significativos devido à falta de conformidade de muitos websites com as diretrizes internacionais, como as Web Content Accessibility Guidelines (WCAG). Este trabalho tem como objetivo desenvolver o FullScan Accessibility Checker, uma aplicação gratuita e automatizada capaz de avaliar a acessibilidade de todas as páginas de um website, proporcionando uma visão abrangente sobre seu nível de conformidade. Como estudo de caso, a ferramenta foi aplicada em websites de museus virtuais, revelando que a maioria dos sites apresenta um nível intermediário de acessibilidade, com falhas recorrentes em áreas essenciais como textos alternativos para imagens e navegação intuitiva. Esses resultados evidenciam a importância de ferramentas automatizadas para diagnosticar e corrigir problemas de acessibilidade, promovendo um ambiente digital mais inclusivo. O FullScan Accessibility Checker se destacou como uma solução eficaz, contribuindo para a detecção de problemas e auxiliando no processo de correção dos mesmos.","Digital accessibility is an essential requirement to ensure the inclusion of people with disabilities in the online environment, yet it still faces significant challenges due to the lack of compliance of many websites with international guidelines, such as the Web Content Accessibility Guidelines (WCAG). This study aims to develop the FullScan Accessibility Checker, a free and automated application capable of assessing the accessibility of all pages of a website, providing a comprehensive overview of its compliance level. As a case study, the tool was applied to virtual museum websites, revealing that most of them exhibit an intermediate level of accessibility, with recurring issues in critical areas such as alternative text for images and intuitive navigation. These findings highlight the importance of automated tools in diagnosing and addressing accessibility issues, fostering a more inclusive digital environment. The FullScan Accessibility Checker proved to be an effective solution, contributing to the detection of accessibility barriers and supporting the process of their resolution.","('Acessibilidade web', 'Verificadores de acessibilidade', 'Wcag', 'Web crawler', 'Museus virtuais', 'Web accessibility', 'Accessibility checkers', 'Virtual museums')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/17701","2024-12-20","https://www.repositorio.ufal.br/bitstream/123456789/17701/1/Desenvolvimento%20de%20um%20verificador%20de%20acessibilidade%20web%20de%20varredura%20%20completa.pdf","",""
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/14751","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Desenvolvimento de um questionário avaliativo a partir da metodologia Design Science Research","('Lucas Tadeu Vieira Moura de Santana',)","('Alan Pedro da Silva',)","('Ranilson Oscar Araújo Paiva', 'Maria Cristina Tenório Cavalcante Escarpini')","Neste Trabalho de Conclusão de Curso (TCC), investigamos a eficácia dos questionários como ferramenta de avaliação educacional e a aplicabilidade da metodologia Design Science Research (DSR) no desenvolvimento de software. A motivação para a pesquisa emergiu da problemática relacionada a modernizar as práticas de avaliação educacional, adaptando-as para melhor atender às demandas da era digital e aos novos paradigmas de ensino e aprendizagem. O objetivo deste estudo foi o desenvolvimento do ICQuiz, um sistema de questionários online. Este sistema se destaca não apenas pela sua funcionalidade de registro de questões, mas também pela sua capacidade de automatizar o processo de avaliação quantitativa, oferecendo também espaço para feedback individualizado. Tal abordagem visa essencialmente enriquecer a experiência educacional tanto para os educadores quanto para os alunos. Para alcançar tal feito, adotou-se e documentou-se os passos adotados a partir de uma metodologia híbrida que combina os fundamentos da Design Science Research (DSR) com as estratégias ágeis da metodologia Scrum. Esse enfoque interdisciplinar busca promover a inovação e a eficiência no desenvolvimento do software, alinhando-se assim com as necessidades contemporâneas do setor educacional. O TCC inclui uma revisão teórica que examina o uso histórico e atual dos questionários na avaliação educacional, assim como uma discussão sobre a DSR e sua relevância para a criação de soluções tecnológicas no campo da educação. A metodologia de pesquisa detalha a aplicação dos seis passos da DSR, culminando no desenvolvimento do conhecimento de design sobre a problemática abordada e no artefato de solução desta problemática representado pelo ICQuiz. O processo de desenvolvimento é exposto, enfatizando a demonstração e avaliação do software em ambientes simulados. Os resultados alcançados destacam uma aceitação do ICQuiz, reconhecendo sua adaptabilidade, eficiência e contribuição para o aprimoramento da avaliação educacional. A pesquisa sugere que o ICQuiz pode servir como um modelo para o desenvolvimento futuro de ferramentas de avaliação que atendam às necessidades dos educadores contemporâneos e promovam um ambiente de aprendizado mais interativo e engajador. Concluímos o trabalho com reflexões sobre as contribuições práticas e teóricas do estudo, além de recomendações para pesquisas futuras que possam validar e expandir o uso do ICQuiz. Este TCC representa um passo significativo em direção à integração de metodologias tradicionais e modernas na avaliação educacional, buscando melhorar contínua e sistematicamente o processo de ensino-aprendizagem.","In this Undergraduate thesis, we investigate the effectiveness of questionnaires as a tool for educational assessment and the applicability of the Design Science Research (DSR) methodology in software development. The motivation for this research stemmed from the need to modernize educational assessment practices by adapting them to better meet the demands of the digital age and new paradigms of teaching and learning. The aim of this study was to develop ICQuiz, an online questionnaire system. This system is distinguished not only by its functionality for registering questions but also by its ability to automate the process of quantitative assessment, providing space for individualized feedback. This approach aims primarily to enrich the educational experience for both educators and students. To achieve this, we adopted and documented steps from a hybrid methodology combining the principles of Design Science Research (DSR) with the agile strategies of the Scrum methodology. This interdisciplinary approach seeks to promote innovation and efficiency in software development, thus aligning with contemporary needs of the educational sector. The Undergraduate thesis includes a theoretical review that examines the historical and current use of questionnaires in educational assessment, as well as a discussion on DSR and its relevance for creating technological solutions in the field of education. The research methodology details the application of the six steps of DSR, culminating in the development of design knowledge on the addressed problem and the solution artifact represented by ICQuiz. The development process is outlined, emphasizing the demonstration and evaluation of the software in simulated environments. The results achieved highlight the acceptance of ICQuiz, recognizing its adaptability, efficiency, and contribution to enhancing educational assessment. The research suggests that ICQuiz could serve as a model for the future development of assessment tools that meet the needs of contemporary educators and promote a more interactive and engaging learning environment. We conclude the study with eflections on the practical and theoretical contributions of the research, as well as recommendations for future research that may validate and expand the use of ICQuiz. This Capstone Project represents a significant step towards integrating traditional and modern methodologies in educational assessment, aiming to continuously and systematically improve the teaching-learning process.","('Questionário', 'Avaliação educacional', 'Design Science Research (DSR)', 'Software', 'Questionnaire', 'Assessment', 'Programming', 'Design Science Research')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/14751","2023-10-30","https://www.repositorio.ufal.br/bitstream/123456789/14751/1/Desenvolvimento%20de%20um%20question%c3%a1rio%20avaliativo%20a%20partir%20da%20metodologia%20Design%20Science%20Research.pdf","","('Roberta Vilhena Vieira Lopes',)"
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/14963","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Avaliação de risco em redes 802.11n: uma abordagem baseada em árvores de ataque","('Paloma da Silva Lacerda dos Santos',)","('Almir Pereira Guimarães',)","('Petrúcio Antônio Medeiros Barros', 'Rômulo Nunes de Oliveira')","Com o avanço da tecnologia e a crescente integração das redes wi-fi em diversos aspectos da vida moderna, desde ambientes domésticos até ambientes corporativos e públicos, surge um desafio crítico: garantir a segurança dessas redes. O padrão IEEE 802.11, amplamente utilizado em redes wi-fi, enfrenta uma variedade de ameaças cibernéticas que podem comprometer a integridade, confidencialidade e disponibilidade dos dados transmitidos. Nesse contexto, este estudo propõe uma avaliação abrangente de risco, tanto quantitativa quanto qualitativa, com o objetivo de identificar e analisar essas ameaças. O problema central reside na necessidade de estimar os danos associados a cada ameaça, visando orientar a implementação de medidas de segurança eficazes para proteger as redes wi-fi e os dados dos usuários. Os objetivos deste trabalho incluem compreender a natureza das ameaças em redes wi-fi, calculando parâmetros associados a estas ameaças e fornecer insights para profissionais de segurança na tomada de decisões informadas. A abordagem metodológica empregada consiste na construção de árvores de ataque, utilizando métricas comportamentais associadas ao sistema. Foram consideradas variáveis como a notabilidade, habilidade técnica, custo e impacto das ameaças, baseadas no nível de exposição dos sistemas alvo. Os resultados obtidos fornecem uma visão detalhada do risco associado às ameaças em redes wi-fi, permitindo uma compreensão mais profunda dos desafios de segurança enfrentados por organizações e usuários individuais.","With the advancement of technology and the increasing integration of wi-fi networks in various aspects of modern life, from domestic to corporate and public environments, a critical challenge has arisen: guaranteeing the security of these networks. The IEEE 802.11 standard, widely used in wi-fi networks, faces a variety of cyber threats that can compromise the integrity, confidentiality and availability of transmitted data. In this context, this study proposes a comprehensive risk assessment, both quantitative and qualitative, with the aim of identifying and analyzing these threats. The central problem lies in the need to estimate the damage associated with each threat, in order to guide the implementation of effective security measures to protect Wi-Fi networks and user data. The objectives of this work include understanding the nature of threats in Wi-Fi networks, calculating parameters associated with these threats and providing insights for security professionals to make informed decisions. The methodological approach employed consists of constructing attack trees using behavioral metrics associated with the system. Variables such as notability, technical skill, cost and impact of the threats were considered, based on the level of exposure of the target systems. The results obtained provide a detailed view of the risk associated with threats in Wi-Fi networks, allowing for a deeper understanding of the security challenges faced by these systems.","('Avaliação de risco', 'Redes Wi-Fi (IEEE 802.11)', 'Modelagem de ameaças', 'Segurança de redes', 'Árvores de ataque', 'Negação de serviço', 'Eavesdrop', 'EvilTwin', 'Risk assessment', 'Wi-fi networks', 'IEEE 802.11', 'Threat modeling', 'Attack trees', 'Network security', 'Denial of service', 'Eavesdrop', 'EvilTwin')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/14963","2024-04-03","https://www.repositorio.ufal.br/bitstream/123456789/14963/1/Avalia%c3%a7%c3%a3o%20de%20risco%20em%20redes%20802.11n_uma%20abordagem%20baseada%20em%20%c3%a1rvores%20de%20ataque.pdf","",""
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/17136","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Caracterização de técnicas de aprendizado de máquina para classificação de reatividade entre compostos e proteínas","('Danilo Vasconcelos Freire',)","('André Luiz Lins de Aquino',)","('Amanda Lima Cunha', 'Gean da Silva Santos')","Este trabalho teve como objetivo investigar a previsão binária de reatividade entre compostos químicos e proteínas, utilizando a abordagem de Interação Droga-Alvo (DTI) por meio de diferentes modelos de aprendizado de máquina. A metodologia envolveu a segmentação de índices de reatividade catalogados em grupos de reagentes e não reagentes, a construção de bases de dados para cada composto-alvo e a extração de vetores de características proteicas utilizando diversos padrões, como APAAC, CTDD, CTRiad, DDE, Geary, K-SEP PSSM, PFAM, QSO e SPMAP. Os dados foram coletados a partir da base ChEMBL, e a representação proteica foi obtida da base UniProt. A classificação binária foi realizada separando os valores de reatividade em reagentes e não reagentes, com a conversão em 1 e 0, respectivamente. Para a análise, foram aplicados modelos de classificação, incluindo Random Forest, KNN, SVM, MLP, XGBoost e Dummy Classifier, com otimização de hiperparâmetros utilizando o algoritmo Grid Search. Os resultados mostraram que, embora nenhum modelo tenha se destacado consistentemente em desempenho, alguns pares de modelo-característica apresentaram resultados promissores. O XGBoost com o vetor CTriad obteve uma média de acurácia de 72,78%, enquanto o DDE com Random Forest alcançou 71,08%. O modelo MLP, por outro lado, apresentou desempenho abaixo da média, possivelmente devido à escassez de dados na base. A análise detalhada dos resultados revelou que o XGBoost e o Random Forest se destacaram em termos de performance, especialmente em conjuntos de dados com menor quantidade de amostras, como o composto ChEMBL104. O KNN e o K-SEP PSSM também mostraram resultados acima da média, enquanto o SVM, utilizando o vetor Geary, apresentou uma das melhores performances em muitos compostos, embora tenha enfrentado limitações em alguns casos. Esses achados sugerem que a escolha do modelo e do vetor de características é crucial para a eficácia da predição de reatividade entre compostos e proteínas. A pesquisa destaca a importância de uma investigação mais aprofundada sobre as interações entre os modelos e as características, bem como a necessidade de um maior volume de dados para melhorar a generalização e a consistência dos modelos mais complexos.","This work aimed to investigate the binary prediction of reactivity between chemical compounds and proteins, using the Drug-Target Interaction (DTI) approach through different machine learning models. The methodology involved segmenting cataloged reactivity indices into groups of reactive and non-reactive compounds, constructing databases for each target compound, and extracting protein feature vectors using various patterns, such as APAAC, CTDD, CTRiad, DDE, Geary, K-SEP PSSM, PFAM, QSO, and SPMAP. The data were collected from the ChEMBL database, and the protein representation was obtained from the UniProt database. The binary classification was performed by separating the reactivity values into reactive and non-reactive, converting them to 1 and 0, respectively. For the analysis, classification models were applied, including Random Forest, KNN, SVM, MLP, XGBoost, and Dummy Classifier, with hyperparameter optimization using the Grid Search algorithm. The results showed that, although no model consistently outperformed the others, some model-feature pairs presented promising results. XGBoost with the CTriad vector achieved an average accuracy of 72.78%, while DDE with Random Forest reached 71.08%. The MLP model, on the other hand, exhibited below-average performance, possibly due to the scarcity of data in the dataset. A detailed analysis of the results revealed that XGBoost and Random Forest excelled in terms of performance, especially in datasets with a smaller number of samples, such as the ChEMBL104 compound. KNN and K-SEP PSSM also showed above-average results, while SVM, using the Geary vector, demonstrated one of the best performances across many compounds, although it faced limitations in some cases. These findings suggest that the choice of model and feature vector is crucial for the effectiveness of predicting reactivity between compounds and proteins. The research highlights the importance of further investigation into the interactions between models and features, as well as the need for a larger volume of data to improve the generalization and consistency of more complex models.","('Classificação reativa', 'Vetores de representação proteica', 'Interações droga-alvo', 'Aprendizado de máquina', 'Reactive classification', 'Protein feature vectors', 'Drug-target interactions', 'Machine Learning')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/17136","2024-12-06","https://www.repositorio.ufal.br/bitstream/123456789/17136/1/Caracteriza%c3%a7%c3%a3o%20de%20t%c3%a9cnicas%20de%20aprendizado%20de%20m%c3%a1quina%20para%20classifica%c3%a7%c3%a3o%20de%20reatividade%20entre%20compostos%20e%20prote%c3%adnas.pdf","",""
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/17327","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","CLaRiCe: uma abordagem neural para a correção automática de redações","('João Vitor Santos Tavares',)","('Roberta Vilhena Vieira Lopes',)","('Diego Dermeval de Medeiros da Cunha Matos', 'Aydano Pamponet Machado')","Escrever é uma importante habilidade que adquirimos ao iniciar nossos estudos, sendo utilizada em diversas ocasiões para aquisição, representação, avaliação de conhecimentos, como realizado em meios avaliativos como o ENEM, e entretenimento como no meio literário. Diversos trabalhos anteriores realizaram uma exploração acerca de correção automática de textos dissertativos-argumentativos, mas não chegaram a realizar uma análise e comparação profundas acerca do uso de modelos neurais. A realização de experimentos com a base Extended Essay-BR demonstrou que os modelos convolucionais se sobressaem na tarefa de regressão, atingindo um Erro Absoluto Médio que varia de 15.24 a 21.48 dentre as cinco competências, proporcionando um modelo capaz de realizar uma boa correção simultânea das cinco competências.","Writing is an important skill that we acquire when starting our studies, being used on several occasions for acquisition, representation, evaluation of knowledge, as carried out in evaluation media such as ENEM, and entertainment as in the literary environment. Several previous works explored the automatic correction of essay-argumentative texts, but did not carry out an in-depth analysis and comparison of the use of neural models. Carrying out experiments with the Extended Essay-BR database demonstrated that convolutional models excel in the regression task, reaching an Mean Absolute Error that varies from 15.24 to 21.48 among the five skills, providing a model capable of performing a good simultaneous correction of five skills.","('Processamento de Linguagem Natural', 'Correção de redações', 'Aprendizagem Profunda', 'Regressão aplicada a textos', 'Redes Neurais Artificiais', 'Natural Language Processing', 'Essay correction', 'Deep Learning', 'Text-applied regression', 'Artificial Neural Networks')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/17327","2024-12-03","https://www.repositorio.ufal.br/bitstream/123456789/17327/1/CLaRiCe_uma%20abordagem%20neural%20para%20a%20corre%c3%a7%c3%a3o%20autom%c3%a1tica%20de%20reda%c3%a7%c3%b5es.pdf","","('Luiz Antônio Lima Rodrigues',)"
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/16959","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Avaliação de uma metodologia para recomendação de vestuário com base em similaridade utilizando a arquitetura YOLO e extração de características com DINOv2","('Pedro Mateus Veras Simões',)","('Thales Miranda de Almeida Vieira',)","('Evandro de Barros Costa', 'José Antão Beltrão Moura')","Um sistema de recomendação tem como objetivo sugerir novos itens ao usuário com base em suas preferências. Este trabalho propõe avaliar uma metodologia de recomendação de vestuário baseada em similaridade visual, na qual o usuário insere uma imagem de uma peça de roupa de interesse. O modelo de detecção de objetos YOLOv11 identifica todas as peças de vestuário presentes na imagem, e o usuário seleciona a peça de interesse, enquanto o modelo DINOv2 é utilizado para a extração de suas características visuais. Em seguida, o método envolve a realização de uma busca por peças similares na base de dados DeepFashion2, utilizando a distância euclidiana entre as características geradas. Os resultados mostram que o YOLOv11 obteve bons valores de mAP50, especialmente em experimentos com maior volume de dados de treino. No entanto, dificuldades foram encontradas na diferenciação de classes visualmente semelhantes, sugerindo possíveis ajustes na base de dados. O estudo conclui que a metodologia é viável para aplicação em sistemas de recomendação de vestuário baseados em imagens.","A recommendation system aims to suggest new items to the user based on their preferences. This work proposes evaluating a clothing recommendation methodology based on visual similarity, where the user inputs an image of a clothing item of interest. The YOLOv11 object detection model identifies all clothing items present in the image, and the user selects the item of interest, while the DINOv2 model is used for extracting its visual features. Next, the method involves performing a search for similar items in the DeepFashion2 database, using the Euclidean distance between the generated features. The results show that YOLOv11 achieved good mAP50 values, especially in experiments with a larger volume of training data. However, challenges were encountered in distinguishing visually similar classes, suggesting possible adjustments to the database. The study concludes that the methodology is viable for application in image-based clothing recommendation systems.","('Detecção de Objetos', 'Yolo (Algoritmo)', 'Sistema de recomendação -Vestuário', 'Similaridade', 'Object Detection', 'Yolo (Algorithm)', 'Clothing Recommendation System', 'Similarity')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/16959","2024-11-28","https://www.repositorio.ufal.br/bitstream/123456789/16959/1/Avalia%c3%a7%c3%a3o%20de%20uma%20metodologia%20para%20recomenda%c3%a7%c3%a3o%20de%20vestu%c3%a1rio%20com%20base%20em%20similaridade%20utilizando%20a%20arquitetura%20YOLO%20e%20extra%c3%a7%c3%a3o%20de%20caracter%c3%adsticas%20com%20DINOv2.pdf","",""
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/17246","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Avaliação da percepção de professores e estudantes em relação ao feedback semiautomático e recomendações de estudo","('Priscila Teodório da Silva',)","('Ranilson Oscar Araújo Paiva',)","('Glauber Rodrigues Leite', 'Jeane Félix da Silva')","O feedback educacional desempenha um papel crucial no desenvolvimento acadêmico dos estudantes, e a personalização desse feedback pode ser uma ferramenta poderosa para aumentar a eficácia do processo de ensino-aprendizagem. Este trabalho propõe o desenvolvimento e a avaliação de módulos em um sistema chamado Partner, destinado a fornecer feedback semiautomatizado e recomendações personalizadas para alunos e ajudar os professores a fornecerem isso. O sistema é projetado para alinhar-se com a Base Nacional Comum Curricular (BNCC), ajudando na adaptação do ensino de acordo com as competências e habilidades exigidas. O trabalho aborda a criação de dois módulos principais do sistema: o S-Partner, voltado para os alunos, e o T-Partner, voltado para os professores, ambos oferecendo recomendações baseadas no desempenho dos alunos e em suas interações com o conteúdo. A metodologia adotada envolveu o teste do sistema em um ambiente controlado, com a participação de professores e alunos, cujos dados foram coletados por meio de questionários. Uma análise estatística foi realizada para entender a percepção dos alunos sobre a facilidade e utilidade do feedback e das recomendações oferecidas e a percepção e aceitação dos professores sobre a maneira que eles podem oferecer isso por meio do sistema. O objetivo foi avaliar a aceitação do sistema, sua aplicabilidade e as melhorias que ele poderia proporcionar na prática pedagógica. A análise dos resultados permitiu identificar os pontos fortes e as limitações do sistema, sugerindo melhorias para a implementação em larga escala.","Educational feedback plays a crucial role in the academic development of students, and the personalization of this feedback can be a powerful tool to enhance the effectiveness of the teaching-learning process. This study proposes the development and evaluation of modules in a system called Partner, designed to provide semi-automated feedback and personalized recommendations for students and to help teachers deliver them. The system is designed to align with the National Common Curricular Base (BNCC), aiding in the adaptation of teaching according to the required competencies and skills. The study focuses on the creation of two main modules in the system: the S-Partner, aimed at students, and the T-Partner, intended for teachers, both offering recommendations based on student performance and their interactions with the content. The methodology involved testing the system in a controlled environment, with the participation of teachers and students, whose data were collected through questionnaires. A statistical analysis was conducted to understand students’ perceptions regarding the ease and usefulness of the feedback and recommendations provided, as well as teachers’ perceptions and acceptance of how they can offer this support through the system. The objective was to assess the system’s acceptance, its applicability, and the improvements it could bring to pedagogical practices. The analysis of the results allowed the identification of the system’s strengths and limitations, suggesting improvements for large-scale implementation.","('Base Nacional Comum Curricular', 'Educação -Feedback', 'Ensino -Personalização', 'Sistemas de recomendação', 'Ensino adaptativo', 'Professores -Percepção', 'National Common Curriculum Base', 'Education -Feedback', 'Teaching -Personalization', 'Recommendation systems', 'Adaptive teaching', 'Teachers -Perception')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/17246","2024-12-18","https://www.repositorio.ufal.br/bitstream/123456789/17246/3/Avalia%c3%a7%c3%a3o%20da%20percep%c3%a7%c3%a3o%20de%20professores%20e%20estudantes%20em%20rela%c3%a7%c3%a3o%20ao%20feedback%20semiautom%c3%a1tico%20e%20recomenda%c3%a7%c3%b5es%20de%20estudo.pdf","Assessment of teachers' and students' perceptions of semi-automatic feedback and study recommendations","('Ibsen Mateus Bittencourt Santana Pinto',)"
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/16894","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Aplicação de aprendizado de máquina na identificação de reações de pragas a compostos semioquímicos","('Elias Nogueira da Silva',)","('André Luiz Lins de Aquino',)","('Douglas Leite Leal Moura', 'Eliane dos Santos', 'Josias Jordão Andrade Alves')","Este trabalho investiga a aplicação de técnicas de aprendizado de máquina para identificar reações de pragas a compostos semioquímicos. As séries temporais analisadas foram obtidas a partir de dados de reações de insetos por eletroantenografia (EAG) e respostas de um sistema de cromatografia gasosa com detector de ionização de chama (GC-FID). O pipeline metodológico desenvolvido inclui etapas de pré-processamento, como a remoção de dados não utilizáveis, padronização e equalização de frequências entre as séries, utilizando duas abordagens distintas: remoção de dados excedentes e interpolação. Para unificar os sinais de cada experimento, foi aplicado o valor mínimo absoluto entre as séries, técnica que preserva picos simultâneos — potencialmente correspondentes às reações dos insetos aos semioquímicos — enquanto reduz picos isolados considerados ruídos. As séries unificadas foram então analisadas por modelos de aprendizado de máquina para detecção de anomalias, incluindo K-Means e Isolation Forest. A análise comparativa das abordagens de equalização indicou que o impacto da interpolação foi baixo, com influência mínima sobre o desempenho do K-Means. Ambos os modelos apresentaram bons resultados na identificação das reações, destacando-se o K-Means com janelas deslizantes como o mais eficaz para a detecção das respostas.","This study explores the application of machine learning techniques to identify pest reactions to semiochemical compounds. The analyzed time series consist of insect reaction data obtained through electroantennography (EAG) and responses from a gas chromatography system with flame ionization detector (GC-FID). The developed methodological pipeline includes preprocessing steps such as removal of unusable data, data standardization, and frequency equalization between the series using two distinct approaches: removal of excess data and interpolation. To unify the signals in each experiment, the minimum absolute value between the series was applied, a technique that preserves simultaneous peaks—potentially corresponding to insect reactions to semiochemicals—while reducing isolated peaks considered noise. The unified series were then analyzed using machine learning models for anomaly detection, including K-Means and Isolation Forest. A comparative analysis of the equalization approaches showed that the impact of interpolation was low, with minimal influence on K-Means performance. Both models achieved good results in detecting reactions, with K-Means using sliding windows being the most effective for identifying the responses.","('Aprendizagem de Máquina', 'Séries temporais', 'Cromatografia gasosa', 'Eletroantenografia', 'Machine learning', 'Time series', 'Electroantennography', 'Gas chromatography')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/16894","2024-12-06","https://www.repositorio.ufal.br/bitstream/123456789/16894/1/Aplica%c3%a7%c3%a3o%20de%20aprendizado%20de%20m%c3%a1quina%20na%20identifica%c3%a7%c3%a3o%20de%20rea%c3%a7%c3%b5es%20de%20pragas%20a%20compostos%20semioqu%c3%admicos.pdf","","('Danilo Fernandes Costa',)"
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/17340","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Uma análise temporal do abandono escolar em Alagoas : aspectos geográficos e fatores externos","('Matheus Feitosa Ramos',)","('Bruno Almeida Pimentel',)","('Glauber Rodrigues Leite', 'Ícaro Bezerra Queiroz de Araújo')","O abandono escolar é um dos principais desafios enfrentados pela educação brasileira, caracte rizado por sua natureza multicausal e seu impacto potencial de interromper permanentemente a trajetória acadêmica dos indivíduos, com reflexos profundos em toda a sociedade. Esta pesquisa busca contribuir para as discussões sobre o abandono escolar no Brasil, com foco no estado de Alagoas, abrangendo o ensino fundamental e médio. Para isso, realiza-se uma análise explo ratória extensiva dos dados disponibilizados pelo INEP, referentes ao período de 1996 a 2022. Além disso, examina-se a literatura existente sobre as principais causas do abandono escolar — predominantemente financeiras e educacionais — e as possíveis soluções para esse problema. O estudo visa identificar as características associadas aos maiores índices de abandono e ana lisar como fatores recorrentes, como mudanças governamentais, e eventos imprevistos, como crises financeiras e a pandemia da Covid-19, impactaram as escolas de Alagoas em relação ao abandono estudantil.","School dropout is one of the main challenges faced by Brazilian education, characterized by its multifactorial nature and its potential to permanently interrupting the academic trajectory of in dividuals, with profound repercussions on society as a whole.This research aims to contribute to discussions about school dropout rates in Brazil, focusing on the state of Alagoas and covering elementary and secondary education. For this, an extensive exploratory analysis is conducted using data provided by INEP for the period from 1996 to 2022. In addition, the existing li terature on the main causes of school dropout — predominantly financial and educational — and potential solutions to this issue is examined. The study seeks to identify the characteristics associated with the highest dropout rates and analyze how recurring factors, such as govern mental changes, and unforeseen events, such as financial crises and the Covid-19 pandemic, have impacted schools in Alagoas in relation to student dropout.","('Educação em Alagoas', 'Análise de dados', 'Abandono escolar', 'Série temporal', 'Data Analysis', 'School Dropout', 'Time Series', 'Education in Alagoas', 'Govern ment Exchanges', 'Financial Crises', 'Hydrological Events', 'Pandemic: Covid-19')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/17340","2024-11-28","https://www.repositorio.ufal.br/bitstream/123456789/17340/1/Uma%20an%c3%a1lise%20temporal%20do%20abandono%20escolar%20em%20Alagoas%20%20aspectos%20geogr%c3%a1ficos%20e%20%20fatores%20externos.pdf","",""
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/15619","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Aplicação de learning analytics para fomentar a autorregulação da aprendizagem na educação híbrida","('João Victor Falcão Santos Lima',)","('Ranilson Oscar Araújo Paiva',)","('André Magno Costa de Araújo', 'Bruno Almeida Pimentel')","A Educação Híbrida é uma modalidade pedagógica que combina os ambientes presencial e online e vem ganhando bastante atenção nos últimos anos. Entre seus benefícios, há mais autonomia e flexibilidade para os estudantes; em contrapartida, eles precisam de habilidades de autorregulação da aprendizagem para planejar e cumprir as atividades necessárias. Além disso, existem evidências que indicam uma correlação positiva entre o desenvolvimento destas habilidades e o desempenho obtido pelo estudante. Portanto, o presente estudo propõe o uso de intervenções de Learning Analytics para fomentar a autorregulação da aprendizagem na educação híbrida. Foi desenvolvido um painel de bordo (dashboard) com visualizações de dados e recomendações relacionadas à aprendizagem autorregulada na educação híbrida. Um experimento foi conduzido para avaliar as habilidades de autorregulação de estudantes em uma disciplina de graduação na modalidade híbrida através do instrumento Online Self-Regulated Learning Questionnaire (OSLQ) e também coletar suas percepções acerca do uso do dashboard proposto. Os resultados sugerem percepções positivas sobre o painel de bordo desenvolvido, especialmente com o reconhecimento de sua utilidade para apoiar as etapas envolvidas no processo de autorregulação da aprendizagem.","Blended Learning is an educational modality that combines face-to-face and online environments and has been gaining attention in recent years. Among its benefits, there is more autonomy and flexibility for students; conversely, they need self-regulated learning skills to plan and carry out necessary activities. Furthermore, there is evidence that indicates a positive correlation between the development of these skills and student’s academic performance. Therefore, the present study proposes the use of Learning Analytics interventions to encourage self-regulated learning in blended learning. A dashboard was developed with data visualizations and recommendations related to self-regulated learning in blended learning. An experiment was conducted to evaluate the self-regulation skills of students in a blended undergraduate course using the Online Self-Regulated Learning Questionnaire (OSLQ) and also collect their perceptions regarding the use of the proposed dashboard. The results suggest positive perceptions about the developed dashboard, especially with the recognition of its usefulness in supporting the steps involved in self-regulated learning process.","('Educação híbrida', 'Autorregulação da aprendizagem', 'Learning Analytics', 'Dashboard', 'Self-regulated learning', 'Blended learning', 'OSLQ')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/15619","2024-06-12","https://www.repositorio.ufal.br/bitstream/123456789/15619/1/Aplica%c3%a7%c3%a3o%20de%20learning%20analytics%20para%20fomentar%20a%20autorregula%c3%a7%c3%a3o%20da%20aprendizagem%20na%20educa%c3%a7%c3%a3o%20h%c3%adbrida.pdf","","('Ibsen Mateus Bittencourt Santana Pinto',)"
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/11409","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Uma aplicação descentralizada (dApp / Web3.0) para registros de autorias em blockchain","('Lucas dos Santos Sales',)","('Leandro Melo de Sales',)","('Eduardo Setton Sampaio da Silveira', 'Fellipe Chargel')","Requisitar o registro de uma obra é um processo que requer paciência. O processo, atualmente, requer que haja muita documentação, exemplares físicos do trabalho e deve ser enviado para um órgão específico que irá, manualmente, realizar todo o processo de verificação e validação para oficializar o registro do autor. O uso de tecnologias blockchain para registros é uma questão que vem sendo bastante discutida. As suas características de imutabilidade e transparência permitem uma maior confiabilidade na hora de submeter um registro na rede. Com o avanço de suas tecnologias, um novo modelo de negócios baseado em uma ferramenta emergente chamada NFT (Non-Fungible Token) tem ganhado bastante notoriedade por permitir que artistas pudessem ter mais controle e retorno financeiro com suas artes na Internet. Com isso em mente, este trabalho vem com o intuito de demonstrar um exemplo de aplicação web que consegue replicar o processo de registro de forma totalmente digital gerando um NFT na rede Ethereum que representa o registro de autoria de uma obra digitalizada no formato PDF de forma mais rápida que a usual.","Requesting or registering a work is a process that requires patience. The process, nowadays, requires lots of documentation, physical specimens of the work and it must be sent to an specific agency that will manually carry out the entire process of verification and validation to make the author’s registration official. The use of Blockchain technologies for records is an issue that has been widely discussed. Its immutability and transparency characteristics allow greater reliability when submitting a record on the network. As their technologies advance, a new bussiness model based in an emerging tool called NFT (Non-Fungible Token) has gained considerable notoriety for allowing artists to have more control and financial feedback with their arts on internet. With this in mind, this work comes with the objective of demonstrate an example of web application that can replicate the register process in digital way minting an NFT on Ethereum network that representates the authory register of a digital work in PDF format faster than usual.","('Direito autoral', 'Tecnologia blockchain', 'Non-Fungible Token', 'Copyright')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/11409","2022-11-07","https://www.repositorio.ufal.br/bitstream/123456789/11409/1/Uma%20Aplica%c3%a7%c3%a3o%20Descentralizada%20%28dApp%20-%20Web3.0%29%20para%20Registros%20de%20Autorias%20em%20Blockchain%20%281%29.pdf","",""
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/16094","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Análise dos principais tipos de ataques em redes sem fio IEEE 802.11N","('Leandro Miguel dos Santos',)","('Almir Pereira Guimarães',)","('Petrúcio Antônio Medeiros Barros', 'Giancarlo Lima Torres')","As redes sem fio representam uma evolução significativa no campo das comunicações, oferecendo conectividade sem a necessidade de cabos e permitindo que os dispositivos se comuniquem por meio de radiofrequência. A evolução contínua destas redes e sua ampla adoção as tornam essenciais em diversos contextos impulsionando a busca por segurança e eficiência na transmissão de dados, tornando-as uma parte fundamental da infraestrutura de comunicação moderna. No entanto, a segurança em redes sem fio é uma preocupação crescente devido à sua ampla adoção e à natureza inerentemente vulnerável dessas infraestruturas. O advento destas redes trouxe consigo uma série de vantagens em termos de desempenho e alcance, no entanto introduziu novos desafios relativos à segurança. Este estudo visa analisar os principais tipos de ataques em redes sem fio, com foco no padrão IEEE 802.11n, a fim de identificar fragilidades relacionadas à segurança e propor contramedidas para os ataques abordados. Durante os testes realizados, foram executados ataques de eavesdropping, desautenticação, captura de handshake, força bruta, entre outros, utilizando ferramentas como AirCrack-ng, Hping3, Nmap, Hashcat e outras para explorar vulnerabilidades em redes wireless IEEE 802.11n. Os experimentos mostraram que os ataques podem causar impacto significativo em redes sem fio. O ataque de inundação de SYN causou indisponibilidade do serviço no ponto de acesso. O ataque de desautenticação foi eficaz em redes com protocolos WPA e WPA2. O ataque AssRF resultou em negação de serviço ao consumir excessivamente a memória do ponto de acesso, enquanto o ataque AuthRF aumentou o consumo de CPU, prejudicando o desempenho do ponto de acesso. O eavesdropping mostrou-se eficiente na captura de handshakes nos protocolos WPA e WPA2. Finalmente, a quebra de senha foi eficaz contra senhas fracas, destacando a importância de políticas robustas de senhas para resistir a esse tipo de ataque.","Wireless networks represent a significant evolution in the field of communications, offering connectivity without the need for cables and allowing devices to communicate via radio frequency. The continuous evolution of these networks and their widespread adoption makes them essential in a variety of contexts, driving the search for security and efficiency in data transmission, making them a fundamental part of the modern communications infrastructure. However, security in wireless networks is a growing concern due to their widespread adoption and the inherently vulnerable nature of these infrastructures. The advent of these networks has brought with it a number of advantages in terms of performance and range, but has also introduced new security challenges. This study aims to analyze the main types of attacks on wireless networks, with a focus on the IEEE 802.11n standard, in order to identify security-related weaknesses and propose countermeasures for the attacks addressed. During the tests, attacks were carried out using eavesdropping, deauthentication, handshake capture, brute force, among others, using tools such as AirCrack-ng, Hping3, Nmap, Hashcat and others to exploit vulnerabilities in wireless IEEE 802.11n networks. The experiments showed that attacks can have a significant impact on wireless networks. The SYN flood attack caused service unavailability at the access point. The deauthentication attack was effective on networks with WPA and WPA2 protocols. The AssRF attack resulted in a denial of service by excessively consuming the access point’s memory, while the AuthRF attack increased CPU consumption, impairing the access point’s performance. The eavesdropping attack proved to be effective in capturing handshakes in the WPA and WPA2 protocols. Finally, password cracking was effective against weak passwords, highlighting the importance of robust password policies to resist this type of attack.","('Ataque em redes sem fio', 'IEEE 802.11N', 'Ataques cibernéticos', 'DoS', 'AssRF', 'AuthRF', 'Eavesdropping', 'Deauthentication')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/16094","2024-08-01","https://www.repositorio.ufal.br/bitstream/123456789/16094/1/An%c3%a1lise%20dos%20principais%20tipos%20de%20ataques%20em%20redes%20sem%20fio%20IEEE%20802.11N.pdf","",""
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/16767","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Aprendizado federado e mecanismos de privacidade diferencial para preservar dados sensíveis em treinamento de modelos de machine learning","('João Pedro Brito Tomé',)","('Erick de Andrade Barboza',)","('Glauber Rodrigues Leite', 'Jobson de Araújo Nascimento')","A medida que os dispositivos m´oveis continuam a evoluir, seus recursos de detecção e processamento atingiram níveis de sofisticação sem precedentes. Juntamente com os avanços na aprendizagem profunda, esse progresso abriu diversas oportunidades para aplicativos de alto impacto, principalmente em áreas como saúde e sistemas automotivos. A abordagem tradicional do aprendizado de máquina (ML) baseado em nuvem requer a agregação de dados em um servidor ou data center centralizado. No entanto, essa abordagem levanta problemas críticos de latência, comunicação ineficiente e privacidade de dados. As tecnologias predominantes de ML em redes m´oveis e distribuídas ainda exigem a divulgação de dados pessoais a partes externas. Recentemente, o conceito de Federated Learning (FL) foi introduzido em face da legislação de proteção de dados cada vez mais rigorosa e das crescentes preocupações com a privacidade. No FL, os dispositivos finais usam seus dados locais para treinar um modelo de ML solicitado pelo servidor. Em seguida, os dispositivos enviam atualizações ao modelo, em vez dos dados brutos, para o servidor para agregação. O Federated Learning (FL) tem o potencial de ser uma tecnologia revolucionária em redes móveis, pois permite o treinamento colaborativo de um modelo de ML e, ao mesmo tempo, preserva a privacidade do cliente. No entanto, informações privadas ainda podem ser descobertas por meio da análise de parâmetros carregados de clientes, por exemplo, pesos treinados em redes neurais profundas. O FL é suscetível a ataques de inferência, que podem ter origem em qualquer parte que contribua para o processo de treino. Nesse sentido, a Differential Privacy (DP) ´e uma técnica que introduz ruído estatístico controlado nos dados, impedindo a inferência de informações específicas de um participante, mesmo em circunstâncias adversas. Neste trabalho, a DP foi utilizada em combinação com diferentes mecanismos de ruído, como o laplaciano e o gaussiano, para analisar como a DP afeta a precisão do modelo enquanto tenta mitigar esses ataques durante o treino em ambiente de Aprendizagem Federada. Esta integração visa alcançar um equilíbrio entre a privacidade e o desempenho do modelo.","As mobile devices continue to evolve, their sensing and processing capabilities have reached unprecedented levels of sophistication. Coupled with advances in deep learning, this progress has opened up diverse opportunities for high-impact applications, particularly in areas such as healthcare and automotive systems. The traditional approach to cloud-based machine learning (ML) requires the aggregation of data on a centralised server or data centre. However, this approach raises critical issues of latency, inefficient commu nication and data privacy. The prevailing technologies for ML in mobile and distributed networks still require the disclosure of personal data to external parties. Recently, the concept of Federated Learning has been introduced in the face of increasingly stringent data protection legislation and growing privacy concerns. In FL, end devices use their local data to train an ML model that is then required by the server. The devices then send updates to the model, rather than the raw data, to the server for aggregation. Federated Learning (FL) has the potential to be a revolutionary technology in mobile networks as it enables collaborative training of an ML model while preserving client privacy. However, private information can still be discovered by analysing parameters loaded from clients, for example, weights trained on deep neural networks. FL is susceptible to inference attacks, which can originate from any party that contributes to the training process. In this sense, Differential Privacy (DP) is a technique that introduces controlled statistical noise into the data, preventing the inference of participant-specific information, even in adverse circumstances. In this work, DP was used in combination with different noise mechanisms, such as Laplacian and Gaussian, to analyse how DP affects model accuracy while trying to mitigate these attacks during training in a Federated Learning environment. This integration aims to achieve a balance between privacy and model performance.","('Aprendizado federado', 'Aprendizado de máquina', 'Privacidade de dados', 'Differential privacy', 'Federated Learning', 'Differential Privacy', 'Data Privacy', 'Inference Attacks', 'Machine Learning')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/16767","2024-12-05","https://www.repositorio.ufal.br/bitstream/123456789/16767/1/Aprendizado%20federado%20e%20mecanismos%20de%20privacidade%20diferencial%20para%20preservar%20dados%20sens%c3%adveis%20em%20treinamento%20de%20modelos%20de%20machine%20learning.pdf","",""
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/16577","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Análise temporal e causal das chamadas ao disque 180 e notícias do Ministério da Mulher: um estudo com técnicas de machine learning","('Murilo Urquiza Galvão Ribeiro',)","('André Luiz Lins de Aquino',)","('Douglas Leite Leal Moura', 'Fabiane da Silva Queiroz')","Este estudo investiga a influência das notícias divulgadas pelo Ministério da Mulher sobre o número de chamadas ao Disque 180, utilizando uma abordagem quantitativa que combina téc nicas de séries temporais e modelos estatísticos avançados. Foram analisadas séries temporais de notícias com e sem filtro específico para o tema de violência contra a mulher, para avaliar o impacto direto no comportamento de denúncia da população. Os métodos incluíram o processo gaussiano, a causalidade de Granger, o modelo de vetores autorregressivos (VAR) e a entropia de transferência. A aplicação de um filtro nas notícias resultou em uma previsão mais precisa e na identificação de uma relação mais forte entre as variáveis, destacando que campanhas e di vulgações diretamente focadas no tema promovem uma resposta mais imediata e consistente nas chamadas ao Disque 180. Os resultados reforçam a importância de uma comunicação pública segmentada e específica para influenciar positivamente o comportamento social de denúncia, oferecendo insights relevantes para políticas de conscientização e combate à violência contra a mulher.","This study explores the influence of news from the Ministry of Women on the number of calls to the Disque 180 helpline, utilizing a quantitative approach that combines time series techniques with advanced statistical models. Time series of news, both with and without a specific filter on the theme of violence against women, were analyzed to assess the direct impact on public re porting behavior. Methods included gaussian process, Granger causality, vector autoregressive (VAR) model and the transfer entropy. The application of a thematic filter to news data resulted in more accurate forecasts and a stronger identified relationship between variables, highlighting that focused campaigns and information directly related to violence against women elicit a more immediate and consistent response in calls to Disque 180. These results underscore the impor tance of segmented and specific public communication to positively influence social reporting behavior, providing valuable insights for awareness and anti-violence policy efforts.","('Machine learnig', 'Violência contra a mulher', 'Processos Gaussiano', 'Casualidade de Granger', 'Disque denúncia -Chamadas telefônicas', 'Modelo VAR', 'Violence against women', 'Gaussian process', 'Granger causality', 'Hotline -Phone calls', 'VAR Model')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/16577","2024-11-22","https://www.repositorio.ufal.br/bitstream/123456789/16577/1/An%c3%a1lise%20temporal%20e%20causal%20das%20chamadas%20ao%20disque%20180%20e%20not%c3%adcias%20do%20Minist%c3%a9rio%20da%20Mulher%20um%20estudo%20com%20t%c3%a9cnicas%20de%20machine%20learning.pdf","",""
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/17091","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Aplicações de técnicas de processamento de linguagem natural no direito e na comunicação","('Thalyssa de Almeida Monteiro',)","('André Lages Freitas',)","('Fábio José Coutinho da Silva', 'Orivaldo Vieira de Santana Júnior')","Processamento de Linguagem Natural (PLN) é uma área cujas aplicações se estendem por diversos setores. A capacidade de um computador compreender linguagens naturais serve de base para as mais diversas aplicações do cotidiano: Chatbots de atendimento em lojas, GPS com comandos por voz, resumo e análise de documentos, tradução automática, entre outras coisas. O objetivo deste trabalho é demonstrar exemplos de aplicações de técnicas de PLN em um contexto multidisciplinar, especificamente, no Direito e na Comunicação. As contribuições descritas neste trabalho incluem: Uma ferramenta de Extraction Transform Load (ETL) para o download de ementas dos sites do Supremo Tribunal Federal (STF) e Supremo Tribunal de Justiça (STJ), um modelo capaz de rotular automaticamente ementas de decisões judiciais, uma ferramenta que permite visualizar documentos jurídicos relacionados a decisões judiciais com base em seus conteúdos e um mínimo produto viável (MVP) aplica inteligência artificial generativa na análise de conteúdo para profissionais da comunicação. Com esse trabalho, concluiu-se que as técnicas de PLN e aprendizagem de máquina contribuem para uma análise de documentos eficiente, porém no caso das análises geradas com inteligência artificial generativa, é importante que o profissional responsável saiba verificar os dados gerados, uma vez que os modelos não verificam a veracidade dos fatos.","Natural Language Processing (NLP) is an area whose applications can be applied across several work fields. A computer’s ability to understand natural languages can be used for a wide range of everyday applications: Chatbots for customer service, GPS with voice commands, document summaries and analysis, automatic translation, and many others. The goal of this work is to demonstrate examples of applications of NLP techniques in a multidisciplinary context, specifically in Law and Communication. The contributions described in this work include: An Extraction Transform Load (ETL) tool for downloading legal decisions from the websites of the Brazilian Supreme Court (STF) and the Supreme Court of Justice (STJ), a model capable of automatically labeling court rulings, a tool that allows visualize legal documents related to court rulings based on their content, and a minimum viable product (MVP) that applies generative artificial intelligence to content analysis for communication professionals. With this work, it was concluded that NLP and machine learning techniques contribute to efficient document analysis, however, in the case of analyses generated with generative artificial intelligence, it is important that the responsible professional knows how to verify the data generated, since the models do not verify the veracity of the facts.","('Processamento de linguagem natural', 'Inteligência artificial generativa', 'ChatGPT', 'OpenAI', 'Natural Language Processing', 'Generative Artificial Inteligence')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/17091","2024-11-21","https://www.repositorio.ufal.br/bitstream/123456789/17091/3/Aplica%c3%a7%c3%b5es%20de%20t%c3%a9cnicas%20de%20processamento%20de%20linguagem%20natural%20no%20direito%20e%20na%20comunica%c3%a7%c3%a3o.pdf","","('Leonardo Viana Pereira',)"
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/13927","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Análise do desempenho de estudantes no ensino híbrido com base nas interações","('Michael Miller Rodrigues Cardoso',)","('Ranilson Oscar Araújo Paiva',)","('Ivo Augusto Andrade Rocha Calado', 'Bruno Almeida Pimentel')","O ensino híbrido é uma modalidade de ensino que integra abordagens do ensino presencial e online, que tem despertado interesse na área da educação por trazer maior flexibilidade para os alunos e professores, tendo sua definição básica mais recente dada por Garrison & Vaughan, em 2008. Dessa forma, é crucial explorar mais a fundo as interações e características gerais dessa modalidade de ensino, a fim de compreender seu impacto no desempenho acadêmico dos estudantes. Portanto, no presente trabalho, foi conduzido um estudo de caso em uma disciplina, ofertada no modelo híbrido de ensino, da Faculdade de Economia, Administração e Contabilidade (FEAC) da Universidade Federal de Alagoas (UFAL). Para tanto, foram analisados os dados referentes às interações dos estudantes com o ambiente de aprendizagem online utilizado e acerca das aulas e atividades presenciais. Foram realizadas transformações nos dados e aplicados algoritmos de aprendizagem de máquina não-supervisionados, para gerar um agrupamento dos estudantes em diferentes perfis de aprendizado, permitindo a identificação das características de cada tipo de aluno. Com isso, foram criadas visualizações das interações que tiveram maior influência nas notas dos alunos, foram identificados os perfis com diferentes níveis de desempenho e foram criadas recomendações personalizadas, a depender de como se deram as interações em cada grupo definido. Para validar os resultados da análise e o feedback gerado, foi conduzido um formulário de autoavaliação do desempenho, onde coletamos as percepções dos alunos e algumas sugestões de melhorias a serem aplicadas em futuros cursos no modelo híbrido. Portanto, o presente estudo gera informações relevantes acerca das interações e do desempenho dos estudantes em cursos híbridos. Conclui-se que o curso analisado teve pouca variedade de conteúdos na parte online, recomendando que sejam acrescentadas atividades com pontuação dentro do ambiente virtual de aprendizagem (AVA) e momentos no curso que pontuem a participação do aluno nas aulas, visando aprimorar futuras análises na identificação dos perfis de desempenho e no fornecimento de feedback aos alunos.","Blended learning is a mode of education that integrates aspects of both face-to-face and online teaching. It has garnered significant interest in the field of education due to the increased flexibility it offers to both students and educators. Its most recent fundamental definition was provided by Garrison & Vaughan in 2008. Thus, it is crucial to delve deeper into the interactions and general characteristics of this mode of education to comprehend its impact on students' academic performance. Consequently, in the present study, a case study was conducted in a course offered in the blended learning model at the Faculty of Economics, Administration, and Accounting (FEAC) at the Federal University of Alagoas (UFAL). To achieve this, data regarding student interactions with the online learning environment and in-person classes and activities were analyzed. Data transformations were applied, and unsupervised machine learning algorithms were utilized to cluster students into different learning profiles, enabling the identification of characteristics for each type of student. Subsequently, visualizations of interactions that had the most influence on students' grades were generated, profiles with different levels of performance were identified, and personalized recommendations were created depending on how interactions occurred in each defined group. To validate the analysis results and the generated feedback, a self-assessment performance form was administered, collecting students' perceptions and suggestions for improvements to be applied in future courses following the blended learning model. Consequently, this study generates valuable insights into student interactions and performance in blended courses. It is concluded that the analyzed course had limited online content variety, recommending the addition of activities with scoring within the virtual learning environment (VLE) and moments in the course that assess student participation in classes, aiming to enhance future analyses in identifying performance profiles and providing feedback to students.","('Ensino híbrido', 'Desempenho acadêmico', 'Interação aluno – ensino híbrido', 'Hybrid teaching', 'Academic performance', 'Student interactions', 'Student interaction – hybrid teaching')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/13927","2023-12-04","https://www.repositorio.ufal.br/bitstream/123456789/13927/1/An%c3%a1lise%20do%20desempenho%20de%20estudantes%20no%20ensino%20h%c3%adbrido%20com%20base%20nas%20intera%c3%a7%c3%b5es.pdf","","('Ibsen Mateus Bittencourt Santana Pinto',)"
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/12961","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Análise de critérios visando a distribuição de bolsas de monitoria para Instituições de Ensino Superior","('Karen Nayara Gomes da Silva',)","('Juliana Roberta Theodoro de Lima',)","('Rian Gabriel Santos Pinheiro', 'José Anderson de Lima e Silva', 'Dalgoberto Miquilino Pinho Júnior')","Com os sucessivos cortes que as Instituições Federais de Ensino Superior (IFES) vêm recebendo no decorrer dos anos, os programas e atividades de monitoria acabam sendo atingidos e não colocados como prioridade quando se trata do valor dos recursos que serão alocados a eles. Assim, cada bolsa recebida pelos Institutos e Faculdades são vistas de maneira valiosa, pois a sua escassez pode ser sentida por todos os campi. Deste modo, faz-se necessário haver uma forma na qual possam ser distribuídas do jeito mais otimizado e justo possível as vagas de bolsas remuneradas que chegam até os Institutos e Faculdades para serem repartidas pelo coordenador de monitoria. Neste trabalho, foi desenvolvido um programa implementado em C++ que realiza de forma automática a alocação de bolsas de monitoria de acordo com os pesos associados aos critérios para a seleção e ranqueamento das bolsas. Para a realização deste algoritmo, também foi necessário observar e avaliar os critérios e suas características que serão utilizados dentro dele, visto que esta parte do programa é crucial para o funcionamento e regulação correta do mesmo. Assim, foi pedido e analisado a avaliação de especialistas, através de um questionário qualitativo, dos critérios mais utilizados por 10 Universidades Federais renomadas do país, a fim de auxiliar na escolha dos pesos desses critérios. Com isso, o trabalho traz relevância e discussões signitifativas, além de que a importância do tema pode ser observada nas possíveis continuações em consequência desta monografia.","With the successive budget cuts that the Federal Institutions of Higher Education (IFES) have been receiving over the years, the monitoring programs and their activities are being affected by them since they are not considered a priority item inside the structure functioning of the university. For this reason, each scholarship received by the Institutes and colleges inside the IFES is seen as a valuable object, and its scarcity can be felt by all campuses. In resume, it is necessary to get a way to distribute such grants in the most optimized and fair way possible, by the monitoring coordinator. In this monograph, a program implemented in C++ was developed that automatically allocates monitoring grants according to their weights associated with criteria for their selection and ranking. Also, for the algorithm creation, it was necessary to observe and evaluate the criteria and their specifics that would be used within it, since this part of the program is crucial for its correct functioning and regulation. Besides it, an evaluation of experts was requested and analyzed, through a qualitative questionnaire, with strategies used by 10 remarkable Federal Universities in the country, in order to help by choosing the weights of these strategies. In this way, the work brings relevance and significant discussions, in addition to the importance of the theme can be observed in some possible continuations as consequences of this monograph.","('Bolsas acadêmicas – Monitoria', 'Processo decisório', 'Algoritmo guloso', 'C++ (Linguagem de programação)', 'Problema da mochila', 'Academic scholarships – Monitoring', 'Decision-making process', 'Greedy algorithms', 'C++ (Programming language)', 'Knapsack problem')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/12961","2022-12-16","https://www.repositorio.ufal.br/bitstream/123456789/12961/1/An%c3%a1lise%20de%20crit%c3%a9rios%20visando%20a%20distribui%c3%a7%c3%a3o%20de%20bolsas%20de%20monitoria%20para%20Institui%c3%a7%c3%b5es%20de%20Ensino%20Superior.pdf","","('Ranilson Oscar Araújo Paiva',)"
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/15868","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Sistema de monitoramento em tempo real do matricial do solo","('Maria Júlia de Oliveira Vieira',)","('Davi Bibiano Brito',)","('Erick de Andrade Barboza', 'Thiago Damasceno Cordeiro')","O presente trabalho tem por objetivo o desenvolvimento de um sistema de monitoramento em tempo real de sensores que realizam a medição do potencial matricial do solo. Baseados nos conceitos de Internet das Coisas (IoT) foi realizada a integração da coleta dos dados com um armazenamento em um servidor web, onde os dados dos sensores são enviados via conexão Wi-Fi e protocolo MQTT, permitindo acesso e visualização em tempo real dos dados. Visando uma maior reprodutibilidade, o sistema foi prototipado utilizando a plataforma NodeMCU-32S ESP32, responsável por fazer a leitura dos dados dos sensores e envio dos mesmos para monitoramento remoto. Através de constante monitoramento, é possível ter um controle maior dos insumos necessários para a produção agrícola. Para os recursos hídricos, cada vez mais escassos em várias regiões do planeta, é de suma importância o conhecimento das condições necessárias para acionar sua utilização no processo de irrigação. Com os dados necessários podemos evitar desperdícios, assim como ter o conhecimento do quanto e por quanto tempo é necessário irrigar. O monitoramento facilita o manejo desse recurso importantíssimo, e seu controle é possível utilizando sensores que auxiliam a verificação da umidade do solo, resultando em uma melhor utilização dos recursos hídricos disponíveis.","The present work aims to develop a real-time monitoring system of sensors that measure the soil matric potential. Based on the concepts of the Internet of Things (IoT), the integration of data collection with a storage on a web server was carried out, where sensor data is sent via Wi-Fi connection and the MQTT protocol, allowing real-time access and visualization of data. Aiming at greater reproducibility, the system was prototyped using the NodeMCU-32S ESP32 platform, which was responsible for eading the data from the sensors and sending them for remote monitoring. Through constant monitoring, it is possible to have greater control of the raw materials needed for agricultural production. For water resources, which are increasingly scarce in various regions of the planet, knowledge of the necessary conditions to trigger their use in the irrigation process is of great importance. With the necessary data, we can avoid waste, as well as having the knowledge of how much and for how long it is necessary to irrigate. Monitoring facilitates the management of this very important resource, and its control is only possible using sensors that help to verify soil moisture, resulting in a better use of available water resources.","('Solos – Potencial matricial', 'Monitoramento em tempo real', 'Umidade do solo', 'Soils – Matric potential', 'Real-time monitoring', 'Soil moisture')","Sistemas de Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/15868","2022-07-26","https://www.repositorio.ufal.br/bitstream/123456789/15868/1/Sistema%20de%20monitoramento%20em%20tempo%20real%20do%20matricial%20do%20solo.pdf","Real time monitoring system of soil matric pontential",""
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/14209","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Algoritmo GRASP-VND para o problema da máxima biclique balanceada com peso no vértice","('Lucas Montenegro Andrade Assunção',)","('Rian Gabriel Santos Pinheiro',)","('Bruno Costa e Silva Nogueira', 'Bruno José da Silva Barros')","Este trabalho aborda o problema da ""Máxima Biclique Balanceada com Peso nos Vértices"". Nesse contexto, o objetivo é identificar, em um grafo não direcionado com atributos de peso associados a seus vértices, uma biclique (subgrafo bipartite completo) balanceada que maximize a soma dos pesos. Este problema é notoriamente complexo, caindo na classe NP-difícil, e possui aplicações de grande relevância em diversas áreas. Apresentamos uma abordagem baseada na meta-heurística GRASP, complementada por uma busca local VND com estruturas de vizinhança e uma técnica de redução adaptada ao problema em questão. Avaliamos a eficácia da nossa proposta usando instâncias amplamente reconhecidas na literatura, como as DIMACS e BHOSLIB. Os resultados obtidos indicam que nosso algoritmo supera o algoritmo exato (CPLEX) em termos de eficiência, sendo capaz de encontrar todas as 80 soluções ótimas conhecidas em um tempo computacional reduzido. Por fim, nossa abordagem demonstrou excelentes resultados em instâncias mais desafiadoras, como as do conjunto KONECT, grafos de grande porte e esparsos. Nessas situações, a técnica de redução se mostrou altamente eficaz, eliminando até 99,78% dos vértices. Isso destaca a robustez e versatilidade da nossa metodologia na resolução do problema em diversos cenários, com implicações significativas nas aplicações práticas relacionadas.","This work addresses the problem of ""Maximum Balanced Weighted Vertex Biclique"". In this context, the objective is to identify, in an undirected graph with vertex-weight attributes, a balanced biclique (complete bipartite subgraph) that maximizes the sum of the weights. This problem is notably complex, falling into the NP-hard class, and has significant relevance in various domains. We present an approach based on the GRASP meta-heuristic, complemented by a VND local search with neighborhood structures and a reduction technique tailored to the problem at hand. We evaluated the effectiveness of our proposal using widely recognized instances in the literature, such as DIMACS and BHOSLIB. The results obtained indicate that our algorithm outperforms the exact algorithm (CPLEX) in terms of efficiency, being capable of finding all 80 known optimal solutions in a reduced computational time. Finally, our approach demonstrated excellent results in more challenging instances, such as those from the KONECT dataset, encompassing large and sparse graphs. In these situations, the reduction technique proved highly effective, eliminating up to 99.78% of the vertices. This highlights the robustness and versatility of our methodology in solving the problem in various scenarios, with significant implications in related practical applications.","('Otimização em grafo', 'Bicliques (Grafos)', 'Meta-heurística', 'Graph optimization', 'Biclicks (Graphs)', 'Meta-heuristics')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/14209","2023-10-24","https://www.repositorio.ufal.br/bitstream/123456789/14209/1/Algoritmo%20GRASP-VND%20para%20o%20problema%20da%20m%c3%a1xima%20biclique%20balanceada%20com%20peso%20no%20v%c3%a9rtice.pdf","",""
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/11406","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Ameaça de estereótipo de gênero afeta o desânimo, fluxo e desempenho em um sistema tutor gamificado para lógica?","('Kamila de Almeida Benevides',)","('Ig Ibert Bittencourt Santana Pinto',)","('Marcelo Reis', 'Álvaro Alvares de Carvalho César Sobrinho')","A gamificação é uma abordagem que está sendo cada vez mais adotada em ambientes educacionais para melhorar o envolvimento, a motivação e o aprendizado dos alunos. No entanto, estudos anteriores na literatura relataram que a ameaça do estereótipo de gênero em ambientes educacionais gamificados pode ter efeitos negativos sobre os alunos, como a ansiedade. Nesse sentido, este trabalho tem como objetivo realizar um estudo experimental de modo a investigar empiricamente se a ameaça de estereótipos em ambientes educacionais gamificados pode causar desânimo. Realizamos um estudo experimental, aplicamos um teste de lógica que continha 20 questões para alunos do ensino superior em uma plataforma educacional gamificada e, posteriormente, eles responderam a um questionário para avaliar o desânimo dos alunos em diferentes cenários. Os resultados sugerem que um ambiente gamificado estereotipado pode afetar o desânimo dos participantes.","Gamification is an approach that is increasingly being adopted in educational settings to improve student engagement, motivation, and learning. However, previous studies in the literature reported that gender stereotype threats in gamified educational environments could have negative effects on students, such as anxiety. In this sense, this paper aims to conduct an experimental study to empirically investigate whether stereotype threat in gamified educational en-environments can cause discouragement. We conducted an experimental study, applied a logic test to higher education students in a gamified educational platform, and afterward, they answered a questionnaire to assess students’ discouragement in different scenarios. The results suggest that a stereotyped gamified environment can affect participants’ dejection.","('Estereótipos (Psicologia)', 'Ambiente gamificado estereotipado', 'Desânimo', 'Gender stereotype', 'Stereotyped gamified environment', 'Dismay')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/11406","2022-12-07","https://www.repositorio.ufal.br/bitstream/123456789/11406/1/Amea%c3%a7a%20de%20estere%c3%b3tipo%20de%20g%c3%aanero%20afeta%20o%20des%c3%a2nimo%2c%20fluxo%20e%20desempenho%20em%20um%20sistema%20tutor%20gamificado%20para%20l%c3%b3gica.pdf","","('Jário José dos Santos Júnior',)"
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/16202","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Sistema de gestão e controle de atividades em unidade de saúde","('Wagner Williams Barros Ferreira Filho',)","('Erick de Andrade Barboza',)","('Leandro Dias da Silva', 'Thiago Damasceno Cordeiro')","A saúde no Brasil há muitos anos vem sendo um dos grandes problemas do Brasil, muito por conta do sucateamento de suas unidades públicas de emergência e pronto socorro, por falta de investimentos, falta de modernização e também falta de capacidade de gestão. Com todos esses problemas, e nos tempos modernos em que vivemos é imprescindível contar com a tecnologia para atuar como parceira para ajudar a amenizar ou solucionar alguns deles. Empresas dos mais diversos ramos do mercado apostam na modernização de seus modelos de negócios para incluir sistemas informatizados, inteligentes, que ajudam a processar informações dos serviços realizados na empresa e no mercado a sua volta e assim recomendar aos donos e analistas dessa empresa soluções e tomadas de decisões inteligentes. Na saúde isso não é diferente, no entanto, ainda existe no nosso país um grande atraso na informatização de setores públicos de saúde. Este trabalho propõe uma plataforma base para controle e monitoramento de atividades corriqueiras realizadas em Unidades de Pronto Atendimento (UPA), com foco na execução do protocolo Manchester aplicado nas triagens.","Health in Brazil has been one of Brazil’s biggest problems for many years, largely due to the scrapping of its public emergency and emergency care units, lack of investment, lack of modernization and also lack of management capacity. With all these problems, and in the modern times we live in, it is essential to have technology to act as a partner to help alleviate or solve some of them. With all these problems, and in the modern times we live in, it is essential to have technology to act as a partner to help alleviate or solve some of them. In health this is no different, however, in Brazil there is still a great delay in the computerization of public health sectors. This work proposes a base platform for the control and monitoring of common activities carried out in Emergency Care Units (UPA), with a focus on the implementation of the Manchester protocol applied in screenings.","('Sistema de Saúde -Brasil', 'Protocolo de Manchester', 'Análise de dados', 'Sistema web', 'Health System -Brazil', 'Manchester Protocol', 'Data analysis', 'Web system')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/16202","2022-02-01","https://www.repositorio.ufal.br/bitstream/123456789/16202/1/Sistema%20de%20gest%c3%a3o%20e%20controle%20de%20atividades%20em%20unidade%20de%20sa%c3%bade.pdf","Activity control and management system in health unit",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/14303","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Sistema autônomo de baixo custo para mediação multiparâmetro de água superficial","('João Arthur Gaia da Rocha Almeida',)","('Ícaro Bezerra Queiroz de Araújo',)","('Erick de Andrade Barboza', 'Carlos Ruberto Fragoso Júnior')","Este trabalho apresenta o desenvolvimento de uma solução autônoma, baixo custo, para coleta, registro e transmissão de dados multiparâmetros de qualidade de água. Tais características reunidas formam um datalogger. Por ser autônomo, não necessita que um operador esteja presente para aquisição e anotação dos dados. O baixo custo facilita sua aplicação em diversos cenários, sem contra partida onerosa. A transmissão da informação permite a tomada de decisão em tempo real, mesmo que à distância. Por ser multiparamétrico, entrega um perfil mais completo da qualidade da água, pois, quando uma variável sozinha não é capaz de explicar um fenômeno, a conjunção com outras pode fazê-lo. Os resultados mostram a construção de hardware, com o custo inferior a R$ 1.300,00, cerca de 1 salário mínimo, e software, bem como a calibração dos sensores de temperatura, sólidos dissolvidos totais, turbidez e pH, além de um teste real em campo bem sucedido de 3 dias.","This work presents the development of an autonomous, low-cost solution for the collection, recording, and transmission of multiparameter water quality data. These combined features form a datalogger. Being autonomous, it does not require an operator to be present for data acquisition and annotation. The low cost facilitates its application in various scenarios without a burdensome counterpart. The information transmission allows real-time decision-making, even from a distance. As a multiparameter system, it provides a more comprehensive profile of water quality. When a single variable cannot explain a phenomenon, the conjunction with others can. The results demonstrate the construction of hardware, with a cost below R$ 1,300.00, approximately one minimum wage, and software. The calibration of temperature, total dissolved solids, turbidity, and pH sensors is also presented, along with a successful 3-day real field test.","('Monitoramento da água', 'Água – Qualidade', 'Sistemas embarcados (Computadores)', 'IoT', 'Water Quality Monitoring', 'Embedded Systems')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/14303","2024-02-02","https://www.repositorio.ufal.br/bitstream/123456789/14303/1/Sistema%20aut%c3%b4nomo%20de%20baixo%20custo%20para%20media%c3%a7%c3%a3o%20multipar%c3%a2metro%20de%20%c3%a1gua%20superficial.pdf","",""
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/13797","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Uma abordagem do algoritmo genético com foco na inicialização para o problema do caixeiro viajante","('Matheus Gomes de Oliveira',)","('Roberta Vilhena Vieira Lopes',)","('João Victor Ribeiro Ferro', 'Augusto Ícaro Farias da Cunha', 'Maria Cristina Tenório Cavalcante Escarpini', 'Evandro de Barros Costa')","Os Algoritmos Genéticos são métodos de busca heurística que simulam o processo evolutivo conforme explicado na Teoria da Evolução de Charles Darwin. Segundo essa teoria, os indivíduos que possuem adaptações mais vantajosas ao ambiente são os que têm maior probabilidade de sobreviver. Este método de busca é particularmente ecaz na resolução de um problema clássico da literatura, conhecido como o Problema do Caixeiro Viajante, que se enquadra na categoria NP-Difícil. Este problema tem ampla aplicação em cenários que envolvem roteamento, logística e otimização de recursos. Neste trabalho, será introduzida uma abordagem inovadora para a geração da população inicial dos Algoritmos Genéticos. O principal objetivo é apresentar um novo método de inicialização especíco para o problema em discussão e, ao mesmo tempo, realizar uma simulação abordando um cenário de distribuição logística com estoque predenido no estado de Alagoas. Para a avaliação do algoritmo proposto, será comparado os resultados do mesmo com outra implementação simples do Problema do Caixeiro Viajante, utilizando as mesma métricas e base de dados. Será realizada uma avaliação considerando o desempenho de cada algoritmo, levando em consideração o seu score por geração, o número de gerações em que ambos encontraram a melhor solução e o tempo de execução que cada algoritmo demandou para atingir essa solução. O estudo em pauta apresentou resultados favoráveis nas duas primeiras métricas de avaliação, apenas demonstrando um desempenho inferior em relação ao aspecto de tempo.","Genetic Algorithms are heuristic search methods that replicate the evolutionary process as explained in Charles Darwin’s Theory of Evolution. According to this theory, individuals with more advantageous adaptations to their environment are more likely to survive. This search method is particularly eective in solving a classic problem in the literature known as the Traveling Salesman Problem, which falls into the NP-Complete category. This problem has broad applications in scenarios involving routing, logistics, and resource optimization. In this work, we introduce an innovative approach based on Genetic Algorithms. The primary goal is to present a new initialization method specic to the discussed problem while simultaneously conducting a simulation addressing a logistics distribution scenario with predened stock in the state of Alagoas. To evaluate the proposed algorithm, we will compare its results with another simple implementation of the Traveling Salesman Problem, using the same metrics and dataset. An assessment will be conducted considering the performance of each algorithm, taking into account their score per generation, the number of generations in which they found the best solution, and the execution time required for each algorithm to reach that solution. The study at hand yielded favorable results in the rst two evaluation metrics, with only a relatively lower performance in terms of execution time.","('Algoritmos genéticos – Inicialização', 'Problema do caixeiro viajante', 'Logística – Alagoas', 'Genetic Algorithms -Initialization', 'Traveling salesman problem', 'Logistics – Alagoas')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/13797","2024-11-06","https://www.repositorio.ufal.br/bitstream/123456789/13797/1/Uma%20abordagem%20do%20algoritmo%20gen%c3%a9tico%20com%20foco%20na%20inicializa%c3%a7%c3%a3o%20para%20o%20problema%20do%20caixeiro%20viajante.pdf","",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/15681","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Resolução de redundância aplicada a um manipulador robótico com cinco graus de liberdade","('Hugo Tallys Martins Oliveira',)","('Glauber Rodrigues Leite',)","('Ícaro Bezerra Queiroz de Araújo', 'Arthur da Vangasse')","Manipuladores cinematicamente redundantes possuem mais graus de liberdade (DoFs) do que o necessário para realizar uma tarefa específica, oferecendo maior flexibilidade e destreza na execução de trajetórias. No entanto, esses DoFs adicionais também introduzem uma maior complexidade na cinemática inversa do manipulador, sendo necessário recorrer a esquemas de resolução de redundância, para encontrar uma solução particular otimizando critérios de desempenho do manipulador, como velocidade das jun#tas, manipulabilidade ou distância para obstáculos. Este trabalho, apresenta uma fundamentação teórica sobre os principais pontos relativos a cinemática inversa diferencial voltada para manipuladores redundantes. Para validar a metodologia proposta, foi implementado um ambiente virtual utilizando o simulador Webots e o Sistema Operacional de Robˆos (ROS), permitindo a aplicação prática do esquema de controle Resolved Rate Motion Control (RRMC). As simulações realizadas mostram que o controlador é capaz de otimizar métricas de desempenho, sem violar as restrições cinemáticas primárias em diferentes cenários de execução de trajetórias cartesianas.","Kinematically redundant manipulators have more degrees of freedom (DoFs) than ne cessary to perform a specific task, offering greater flexibility and dexterity in executing trajectories. However, these additional DoFs also introduce greater complexity in the manipulator’s inverse kinematics, requiring the use of redundancy resolution schemes to find a particular solution that optimizes the manipulator’s performance criteria, such as joint speed, manipulability, or distance to obstacles. This work presents a theoretical foundation on the main points related to differential inverse kinematics for redundant manipulators. To validate the proposed methodology, a virtual environment was imple mented using the Webots simulator and the Robot Operating System (ROS), allowing the practical application of the Resolved Rate Motion Control (RRMC) control scheme. The simulations carried out show that the controller is capable of optimizing performance me trics without violating the primary kinematic constraints in different Cartesian trajectory execution scenarios.","('Manipuladores robóticos', 'Cinemática inversa diferencial', 'Resolução de redundância', 'Simulação de robótica', 'Resolved rate motion control', 'Robotic manipulators', 'Differential inverse kinematics', 'Redundancy resolution', 'Robotics simulation', 'Resolved rate motion control')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/15681","2024-07-26","https://www.repositorio.ufal.br/bitstream/123456789/15681/1/Resolu%c3%a7%c3%a3o%20de%20redund%c3%a2ncia%20aplicada%20a%20um%20manipulador%20rob%c3%b3tico%20com%20cinco%20graus%20de%20liberdade.pdf","",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/13450","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Otimizando funções de Kernel racionais para máquinas de vetores de suporte","('José Augusto dos Santos Silva',)","('Erick de Andrade Barboza',)","('Rian Gabriel Santos Pinheiro', 'Bruno Almeida Pimentel')","Aprendizado de máquina, um subconjunto da inteligência artificial, foca no desenvolvi mento de modelos matemáticos que permitem que computadores aprendam e tomem decisões a partir do uso de dados. Em vez de serem explicitamente programados para executar uma tarefa, esses modelos usam métodos estatísticos para identificar padrões a partir dos dados e fazer predições. No centro deste paradigma está o desenvolvimento de algoritmos capazes de modelar relações não lineares pelo uso dos dados. Um desses proeminentes modelos são as Máquinas de Vetores de Suporte, com raízes na teoria do aprendizado estatístico, que são modelos de aprendizagem supervisionada que se destacam em tarefas de classificação ao encontrar o melhor hiperplano que separa as classes distintas de um conjunto de dados rotulado. Máquinas de Vetores de Suporte têm notória popularidade em diferentes cenários devido a sua habilidade de generalização e de lidar com funções de decisão não lineares. Um dos fatores críticos que influenciam a sua função de decisão para lidar com problemas não lineares é a escolha da função de kernel, que representa o resultado do produto interno no espaço de alta dimensão onde os dados são implicitamente transformados para que modelos lineares possam encontrar funções de decisão não lineares. Enquanto o kernel de Função de Base Radial tem sido uma escolha tradicional e amplamente utilizada, este trabalho explora a viabilidade de funções racionais, que são funções definidas pelo quociente entre dois polinômios, como funções de kernel, otimizadas pelo uso da Evolução Diferencial. Deste modo, o objetivo principal deste trabalho é construir uma metodologia de aprendizado automatizado de funções de kernel modeladas por funções racionais para investigar a viabilidade de obter desempenho comparável em relação ao kernel de Função de Base Radial, uma das funções de kernel mais utilizadas, ao passo que podem oferecer vantagens em termos de convergência, com plexidade e capacidade de generalização. Os experimentos foram conduzidos utilizando o conjunto de dados Pima e os resultados mostram que as funções de kernel racionais foram capazes de alcançar acurácia balanceada estatisticamente igual ao kernel de Função de Base Radial. Esse resultado demonstra o potencial de funções racionais, de coeficientes otimizados pela Evolução Diferencial, como alternativa viável para o kernel de Máquinas de Vetores de Suporte. Além disso, as funções racionais como kernel utilizaram um número menor de iterações para convergir (84,14% menor) e um número menor de vetores de suporte (3,84% menor), o que indica um modelo menos complexo. Os resultados foram comparados por meio de testes estatísticos com nível de confiança igual a 95% e indicam que ainda há espaço na literatura para explorar aprimoramentos no uso de funções de kernel em Máquinas de Vetores de Suporte.","Machine learning, a subset of artificial intelligence, focuses on the development of mathe matical models that allow computers to learn and make decisions from data. Instead of being explicitly programmed to perform a task, these models employ statistical methods to identify patterns from data and make predictions. At the heart of this paradigm is the development of algorithms capable of modeling non-linear relationships through data. One of these prominent models is the Support Vector Machines, with roots in statistical learning theory, which are supervised learning models that excel in classification tasks by finding the best hyperplane that separates the distinct classes of a labeled dataset. Support Vector Machines have notable popularity in various scenarios due to their generalization ability and handling non-linear decision functions. One of the critical factors influencing its decision function to deal with non-linear problems is the choice of the kernel function, which represents the outcome of the inner product in the high-dimensional space where data is implicitly transformed so that linear models can find non-linear decision functions. While the Radial Basis Function kernel has been a traditional choice and widely used, this work explores the feasibility of rational functions, which are functions defined by the quotient between two polynomials, as kernel functions, optimized by the use of Differen tial Evolution. Thus, the main objective of this work is to build an automated learning methodology for rational functions as kernel functions to investigate the feasibility of achi eving comparable performance to the Radial Basis Function kernel, one of the most used kernel functions, while possibly offering advantages in terms of convergence, complexity and generalization ability. Experiments were conducted using the Pima dataset, and the results show that the rational kernel functions were able to achieve balanced accuracy statistically equal to the Radial Basis Function kernel. This outcome demonstrates the potential of rational functions, with coefficients optimized by Differential Evolution, as a viable alternative for the Support Vector Machines kernel. Moreover, rational functions as a kernel used fewer iterations to converge (84.14% lower) and fewer support vectors (3.84% lower), indicating a less complex model. The results were compared through statistical tests with a confidence level equal to 95%, and they indicate that there is still room in the literature to explore improvements in the use of kernel functions in Support Vector Machines.","('Máquinas de vetores de suporte', 'Funções de Kernel', 'Funções racionais', 'Evolução diferencial', 'Aprendizado de máquina automatizado', 'Support vector machines', 'Kernel functions', 'Rational functions', 'Differential evolution', 'Automated machine learning')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/13450","2023-10-20","https://www.repositorio.ufal.br/bitstream/123456789/13450/1/Otimizando%20fun%c3%a7%c3%b5es%20de%20Kernel%20racionais%20para%20m%c3%a1quinas%20de%20vetores%20de%20suporte.pdf","",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/16453","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Uma meta-heurística híbrida para o problema da cobertura de disco de raio fixo","('Mateus da Silva Batista',)","('Rian Gabriel Santos Pinheiro',)","('Bruno Costa e Silva Nogueira', 'Alfredo Lima Moura Silva')","O problema de cobertura na geometria computacional possui aplicações em uma ampla gama de áreas, incluindo redes de comunicação sem fio, planejamento de localização de instalações, robótica, processamento de imagens e aprendizado de máquina. Além disso, ele desempenha um papel crucial na otimização da alocação de recursos e no design de infraestrutura, abordando desafios como a minimização de custos enquanto garante cobertura total em aplicações como torres de celular, pontos de acesso a redes sem fio. Ademais, este problema é fundamental na logística, para a otimização de centros de distribuição, e na defesa militar, para o posicionamento estratégico de sistemas de defesa antimísseis ou transmissores de rádio. Sua ampla aplicabilidade reforça sua importância no enfrentamento de desafios econômicos, sociais e tecnológicos, destacando a necessidade de metodologias inovadoras e eficientes. Este trabalho apresenta a meta-heurística híbrida Construct, Merge, Solve, and Adapt (CMSA) para o Problema de Cobertura de Discos de Raio Fixo, que é N P-difícil. O objetivo é determinar o conjunto mínimo de discos, juntamente com suas localizações, necessário para cobrir todos os pontos dados. A meta-heurística proposta foi avaliada por meio de testes experimentais, com a análise comparativa focada no número de discos necessários e nos tempos de execução computacional. Os resultados experimentais demonstram que a meta-heurística CMSA supera significativamente os métodos mais avançados da literatura, obtendo consistentemente as melhores soluções em quase todos os casos de teste, com tempos de execução competitivos.","The coverage problem in computational geometry has applications across a wide range of fields, including wireless communication networks, facility location planning, robotics, image processing, and machine learning. It plays a crucial role in optimizing resource allocation and infrastructure design, addressing challenges such as cost minimization while ensuring complete coverage in applications like cell towers and wireless access points. Furthermore, this problem is fundamental in logistics for optimizing distribution centers and in military defense for the strategic positioning of anti-missile defense systems or radio transmitters. Its broad applicability underscores its importance in tackling economic, social, and technological challenges, highlighting the need for innovative and efficient methodologies. This work presents a hybrid meta-heuristic Construct, Merge, Solve, and Adapt (CMSA) for the Fixed Radius Disk Coverage Problem, which is N P-hard. The objective is to determine the minimum set of disks, along with their locations, required to cover all given points. The proposed CMSA meta-heuristic was evaluated through experimental tests. The comparative analysis focused on the number of disks required and computational execution times. The experimental results demonstrate that the CMSA meta-heuristic significantly outperforms the most advanced methods in the literature, consistently obtaining the best solutions in almost all test cases, with competitive execution times.","('Meta heurística', 'Discos de raio fixo', 'Cobertura (Redes de computadores)', 'Geometria computacional', 'Otimização combinatória', 'Cobertura de disco', 'Computational geometry', 'Combinatorial optimization', 'Disk coverage', 'CMSA', 'Meta-heuristic')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/16453","2024-11-29","https://www.repositorio.ufal.br/bitstream/123456789/16453/1/Uma%20meta-heur%c3%adstica%20h%c3%adbrida%20para%20o%20problema%20da%20cobertura%20de%20disco%20de%20raio%20fixo.pdf","",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/15802","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","MassFormer: uma abordagem de aprendizado profundo para a predição de espectros de massa","('Anderson Miguel Clemente Santos',)","('André Luiz Lins de Aquino',)","('Danilo Fernandes Costa', 'Josias Jordão Andrade Alves')","Este trabalho apresenta uma investigação detalhada do uso do MassFormer, um modelo baseado em transformer, para a predição de espectros de massa a partir de estruturas moleculares. Utilizando o conjunto de dados público MassBank of North America (MoNA), este estudo explora a eficácia do modelo MassFormer, que é refinado a partir de um modelo Graphormer pré-treinado. O Graphormer, conhecido por sua capacidade de modelar eficientemente dados estruturados como grafos, fornece uma base sólida para o MassFormer ao capturar as interações complexas entre os nós representativos dos átomos em uma molécula. No decorrer deste trabalho, foram implementadas e comparadas duas abordagens de divisão dos dados: uma divisão aleatória simples e uma mais complexa baseada em Scaffold. Ambas as estratégias produziram resultados similares, demonstrando a robustez do modelo em condições variadas. A performance do MassFormer, embora inferior à dos modelos comerciais devido às limitações nos dados públicos disponíveis, mostrou-se promissora, especialmente considerando a possibilidade de melhoria contínua através da contribuição comunitária para o banco de dados MoNA. Este estudo não apenas demonstra a aplicabilidade do MassFormer em contextos acadêmicos e de pesquisa, mas também destaca o potencial para futuras melhorias e expansões na modelagem de espectros de massa, promovendo uma compreensão mais profunda e a aplicação prática em espectrometria de massa.","This work presents a detailed investigation into the use of the MassFormer, a transformer based model, for predicting mass spectra from molecular structures. Utilizing the public dataset MassBank of North America (MoNA), this study explores the efficacy of the MassFormer model, which is refined from a pre-trained Graphormer model. Graphormer, known for its ability to efficiently model structured data like graphs, provides a solid foundation for the MassFormer by capturing the complex interactions between nodes representing atoms in a molecule. Throughout this work, two approaches to data splitting were implemented and compared: a simple random split and a more complex Scaffold-based split. Both strategies produced similar results, demonstrating the robustness of the model under varied conditions. The performance of the MassFormer, although inferior to commercial models due to the limitations in publicly available data, proved promising, especially considering the potential for continuous improvement through community contributions to the MoNA database. This study not only demonstrates the applicability of the MassFormer in academic and research contexts but also highlights the potential for future improvements and expansions in mass spectrum modeling, promoting a deeper understanding and practical application in mass spectrometry.","('Espectrometria de massa', 'Redes neurais (Computação)', 'Predição de espectros', 'Modelagem molecular.', 'Deep Learning', 'Mass Spectrometry', 'Spectrum Prediction', 'Molecular Modeling')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/15802","2024-08-09","https://www.repositorio.ufal.br/bitstream/123456789/15802/1/MassFormer_uma%20abordagem%20de%20aprendizado%20profundo%20para%20a%20predi%c3%a7%c3%a3o%20de%20espectros%20de%20massa.pdf","",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/12786","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Proposta de um sistema de supervisão e controle de tanques acoplados","('André Luiz de Oliveira Cezário',)","('João Raphael Souza Martins',)","('Andressa Martins Oliveira', 'Ícaro Bezerra Queiroz de Araújo')","O uso de recursos tecnológicos para o controle de processos e redução dos custos de produção tem se tornado crescentes na automação industrial, sendo cada vez mais indispensável o uso de controladores lógicos programáveis (CLP) e sistemas de controle e aquisição de dados supervisórios (SCADA). Essas tecnologias facilitam o desenvolvimento de sistemas de controle de modo mais rápido e eficiente, seja na automação de processos na indústria ou em plantas de bancadas didáticas no ensino de disciplinas de Engenharia. Contudo, quando se tratam de diferentes fabricantes a comunicação direta é inviabilizada devido ao uso de protocolos de comunicação distintos. Tal barreira é resolvida pelo protocolo de comunicação OPC, que permite a interoperabilidade entre os diferentes sistemas de fornecedores. Neste trabalho foi proposta a integração de uma plataforma de simulação do MATLAB com CLP para o controle de nível de líquidos em um sistema de tanques acoplados, utilizando controle PID em um CLP S7-1200 da Siemens, de uma planta modelada no MATLAB Simulink, no qual a comunicação entre o CLP e o MATLAB foi realizada por um servidor OPC KEPServerEX.V4. O intuito foi ampliar recursos para projetos de controle de plantas didáticas, auxiliando no processo de ensinoaprendizagem de estudantes do curso de Engenharia da Computação. Os resultados mostraram que o sistema controlado via CLP tem uma boa resposta, mantendo o controle mesmo diante as variações de setpoint. Além disso, a IHM desenvolvida fornece uma ferramenta para supervisão em tempo real de um sistema de controle de tanques acoplados, integrando os diferentes softwares e tecnologias em um único processo, podendo ainda ser escalada para outros tipos de plantas.","The use of technological resources for process control and production cost reduction has become increasingly important in industrial automation, and the use of programmable logic controllers (PLC) and supervisory control and data acquisition (SCADA) systems is becoming more and more indispensable. These technologies facilitate the development of control systems in a faster and more efficient way, whether in the automation of industrial processes or in bench top plants in the teaching of engineering disciplines. However, when different manufacturers are involved, direct communication is not possible due to the use of different communication protocols. This barrier is solved by the OPC communication protocol, which allows interoperability between the different supplier systems. In this work we proposed the integration of a MATLAB simulation platform with a PLC for the control of liquid levels in a coupled tank system, using PID control in a Siemens PLC S7-1200, from a plant modeled in MATLAB Simulink, in which the communication between the PLC and MATLAB was done through an OPC server KEPServerEX.V4. The purpose was to extend resources for didactic plant control projects, helping in the teaching-learning process of Computer Engineering students. The results showed that the system controlled via PLC has a good response, maintaining control even when facing setpoint variations. Furthermore, the developed HMI provides a tool for real-time supervision of a coupled tank control system, integrating different software and technologies in a single process, and can also be scaled to other types of plants.","('Controladores lógicos programáveis', 'Sistemas de controle (Computação)', 'Sistema de tanques acoplados', 'Programmable logic controllers', 'Control systems (Computing)', 'Coupled tank system')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/12786","2023-06-02","https://www.repositorio.ufal.br/bitstream/123456789/12786/1/Proposta%20de%20um%20sistema%20de%20supervis%c3%a3o%20e%20controle%20de%20tanques%20acoplados.pdf","",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/16754","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Uma pesquisa sistemática sobre defeitos em sistemas de aprendizagem de máquina","('Sandoval da Silva Almeida Júnior',)","('Erick de Andrade Barboza',)","('Baldoíno Fonseca dos Santos Neto', 'Márcio de Medeiros Ribeiro')","Nos últimos anos, a integração de sistemas apoiados por aprendizagem de máquina (SAAM) tem se expandido em diversas áreas, impulsionando avanços tecnológicos em setores críticos como saúde, finanças, segurança e transporte. Contudo, à medida que esses sistemas se tornam cada vez mais complexos e difundidos, surgem também desafios significativos relacionados à confiabilidade e robustez das soluções implementadas. Problemas como erros de classificação, falhas de desempenho e vulnerabilidades a ataques adversários podem comprometer não apenas a integridade dos sistemas, mas também a segurança e a confiança nas decisões automatizadas. Nesse cenário, compreender e mitigar esses defeitos é crucial para garantir o avanço seguro e eficaz das tecnologias de aprendizagem de máquina. Este Trabalho de Conclusão de Curso apresenta uma revisão sistemática da literatura so bre defeitos, erros e falhas que mais comprometem a integridade e desempenho de sistemas apoiados por aprendizagem de máquina (SAAM). A análise foca em identificar e categorizar os principais problemas relatados, bem como os artefatos gerados pela comunidade acadêmica em resposta a esses desafios. O estudo abrange uma ampla gama de artigos publicados nos últimos anos, destacando tendências predominantes na pesquisa de SAAM, como a robustez dos sistemas frente a ataques adversários, a otimização de algoritmos e a gestão de conjuntos de dados. A partir de uma metodologia de pesquisa e seleção de artigos, problemas são identificados e classificados em subgrupos, revelando que questões como classificação de imagens, detecção de anomalias e defesa contra ataques adversários estão no centro das preocupações atuais. Adi cionalmente, são examinados os artefatos gerados pelos estudos, tais como modelos de aprendi zagem de máquina, algoritmos de otimização e conjuntos de dados, que são fundamentais para o avanço da pesquisa. A revisão não apenas mapeia as falhas críticas que podem deteriorar os SAAM, mas também destaca as soluções propostas para mitigar esses riscos, oferecendo uma visão abrangente dos esforços de pesquisa e desenvolvimento na área. A compreensão dessas dinâmicas é es sencial para pesquisadores, desenvolvedores e decisores que buscam explorar ou aprimorar a implementação de tecnologias de aprendizado de máquina em sistemas críticos.","In recent years, the integration of systems supported by machine learning (SAAM) has expanded across various fields, driving technological advancements in critical sectors such as healthcare, finance, security, and transportation. However, as these systems become increasingly complex and widespread, significant challenges related to the reliability and robustness of implemented solutions also arise. Issues such as classification errors, performance failures, and vulnerabilities to adversarial attacks can compromise not only the integrity of these systems but also the safety and trust in automated decisions. In this context, understanding and mitigating these defects is crucial to ensuring the safe and effective advancement of machine learning technologies. This Thesis presents a systematic literature review on defects, errors, and failures that most compromise the integrity and performance of machine learning-supported systems (SAAM). The analysis focuses on identifying and categorizing the main reported issues, as well as the artifacts produced by the academic community in response to these challenges. The study covers a wide range of articles published in recent years, highlighting predominant trends in SAAM research, such as system robustness against adversarial attacks, algorithm optimization, and data set management. Based on a research and article selection methodology, issues are identified and classified into subgroups, revealing that topics like image classification, anomaly detection, and defenseagainst adversarial attacks are central to current concerns. Additionally, the study examines the artifacts generated by these studies, such as machine learning models, optimization algorithms, and data sets, which are essential to advancing research. The review not only maps the critical failures that can deteriorate SAAM but also highlights proposed solutions to mitigate these risks, providing a comprehensive view of research and development efforts in the field. Understanding these dynamics is essential for researchers, developers, and decision-makers seeking to explore or enhance the implementation of machine learning technologies in critical systems.","('Aprendizagem de máquina', 'Inteligência artificial', 'Revisão sistemática da literatura', 'Machine Learning', 'Artificial intelligence', 'Systematic review')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/16754","2024-11-25","https://www.repositorio.ufal.br/bitstream/123456789/16754/1/Uma%20pesquisa%20sistem%c3%a1tica%20sobre%20defeitos%20em%20sistemas%20de%20aprendizagem%20de%20m%c3%a1quina.pdf","",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/16185","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Reconhecimento e análise de entidades nomeadas em textos não-estruturados usando LLMs e redes complexas","('Yuri Dimitri Ramos Costa',)","('Thales Miranda de Almeida Vieira',)","('Marcelo Costa Oliveira', 'Adriano Oliveira Barbosa')","A disponibilidade de dados textuais na internet vem crescendo exponencialmente. Se o acesso à informação já foi um grande desafio em outros momentos, hoje, o grande volume de conteúdo disponível exige a utilização de métodos cada vez mais sofisticados para automatizar a extração de informações. Seja por meio de livros, artigos, e-mails ou postagens em redes sociais, as informações disponíveis nesses meios podem contribuir para a geração de ideias inovadoras, a melhor compreensão do público alvo em campanhas publicitárias e o avanço da ciência por meio de revisões de literatura. Dessa forma, os dados textuais tem se mostrado valiosos em um mundo cada vez mais conectado. O reconhecimento de entidades nomeadas (NER) permite identificar palavras de um texto que se referem a um tema em comum. A estruturação das entidades nomeadas em um grafo de relações fornece uma estrutura capaz de representar o contexto do conjunto de dados, permitindo a identificação de padrões. Com os recentes avanços dos modelos generativos Large Language Models (LLM), o presente trabalho avaliou o desempenho desse tipo de modelo no reconhecimento de entidades nomeadas, discutindo acerca de vantagens e desvantagens por meio de uma análise quantitativa da tarefa realizada, comparando o ChatGPT com modelos como BERT e BILSTM. Além disso, uma análise qualitativa busca avaliar as capacidades dos modelos BERT e ChatGPT na geração de grafos de relações entre entidades nomeadas, além de propor técnicas de exploração para esse tipo de rede complexa. Desta forma, buscou-se neste estudo apresentar uma metodologia para a geração de representações em redes complexas de dados textuais. A metodologia apresentada permite duas abordagens: a utilização de modelos LLM, como o ChatGPT, por meio da engenharia de prompt, necessitando uma quantidade mínima de exemplos, e o treinamento ou refino de modelos estado da arte, como o BERT.","The availability of textual data on the internet has been growing exponentially. While access to information was a major challenge in the past, today, the vast amount of available content requires increasingly sophisticated methods to automate information extraction. Whether through books, articles, emails, or social media posts, the information available in these media can contribute to generating innovative ideas, better understanding the target audience in advertising campaigns, and advancing science through literature reviews. In this way, textual data has proven to be valuable in an increasingly connected world. Named entity recognition (NER) allows identifying words in a text that refer to a common theme. Structuring the named entities in a relation graph provides a framework capable of representing the context of the dataset, enabling the identification of patterns. With the recent advances in generative models, such as Large Language Models (LLM), this study evaluated the performance of this type of model in named entity recognition, discussing the advantages and disadvantages through a quantitative analysis of the task performed, comparing ChatGPT with models like BERT and BiLSTM. Additionally, a qualitative analysis seeks to evaluate the capabilities of the BERT and ChatGPT models in generating relation graphs between named entities, as well as proposing exploration techniques for this type of complex network. Thus, the aim of this study was to present a methodology for generating representations in complex networks of textual data. The presented methodology allows two approaches: the use of LLM models, such as ChatGPT, through prompt engineering, requiring a minimal number of examples, and the training or fine-tuning of state-of-the-art models, such as BERT.","('Processamento de linguagem natural (Computação)', 'Redes complexas', 'Transformers', 'Natural language processing', 'Complex networks', 'Transformer models')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/16185","2024-10-23","https://www.repositorio.ufal.br/bitstream/123456789/16185/1/Reconhecimento%20e%20an%c3%a1lise%20de%20entidades%20nomeadas%20em%20textos%20n%c3%a3o-estruturados%20usando%20LLMs%20e%20redes%20complexas.pdf","",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/14087","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","OCR de placas veiculares em dispositivos Android","('André dos Santos',)","('Tiago Figueiredo Vieira',)","('Erick de Andrade Barboza', 'Bruno Georgevich Ferreira')","No presente trabalho efetuou-se o desenvolvimento de um sistema ALPR (do inglês, Automatic License Plate Recognition) para realizar o reconhecimento automático de placas veiculares em Smartphones Android utilizando algoritmos de detecção de objetos Yolov5s. O sistema consiste em duas etapas nomeadas Code Detection (CD) e Code Recognition (CR), respectivamente. Inicialmente, a localização da placa é efetuada na etapa CD, produzindo a caixa delimitadora, a qual é utilizada para extrair a região de interesse que será utilizada na etapa CR, responsável pelo reconhecimento dos caracteres presentes na placa. O sistema apresenta acurácia de reconhecimento de 89.6% no conjunto de teste, consumo de memória inferior a 10% durante a utilização da aplicação e eficiência energética na GPU Mobile consumindo aproximadamente 54% menos de bateria em comparação com a execução em CPU Mobile.","We have developed an ALPR application to extract vehicle license plates from images using YOLOV5s object detection algorithms on Android mobile devices. The system consists of a two-step approach, designated Code Detection (CD) and Code Recognition (CR), respectively. Initially, the plate location is done on CD phase, yielding the plate bounding box, which is used to extract the region of interest that will be used on CR phase, responsible for executing character recognition on the plate region. The system reaches a recognition accuracy of 89.6% on the test set, memory consumption lower than 10% during application execution, and power efficiency on Mobile GPU consuming about 54% battery lower than Mobile CPU execution.","('Yolo (Algoritmo)', 'Android (Recurso eletrônico)', 'Dispositivos móveis', 'ALPR', 'Detecção de objetos', 'Reconhecimento de caracteres', 'YOLOv5s', 'Yolo (Algorithm)', 'Android (Electronic Resource)', 'Mobile devices', 'Object detection', 'Character recognition')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/14087","2023-12-12","https://www.repositorio.ufal.br/bitstream/123456789/14087/1/OCR%20de%20placas%20veiculares%20em%20dispositivos%20Android.pdf","",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/16399","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Uma linha de produto de software para sistemas de gerenciamento de refeições utilizando uma arquitetura baseada em microsserviços","('Wilamis Micael de Araujo Aviz',)","('Arturo Hernández-Domínguez',)","('Reinaldo Cabral Silva Filho', 'Patrick Henrique da Silva Brito')","Empresas de software enfrentam uma crescente necessidade de desenvolver soluções de forma cada vez mais rápida e eficiente, visando atender à demanda por automatização de tarefas e otimização de processos. Para ter agilidade na construção de softwares, técnicas de reuso e a adoção de Linhas de Produto de Software (LPS) mostram-se estratégias promissoras. A LPS contém um código base que será comum para toda a família de software e as partes variantes. As variações nos componentes permitem a criação de novos produtos. A LPS é implementada em um domínio, neste trabalho o domínio foi para sistema de agendamento de refeição utilizando a arquitetura de microsserviços. O objetivo foi facilitar a construção de sistemas personalizados. As tecnologias usadas na implementação incluem Nest.js e React.js, utilizando TypeScript como linguagem principal. Para validar a instância da LPS, foi desenvolvido um sistema de agendamento de refeições com alguns componentes e funcionalidades que a linha pode oferecer, sendo aplicado ao contexto da UFAL. Estudantes da universidade participaram de um estudo de caso preliminar, interagindo com o sistema e, posteriormente, respondendo a um questionário de satisfação. Os resultados do teste indicam que houve aceitação da solução pelos usuários, destacando a importância de a UFAL adotar um sistema de agendamento de refeições baseado na arquitetura da LPS desenvolvida.","Software companies face a growing need to develop solutions faster and more efficiently, aiming to meet the demand for task automation and process optimization. To achieve agility in software development, reuse techniques and the adoption of Software Product Lines (SPL) have proven to be promising strategies. The SPL contains a code base that will be common to the entire software family and its variant parts. Variations in the components allow the creation of new products. The SPL is implemented in a domain; in this work, the domain was a meal scheduling system using the microservices architecture. The goal was to facilitate the construction of customized systems. The technologies used in the implementation include Nest.js and React.js, using TypeScript as the main language. To validate the SPL instance, a meal scheduling system was developed with some components and functionalities that the line can offer, and was applied to the context of UFAL. Students from the university participated in a preliminary case study, interacting with the system and, later, answering a satisfaction questionnaire. The test results indicate that the solution was accepted by users, highlighting the importance of UFAL adopting a meal scheduling system based on the LPS architecture developed.","('Linhas de produto de software', 'Sistema de agendamento de refeição', 'Microsserviços', 'Software product lines', 'Meal scheduling system', 'Microservices')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/16399","2024-12-03","https://www.repositorio.ufal.br/bitstream/123456789/16399/1/Uma%20linha%20de%20produto%20de%20software%20para%20sistemas%20de%20gerenciamento%20de%20refei%c3%a7%c3%b5es%20utilizando%20uma%20arquitetura%20baseada%20em%20microsservi%c3%a7os.pdf","",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/13695","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","A large multi-language dataset of open-source software vulnerabilities and their fixes","('Kevin Washington da Silva Lira',)","('Baldoíno Fonseca dos Santos Neto',)","('Ícaro Bezerra Queiroz de Araújo', 'Davy de Medeiros Baía')","No cenário atual do aumento progressivo da adoção de ferramentas digitais pela sociedade, softwares de todos os tipos e tamanhos enfrentam constantemente ameaças à sua segurança. No contexto da segurança digital, uma vulnerabilidade é definida como uma fraqueza encontrada em componentes de software e hardware que, quando explorada, resulta em um impacto negativo na confidencialidade, integridade ou disponibilidade do serviço. O processo de mitigação das vulnerabilidades de segurança presentes em soft-wares normalmente envolve alterações de código. Dessa forma, é necessário identificar o trecho de código que introduz uma vulnerabilidade para que seja possível realizar a implementação da correção. Este trabalho apresenta uma metodologia de identificação e extração de códigos vulneráveis em projetos de softwares open-source e seus respectivos patches. Para isso, é apresentada uma ferramenta que identifica as vulnerabilidades de software publicadas e extrai, de forma automática, o código associado. O dataset construído reúne vulnerabilidades de software e seus patches presentes em 3,587 projetos desenvolvidos em 58 linguagens de programação. Além disso, foram realizadas análises com o intuito de verificar a incidência das vulnerabilidades e as características dos fixes desenvolvidos nas principais linguagens do mercado.","In the current scenario of progressive increase in the adoption of digital tools by society, software of all types and sizes constantly faces threats to its security. In the context of digital security, a vulnerability is defined as a weakness found in software and hardware components that, when exploited, negatively impact the service’s confidentiality, integrity, or availability. The process of mitigating security vulnerabilities present in software typically involves code changes. Therefore, it is necessary to identify the snippet of code that introduces a vulnerability to implement the correction. This work presents a methodology for identifying and extracting vulnerable codes in open-source software projects and their patches. For this purpose, a tool is presented that identifies published software vulnerabilities and automatically extracts the associated code. The constructed dataset combines software vulnerabilities and their fixes in 3,587 projects developed in 58 programming languages. Furthermore, analyses were carried out to verify the incidence of vulnerabilities and the characteristics of fixes developed in the main languages on the market.","('Segurança da informação', 'Ameaça', 'Vulnerabilidades (Informática)', 'Software de código aberto', 'Information security', 'Threats', 'Vulnerabilities (Computing)', 'Open-source software')","Ciência da Computação","eng","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/13695","2023-12-04","https://www.repositorio.ufal.br/bitstream/123456789/13695/3/A%20large%20multi-language%20dataset%20of%20open-source%20software%20vulnerabilities%20and%20their%20fixes.pdf","",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/13597","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Frequência escolar por meio de reconhecimento facial utilizando redes neurais residuais","('John Davi Dutra Canuto Pires',)","('Marcelo Costa Oliveira',)","('Andressa Martins Oliveira', 'Erick de Andrade Barboza')","A prática de registrar e monitorar a frequência dos alunos é uma ação fundamental em diversos contextos, especialmente no ambiente escolar, apesar de frequentemente consumir parte significativa do tempo de aula devido ao seu processo manual. Neste estudo, é proposto o desenvolvimento de um modelo de reconhecimento facial com o propósito de automatizar o controle de frequência escolar. Baseado nas contribuições de King (2009) e nas técnicas de Redes Neurais Convolucionais (CNN), o modelo é projetado para superar os desafios relacionados à defasagem dos dispositivos de captura de imagem e às variações de ambiente na sala de aula.A base de dados é composta por cinco sessões de aula provenientes do estudo conduzido por Mery et al. (2019) e uma sessão de aula coletada em uma unidade escolar do Serviço Social da Indústria (SESI), totalizando quase 100 imagens para análise. Em comparação com os modelos Facenet512, Facenet e ArcFace, em relação à precisão na marcação de frequência final, o modelo apresentou um desempenho superior, com um aumento de cerca de 51% na acurácia em relação aos demais, atingindo uma marca satisfatória de 76% de acurácia, além de demonstrar uma especificidade superior. É importante destacar que, neste estágio de desenvolvimento, o modelo tem o potencial de beneficiar tanto os professores quanto os alunos, contribuindo para economizar tempo e reduzir erros na gestão da frequência escolar.","The practice of recording and monitoring student attendance is a fundamental action in various contexts, especially in the school environment, although it often consumes a significant part of class time due to its manual process. This study proposes the development of a facial recognition model with the aim of automating school attendance control. Based on the contributions of King (2009) and Convolutional Neural Network (CNN) techniques, the model is designed to overcome the challenges related to the lag of image capture devices and variations in the classroom environment.The database consists of five class sessions from the study conducted by Mery et al. (2019) and one class session collected at a school unit of the Serviço Social da Indústria (SESI), totaling almost 100 images for analysis. Compared to the Facenet512, Facenet and ArcFace models, in terms of final frequency marking accuracy, the model showed superior performance. With an increase of around 51% in accuracy compared to the others, reaching a satisfactory 76% accuracy mark, as well as demonstrating superior specificity. It is important to note that, at this stage of development, the model has the potential to benefit both teachers and students, helping to save time and reduce errors in school attendance management.","('Reconhecimento facial', 'Frequência escolar – Automatização', 'Redes neurais', 'Aprendizagem profunda', 'Visão computacional', 'Sistemas ciberfísicos', 'Tecnologias na educação', 'Face Recognition', 'School attendance – Automation', 'Neural networks', 'Deep Learning', 'Computer vision', 'Cyber-physical systems', 'Technologies in Education')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/13597","2023-11-24","https://www.repositorio.ufal.br/bitstream/123456789/13597/1/Frequ%c3%aancia%20escolar%20por%20meio%20de%20reconhecimento%20facial%20utilizando%20redes%20neurais%20residuais.pdf","",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/13777","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Indústria 4.0: conceitos e análise dos principais desafios de implantação nas empresas","('Arthur Nunes de Castro Oliveira',)","('João Raphael Souza Martins',)","('Glauber Rodrigues Leite', 'Tiago Alves de Almeida')","Com o crescente desenvolvimento da computação, o mundo presencia o surgimento de novas tecnologias capazes de impactar diretamente o cotidiano das pessoas, além das mais diversas áreas do mercado, como: economia, indústria e serviços. Diante deste contexto de avanços tecnológicos, surge o conceito de Indústria 4.0, onde o uso generalizado de sensores e a troca autônoma de dados entre dispositivos, possibilita a criação de Sistemas Físicos Cibernéticos (CPS) cuja principal característica é a virtualização do ambiente fabril, possibilitando maior controle e monitoramentos dos processos, porém essa nova Revolução Industrial traz consigo novos desafios. Desta forma foi realizada uma revisão bibliográfica, a fim de abordar os principais conceitos referentes as Indústria 4.0, como também identificar as principais dificuldades de implantação dessas novas tecnologias na indústria. Para realização da pesquisa, foram utilizados os mecanismos de busca: Science Direct, Web Of Science, IEEE Xplore e Scopus, utilizando palavras-chave relacionadas à Quarta Revolução Industrial e tecnologias afins. Inicialmente foi realizada uma análise crítica do material bibliográfico para identificar os principais desafios relacionados a Indústria 4.0, em seguida, por meio do método Survey, será realizada uma coleta de dados com gestores para validação dos resultados obtidos. Portanto, como resultados preliminares, pode-se perceber que os principais problemas enfrentados consistem na segurança das informações, falta de integração entre os processos de desenvolvimento e implantação dos algoritmos, a complexidade dos dados e o elevado custo de implantação.","With the growing development of computing, the world is witnessing the emergence of new technologies capable of directly impacting people's daily lives, in addition to the most diverse areas of the market, such as: economy, industry and services. Faced with this context of technological advances, the concept of Industry 4.0 emerges, where the widespread use of sensors and the autonomous exchange of data between devices, enables the creation of Cyber Physical Systems (CPS) whose main characteristic is the virtualization of the manufacturing environment, enabling greater control and monitoring of processes, but this new Industrial Revolution brings with it new challenges. In this way, a bibliographic review was carried out in order to address the main concepts related to Industry 4.0, as well as to identify the main difficulties of implantation of these new technologies in the industry. To carry out the research, the search engines were used: Science Direct, Web Of Science, IEEE Xplore and Scopus, using keywords related to the Fourth Industrial Revolution and related technologies. Initially, a critical analysis of the bibliographic material was carried out to identify the main challenges related to Industry 4.0, then, using the Survey method, data collection will be carried out with managers to validate the results obtained. Therefore, as preliminary results, it can be seen that the main problems faced consist of information security, lack of integration between the development and implementation processes of the algorithms, the complexity of the data and the high cost of implementation.","('Quarta Revolução Industrial', 'Indústria 4.0 – Desafios', 'Sistemas físicos cibernéticos', 'Fourth Industrial Revolution', 'Challenges', 'Cyber physical systems')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/13777","2023-10-26","https://www.repositorio.ufal.br/bitstream/123456789/13777/1/Ind%c3%bastria%204.0_conceitos%20e%20an%c3%a1lise%20dos%20principais%20desafios%20de%20implanta%c3%a7%c3%a3o%20nas%20empresas.pdf","",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/13388","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Interoperabilidade entre controladores industriais e Factory I/O através de um servidor OPC UA","('Glauber de Arruda Braga',)","('João Raphael Souza Martins',)","('Thiago Damasceno Cordeiro', 'Tiago Alves de Almeida')","O uso de computadores e softwares nas indústrias e sistemas de automação industrial teve um grande avanço na década de 1990. No entanto, a integração desses sistemas nem sempre é fácil, pois eles são compostos por componentes de diferentes fabricantes com protocolos proprietários. Para solucionar esse problema, foi criado o padrão OPC UA (Open Platform Communication Unified Architecture), que é uma tecnologia aberta e independente de plataforma para a integração de sistemas de automação industrial. Este trabalho apresenta um estudo sobre a integração de sistemas de automação industrial utilizando o padrão OPC UA. O trabalho apresenta uma metodologia para configurar uma rede através de um controlador CLP que se comunica com softwares que não possuem o mesmo protocolo de comunicação nativo, o Factory IO e o SIMULINK. A integração é realizada através do padrão OPC UA, realizando a troca de informações e de comandos. Os resultados mostraram que a integração de sistemas de automação industrial utilizando o padrão OPC UA é uma solução eficaz para os problemas de interoperabilidade, pois ele permite a troca de dados e comandos entre sistemas de diferentes fabricantes e protocolos, de forma segura e eficiente.","The use of computers and software in industrial automation systems has made significant advances since the 1990s. However, the integration of these systems is not always straightforward, as they are often composed of components from different manufacturers with proprietary protocols. To address this issue, the OPC UA (Open Platform Communication Unified Architecture) standard was developed. OPC UA is an open and platform-independent technology for the integration of industrial automation systems. This work presents a study on the integration of industrial automation systems using the OPC UA standard. The work presents a methodology for configuring a network through a PLC controller that communicates with software that does not have the same native communication protocol, Factory IO and SIMULINK. The integration is performed through the OPC UA standard, exchanging information and commands. The results showed that the integration of industrial automation systems using the OPC UA standard is an effective solution to interoperability problems, as it allows the exchange of data and commands between systems from different manufacturers and protocols in a secure and efficient manner.","('Automação industrial', 'OPC UA -Métodos orientados a objetos (Computação)', 'Factoy IO (Software)', 'CLP -Métodos orientados a objetos (Computação)', 'Industrial automation', 'OPC UA -Object-oriented methods (Computing)', 'CLP -Object-oriented methods (Computing)')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/13388","2023-10-26","https://www.repositorio.ufal.br/bitstream/123456789/13388/1/Interoperabilidade%20entre%20controladores%20industriais%20e%20Factory%20IO%20atrav%c3%a9s%20de%20um%20servidor%20OPC%20UA.pdf","",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/15045","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Identificação automática de comentários tóxicos em discussões online: uma análise de toxidade utilizando processamento de linguagem natural e aprendizado de máquina","('Jadson César da Silva Santos',)","('Leandro Dias da Silva',)","('Baldoíno Fonseca dos Santos Neto', 'Evandro de Barros Costa')","Este trabalho aborda a classificação de comentários tóxicos presentes em plataformas de mídia social e seu impacto, utilizando como base de dados da competição ""Jigsaw Toxic Comment Classification Challenge""da plataforma Kaggle. O problema dos comentários tóxicos é discutido em relação ao ambiente online e sua influência negativa. O objetivo do estudo é contribuir para uma moderação eficaz da toxicidade nas plataformas digitais por meio de modelos de classificação de machine learning. A metodologia envolveu treinamentos iniciais, onde cada modelo foi designado para uma classe específica e selecionados aqueles com a maior pontuação F1-score para refinamento dos hiperparâmetros. Foram utilizados os algoritmos SVM, RF, LR e LSTM, juntamente com os vetorizadores TFIDF, CountVectorizer e Tokenizer (exclusivamente para LSTM). Os resultados demonstraram resultados satisfatórios, superando em alguns casos as expectativas da literatura, com validação cruzada que comprovou a robustez dos modelos. Conclui-se que os objetivos do trabalho foram alcançados, e sugere-se para análises futuras a incorporação de técnicas utilizadas na competição e na literatura para melhorar o desempenho na competição da base de dados.","This work addresses the classification of toxic comments present on social media platforms and their impact, using the ""Jigsaw Toxic Comment Classification Challenge"" dataset from the Kaggle platform. The issue of toxic comments is discussed in relation to the online environment and its negative influence. The study aims to contribute to effective moderation of toxicity on digital platforms through machine learning classification models. The methodology involved initial training, where each model was assigned to a specific class, and those with the highest F1-score were selected for hyperparameter refinement. The algorithms SVM, RF, LR, and LSTM were used, along with the vectorizers TFIDF, CountVectorizer, and Tokenizer (exclusively for LSTM). The results showed satisfactory outcomes, surpassing, in some cases, the expectations of the literature, with cross-validation confirming the robustness of the models. It is concluded that the objectives of the work were achieved, and it is suggested for future analyses to incorporate techniques used in the competition and literature to enhance performance in the competition dataset.","('Processamento de Linguagem Natural', 'Aprendizado do computador', 'Ambiente online -Comentários Tóxicos', 'Validação Cruzada', 'Natural Language Processing', 'Machine Learning', 'Text Classification', 'Toxic Comments', 'Cross-validation')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/15045","2024-04-30","https://www.repositorio.ufal.br/bitstream/123456789/15045/1/Identifica%c3%a7%c3%a3o%20autom%c3%a1tica%20de%20coment%c3%a1rios%20t%c3%b3xicos%20em%20discuss%c3%b5es%20online_uma%20an%c3%a1lise%20de%20toxidade%20utilizando%20processamento%20de%20linguagem%20natural%20e%20aprendizado%20de%20m%c3%a1quina.pdf","Automatic identification of toxic comments in online discussions: a toxicity analysis using natural language processing and machine learning","('Marcos Antonio Barbosa Lima',)"
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/16768","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Heurística baseada em agrupamentos hierárquicos para resolver um problema de roteamento de veículos dinâmico e estocástico","('Ruan Heleno Correa da Silva',)","('Rian Gabriel Santos Pinheiro',)","('Bruno Costa e Silva Nogueira', 'Bruno José da Silva Barros')","Esta monografia aborda o desenvolvimento de algoritmos para resolver um caso específico do Stochastic and Dynamic Capacitated Vehicle Routing Problems (SD-CVRP), denominado Last Mile Incremental Capacitated Vehicle Routing Problem (ICVRP). A proposta envolve a aplicação de uma estratégia fundamentada na organização de modelos de agrupamento em níveis para definição do veículo de cada encomenda analisada. Tal aplicação tem como objetivo a geração de rotas eficientes com intuito de otimizar métricas fundamentais, como a distância a ser percorrida, a quantidade de rotas geradas, o tempo de execução das etapas presentes. Os resultados experimentais, obtidos a partir de mais de cem mil entregas entre entregadores de onze regiões do Brasil, demonstram a eficácia da abordagem para resolver o ICVRP, tendo demonstrado um desempenho competitivo. Em comparação com a abordagem K-means Greedy, que apresentou a menor distância percorrida total entre os algoritmos de referência, a solução proposta reduziu a distância percorrida em 2.500 km, além de manter um tempo de execução competitivo, com diferença inferior a 2 minutos em relação ao algoritmo QRP Sweep, o mais rápido entre os testados. No entanto, a proposta teve um aumento de quase 52% na distância percorrida em relação ao VRP estático, compensado por uma economia de 75% no tempo de execução. Comparada ao método MAS, da Loggi, a solução mostrou um aumento de 19% na distância total percorrida. Esses resultados indicam a viabilidade e a eficiência da solução para o ICVRP, ao mesmo tempo em que evidenciam oportunidades para aprimoramentos futuros.","This monograph presents the development of algorithms to solve a specific case of the Stochas tic and Dynamic Capacitated Vehicle Routing Problems (SD-CVRP), known as the Last Mile Incremental Capacitated Vehicle Routing Problem (ICVRP). The proposed approach involves applying a strategy based on hierarchical clustering models to determine vehicle assignments for each analyzed delivery. This application aims to generate efficient routes to optimize key metrics such as distance traveled, number of routes generated, and execution time of the various process stages. Experimental results, obtained from over one hundred thousand deliveries across eleven regions in Brazil, demonstrate the effectiveness of the proposed approach for solving the ICVRP and show competitive performance. Compared to the K-means Greedy approach, which had the lowest total distance traveled among the reference algorithms, the proposed solution reduced the total distance by 2,500 km and maintained a competitive execution time, with a difference of less than 2 minutes compared to the QRP Sweep algorithm, the fastest among those tested. However, the proposed method showed an increase of nearly 52% in the distance traveled compared to the static VRP, offset by a 75% reduction in execution time. When compared to the MAS method from Loggi, the solution showed an increase of 19% in the total distance traveled. These results indicate the feasibility and efficiency of the solution for the ICVRP while highlighting potential opportunities for future improvements.","('Roteamento de veículos', 'Last Mile', 'Logística', 'Otimização combinatória', 'Inteligência artificial', 'Aprendizado do computador', 'Clusters', 'SDCVRP', 'ICVRP', 'Vehicle routing', 'Last Mile', 'Logistics', 'Optimization', 'Artificial Intelligence', 'Machine learning', 'Clustering', 'SDCVRP', 'ICVRP')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/16768","2024-12-02","https://www.repositorio.ufal.br/bitstream/123456789/16768/1/Heur%c3%adstica%20baseada%20em%20agrupamentos%20hier%c3%a1rquicos%20para%20resolver%20um%20problema%20de%20roteamento%20de%20ve%c3%adculos%20din%c3%a2mico%20e%20estoc%c3%a1stico.pdf","",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/16556","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Identificação de sistemas usando NARX com termos","('Jonh Lucas Alves da Silva',)","('Ícaro Bezerra Queiroz de Araújo',)","('Jobson de Araújo Nascimento', 'João Raphael Souza Martins')","Os modelos lineares foram amplamente descritos na literatura, possuindo métodos de análise e controle consolidados. Esses modelos são caracterizados pela simplicidade, efici-ência, estabilidade e robustez, contudo essa classe não é capaz representar com fidelidade sistemas mais complexos. Além disso, o desenvolvimento de novas representações ma-temáticas, o avanço do poder computacional e o aumento da demanda por estimações mais precisas motivam o estudo de modelos não lineares. Este trabalho aborda a iden-tificação ofline de sistemas por meio de uma abordagem caixa cinza. Onde o modelo NARX polinomial foi alterado para que novos regressores gerados a partir das entradas e saídas fossem adicionados. Sua representação permaneceu linear nos parâmetros, então o método de mínimos quadrados foi utilizado para estimação. Enquanto, seleção de estru-tura foi realizada a partir dos algoritmos SEMP e FRP. Os casos de estudo abordaram as medições sobre um sistema de tanques conectados, um benchmark de motores acoplados à pólia e um exemplo numérico. Por fim, os modelos obtidos foram simulados, validados e comparados com sua contraparte polinomial, a fim de verificar o ganho vindo da aplicação de funções não lineares para criação de novos regressores.","Linear models have been widely described in the literature and have consolidated analysis and control methods. These models are characterized by their simplicity, efficiency, sta-bility and robustness, but this class is not capable of faithfully representing more complex systems. In addition, the development of new mathematical representations, advances in computing power and the increased demand for more ccurate estimates have motivated the study of non-linear models. This work addresses the offline identification of systems using a gray box approach. Where the polynomial NARX model was altered so that new regressors generated from the inputs and outputs were added. Its representation remained linear in parameters, so the least squares method was used for estimation. Meanwhile, structure selection was carried out using the SEMP and FRP algorithms. The case studies covered measurements on a system of connected tanks, a benchmark of motors coupled to the pulley and a numerical example. Finally, the models obtained were simulated, validated and compared with their polynomial counterpart, in order to verify the gain from applying non-linear functions to create new regressors.","('sistemas não lineares', 'NARX', 'MMQ', 'seleção de estrutura.', 'non-linear systems', 'NARX', 'MMQ', 'structure selection')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/16556","2024-11-25","https://www.repositorio.ufal.br/bitstream/123456789/16556/1/Identifica%c3%a7%c3%a3o%20de%20sistemas%20usando%20NARX%20com%20termos.pdf","","('Tiago Alves de Almeida',)"
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/17239","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Direção autônoma com aprendizado por reforço e TinyML","('Valério Nogueira Rodrigues Junior',)","('Erick de Andrade Barboza',)","('Glauber Rodrigues Leite', 'Ícaro Bezerra Queiroz de Araújo')","O aprendizado de máquina desempenha um papel importante no desenvolvimento de veículos autônomos. Este trabalho tem como objetivo abordar o problema direção autônoma utilizando apenas imagens em um protótipo de mini-veículo de baixo custo. Para isso, foram empregados algoritmos de aprendizado por reforço para treinar o modelo de inteligência artificial em um ambiente simulado virtualmente e posteriormente técnicas de TinyML para otimizá-lo e torná-lo compatível para ser executado em microcontroladores. Como resultado foi obtido um modelo capaz de dirigir o veículo corretamente em uma pista. Além disso, constatou-se uma redução significativa na latência do sistema com a abordagem de TinyML se comparado com a abordagem convencional de computação em nuvem.","Machine learning plays an important role in the development of autonomous vehicles. This work aims to tackle the autonomous driving problem using only images in a low-cost mini-vehicle prototype. For this, reinforcement learning algorithms were employed to train the artificial intelligence model in a simulated virtual environment and posteriorly TinyML techniques were used to make it compatible to be executed by microcontrollers. This resulted in a model capable of successfully drive the vehicle in a road and a comparison between the conventional cloud based and TinyML approaches showed a significant reduction in the system latency.","('Inteligência artificial', 'Sistemas embarcados', 'Aprendizado por reforço', 'TinyML', 'Deep Q-Learning', 'Artificial intelligence', 'Embedded systems', 'Reinforcement learning', 'Autonomous driving')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/17239","2024-12-05","https://www.repositorio.ufal.br/bitstream/123456789/17239/1/Dire%c3%a7%c3%a3o%20aut%c3%b4noma%20com%20aprendizado%20por%20refor%c3%a7o%20e%20TinyML.pdf","",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/13396","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Um estudo sobre o TinyML a partir de uma aplicação mobile para detecção de doenças em folhas de manga","('Itallo Patrick Castro Alves da Silva',)","('Erick de Andrade Barboza',)","('Allan Cunha Barros', 'Tiago Figueiredo Vieira')","No contexto mundial, a manga é uma das frutas mais importantes e, no Brasil, ela também se estabelece com um papel de grande importância. Contudo, as doenças que acometem a mangueira podem prejudicar de forma bastante significativa a colheita de seus frutos. Nesse sentido, a aprendizagem de máquina pode se fazer presente para ajudar o agricultor a descobrir se a sua mangueira sofre de alguma enfermidade. A partir disso, tem-se o TinyML que é uma tecnologia em plena ascensão que permite trazer o poder da aprendizagem de máquina para hardwares com recursos limitados e traz diversas vantagens com a sua utilização, como o baixo custo, latência reduzida, eficiência energética e segurança. Com isso, este trabalho se propôs a trazer uma aplicação mobile para detecção de doenças em folhas de manga e, além disso, trazer o impacto do TinyML em comparação à utilização de modelos de aprendizagem de máquina tradicionais, normalmente, hospedados em algum servidor na nuvem. Notou-se, portanto, que os resultados obtidos neste trabalho corroboram com as vantagens da utilização dessa tecnologia e que em situações onde o acesso à internet é limitado essa aplicação pode ser de grande valia, porque não se faz necessária a utilização de internet.","In the global context, mango is one of the most important fruits in the world and, in Brazil, it also plays a very important role. However, diseases that affect mango trees can significantly harm the harvest of its fruits. In this sense, machine learning can be done to help the farmer find out if his mango tree suffers from any disease. From this, we have TinyML, which is a technology on the rise that allows the power of machine learning to be brought to hardware with limited resources and brings several advantages with its use, such as low cost, reduced latency , energy efficiency and safety. With this, this work proposed to bring a mobile application for detecting diseases in manga leaves and, in addition, to bring the impact of TinyML in comparison to the use of traditional machine learning models, normally hosted on some server in the cloud. It was noted, therefore, that the results obtained in this work corroborate the advantages of using this technology and that in situations where access to the internet is limited, this application can be of great value, because the use of the internet is not necessary.","('Inteligência artificial', 'Aprendizagem de máquina', 'Manga – doença', 'Agricultura Inteligente', 'Mangifera indica -Doenças', 'Artificial intelligence', 'Machine Learning', 'Mango – disease', 'Smart Agriculture', 'Mangifera indica -Diseases', 'TinyML')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/13396","2023-10-17","https://www.repositorio.ufal.br/bitstream/123456789/13396/1/Um%20estudo%20sobre%20o%20TinyML%20a%20partir%20de%20uma%20aplica%c3%a7%c3%a3o%20mobile%20para%20detec%c3%a7%c3%a3o%20de%20doen%c3%a7as%20em%20folhas%20de%20manga.pdf","",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/12787","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Entropia de permutação espacial multivariada e sua aplicação para análise da complexidade de sistemas caóticos","('Givanildo Lima do Nascimento Júnior',)","('André Luiz Lins de Aquino',)","('Rian Gabriel Santos Pinheiro', 'Fabiane da Silva Queiroz', 'Osvaldo Aníbal Rosso')","A análise de séries temporais que modelam sistemas dinâmicos não lineares é um tema bastante explorado no meio científico, em função da ampla gama de aplicações das medidas de complexidade que são utilizadas para caracterização e estudo desses sistemas. Em particular, o caos é um dos comportamentos que podem ser observados em sistemas nãolineares a depender dos valores que determinados para seus parâmetros e as condições iniciais estabelecidas. Por apresentar grande sensibilidade a essas condições, sua trajetória pode divergir exponencialmente com pequenas mudanças de parâmetros. Dessa forma, a identificação de regimes caóticos e a quantificação do grau de caoticidade são essenciais para determinar os limites dentro dos quais é possível realizar predições. Para efetuar essa caracterização, foi introduzido o conceito do Plano Causal de Complexidade-Entropia (CECP), capaz de detectar a complexidade subjacente de sistemas dinâmicos e extrair a estrutura da série temporal de acordo com o função de distribuição de probabilidade construída a partir de seus padrões ordinais. O algoritmo desta técnica é simples e tem a capacidade de distinguir entre sinais periódicos, caóticos e estocásticos. Entretanto, nessa abordagem, a avaliação é feita sobre séries temporais univariadas, não garantindo uma caracterização adequada para sistemas multivariados, visto que a técnica adotada desconsidera a correlação existente entre as séries componentes do sistema. Além disso, por só considerar os padrões ordinais intrínsecos as séries temporais, essa abordagem implica na perda de alguns detalhes de informações de amplitude da série original. Neste trabalho, é proposta uma abordagem multivariada do CECP para caracterização de sistemas dinânimos multidimensionais, por meio do Plano de Causal Multivariado de Complexidade-Entropia (MvCECP). Além disso, é adicionada a função de distribuição de probabilidade a identificação de subpadrões espaciais, tornando a abordagem sensível a mudanças de escala nos conjuntos de dados avaliados. Para assegurar a eficácia do método, é demonstrada sua capacidade de distinguir os comportamentos caótico, estocástico e periódico de sistemas multivariados, sendo ainda mais precisa que a abordagem univariada na caracterização da dinâmica caótica.","The analysis of time series that model nonlinear dynamic systems is a topic that has been widely explored in the scientific world, due to the wide range of applications of complexity measures that are used to characterize and study these systems. In particular, chaos is one of the behaviors that can be observed in nonlinear systems depending on the values that are determined for its parameters and the initial conditions established. Due to its great sensitivity to these conditions, its trajectory can diverge exponentially with small parameter changes. Thus, the identification of chaotic regimes and the quantification of the degree of chaoticity are essential to determine the limits within which it is possible to make predictions. To carry out this characterization, the concept of the Causal Complexity-Entropy Plan (CECP) was introduced, capable of detecting the underlying complexity of dynamic systems and extracting the structure of the time series according to the probability distribution function constructed from its ordinal patterns. The algorithm of this technique is simple and has the ability to distinguish between periodic, chaotic and stochastic signals. However, in this approach, the evaluation is performed on univariate time series, not guaranteeing an adequate characterization for multivariate systems, since the technique adopted disregards the existing correlation between the component series of the system. Furthermore, as it only considers the ordinal patterns intrinsic to the time series, this approach implies the loss of some details of amplitude information from the original series. In this work, a multivariate CECP approach is proposed for the characterization of dynamic multidimensional systems, through the Complexity-Entropy Multivariate Causal Plan (MvCECP). In addition, the probability distribution function is added to the identification of spatial subpatterns, making the approach sensitive to scale changes in the evaluated datasets. To ensure the effectiveness of the method, its ability to distinguish the chaotic, stochastic and periodic behavior of multivariate systems is demonstrated, being even more accurate than the univariate approach in the characterization of chaotic dynamics.","('Sistemas dinâmico diferenciais', 'Caos (Sistemas dinâmicos)', 'Entropia (Teoria da informação)', 'Complexidade estatística', 'Análise multivariada', 'Differential dynamic systems', 'Chaos (Dynamic systems)', 'Information theory', 'Entropy (Information theory)', 'Statistical complexity', 'Multivariate analysis')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/12787","2023-07-11","https://www.repositorio.ufal.br/bitstream/123456789/12787/1/Entropia%20de%20permuta%c3%a7%c3%a3o%20espacial%20multivariada%20e%20sua%20aplica%c3%a7%c3%a3o%20para%20an%c3%a1lise%20da%20complexidade%20de%20sistemas%20ca%c3%b3ticos.pdf","",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/12907","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Estimação de estado usando fusão de sensores para um robô holonômico","('Eduardo Henrique Farias Silva',)","('Ícaro Bezerra Queiroz de Araújo',)","('Andressa Martins Oliveira', 'Tiago Alves de Almeida')","Com achegada da Revolução Industria 4.0, a robótica se tornou um mercado mais popular e desejado. Robôs articulados, veículos guiados automaticamente (AGV), humanóides, robôs móveis autônomos (AMR) entre outros; têm sido alvo de grandes estudos com objetivo de realizar trabalhos repetitivos, complicados ou que colocariam em risco a vida humana. Na robótica móvel, cujo objetivo é permitir ao robô sua locomoção em um ambiente de trabalho, desafios surgem no domínio da navegação. Este trabalho apresenta uma modelagem para o problema de rastramento de posição para robôs móveis utilizando fusão de sensores, proprioceptivos e exteroceptivos, por meio do filtro de Kalman. A modelagem utiliza como sensores uma unidade de medida inercial (IMU) e uma câmera, ambos de baixo custo, para realizar os processos do filtro, e sua implementação é feita utilizando o ROS, visando a integração em qualquer dispositivo que seja compatível.","With the arrival of Fourth Industrial Revolution, robotics has become a more popular anddesiredmarket. Articulatedrobots,automaticallyguidedvehicles(AGV),humanoids, autonomous mobile robots (AMR), and others; have been the subject of large studies with the aim of carrying out repetitive, complicated work or work that would endanger human life. In mobile robotics, whose objective is to allow the robot to move around in a work environment, challenges arise in the field of navigation. This work presents a modeling for the position tracking problem for mobile robots using sensor fusion, proprioceptive and exteroceptive sensors, through the Kalman filter. The modeling uses an inertial measurement unit (IMU) and a camera as sensors, both of low cost, to carry out the filter processes, and its implementation is done using ROS, aiming at integration in any device that is compatible.","('Robótica móvel', 'Filtro de Kalman', 'Sensor inercial', 'Mobile robotics', 'Kalman filter', 'Inertial sensor')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/12907","2023-08-10","https://www.repositorio.ufal.br/bitstream/123456789/12907/1/Estima%c3%a7%c3%a3o%20de%20estado%20usando%20fus%c3%a3o%20de%20sensores%20para%20um%20rob%c3%b4%20holon%c3%b4mico.pdf","","('Glauber Rodrigues Leite',)"
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/12847","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Estimação paramétrica para um modelo de sinais de eletrocardiograma sintético utilizando o algoritmo da região de confiança","('Joicy Jovelina Oliveira Soares',)","('Thiago Damasceno Cordeiro',)","('Davi Bibiano Brito', 'Álvaro Alvares de Carvalho César Sobrinho')","A aplicação de modelos computacionais em métodos para detecção de doenças cardíacas tornou-se muito importante, uma vez que essas doenças caracterizam a maior causa de mortalidade no mundo. Existem alguns mecanismos para diagnósticos de tais cardiopatias, entre eles destaca-se o Eletrocardiograma (ECG), cujo fundamental estudo trouxe-se à tona trabalhos que se propuseram a desenvolver sinais sintéticos de ECGs. O presente estudo apresenta uma metodologia capaz de apresentar sinais de ECG mediante estimação paramétrica de um modelo sintético. Para tal, se fez necessária a aprendizagem de conceitos específicos sobre o coração e a morfologia do eletrocardiograma, caracterizada pela presença das ondas P, Q, R, S e T. Notou-se que a combinação de diferentes valores para parâmetros θi , ai e bi , que formulam tais ondas, resultam em diferentes morfologias para o sinal de ECG gerado. Valores aleatórios foram utilizados para análise de convergência entre o sinal de ECG estimado e o sinal de ECG gerado através de dados obtidos por trabalhos anteriores. Os resultados do processo de estimação foram obtidos com análise de cada parâmetro em particular e do sinal resultante que apresentou excelente eficiência.","The application of computer models in methods for detecting heart diseases has become very important since these diseases are the leading cause of mortality worldwide. There are some mechanisms for diagnosing such heart diseases, among them the Electrocardiogram (ECG), whose fundamental study brought to light studies that proposed to develop synthetic signals of ECGs. The present study presents a methodology capable of giving ECG signals through parametric estimation of a synthetic model. To this end, it was necessary to learn specific concepts about the heart and the electrocardiogram morphology, characterized by the presence of P, Q, R, S, and T waves. It was noted that the combination of different values for parameters θi , ai, and bi , which formulate such waves, result in different morphologies for the generated ECG signal. Random values were used to analyze the convergence between the estimated ECG signal and the signal generated from previous works’ data. The main results were obtained by analyzing each parameter and the resulting signal, which showed excellent efficiency.","('Eletrocardiograma', 'Estimação paramétrica', 'Sinais sintéticos', 'Electrocardiograms', 'Parametric estimation', 'Sythetic signals')","Ciência da Informação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/12847","2022-07-29","https://www.repositorio.ufal.br/bitstream/123456789/12847/1/Estima%c3%a7%c3%a3o%20param%c3%a9trica%20para%20um%20modelo%20de%20sinais%20de%20eletrocardiograma%20sint%c3%a9tico%20utilizando%20o%20algoritmo%20da%20regi%c3%a3o%20de%20confian%c3%a7a.pdf","",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/17163","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Desenvolvimento de uma tomada inteligente com proteção contra surtos e monitoramento de energia","('Élisson França de Souza',)","('João Raphael Souza Martins',)","('Glauber Rodrigues Leite', 'Jobson de Araújo Nascimento')","A crescente demanda por soluções de automação e proteção no ambiente residencial impulsiona o desenvolvimento de dispositivos inteligentes capazes de garantir maior segurança e eficiência energética. Com o avanço da tecnologia e a popularização dos conceitos de Internet das Coisas (IoT), a automação residencial tem se tornado uma ferramenta essencial para melhorar o controle sobre o consumo de energia e a proteção dos equipamentos domésticos. Este trabalho se propõe a desenvolver uma tomada inteligente que combina monitoramento de energia, proteção contra surtos e controle remoto, proporcionando uma solução eficiente e acessível para o gerenciamento elétrico em casas conectadas. Utilizando a ESP32 como microcontrolador e a plataforma Blynk para interação com o usuário, o sistema permite monitoramento contínuo da corrente e tensão da rede elétrica, além de fornecer alertas em tempo real e a capacidade de desligar dispositivos em caso de oscilações prejudiciais, como swell e sag de tensão. A proteção contra surtos é garantida por componentes como Varistor de Óxido Metálico (MOV) e centelhador a gás (GDT), que atuam na limitação de picos de tensão, assegurando a integridade dos equipamentos conectados. A solução foi validada por meio de testes que demonstraram a precisão das medições e a eficácia do sistema em condições de operação, destacando seu potencial como uma ferramenta prática e confiável para a automação e proteção elétrica residencial.","The growing demand for automation and protection solutions in residential environments drives the development of smart devices capable of ensuring greater security and energy efficiency. With the advancement of technology and the widespread adoption of Internet of Things (IoT) concepts, home automation has become an essential tool for improving control over energy consumption and protecting household appliances. This work aims to develop a smart plug that combines energy monitoring, surge protection, and remote control, providing an efficient and cost effective solution for electrical management in connected homes. Using the ESP32 as the microcontroller and the Blynk platform for user interaction, the system enables continuous monitoring of the current and voltage of the electrical grid, in addition to providing real-time alerts and the ability to turn off devices in the event of harmful voltage fluctuations, such as swell and sag. Surge protection is ensured by components such as Metal Oxide Varistor (MOV) and Gas Discharge Tube (GDT), which limit voltage spikes and safeguard the connected equipment. The solution was validated through tests that demonstrated the accuracy of the measurements and the effectiveness of the system under operating conditions, highlighting its potential as a practical and reliable tool for home electrical automation and protection.","('Automação residencial', 'Internet das coisas', 'Energia-Monitoramento', 'Tomada inteligente', 'Home automation', 'electrical protection', 'Surge Protection Device (SPD)', 'Internet of Things (IoT)', 'energy monitoring', 'smart plug', 'smart home', 'ESP32', 'Blynk')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/17163","2024-12-05","https://www.repositorio.ufal.br/bitstream/123456789/17163/1/Desenvolvimento%20de%20uma%20tomada%20inteligente%20com%20prote%c3%a7%c3%a3o%20contra%20surtos%20e%20monitoramento%20de%20energia.pdf","",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/16195","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Detecção automática de nódulos pulmonares utilizando transformers","('Nilson Sales de Carvalho',)","('Marcelo Costa Oliveira',)","('Baldoíno Fonseca dos Santos Neto', 'Erick de Andrade Barboza')","O câncer de pulmão (CP) é o segundo tipo de câncer mais prevalente no mundo e o mais letal, sendo responsável por uma a cada cinco mortes por câncer no mundo. As chances de sobrevida dos pacientes detectados com este tipo de câncer aumentam consideravelmente quando o diagnóstico é realizado de maneira precoce, com a taxa de sobrevida em 5 anos chegando a até 70%. O diagnóstico do CP é realizado por radiologistas através de imagens de Tomografia Computadorizada (TC), porém tal diagnóstico é uma tarefa complexa e sujeita a erros, uma vez que os nódulos podem apresentar tamanho muito pequeno ou estar localizado próximos a outras estruturas anatômicas. Os profissionais da área sofrem ainda de fadiga e pressa no diagnóstico, já que a quantidade de exames a serem analisados é geralmente muito alta. Através das ferramentas de auxílio computadorizado (CAD), esse processo de diagnóstico pode ser automatizado, reduzindo tempo e esforço dos especialista, bem como melhorar a confiança no diagnóstico. Atualmente as técnicas de deep learning (DL), em especial com o uso de CNNs, são o estado-da arte para a detecção automática de nódulos pulmonares, porém com a introdução da arquitetura transformer às tarefas de visão computacionais, abre-se mais uma área a ser explorada. Nesse contexto, o objetivo deste trabalho foi apresentar um sistema de detecção automática de nódulos pulmonares em imagens de TC utilizando a arquitetura transformer. Avaliamos ainda a hipótese de que a arquitetura transformer seja tão eficiente quanto os modelos de CNN na detecção de nódulos pulmonares.","Lung cancer is the second most prevalent type of cancer in the world and the most deadly, accounting for one in five cancer deaths worldwide. The chances of survival of a patient detected with lung cancer increase considerably when the diagnosis is made early, with the 5-year survival rate reaching up to 70%. The lung cancer diagnosis is performed by radiologists through Computed Tomography (CT) images, but this is a complex task and subject to errors, since the nodules may be very small or located close to other anatomical structures. Professionals in the area also suffer from fatigue and a rush to diagnose, given that the number of exams to be analyzed is usually very high. Computer aided diagnosis (CAD) systems can automate this diagnosis process, reducing the time and effort from the specialists, as well as improving diagnostic confidence. Currently, deep learning (DL) techniques, especially with the use of CNNs, are the state-of-the-art for the automatic detection of pulmonary nodules, but with the introduction of the transformer architecture to computer vision tasks, a new area can be explored. In this context, the objective of this work is to present a system for the automatic detection of pulmonary nodules in CT images using the transformer architecture. We also evaluated the hypothesis that the transformer architecture is as efficient as the CNN models in the detection of pulmonary nodules.","('Detecção de objetos', 'Transformers -Aprendizagem profunda', 'Processamento de imagem assistida por computador', 'Nódulos pulmonares', 'Object detection', 'Transformers -Deep Learning', 'Computer-assisted image processing', 'Pulmonary nodules')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/16195","2022-07-15","https://www.repositorio.ufal.br/bitstream/123456789/16195/1/Detec%c3%a7%c3%a3o%20autom%c3%a1tica%20de%20n%c3%b3dulos%20pulmonares%20utilizando%20transformers.pdf","Automatic detection of pulmonary nodules using transformers",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/15653","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","A CNN model to classify traditional ethnic clothing style garments","('Larissa Duarte Santana',)","('Márcio de Medeiros Ribeiro',)","('Erick de Andrade Barboza', 'Marcelo Costa Oliveira')","A classificação de vestimentas tradicionais está nos estágios iniciais de exploração dentro do estudo acadêmico da tecnologia da moda, com relativamente poucos estudos dedicados a essa área específica. Apesar do crescente interesse em aplicar técnicas de visão computacional na indústria da moda, a pesquisa atual foca predominantemente em estilos de moda moderna, deixando a necessidade de mais atenção para roupas tradicionais culturalmente significativas. Esta pesquisa visa atender a essa necessidade utilizando Redes Neurais Convolucionais (CNNs) para classificar estilos de vestimentas femininas tradicionais étnicas, especificamente roupas de quatro nacionalidades: alemã (dirndl), indiana (sari), japonesa (quimono) e espanhola (flamenco). Ao aproveitar técnicas de aprendizado profundo, particularmente CNNs, buscamos melhoraraprecisãoeaeficiênciadossistemasdeclassificaçãodemodaparavestimentastradicionais. Nosso estudo envolve a construção de um conjunto de dados diversificado com quatro etiquetas de nacionalidade, totalizando 5.879 imagens, e o desenvolvimento de um novo modelodeclassificador,precedidoporumarevisãoabrangentedaliteraturaqueexaminaastécnicas de classificação existentes e os contextos nos quais vários tipos de vestimentas étnicas foram estudados academicamente. Esta revisão destaca o trabalho limitado, mas crescente, focado em vestimentas tradicionais. Avaliamos empiricamente o desempenho do nosso modelo em comparação com modelos estabelecidos, comparando sua eficácia em reconhecer e categorizar estilos de vestimentas tradicionais de diferentes culturas. Como resultado, alcançamos uma taxa de precisão de 94% e uma perda de 21%, demonstrando a eficácia do modelo na classificação de vestimentas tradicionais étnicas. Além disso, observando a matriz de confusão, o modelo classificou corretamente o conjunto de testes para as etiquetas alemã (95,88%), indiana (97,54%), japonesa (92,59%) e espanhola (89,22%). Esses achados são esperados para contribuir significativamente para a visão computacional e a tecnologia da moda, oferecendo novos insights e aplicações práticas para a indústria da moda. Ao focar em vestimentas tradicionais, nosso trabalho não só aprimora as capacidades técnicas dos sistemas de classificação de moda, mas também promove uma apreciação e compreensão mais profundas das diversas heranças culturais através da tecnologia.","Theclassificationoftraditionalgarmentsisintheearlystagesofexplorationwithintheacademic study of fashion technology, with relatively few studies dedicated to this specific area. Despite the growing interest in applying computer vision techniques to the fashion industry, current research predominantly focuses on modern fashion styles, leaving a need for more attention to culturally significant traditional clothing. This research aims to address this need by utilizingConvolutionalNeuralNetworks(CNNs)toclassifyfemininetraditionalethnicclothing styles, specifically garments from four nationalities: German (dirndl), Indian (saree), Japanese (kimono),andSpanish(flamenco). Byleveragingdeeplearningtechniques,particularlyCNNs, we seek to enhance the accuracy and efficiency of fashion classification systems for traditional garments. Our study involves the construction of a diverse dataset with four nationality labels withatotalof5,879imagesandthedevelopingofanovelclassifiermodel,precededbyacomprehensive literature review that examines existing classification techniques and the contexts in which various ethnic clothing types have been studied academically. This review underscores the limited but growing work focusing on traditional garments. We empirically evaluate the performance of our model against established models, comparing its effectiveness in recognizing and categorizing traditional clothing styles from different cultures.As result, we achieved an accuracy rate of 94%, and loss 21% demonstrating the model’s effectiveness in classifying traditional ethnic garments. Additionaly, observing from the confusion matrix, the model classifiedcorrectlyfromthetestdatasetgerman(95.88%),indian(97.54%),japanese(92.59%)and spanish (89.22%). These findings are expected to contribute significantly to computer vision and fashion technology, offering new insights and practical applications for the fashion industry. By focusing on traditional garments, our work not only enhances the technical capabilities of fashion classification systems but also promotes a deeper appreciation and understanding of diverse cultural heritages through technology.","('Inteligência artificial', 'Aprendizagem profunda', 'Redes neurais', 'Redes neurais convolucionais', 'Moda -Classificação', 'Trajes étnicos', 'Artificial intelligence', 'Deep Learning', 'Neural Networks', 'Convolutional Neural Networks', 'Classification', 'Fashion', 'Traditional Garments')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/15653","2024-07-29","https://www.repositorio.ufal.br/bitstream/123456789/15653/1/A%20CNN%20model%20to%20classify%20traditional%20ethnic%20clothing%20style%20garments.pdf","",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/13866","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Desenvolvimento de um modelo para detecção de uso de máscara facial e sua adaptação para um dispositivo embarcado","('Matheus Ferreira Gêda',)","('Erick de Andrade Barboza',)","('Baldoíno Fonseca dos Santos Neto', 'Bruno Almeida Pimentel')","Essa monografia aborda a elaboração de modelos de aprendizado de máquina destinados a sistemas embarcados. No âmbito deste estudo, foram treinados diversos modelos com o propósito de classificar o uso de máscaras, sendo esses modelos posteriormente adaptados para integração em um sistema embarcado. O treinamento do modelo baseou-se em uma base de dados preexistente, composta por cinco mil imagens distribuídas em duas classes distintas. Os resultados experimentais obtidos indicam a viabilidade de incorporar esse modelo, desde que sejam observadas as restrições específicas de cada hardware, como limitações de memória, capacidade de processamento reduzida, baixo consumo de energia, entre outros aspectos. Durante a fase de teste, a avaliação dos modelos destacou a superioridade dos modelos em escala de cinza em termos de acurácia e perda, sendo notável o desempenho do modelo 64×64 em escala de cinza, que alcançou uma acurácia impressionante de 99.66%","This dissertation explores the development of machine learning models tailored for embedded systems. Within this study, diverse models were trained with the objective of classifying mask usage, and subsequently adapted for integration into an embedded system. Model training re lied on an existing dataset comprising five thousand images categorized into two distinct classes. Experimental results suggest the feasibility of incorporating this model, provided specific hard ware constraints such as limited memory, reduced processing capacity, low power consumption, among other aspects, are carefully considered. This research contributes to the understanding of deploying machine learning in resource-constrained embedded environments, with a focus on real-world applications like mask detection.","('Aprendizagem de máquina', 'Sistemas embarcados', 'Máscara facial', 'Embedded Systems', 'TinyML', 'Artificial inteligence', 'Machine learning', 'Deep Learning', 'Computer Vision', 'Image Processing', 'Neural Networks', 'Convolutional Neural Networks', 'Workplace safety', 'Personal protective equipment')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/13866","2023-12-22","https://www.repositorio.ufal.br/bitstream/123456789/13866/1/Desenvolvimento%20de%20um%20modelo%20para%20detec%c3%a7%c3%a3o%20de%20uso%20de%20m%c3%a1scara%20facial%20e%20sua%20adapta%c3%a7%c3%a3o%20para%20um%20dispositivo%20embarcado.pdf","",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/15762","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Avaliação de métodos de agregação em ambientes federados: aplicações em classificação de imagens com redes neurais convolucionais","('Ester de Lima Pontes Andrade',)","('André Luiz Lins de Aquino',)","('Douglas Leite Leal Moura', 'Geymerson dos Santos Ramos')","Este trabalho apresenta uma análise técnica detalhada dos métodos de agregação FedAvg, FedProx e WeightedFedAvg no contexto do aprendizado federado, aplicados a redes neurais convolucionais para tarefas de classificação em três datasets: MNIST, FashionMNIST e CIFAR10. O aprendizado federado, uma abordagem descentralizada de treinamento de modelos, permite a colaboração entre múltiplos dispositivos mantendo os dados localmente, o que é crucial para a preservação da privacidade em cenários distribuídos. Os experimentos foram conduzidos em um ambiente de dados não IID (não independentemente e identicamente distribuídos), replicando condições do mundo real onde a distribuição dos dados entre os clientes é heterogênea. Para cada método de agregação, o treinamento local foi realizado por 5 épocas em cada cliente, seguido da agregação central das atualizações dos pesos, com o ciclo repetido por 10 rodadas. A avaliação do desempenho foi realizada com base em métricas tradicionais de acurácia e perda, além de análises mais sofisticadas utilizando curvas ROC/AUC e matrizes de confusão, proporcionando uma avaliação granular da capacidade discriminativa dos modelos e dos padrões de erro específicos. Os resultados obtidos revelam que o método WeightedFedAvg supera consistentemente os demais em ambientes de alta heterogeneidade e desbalanceamento de dados, especialmente no CIFAR-10, atingindo uma acurácia superior e menor perda, o que reforça sua adequação para cenários federados desafiadores. O FedProx demonstrou estabilidade em cenários com grande variabilidade entre os dados dos clientes, mitigando a divergência das atualizações locais e preservando a coesão do modelo global. Por outro lado, o FedAvg, embora eficiente em ambientes com distribuição de dados mais homogênea, mostrou limitações significativas em cenários mais complexos, alinhando-se com os desafios discutidos na literatura. A pesquisa conclui que, embora FedAvg permaneça uma solução eficaz para ambientes federados homogêneos, a crescente complexidade dos cenários reais exige a adoção de métodos de agregação mais avançados, como FedProx e WeightedFedAvg, que demonstram maior resiliência e precisão em contextos de alta variabilidade dos dados. Estes achados indicam a necessidade de futuras investigações que possam desenvolver novos algoritmos de agregação capazes de equilibrar ainda mais a estabilidade e a precisão dos modelos em ambientes federados complexos e desafiadores.","This study presents a detailed technical analysis of the FedAvg, FedProx, and WeightedFedAvg aggregation methods in the context of federated learning, applied to convolutional neural networks for classification tasks on three datasets: MNIST, FashionMNIST, and CIFAR-10. Federated learning, a decentralized model training approach, facilitates collaboration across multiple devices while maintaining data locally, which is crucial for preserving privacy in distributed scenarios. The experiments were conducted in a non-IID (non-independently and identically distributed) data environment, replicating real-world conditions where data distribution among clients is heterogeneous. For each aggregation method, local training was performed for 5 epochs on each client, followed by central aggregation of the weight updates, with this cycle repeated for 10 rounds. Performance evaluation was based on traditional metrics such as accuracy and loss, as well as more sophisticated analyses using ROC/AUC curves and confusion matrices, providing a granular assessment of the models’ discriminative capabilities and specific error patterns. The results reveal that the WeightedFedAvg method consistently outperforms the others in environments characterized by high heterogeneity and data imbalance, particularly on CIFAR10, achieving superior accuracy and lower loss, which reinforces its suitability for challenging federated learning scenarios. FedProx demonstrated stability in settings with significant variability among client data, mitigating divergence in local updates and preserving the cohesion of the global model. In contrast, while FedAvg is efficient in more homogeneous data distribution environments, it showed significant limitations in more complex scenarios, aligning with the challenges discussed in the literature. The research concludes that, although FedAvg remains an effective solution for homogeneous federated environments, the increasing complexity of real-world scenarios necessitates the adoption of more advanced aggregation methods, such as FedProx and WeightedFedAvg, which exhibit greater resilience and accuracy in contexts of high data variability. These findings indicate the need for future investigations to develop new aggregation algorithms capable of further balancing the stability and accuracy of models in complex and challenging federated environments.","('Aprendizado federado', 'Agregação (Computação)', 'Classificação de imagens', 'Redes neurais convolucionais', 'Classificação de imagens', 'FedAvg', 'FedProx', 'WeightedFedAvg', 'FashionMNIST', 'CIFAR-10', 'Federated learning', 'Aggregation methods', 'Image Classification')","Sistemas de Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/15762","2024-08-22","https://www.repositorio.ufal.br/bitstream/123456789/15762/1/Avalia%c3%a7%c3%a3o%20de%20m%c3%a9todos%20de%20agrega%c3%a7%c3%a3o%20em%20ambientes%20federados_aplica%c3%a7%c3%b5es%20em%20classifica%c3%a7%c3%a3o%20de%20imagens%20com%20redes%20neurais%20convolucionais.pdf","",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/17525","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Controle PID aplicado a um sistema de geração elétrico","('Lilian Fabrício Marques Neves',)","('Ícaro Bezerra Queiroz de Araújo',)","('Glauber Rodrigues Leite', 'Andressa Martins Oliveira')","Este trabalho apresenta a implementação e análise comparativa dos controlador PID aplicados ao controle de velocidade de um sistema motor-gerador de corrente contínua (CC) em uma bancada experimental de baixo custo. Utilizando componentes acessíveis, como Arduino Nano, transistor TIP120, sensores de velocidade e uma fonte de alimentação de 5V, a bancada permite explorar o ajuste manual dos parâmetros de controle, proporcionando uma visão prática das diferenças entre as estratégias de controle. Para cada controlador, foi avaliado o desempenho em termos de tempo de resposta, estabilidade e precisão. O sistema foi programado na Arduino IDE e, através do monitor serial, foram coletados dados para plotagem dos gráficos de medição, atuação e referência, permitindo uma análise detalhada da resposta do sistema em diferentes condições operacionais.","This work presents the implementation and comparative analysis of PID controller applied to the speed control of a direct current (DC) motor-generator system in a low-cost experimental setup. Using accessible components such as an Arduino Nano, TIP120 transistor, speed sensors, and a 5V power supply, the setup enables the manual tuning of control parameters, providing a practical understanding of the differences between control strategies. The performance of each controller was evaluated in terms of response time, stability, and accuracy. The system was programmed using the Arduino IDE, and data were collected via the serial monitor for plotting measurement, control, and reference graphs, enabling a detailed analysis of the system’s response under various operational conditions.","('Engenharia de computação', 'Controle de processos', 'Controladores PID', 'Process Control', 'PID Controller', 'Motor-Generator System', 'Control Systems')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/17525","2024-12-06","https://www.repositorio.ufal.br/bitstream/123456789/17525/1/Controle%20PID%20aplicado%20a%20um%20sistema%20de%20gera%c3%a7%c3%a3o%20el%c3%a9trico.pdf","",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/17196","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Comparativo entre o campeonato brasileiro de futebol e as principais ligas europeias de futebol: uma análise estatística","('Victor Accete Nicácio Placido',)","('Bruno Almeida Pimentel',)","('Roberta Vilhena Vieira Lopes', 'Evandro de Barros Costa')","Apesar do futebol ser o esporte mais popular do Brasil, o campeonato brasileiro de futebol é sub-representado em estudos científicos que analisam aspectos técnicos e táticos do esporte. Estudos que comparam ligas são relativamente comuns, mas eles geralmente focam nas principais ligas europeias. Este trabalho se propõe a analisar como o campeonato brasileiro de futebol se compara, em aspectos técnicos e táticos, às quatro principais ligas europeias de futebol: Premier League da Inglaterra, La Liga da Espanha, Bundesliga da Alemanha e Série A da Itália. Apesar de existir uma grande diferença em receitas e valor de mercado dos elencos, este trabalho explora a oportunidade de analisar se essas diferenças se traduzem em grandes diferenças no que diz respeito a aspectos técnicos e táticos do esporte, avaliando algumas métricas de desempenho notacionais. Além disso, este trabalho analisa também o equilíbrio interno das ligas. Para as análises, foram coletados dados notacionais das ligas e das equipes em cinco temporadas. Os resultados demonstraram que o campeonato brasileiro possui indicadores piores em diversas métricas de desempenho, especialmente ao se considerar apenas os clubes do topo das tabelas de classificação. No entanto, também foi possível observar que algumas métricas foram similares ou até melhores, apesar da discrepância econômica. Também foi possível perceber que o campeonato brasileiro é mais equilibrado do que as principais ligas europeias.","Although football is the most popular sport in Brazil, the brazilian football league is underrepresented in scientific studies that analyse technical and tactical aspects of the sport. Studies that compare leagues are relatively common, mas they usually focus on the major european leagues. This work aims to analyse how the brazilian football league compares, in technical and tactical aspects, to the four major european football leagues: English Premier League, Spanish La Liga, German Bundesliga and Italian Serie A. Even though there is a big difference in revenue and market value of the squads, this work explores the opportunity to analyse if these differences translate into big differences concerning technical and tactical aspects of the sport, by analysing a few notational performance metrics. Besides this, this work also analyses the internal balance of the leagues. For the analyses, we collected five seasons of leagues’ and squads’ notational data. Results showed that the brazilian league has worse indicators in many performance metrics, especially when considering only the top clubs from ranking tables in each season. However, it was also possible to observe that some metrics were similar ou even better, despite the economic discrepancy. It was also possible to see that the brazilian league if more balanced than the major european leagues.","('Análise de dados', 'Análise estatística', 'Método comparativo', 'Ciências de dados', 'Futebol -Brasil', 'Futebol -Europa', 'Visualização da informação', 'Futebol -Análise', 'Data analysis', 'Statistical analysis', 'Comparative method', 'Data science', 'Football -Brazil', 'Football -Europe', 'Information visualization', 'Football -Analysis')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/17196","2024-11-28","https://www.repositorio.ufal.br/bitstream/123456789/17196/1/Comparativo%20entre%20o%20campeonato%20brasileiro%20de%20futebol%20e%20as%20principais%20ligas%20europeias%20de%20futebol%3a%20uma%20an%c3%a1lise%20estat%c3%adstica.pdf","",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/16354","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","A computational approach to screen scratch detection and analysis for improved maintenance of LCD terminals","('Hiago Lopes Cavalcante',)","('Tiago Figueiredo Vieira',)","('Erick de Andrade Barboza', 'Ícaro Bezerra Queiroz de Araújo')","Fabricantes de terminais de cartão de crédito e débito emprestam seus produtos aos varejistas, atribuindo a responsabilidade pela reparação ou substituição dos dispositivos pós-verificação de defeitos funcionais, ou estéticos. Um operador logístico, que processa cerca de dez mil produtos diariamente, deve avaliar a condição de cada dispositivo por meio de testes e inspeções visuais manuais. Dependendo da avaliação, um terminal pode ser devolvido ao cliente ou enviado ao centro técnico do fabricante para reparo. Este processo de inspeção é altamente subjetivo e propenso a erros humanos, pelo fato de que diferentes operadores podem avaliar o mesmo dispositivo de maneira inconsistente. Para resolver essas inconsistências, desenvolvemos um sistema de inspeção visual para avaliar as condições das telas LCD desses terminais de pagamento. O hardware inclui uma estrutura impressa em 3D para otimizar a aquisição de imagens, um esquema de iluminação ativa e uma câmera para a obtenção das imagens dos terminais. A aplicação desktop integra um modelo de detecção de objetos YOLOv8, treinado com os nossos dados, para destacar defeitos na tela dos terminais, que possui por uma interface intuitiva com várias funcionalidades. Esse sistema melhorou a eficiência e a precisão das inspeções, proporcionando aos operadores uma ferramenta confiável que garante consistência. O modelo final alcançou uma precisão média (mAP) de 77,4% e uma velocidade de processamento de 88 milissegundos em CPU. Além disso, a interface da aplicação em tempo real oferece usabilidade de baixa latência, aprimorando mais o processo de inspeção. Após um rigoroso treinamento e testes do modelo, realizados em colaboração com o fabricante dos terminais, o sistema demonstrou sua confiabilidade para implantação em nível de produção.","Manufacturers of credit and debit card terminals lend their products to retailers, retaining responsibility for repairing or replacing devices upon verification of malfunctions or cosmetic defects. The logistic operator, which processes up to ten thousand products daily, must assess each device’s condition through tests and manual visual inspections. Depending on the evaluation, a terminal may be returned to the client or sent to the manufacturer’s tech center for repair. This inspection process is highly subjective and prone to human error, as different inspectors may assess the same device inconsistently. To address these inconsistencies, we developed a visual inspection system specifically for evaluating the LCD conditions of payment terminals. The hardware includes a 3D-printed structure to optimize image acquisition, an active illumination scheme, and a camera to capture images of the terminals. The web application features a YOLOv8 object detection model to highlight defects on the terminal’s screen, complemented by a user-friendly interface with various functionalities. Our system significantly improved the efficiency and accuracy of inspections, providing operators with a reliable tool that ensures consistency. The final model achieved a mean Average Precision (mAP) of 77.4% and a processing speed of 88 milliseconds on CPU. Additionally, the real-time application interface offers low-latency usability, further enhancing the inspection process. After thorough model training and testing conducted in collaboration with the terminal manufacturer, the system has demonstrated its reliability for deployment at the production level.","('YOLOv8 (Detecção de objetos)', 'Cartão de crédito -Terminais (Computador)', 'Inspeção visual automática', 'Visão computacional', 'Object detection', 'Credit card terminals', 'Visual inspection', 'Computer vision')","Ciência da Computação","eng","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/16354","2024-09-27","https://www.repositorio.ufal.br/bitstream/123456789/16354/1/A%20computational%20approach%20to%20screen%20scratch%20detection%20and%20analysis%20for%20improved%20maintenance%20of%20LCD%20terminals.pdf","Uma abordagem computacional para detecção e análise de arranhões em telas para manutenção aprimorada de terminais LCD",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/15687","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Aplicação do algoritmo MOESP na identificação de sistemas dinâmicos","('Maria Fernanda Herculano Machado da Silva',)","('Ícaro Bezerra Queiroz de Araújo',)","('Thiago Damasceno Cordeiro', 'Glauber Rodrigues Leite', 'Allan de Medeiros Martins')","A identificação de sistemas é uma área de grande relevância na engenharia por oferecer uma solução a um problema de controle quando a modelagem direta de sistemas complexos não é viável. Ao utilizar dados de entrada e saída de um sistema em análise, é possível obter um modelo matemático que represente sua dinâmica sem a necessidade de compreender completamente seu funcionamento interno. Entre os métodos de identificação da literatura, o algoritmo MOESP se destaca por sua simplicidade, relevância e determinismo, capaz de identificar algebricamente um sistema representado por equações de estados. Este trabalho propõe o estudo das etapas desse algoritmo, bem como sua aplicação e validação em exemplos de sistemas com comportamentos dinâmicos diversos. Além disso, investiga-se a influência da ordem estimada nos resultados (variável livre do algoritmo), analisando-os tanto de forma gráfica quanto matemática. Os resultados obtidos indicam um potencial significativo para a aplicação prática do MOESP na área de identificação de sistemas, oferecendo uma abordagem robusta e eficaz para engenheiros lidarem com problemas complexos de modelagem e controle.","System identification is an area of great relevance in engineering as it offers a solution to a control problem when direct modeling of complex systems is not feasible. By using input and output data from a system under analysis, it is possible to obtain a mathematical model that represents its dynamics without the need to fully understand its internal workings. Among the identification methods in the literature, the MOESP algorithm stands out for its simplicity, relevance, and determinism, capable of algebraically identifying a system represented by state equations. This work proposes the study of the stages of this algorithm, as well as its application and validation in examples of systems with diverse dynamic behaviors. Additionally, the influence of the estimated order on the results (a free variable of the algorithm) is investigated, analyzing them both graphically and mathematically. The results obtained indicate significant potential for the practical application of MOESP in the field of system identification, offering a robust and effective approach for engineers to deal with complex modeling and control problems.","('Identificação de sistemas', 'MOESP (Algoritmo)', 'Método de subespaço', 'Espaço de estados', 'Sistemas dinâmicos', 'System Identification', 'Subspace Methods', 'State Space', 'Dynamic Systems')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/15687","2024-07-25","https://www.repositorio.ufal.br/bitstream/123456789/15687/1/Aplica%c3%a7%c3%a3o%20do%20algoritmo%20MOESP%20na%20identifica%c3%a7%c3%a3o%20de%20sistemas%20din%c3%a2micos.pdf","",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/13779","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Classification of DPLDs in HRCT scans: a comparative study of texture analysis methods and a novel statistical and graph-based approach","('Álvaro Amorim de Albuquerque',)","('Fabiane da Silva Queiroz',)","('André Luiz Lins de Aquino', 'Rian Gabriel Santos Pinheiro')","Problemas de classificação de textura são consistentemente desafiadores uma vez que padrões de diferentes instâncias podem ser bastante similares. Além disso, os descritores precisam ser invariantes a rotações e variações de escala e iluminação. No contexto de imagens médicas, esse grupo de métodos pode auxiliar no diagnóstico de pacientes como parte do conceito de Diagnóstico Auxiliado por Computador (Computer-aided Diagnosis -CAD). Neste paper, nós revisamos métodos de classificação de textura no contexto de classificação de Doenças Pulmonares Parenquimatosas Difusas (Diffuse Parenchymal Lung Diseases -DPLDs) em Tomografias Computadorizadas de Alta Resolução (HighResolution Computed Tomographies -HRCTs) e propomos um novo método que utiliza conceitos de Redes Complexas e métricas estatísticas. Nosso método é baseado em mapear a imagem de entrada em grafos multi-escala e extrair métrica de centralidade de proximidade. Transformamos as imagens de centralidade de proximidade multi-escala em uma matriz que encapsula informação de textura global e local. Desta matriz, extraímos um vetor de features que representa um padrão de DPLD que, por sua vez, é combinado com descritores de Haralick e Padrão Binário Local (LBP) para gerar o vetor de features final. Uma vez que isto caracteriza todas as imagens, passamos para a etapa de classificação para reconhecer a imagem. Analisamos a performance do método proposto ao compará-lo com outros métodos de classificação de textura e discutindo as métricas para cada classe (padrão da DPLD) do dataset. Após a avaliação de diferentes métodos e do método proposto, é possível concluir a efetividade da nossa abordagem para auxiliar o diagnóstico de DPLDs. Além disso, podemos destacar nossa técnica como um auxílio ao problema de diagnosticar pacientes com COVID-19.","Problems of texture classification are consistently challenging once the patterns of different instances can be very similar. Moreover, the descriptors need to be invariant to rotations, scale, and lighting variations. In the context of medical imaging, this group of methods can aid in diagnosing patients as part of the concept of Computer-Aided Diagnosis (CAD). In this paper, we review methods for texture classification in the context of classifying Diffuse Parenchymal Lung Diseases (DPLDs) on High-Resolution Computed Tomographies (HRCTs) and propose a new method that uses concepts of complex networks and statistical metrics. Our approach is based on mapping the input image into multiscale graphs and extracting the closeness centrality metric. We transform the multiscale closeness centrality images into one matrix that encapsulates local and global texture information. From the matrix, we extract a feature vector that represents a DPLD pattern. This vector is then combined with Haralick and Local Binary Pattern descriptors to generate the final feature vector. Once this process characterizes all the images, we go through a classification step to recognize the image. We analyze the proposed approach’s performance by comparing it with other texture analysis methods and discussing its metrics for each class (DPLD pattern) of the dataset. After the evaluation of different methods and our proposed method, it is possible to conclude the effectiveness of our approach to aid the diagnose process of DPDLs. Furthermore, we can highlight our technique as an aid on the problem of diagnosing patients with COVID-19.","('Classificação de imagens', 'Classificação de textura', 'Descritor de textura (Teoria dos grafos)', 'Imagens médicas', 'Doenças pulmonares intersticiais', 'Image classification', 'Texture classification', 'Graph-based texture descriptor', 'Medical image analysis', 'Diffuse parenchymal lung diseases classification')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/13779","2023-11-29","https://www.repositorio.ufal.br/bitstream/123456789/13779/1/Classification%20of%20DPLDs%20in%20HRCT%20scans_a%20comparative%20study%20of%20texture%20analysis%20methods%20and%20a%20novel%20statistical%20and%20graph-based%20approach.pdf","Classificação de DPLDs em tomografias computadorizadas de alta resolução: um estudo comparativo de métodos de análise de textura e uma abordagem inovadora baseada em estatísticas e grafos",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/16610","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Aplicação de TinyML em sensores virtuais para monitoramento da qualidade do ar em ambientes industriais","('Tayco Murilo Santos Rodrigues',)","('Thiago Damasceno Cordeiro',)","('Erick de Andrade Barboza', 'Andressa Martins Oliveira')","O monitoramento contínuo da qualidade do ar, especialmente no setor de mineração, é essencial para garantir que os níveis de poluentes estejam dentro dos padrões regulatórios. As soluções tradicionais para este monitoramento enfrentam limitações técnicas e econômicas e, neste contexto, as técnicas de aprendizagem de Máquina, do termo em inglês machine learning (ML), aplicadas a sistemas embarcados (TinyML), oferecem uma alternativa promissora para a previsão e análise de poluentes atmosféricos. Este trabalho tem como objetivo desenvolver um sistema de baixo custo e com recursos computacionais limitados para monitoramento contínuo da qualidade do ar que utilize técnicas de inteligência artificial (IA) para prever a concentração de cloro no ar com base em variáveis de entrada facilmente acessíveis: potássio e sódio. O modelo de IA foi treinado, otimizado e embarcado em um microcontrolador ESP32-S3. A quantização dos modelos reduziu o tamanho dos mesmos sem comprometer a precisão, garantindo a viabilidade de processamento em dispositivos com recursos limitados, com média de tempo para o processo de inferência sendo aproximadamente de 49,01 µs. No que diz respeito à precisão nas previsões de cloro, o modelo apresentou um erro quadrático médio de 3,96, um erro absoluto médio de 1,14 e um coeficiente de determinação de 0,95, demonstrando alta eficiência confirmando a viabilidade do sistema proposto.","Continuous air quality monitoring, especially in the mining sector, is essential to ensure that pollutant levels remain within regulatory standards. Traditional solutions for this monitoring face technical and economic limitations. In this context, Machine Learning (ML) techniques applied to embedded systems (TinyML) offer a promising alternative for forecasting and analyzing atmospheric pollutants. This work aims to develop a low-cost system with limited computational resources for continuous air quality monitoring that uses artificial intelligence (AI) techniques to predict chlorine concentration in the air based on easily accessible input variables: potassium and sodium. The AI model was trained, optimized, and embedded in an ESP32-S3 microcontroller. Model quantization reduced the model size without compromising accuracy, ensuring processing feasibility on resource-limited devices, with an average inference process time of approximately 49.01 µs. Regarding chlorine prediction accuracy, the model presented a mean squared error of 3.96, a mean absolute error of 1.14, and a determination coefficient of 0.95, demonstrating high efficiency and confirming the viability of the proposed system.","('Inteligência artificial', 'TinyML', 'Monitoramento ambiental (Poluição atmosférica)', 'Mineração', 'ESP32-S3 (Sistemas em chip)', 'Quantização de modelos', 'Redes neurais artificiais', 'Artificial intelligence', 'Environmental monitoring (Air pollution)', 'Mining', 'ESP32-S3 (Systems on Chip)', 'Model quantization', 'Artificial neural networks')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/16610","2024-11-22","https://www.repositorio.ufal.br/bitstream/123456789/16610/1/Aplica%c3%a7%c3%a3o%20de%20TinyML%20em%20sensores%20virtuais%20para%20monitoramento%20da%20qualidade%20do%20ar%20em%20ambientes%20industriais.pdf","","('Frede de Oliveira Carvalho',)"
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/17159","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Uma abordagem tecnológica para o cumprimento da Lei Geral de Proteção de Dados: para especialistas e leigos","('Lucas Buarque de Araujo Barros',)","('Ranilson Oscar Araújo Paiva',)","('Almir Pereira Guimarães', 'Eduardo Cardoso Moraes')","No cenário global, a segurança da informação é um tema de extrema relevância que está em constante debate. Com o avanço da tecnologia, grandes empresas coletam diariamente uma quantidade imensa de dados, levantando dilemas cruciais sobre a privacidade e os direitos dos titulares dessas informações. Esse aumento na coleta de dados não apenas facilita a personalização de serviços e produtos, mas também gera preocupações sobre como essas informações são armazenadas, utilizadas e compartilhadas. Assim, em 2018, o Brasil promulgou a Lei Geral de Proteção de Dados com o objetivo de assegurar os direitos dos indivíduos em relação aos seus dados pessoais, representando um marco importante na proteção da privacidade, garantindo maior transparência e controle aos titulares sobre suas informações. Dessa forma, os administradores de sites são legalmente obrigados a implementar as normas estabelecidas pela LGPD. Sem a orientação de um especialista, essa tarefa se torna cada vez mais desafiadora, exigindo conhecimentos técnicos e um entendimento aprofundado das exigências legais para garantir a conformidade e a proteção dos dados pessoais. Portanto, este trabalho tem como objetivo desenvolver uma ferramenta web de análise automática de sites, destinada a identificar não conformidades em relação à legislação e a sugerir ajustes necessários para assegurar a conformidade com a lei. Além disso, foi proposta uma comparação entre a análise realizada pela ferramenta e a análise manual realizada por voluntários que se dispuseram a participar de um experimento, oferecendo suas opiniões sobre a ferramenta.","In the global landscape, information security is an extremely relevant topic that is constantly under debate. With the advancement of technology, large companies collect an immense amount of data daily, raising crucial dilemmas about privacy and the rights of data subjects. This increase in data collection not only facilitates the personalization of services and products but also generates concerns about how this information is stored, used, and shared. Thus, in 2018, Brazil enacted the General Data Protection Law (LGPD) with the aim of ensuring individuals’ rights regarding their personal data, representing an important milestone in privacy protection by guaranteeing greater transparency and control for data subjects over their information. Consequently, website administrators are legally obligated to implement the standards established by the LGPD. Without the guidance of a specialist, this task becomes increasingly challenging, requiring technical knowledge and a deep understanding of legal requirements to ensure compliance and the protection of personal data. Therefore, this work aims to develop a web-based tool for automatic website analysis, intended to identify non-compliances with the legislation and suggest necessary adjustments to ensure compliance with the law. Additionally, a comparison was proposed between the analysis performed by the tool and the manual analysis conducted by volunteers who were willing to participate in an experiment, providing their feedback on the tool.","('Lei geral de proteção de dados', 'Sistemas de recomendação', 'Web scraping', 'Web crawler', 'Aplicação web', 'General Data Protection Law', 'Recommendation systems', 'Web application')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/17159","2024-11-11","https://www.repositorio.ufal.br/bitstream/123456789/17159/1/Uma%20abordagem%20tecnol%c3%b3gica%20para%20o%20cumprimento%20da%20Lei%20Geral%20de%20Prote%c3%a7%c3%a3o%20de%20Dados_para%20especialistas%20e%20leigos.pdf","",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/13201","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Análise da percepção da utilidade de uma ferramenta de apoio à leitura de textos digitais","('Diego de Oliveira Feitosa',)","('Ranilson Oscar Araújo Paiva',)","('Alan Pedro da Silva', 'André Magno Costa de Araújo', 'Dalgoberto Miquilino Pinho Júnior')","Um texto digital pode ser definido como qualquer conteúdo de informação, semelhante a um livro, em formato digital, que pode ser lido em equipamentos eletrônicos, como computadores, celulares, leitores de livros digitais, entre outros, de maneira que independe da existência da versão em papel. Com os avanços da tecnologia, novas aplicações foram introduzidas no setor educacional. Os textos educacionais ou mesmo os livros didáticos da atualidade, limitam-se a replicar o conteúdo impresso acrescido de poucos REDs (recursos educacionais digitais) com baixo nível de interação. Logo é notável a distância que os textos digitais estão das potencialidades da tecnologia. O presente trabalho tem como objetivo geral o desenvolvimento de uma interface de uma ferramenta que gerenciará textos educacionais digitais com recursos personalizados, possibilitando que os estudantes tenham uma melhor experiência de leitura, bem como uma melhor síntese do conteúdo lido. Depois das análises dos resultados, as funcionalidades “Zoom”, “adicionar comentários ao texto”, “ampliar o tamanho/mudar a cor do texto”, principalmente, foram consideradas como recursos úteis que poderiam ajudar na leitura/compreensão do texto e são recursos que devem ser acrescidos aos textos digitais, além de também serem considerados úteis para melhorar a experiência na compreensão da leitura e aprendizagem. Já as funcionalidades que oferecem questões sobre o texto aos leitores, teve uma avaliação mediana no primeiro experimento e uma avaliação não tão boa no segundo, embora tal recurso tenha sido considerado como fácil de utilizar.","A digital text can be defined as any information content, similar to a book, in digital format, which can be read on electronic equipment, such as computers, cell phones, digital book readers, among others, in a way that, regardless of the existence of the version on paper. With advances in technology, new applications have been computed in the educational sector. Educational texts or even current textbooks are limited to replicating printed content plus a few DERs (digital educational resources) with a low level of interaction. Therefore, the distance that digital texts are from the potential of technology is remarkable. The present work has as its general objective the development of an interface of a tool that will manage digital digital texts with personalized resources, allowing students to have a better reading experience, as well as a better synthesis of the content read. After analyzing the results, functionalities such as “Zoom”, “add comments to the text”, “enlarge the size/change the text color”, mainly, were understood as useful resources that could help in the reading/understanding of the text and are resources that should be added to digital texts, in addition to being considered useful to improve the experience in reading comprehension and learning. The functionalities that offer questions about the text to the readers, had a medium evaluation in the first experiment and a not so good evaluation in the second, although this resource was considered easy to use.","('Texto digital', 'Tecnologia', 'Recursos Educacionais Digitais (REDs)', 'Recursos personalizados', 'Leitura', 'Digital text', 'Technology', 'Digital Educational Resources', 'Personalized resources', 'Reading')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/13201","2023-10-09","https://www.repositorio.ufal.br/bitstream/123456789/13201/1/An%c3%a1lise%20da%20percep%c3%a7%c3%a3o%20da%20utilidade%20de%20uma%20ferramenta%20de%20apoio%20%c3%a0%20leitura%20de%20textos%20digitais.pdf","",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/16766","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Algoritmos Tabu Search em GPU para problemas de maximização de diversidade","('William Gabriel da Paz Rosendo',)","('Bruno Costa e Silva Nogueira',)","('Rian Gabriel Santos Pinheiro', 'Ermeson Carneiro de Andrade')","Os problemas de otimização combinatória, como o Problema da Máxima Diversidade (MDP) e o Problema de Dispersão Maxima Média Ponderada (GMaxMeanDP), têm sido amplamente estudados devido à sua relevância em diversas aplicações práticas, como classificação de páginas web, ineração de comunidades, redes de confiança, formação de grupos, alocação de recursos e análise de redes sociais. Contudo, esses problemas enfrentam desafios significativos quando aplicados a instâncias de grande escala, frequentemente encontradas em cenários reais. Tanto o MDP quanto o GMaxMeanDP apresentam limitações em instâncias massivas, principalmente por utilizarem representações baseadas em matrizes, que se mostram ineficientes para dados esparsos. Além disso, a execução da busca local acaba demorando muito à medida que o tamanho do problema cresce, dificultando a obtenção de soluções em tempo viável. Essa combinação de ineficiência estrutural e aumento da complexidade computacional compromete a eficácia das estratégias de busca convencionais para problemas de grande escala. Para superar essas limitações, este estudo propõe algoritmos de busca tabu paralelizados, projetados especificamente para lidar com instâncias massivas de ambos os problemas. Os algoritmos exploram o poder do processamento paralelo em GPUs para acelerar significativamente o processo de busca local, permitindo a exploração eficiente de grandes espaços de soluções em menos tempo. Além disso, a implementação de estruturas de dados otimizadas para representar instâncias esparsas reduz a sobrecarga de memória e aumenta a escalabili dade do método. Os resultados experimentais demonstram que os algoritmos de busca tabu em GPU oferecem desempenho superior em relação aos algoritmos da literatura, tanto em termos de qualidade das soluções quanto de tempo de execução. Essa eficiência é ainda mais evidente em instâncias de grande escala, onde os algoritmos se destacam como uma alternativa eficaz e escalável para resolver os desafios impostos por problemas de otimização combinatória em cenários massivos.","Combinatorial optimization problems, such as the Maximum Diversity Problem (MDP) and the Generalized Max-Mean Dispersion Problem (GMaxMeanDP), have been extensively studied due to their relevance in various practical applications, including web page classification, community mining, trust networks, group formation, resource allocation, and social network analysis. However, these problems face significant challenges when applied to large-scale in stances commonly encountered in real-world scenarios. Both MDP and GMaxMeanDP exhibit limitations with massive instances, primarily due to their reliance on matrix-based representations, which are inefficient for sparse data. Additionally, the execution of local search becomes increasingly time-consuming as the problem size grows, hindering the ability to obtain solutions within a feasible timeframe. This combination of structural inefficiency and growth in computational complexity compromises the effectiveness of conventional search strategies for large-scale problems. To overcome these limitations, this study proposes parallelized tabu search algorithms specifically designed to handle massive instances of both problems. The algorithms leverage the power of parallel processing on GPUs to significantly accelerate the local search process, enabling the efficient exploration of large solution spaces in less time. Moreover, the implementation of optimized data structures for representing sparse instances reduces memory overhead and enhances the scalability of the method. Experimental results demonstrate that GPU-based tabu search algorithms outperform state-of-the-art methods in the literature, both in terms of solution quality and execution time. This efficiency is particularly evident in large-scale instances, where the algorithms stand out as an effective and scalable alternative to address the challenges posed by combinatorial optimization problems in massive scenarios.","('Otimização combinatória', 'Processamento paralelo (Computadores)', 'Unidade de processamento gráfico', 'Busca tabu', 'Algoritmos híbridos', 'Combinatorial Optimization', 'Parallel Processing', 'GPU', 'Tabu Search', 'Hybrid Algorithms')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/16766","2024-12-05","https://www.repositorio.ufal.br/bitstream/123456789/16766/1/Algoritmos%20Tabu%20Search%20em%20GPU%20para%20problemas%20de%20maximiza%c3%a7%c3%a3o%20de%20diversidade.pdf","",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/17008","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Análises de modelos de predição de tweets de jornais e de seus comentaristas sobre as vacinas de Covid-19","('Alvino Lessa de Lima Junior',)","('André Luiz Lins de Aquino',)","('Leonardo Viana Pereira', 'Jorge Artur Peçanha de Miranda Coelho')","Este trabalho propõe uma análise de tweets feitos por dois jornais (The Guardian e The Economist), e dos comentários recebidos (replies), sobre o termo vaccine no ano de 2020.A amostra de dados coletadas do Twitter possui 1343 tweets feitos pelos dois jornais e11784 comentários. Para as análises foram utilizadas as seguintes técnicas: análise de sentimentos (Vader), análise de toxicidade (Perspective API), tópicos não-supervisionados (LDA) e modelos de predição baseados em um classificador de regressão logística. As análises indicam diferenças entre os Jornais, com o jornal The Economist sendo cerca de 40% mais positivo que The Guardian em suas publicações no Twitter, o mesmo não foi observado para os comentários. Porém, percebemos uma alta de comentários tóxicos nas semanas de aprovação das vacinas da Pfizer e Moderna, e também quando a primeira pessoa foi vacinada com a primeira dose no Reino Unido. 0s modelos de predição propostos possuem 92% de acurácia para o modelo baseado nos tweets feitos pelos jornais e 68,5% de acurácia para o modelo baseado nos comentários.","This work proposes an analysis of tweets written by two newspapers (The Guardian and The Economist), and the comments received (replies), about the term ""vaccine"" in the year 2020. A sample data collected from Twitter has 1,343 tweets written by two newspapers and 11,784 comments. For the analyses, the following techniques were used: sentiment analysis (Vader), toxicity analysis (Perspective API), unsupervised topic analysis (LDA), and prediction models based on a logistic regression classifier. The Analyzes indicates differences between the newspapers, and The Economist is 40% more positive than The Guardian in their publications on Twitter, this difference was not observed for comments. However, we saw a spike in toxic comments in the weeks of approval for the Pfizer and Moderna vaccines, and also when the first person was vaccinated with the first dose in the UK. The proposed prediction models have 92% accuracy for the newspaper tweets based model and 68.5% accuracy for the comments based model.","('Modelo de predição', 'Análise de sentimento', 'Tweets', 'Redes sociais', 'Twitter', 'Vacinas – Covid-19', 'Prediction model', 'Sentiment analysis', 'Social media', 'Vaccines – Covid-19')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/17008","2021-09-15","https://www.repositorio.ufal.br/bitstream/123456789/17008/1/An%c3%a1lises%20de%20modelos%20de%20predi%c3%a7%c3%a3o%20de%20tweets%20de%20jornais%20e%20de%20seus%20comentaristas%20sobre%20as%20vacinas%20de%20Covid-19.pdf","Tweets Analytics and Prediction Models newspapers and their commentators about Covid-19 vaccines",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/14910","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Análise comparativa entre detection transformer e yolov8 para detecção precoce de nódulos pulmonares","('Victor Mafra de Holanda Ferraz',)","('Marcelo Costa Oliveira',)","('Thales Miranda de Almeida Vieira', 'Lucas Lins de Lima')","O câncer de pulmão (CP) é o segundo tipo mais prevalente de câncer em todo o mundo e o mais mortal, sendo responsável por uma em cada cinco mortes relacionadas ao câncer globalmente. As chances de sobrevivência para pacientes diagnosticados com esse tipo de câncer aumentam consideravelmente quando o diagnóstico é feito precocemente, com a taxa de sobrevivência de 5 anos chegando a até 70%. Radiologistas realizam o diagnóstico de CP por meio de imagens de Tomografia Computadorizada (TC), mas esse diagnóstico é uma tarefa complexa e sujeita a erros. Por meio de ferramentas auxiliadas por computador, esse processo de diagnóstico pode ser automatizado com o intuito de auxiliar o profissional, reduzindo o tempo e o esforço para os especialistas, além de melhorar a confiança no diagnóstico. O objetivo deste trabalho foi avaliar e comparar a eficácia das arquiteturas de Redes Neurais Convolucionais (CNN) e Transformer na detecção de pequenos nódulos pulmonares (≤15mm), onde a questão orientadora da pesquisa deste trabalho foi ""Qual é o impacto do tamanho dos nódulos pulmonares na precisão de detecção das arquiteturas CNN e Transformer ?"". O conjunto de dados utilizado foi baseado no banco de dados público LUNA16, filtrando o conjunto de testes para incluir apenas cortes de TC com nódulos com até 15mm. Os modelos escolhidos para nossas comparações foram o YOLOv8, uma CNN considerada estado-da-arte em detecção de objetos, e o DEtection TRansformer (DETR), que combina a arquitetura de transformer com uma camada CNN, onde obtivemos resultados como mAP50 = 0,70, sensibilidade = 0,91 e λ = 0,85 para o DETR e mAP50 = 0,90, sensibilidade = 0,83 e Λ = 0,77 para o YOLOv8. Também avaliamos o impacto do tamanho do nódulo no desempenho de ambos os modelos, onde o desempenho do YOLOv8 foi impactado pela diminuição do tamanho dos nódulos, enquanto o DETR continuou a mostrar resultados satisfatórios independentemente de quão pequenos os nódulos fossem.","ung cancer (LC) is the second most prevalent type of cancer worldwide and the deadliest, accounting for one in every five cancer-related deaths globally. The chances of survival for patients detected with this type of cancer increase considerably when the diagnosis is made early, with the 5-year survival rate reaching up to 70%. Radiologists perform LC diagnosis through Computed Tomography (CT) images, but such diagnosis is a complex and errorprone task. Through computer-aided tools, this diagnostic process can be automated in order to assist the professional, reducing time and effort for specialists, as well as improving confidence in the diagnosis. The objective of this work was to evaluate and compare the effectiveness of Convolutional Neural Network (CNN) and Transformer architectures in detecting small lung nodules (≤15mm), where the guiding research question of this work was “What is the impact of the size of lung nodules on the detection accuracy of CNN and Transformer architectures?"". The dataset used was based on the public database LUNA16, filtering the test set to include only sections with nodules with up to 15mm. The models chosen for our comparisons were YOLOv8, a CNN considered state of-th e-art in object detection, and DEtection TRansformer (DETR), which combines he transformer architecture with a CNN layer, where we obtained results such as mAP50 = 0.70, Sensitivity = 0.91 and Λ = 0.85 for the DETR and mAP50 = 0.90, Sensitivity = 0.83 and Λ = 0.77 for the YOLOv8. We also assessed the impact of nodule size on the performance of both models, where the performance of YOLOv8 was impacted by the decrease in nodules size, while DETR continued to show satisfactory results regardless of how small the nodules were.","('Detecção de objetos', 'Transformers', 'Redes neurais', 'Nódulo pulmonares -Diagnóstico clínico', 'Object Detection', 'Transformers', 'Neural Networks', 'Pulmonary Nodules', 'Medical Diagnostic')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/14910","2024-04-03","https://www.repositorio.ufal.br/bitstream/123456789/14910/1/An%c3%a1lise%20comparativa%20entre%20detection%20transformer%20e%20yolov8%20para%20detec%c3%a7%c3%a3o%20precoce%20de%20n%c3%b3dulos%20pulmonares.pdf","",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/16895","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Aplicação de filtro de kalman para predição do alunado em escolas públicas do Estado de Alagoas e da região Nordeste do Brasil","('José Ferreira Leite Neto',)","('Bruno Almeida Pimentel',)","('Dalgoberto Miquilino Pinho Júnior', 'Glauber Rodrigues Leite')","Este trabalho investigou a aplicação do Filtro de Kalman para a predição do número de alunos em escolas públicas do estado de Alagoas e da região Nordeste do Brasil. A pesquisa foi motivada pela observação da necessidade de predições precisas do número de alunos para a logística do Programa Nacional do Livro Didático (PNLD). Foram coletados e processados dados do Censo Escolar de 2007 a 2023, e o Filtro de Kalman foi implementado e comparado com baselines como média e regressão linear. Os resultados mostraram que o Filtro de Kalman proporcionou predições mais precisas, adaptando-se melhor às variações nos dados. Como futuras investigações, sugere-se utilizar variações anuais e analisar a evolução de turmas específicas ao longo do tempo para refinar ainda mais a precisão das previsões.","This study investigated the application of the Kalman Filter for forecast the number of students in public schools in the state of Alagoas and the Northeast region of Brazil. The research was motivated by the observed need for accurate student number predictions for the logistics of the National Textbook Program (PNLD). Data from the School Census from 2007 to 2023 were collected and processed, and the Kalman Filter was implemented and compared with baselines such as mean and linear regression. The results showed that the Kalman Filter provided more accurate predictions, better adapting to variations in the data. For future investigations, it is suggested to use annual variations and analyze the evolution of specific classes over time to further refine the accuracy of predictions.","('Kalman, Filtragem de', 'Predição de alunado', 'Programa Nacional do Livro Didático (Brasil)', 'Análise de séries temporais', 'Mineração de dados', 'Kalman filter', 'Student enrollment prediction', 'National Textbook Program (Brazil)', 'Time series', 'Data mining')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/16895","2024-07-05","https://www.repositorio.ufal.br/bitstream/123456789/16895/1/Aplica%c3%a7%c3%a3o%20de%20filtro%20de%20kalman%20para%20predi%c3%a7%c3%a3o%20do%20alunado%20em%20escolas%20p%c3%bablicas%20do%20Estado%20de%20Alagoas%20e%20da%20regi%c3%a3o%20nordeste%20do%20Brasil.pdf","","('Ícaro Bezerra Queiroz de Araújo',)"
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/17629","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Análise de matrículas escolares em Maceió: um estudo de séries temporais com LSTM","('Artur Cavalcante de Jesus',)","('Bruno Almeida Pimentel',)","('Thiago Damasceno Cordeiro', 'Diego Carvalho do Nascimento')","A previsão da evolução das matrículas escolares é essencial para o planejamento educacional, possibilitando uma alocação eficiente de recursos e a formulação de políticas públicas fundamentadas em dados. Este estudo analisa os fatores que influenciam a quantidade de matrículas nos ensinos infantil, fundamental e médio na rede pública de Maceió, utilizando redes neurais Long Short-Term Memory (LSTM) para análise de séries temporais. A pesquisa foi conduzida com dados do Censo Escolar do INEP, abrangendo um período de dez anos. Além da análise preditiva, foram aplicadas técnicas de inteligência artificial explicável, como SHAP (SHapley Additive Explanations) e Causalidade de Granger, a fim de interpretar os fatores mais relevantes na variação das matrículas. Os resultados indicam que, no ensino infantil, a infraestrutura escolar, incluindo banheiros adaptados, equipamentos multimídia e parques infantis, influencia diretamente a decisão dos pais em matricular seus filhos. No ensino fundamental, a manutenção de um corpo docente adequado e a presença de bibliotecas bem estruturadas foram identificadas como fatores fundamentais para a retenção dos alunos. No ensino médio, a existência de laboratórios de ciências, infraestrutura esportiva e acesso à tecnologia demonstrou ser essencial para a permanência dos estudantes. Além disso, a análise revelou interdependências entre variáveis, sugerindo que cortes orçamentários em determinados setores podem gerar impactos negativos indiretos sobre a taxa de matrículas. Assim, os achados deste estudo fornecem subsídios para que gestores educacionais adotem estratégias baseadas em evidências, garantindo um planejamento mais eficiente e políticas educacionais voltadas à melhoria da qualidade da educação pública.","The prediction of school enrollment trends is essential for educational planning, enabling the efficient allocation of resources and the formulation of data-driven public policies. This study analyzes the factors influencing enrollment rates in preschool, elementary, and high school education in the public network of Maceió, using Long Short-Term Memory (LSTM) neural networks for time series analysis. The research was conducted with data from the INEP School Census, covering a ten-year period. In addition to predictive analysis, Explainable Artificial Intelligence techniques such as SHAP (SHapley Additive Explanations) and Granger Causality were applied to interpret the most relevant factors affecting enrollment trends. The results indicate that, in preschool education, school infrastructure, including adapted restrooms, multimedia equipment, and playgrounds, directly impacts parents’ decisions regarding enrollment. In elementary school, maintaining an adequate teaching staff and providing well-structured libraries were identified as crucial factors for student retention. In high school, the availability of science laboratories, sports infrastructure, and access to technology proved to be essential for student retention. Furthermore, the analysis revealed interdependencies among variables, suggesting that budget cuts in specific areas may indirectly impact enrollment rates. Therefore, the findings of this study provide valuable insights for educational policymakers to adopt evidencebased strategies, ensuring more efficient planning and public policies aimed at improving the quality of public education.","('Matrícula escolar', 'Análise de séries temporais', 'Long Short-Term Memory', 'Inteligência artificial explicável', 'Educação pública', 'School enrollment', 'Time series analysis', 'Explainable artificial intelligence', 'Public education')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/17629","2025-02-27","https://www.repositorio.ufal.br/bitstream/123456789/17629/1/An%c3%a1lise%20de%20matr%c3%adculas%20escolares%20em%20Macei%c3%b3_um%20estudo%20de%20s%c3%a9ries%20temporais%20com%20LSTM.pdf","",""
"Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/813","Campus A.C. Simões","Instituto de Computação","Dissertação","Scheduling do transporte de petróleo das plataformas marítimas e de atendimento a centros consumidores","('Adrian Esteban Muract',)","('João Inácio Soletti',)","('Henrique Pacca Loureiro Luna', 'Márcio Henrique dos Santos Andrade')","Hoje em dia, as empresas petroleiras enfrentam o desafio de conhecer qual é a melhor forma de movimentar uma frota de navios cargueiros sem que isso signifique um aumento de custo, entre outras. Neste trabalho será apresentada uma solução para este, mediante o desenvolvimento de um sistema que permita calcular as rotas para transporte de petróleo bruto de plataformas marítimas a refinarias, bem como transporte dos derivados do petróleo de refinarias a centros consumidores. Para a solução do sistema, foi realizado um scheduling no qual determina-se a rota que cada navio deve realizar para que o petróleo seja entregue, buscando a rota que conduza ao melhor caminho, sendo considerado o tempo de deslocamento, carga e descarga do produto, além do limite de armazenamento de produto em cada plataforma, entre outros parâmetros.","Now a day, petroleum companies are looking for a way to calculate the best economic and time consuming alternative to move a group of ships between platforms, refineries and consuming centers. In the following research is introduced a solution to this problem through a system which optimize the main variables involved. Variables such as scheduling and road have been taken into account. The variable scheduling defines the road that each ship must follow. Meanwhile, the optimization of the route is based on traveling time between each points, uploaded and downloaded time, storing capacity at each point, etc. The following system has been tested in two real cases showing a good performance.","('Maritime transportation -Fleet sizing', 'Maritime transportation -Oil -Derived -Logistic', 'Execution agenda (Administration) -Mathematical models', 'Transporte marítimo -Dimensionamento de frota', 'Transporte marátimo -Petróleo -Derivados -Logística', 'Agenda de execução (Administração) -Modelos matemáticos', 'Scheduling')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Embargado","http://repositorio.ufal.br/handle/riufal/813","2008-10-17","https://www.repositorio.ufal.br/bitstream/riufal/813/1/Scheduling%20do%20transporte%20de%20petr%c3%b3leo%20das%20plataformas%20mar%c3%ad%c2%adtimas%20e%20de%20atendimento%20a%20centros%20consumidores.pdf","Scheduling the petroleun and oil offshore and consumers centers.","('Sandra Helena Vieira de Carvalho',)"
"Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/828","Campus A.C. Simões","Instituto de Computação","Dissertação","Raciocínio científico por meio dos jogos educacionais colaborativos","('Romero Araújo de Medeiros',)","('Fábio Paraguaçu Duarte da Costa',)","('Arturo Hernández-Domínguez', 'Cleide Jane de Sá Araujo Costa', 'Filomena Maria Gonçalves da Silva Cordeiro Moita')","Jogos em rede estão em destaque graças ao alto nível de interação entre pares, situação promotora do alto índice de jovens que passam horas em frente ao computador. O que norteia este trabalho é usar esta motivação para aprendizagem de forma científica, contemplando também a visão sócio-construcionista (VYGOTSKY, 1996) de educação. Esta estudo tem como objetivo o desenvolvimento de um modelo computacional para o ensino do raciocínio científico por meio da utilização de jogos colaborativos, utilizando o formalismo Rede de Petri Colorida. A relevãncia do projeto reside na crença de que o jogo educacional modelado funcione como um meio de aprendizagem, pelos princípios do Raciocínio Científico, com uma abordagem lúdica. Foi proposta uma arquitetura que define desde a concepção do jogo colaborativo, passando pela interface a ser aplicada, chegando à execução do jogo. Foi então modelado o processo de interação do jogo utilizando o formalismo baseado em Rede de Petri Colorida. Para analisar esse estudo, desenvolveu-se um protótipo de jogo em rede que foi aplicado a uma turma de alunos do segundo ano do Ensino médio, quando se constatou, através de questionários, a viabilidade deste modelo, que utiliza aprendizagem colaborativa usando Raciocínio Científico","Games on net are in prominence due to the high level of interaction between pairs, situation that promotes a high number of youth spending hours in front of the computer. What guides this paper is to use this motivation for scientific learning, also focusing the education socio-constructivist view (VYGOTSKY, 1996). This paper's goal is to develop a computational model for the Scientific Reasoning teaching through the use of collaborative games, using the Coloured Petri Net formalism. This project relevance is in the belief that the shaped educational game functions as a way of learning, through principles of Scientific Reasoning, with a playful focus. It was proposed a frame that defines since the conception of collaborative game, including the interface to be applied, to the game execution. Then it was made the game interaction process using the formalism based on Coloured Petri Net. In order to evaluate this study, it was developed a game archetype on net that was used with high-school students, what made possible evidence, through questionnaires, this model viability, which uses collaborative learning through Scientific Reasoning","('Scientific reasoning', 'Collaborative games', 'Socio-interactionist learning', 'Petri Net', 'Raciocínio científico', 'Jogos colaborativos', 'Aprendizagem sócio-interacionista', 'Rede de Petri')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/828","2009-07-31","https://www.repositorio.ufal.br/bitstream/riufal/828/1/Dissertacao_RomeroMedeiros_2009.pdf","Scientific reasoning through educational collaborative games.",""
"Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/809","Campus A.C. Simões","Instituto de Computação","Dissertação","Um modelo híbrido baseado em ontologias e RBC para a concepção de um ambiente de descoberta que proporcione a aprendizagem de conceitos na formação de teorias por intermédio da metáfora de contos infantis","('Agnaldo Cavalcante de Albuquerque Pessôa Neto',)","('Fábio Paraguaçu Duarte da Costa',)","('Arturo Hernández-Domínguez', 'Edilson Ferneda')","O presente trabalho apresenta um modelo de aprendizagem por descoberta no Âmbito de realização de um ambiente de descoberta (PARAGUAÇU,1997) para proporcionar a alunos aprendizes em ciência, o entendimento de como os conceitos que são utilizados na formação de teorias científicas estão relacionados. O assunto são abordado com a suposição de que ão possível formular teorias científicas em modelos científicos (FRIGG; HARTMANN, 2006; RUDNER, 1969), e que estes modelos podem ser disponibilizados para proporcionar tal aprendizagem. Porém, com a disponibilidade de tais modelos, em vez de introduzir termos científicos relacionados a alguma disciplina científica, pretende-se para tal realização utilizar a metáfora de contos infantis, ou seja, utilizar um vocabulário de termos onde o aprendiz possa entender intuitivamente como são elaborada uma teoria científica. Por outro lado, para proporcionar a formalização deste modelo científico, foi adotada a idéia proposta pela arquitetura MIDES (PARAGUAÇU et al., 2003), ou seja, a realização de um modelo científico com uma representação em XML (W3SCHOOLS, 2005b), em quatro visões de conhecimento: hierárquica, relacional, causal e de questionamento. Sendo assim, pretende-se no decorrer deste trabalho mostrar como são realizada esta formalização em XML e, para isso, são necessário revisar os seguintes assuntos: ambientes de aprendizagem; ontologias; ensino baseado em casos; e alguns aspectos gerais sobre a elaboração de uma teoria científica e sobre a formulação de uma teoria como um sistema axiomático, como também apresentar as idéias para a elaboração de modelos de aprendizagem por descoberta. Feita esta revisão, tem-se o embasamento necessário para propor uma arquitetura que possa integrar duas aplicações por intermédio deste modelo XML, ou seja, a primeira aplicação serve para uma comunidade de professores que elaboram teorias em modelos científicos, utilizando a metá¡fora de contos, e a segunda, para alunos que desejam aprender como são realizada a formação de uma teoria, por intermédio dos modelos que foram disponibilizados pela comunidade de professores.","The actual work shows a model of discovery learning in order to realize a discovery environment (PARAGUAÇU, 1997) to demonstrate to the apprentice students in science, the understanding of how the concepts that are used in the creation of scientific theories are related. The subject is reached with the idea that is possible to create scientific theories in scientific models (FRIGG; HARTMANN, 2006; RUDNER, 1969), and that these models can be used to help in such learning. However, with the availability of such models, instead of introducing scientific terms related to some scientific topics, it intends to use the metaphor of Fairy Tales, what means, the vocabulary use of terms where the apprentice can understand by intuition on how a scientific theory is elaborated. On the other hand, in order to create and formalize this scientific model it was created the idea that was proposed by MIDES Architecture MIDES (PARAGUAÃ‡U et al., 2003), which means the creation of a scientific model with the representation in XML (W3SCHOOLS, 2005b) in four views of knowledge: Hierarchy, Relational, Causal, and by Asking. So, the idea of this work is to show how the creation in XML is made, and to do so, it s necessary to make a review of the following subjects: learning environments; teaching based on cases; and some general aspects of a creation of a scientific theory, and about the creation of a theory like an axiomatic system, as well as to present the ideas for the elaboration of discovery learning models. When this review is done, we have the necessary knowledge to propose an architecture able to integrate two applications by the use of XML, that is, the first application is to a teacher s community that elaborate theories in scientific models using the metaphor of the Fairy Tales, and the second one, for students that desire to learn how the creation of a theory is made, by the use of models that were introduced by the teacher s community.","('Science', 'Ontology', 'CBR', 'XML', 'Scientific theory', 'Discovery learning', 'Scientific reasoning', 'CiÃªncia', 'Ontologia', 'RBC', 'XML', 'Teoria científica', 'Aprendizagem por descoberta', 'Raciocínio científico')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/809","2006-12-11","https://www.repositorio.ufal.br/bitstream/riufal/809/1/Dissertacao_AgnaldoCavalcante_2006.pdf","",""
"Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/808","Campus A.C. Simões","Instituto de Computação","Dissertação","Predição da função das proteínas sem alinhamentos usando máquinas de vetor de suporte.","('Ulisses Martins Dias',)","('Roberta Vilhena Vieira Lopes',)","('Evandro de Barros Costa', 'Luiz Marcos Garcia Gonçalves')","Este trabalho apresenta um novo modelo capaz de prever a função de proteínas utilizando máquinas de vetor de suporte, um método de aprendizagem de máquina treinado usando parâmetros estruturais calculados a partir da conformação espacial da própria proteína. O modelo difere do paradigma comum de predição por não ser necessário calcular similaridades por meio de alinhamentos entre a proteína que se deseja prever a função e as proteínas de função conhecida presentes nos bancos de dados públicos. Dessa forma, o modelo é capaz de associar função às proteínas que não possuem qualquer semelhança com proteínas conhecidas, podendo ser usado quando todos os outros métodos falham ou quando não se deseja utilizar o conceito de similaridade na predição da função. A justificativa de que o modelo é válido foi realizada analisando sua performance ao prever funções de proteínas desconhecidas, proteínas não usadas no treinamento, utilizando como estudo de caso um conjunto de proteínas de ligação.","This thesis presents a new model to protein function prediction using support vector machines, a machine learning approach trained using structural parameters calculated from protein tertiary structure. The model is different from the others paradigms because it is not necessary to search for similarities against the others known proteins in public databases by alignments. In this way, the model is able to associate functional relationships among proteins with no similarities and it could be used when all other methods fail or when the user don t want to use the concept of similarity in function predictions. The proof that the model is valid was accomplished analyzing its performance with unknown proteins, i.e proteins not used in the training set. The validation approach used a set of binding proteins.","('Bioinformatic', 'Protein', 'Function', 'Artificial intelligence', 'Suport vector machines', 'Ontological Gene', 'Sting', 'Bioinformática', 'Proteína', 'Função', 'Inteligência artificial', 'Máquina de vetor de suporte', 'Gene ontológico')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/808","2007-03-26","https://www.repositorio.ufal.br/bitstream/riufal/808/1/Dissertacao_UlissesMartinsDias_2007.pdf","Protein function prediction without alignments by using support vector machines.","('Eliana Silva de Almeida',)"
"Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/807","Campus A.C. Simões","Instituto de Computação","Dissertação","Plataforma para construção de ambientes interativos de aprendizagem baseados em agentes","('Ig Ibert Bittencourt Santana Pinto',)","('Evandro de Barros Costa',)","('Guilherme Bittencourt', 'Angelo Perkusich', 'María Del Rosario Girardi Gutiérrez')","O presente trabalho aborda a concepção e desenvolvimento de ambientes interativos de aprendizagem (AIAs) baseados em agentes, mais especificamente, seguindo o modelo de arquitetura multiagente do Mathema. Tal modelo é definido com base em uma estratégia de aprendizagem baseada em problemas, disposta em um cenário onde agentes artificiais e humanos (alunos e professores) interagem com vistas a ajudar aprendizes humanos a resolver problemas em um determinado domínio de conhecimento. Nesse sentido, esse modelo propõe-se a ajudar os aprendizes durante as várias fases para a construção de uma solução, incluindo a análise do problema. Para tanto, modelou-se três categorias de interações: o agente aprendiz humano, o professor e o agente tutor artificial. Neste trabalho, propõe-se uma plataforma para construção de ambientes interativos de aprendizagem baseados em Agentes, dando suporte tanto de um framework, para os engenheiros de software/desenvolvedores, quanto de um sistema de autoria para os usuários não programadores poderem configurar o domínio de ensino. Além disso, tal plataforma possui ferramentas de colaboração, infraestrutura baseada em ontologia e uma sociedade de agentes que auxiliam na modelagem do domínio e resolução de problemas (através de técnicas de Inteligência Artificial). A fim de experimentar e validar a plataforma proposta foram desenvolvidos dois estudos de casos, um na área de direito e o outro em medicina, além de ter sido iniciado um investimento em matemática.","This dissertation presents the design and development of an agent-based interactive learning environment based on the Mathema Model. Such model adopts a problem-based learning approach as a pedagogical method that is achieved in an interaction environment that is populated by software and human agents (students and teachers), working together in favour of the human learners. This interaction occurs aiming at helping human learners to solve problems into given knowledge domain. This model aims to help learners during several phases involved in the build solution process, including the problem analysis. With this sense, the interaction between three agent categories was modeled: human learner agent, teacher and artificial tutoring agent. This work proposes a platform for building agent-based interactive learning environments, supporting as framework to developers/software engineers as authoring to non developers users like teachers and knowledge engineers. In addition, the platform has collaborative tools, an ontology-based infrastructure and an agent society that help at the domain modeling and problem solving process (through artificial intelligence techniques). It was conducted two case studies (at legal domain and health domain) and an initial investment at mathematical domain that demonstrate that the proposed platform is feasible.","('Interactive learning environments', 'Artificial intelligence', 'Software agents', 'Ontology', 'Ambientes interativos de aprendizagem', 'Agentes de software', 'Ontologia', 'Framework')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/807","2006-10-27","https://www.repositorio.ufal.br/bitstream/riufal/807/1/Plataforma%20para%20constru%c3%a7%c3%a3o%20de%20ambientes%20interativos%20de%20aprendizagem%20baseados%20em%20agentes.pdf","Plataform for building agem-based interactive learning environments",""
"Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/836","Campus A.C. Simões","Instituto de Computação","Dissertação","Modelo de sistema de recomendação de materiais didáticos para ambientes virtuais de aprendizagem.","('Márcio Robério da Costa Ferro',)","('Fábio Paraguaçu Duarte da Costa',)","('Evandro de Barros Costa', 'Edison Francisco Valente', 'Guilherme Ataíde Dias')","Sistemas de Recomendação são utilizados por várias empresas que atuam em comércio eletrônico para sugerir itens aos seus clientes, de forma personalizada. Para alcançar essa finalidade, esses sistemas analisam o perfil dos usuários, por meio dos seus dados pessoais ou pelas suas interações com o ambiente computacional. Ambientes Virtuais de Aprendizagem, por sua vez, são ambientes computacionais, usados no processo de ensino-aprendizagem na educação a distância, e tem como objetivo intermediar as interações entre seus usuários, tais como professores e alunos. Nesses ambientes geralmente são armazenados materiais didáticos utilizados nos cursos, tais como documentos de texto, apostilas, e até mesmo arquivos de áudio e vídeo. Com o passar do tempo, o número de materiais didáticos tende a crescer, tornando-se importante a existência de uma ferramenta que faça recomendações personalizadas aos usuários do ambiente. Diante desses conceitos, este trabalho aborda a criação de um modelo de sistema de recomendação de materiais didáticos, a ser utilizado em Ambientes Virtuais de Aprendizagem, de forma a sugerir, aos usuários, materiais didáticos compatíveis com o seu perfil. Será abordada também a criação de uma arquitetura de sistema de recomendação, utilizada na implementação de um módulo de sistema computacional, para testar e verificar o funcionamento do modelo, assim como do algoritmo gerador de recomendações. Por fim, o trabalho aborda a realização do experimento com alunos de um curso de extensão, onde foram identificados os resultados referentes às recomendações geradas","Recommender Systems are used by many companies that operate e-commerce to suggest items to its customers in a customized way. To achieve this end, these systems analyze the profile of the users through their personal data or by its interaction with the computing environment. Virtual Learning Environments, in turn, are computational environments used in teaching and learning in distance education, and aims to mediate the interactions among their users, such as teachers and students. In these environments are usually stored teaching materials used in courses such as word processing documents, brochures, and even audio and video. Over time, the number of textbooks tends to grow, making it important to have a tool that makes customized recommendations for users of the environment. Given these concepts, this work addresses the creation of a recommender system model of instructional materials to be used in Virtual Learning Environments, in order to suggest to users, instructional materials consistent with their profile. The creation of a recommendation system architecture, used in implementing a computer system model, to test and verify its operation, as the algorithm for generating recommendations, will also be addressed. Finally, the paper addresses the experimental work with students in an extension course, where the results regarding the recommendations generated have been identified","('Recommneder system', 'Virtual Learning Environments', 'E-Learning', 'Instructional Materials', 'Sistema de recomendação', 'Ambiente Virtual de Aprendizagem', 'Educação a distancia', 'Material didático')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/836","2010-11-12","https://www.repositorio.ufal.br/bitstream/riufal/836/1/Modelo%20de%20sistema%20de%20recomenda%c3%a7%c3%a3o%20de%20materiais%20did%c3%a1ticos%20para%20ambientes%20virtuais%20de%20aprendizagem..pdf","Recommender System Model of Instructional materials for Virtual Learning Environments.;Recommender System Model of Instructional materials for Virtual Learning Environments.",""
"Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/833","Campus A.C. Simões","Instituto de Computação","Dissertação","Reconstrução de sinais em redes de sensores sem fios com técnicas de geoestatística","('Bruno Lopes Vieira',)","('Alejandro César Frery Orgambide',)","('Eliana Silva de Almeida', 'Renato José de Sobral Cintra')","As Redes de Sensores sem Fios (RSsF) são conjuntos de dispositivos que obtêm amostras de fenômenos ambientais, sejam eles naturais (como, por exemplo, temperatura, pressão atmosférica, intensidade de iluminação, concentração de substâncias em cursos d'água) ou antrópicos (qualidade do ar em sinais de trânsito, pressão ao longo de um oleoduto). Esses dispositivos têm despertado muito interesse, tanto pelas suas potenciais aplicações quanto pelos desafios teóricos e tecnológicos que seu uso otimizado oferece. O objetivo deste trabalho trata da análise da reconstrução de sinais nessas redes, com base em técnicas de geoestatística. Analisam-se três processos de kriging: simples, ordinário e bayesiano. Ao simples, analisam-se três abordagens encontradas na literatura para estimação ou informação do parâmetro da média e ao bayesiano propõe-se uma variante capaz de reduzir o tempo de processamento necessário, estimando a média por mínimos quadrados generalizados, sendo uma constante na inferência bayesiana. Leva-se em consideração o processo de agrupamento dos nós sensores, com simulações sem agrupamento e com os sensores agrupados pelos algoritmos LEACH e SKATER. O algoritmo de kriging bayesiano apresenta os melhores resultados qualitativos na maioria dos casos,mas se torna inviável para sistemas que necessitem de respostas rápidas. Nesses casos, recomenda-se o algoritmo de kriging ordinário. A variante proposta para o kriging bayesiano reduz o tempo de computação, mas não o suficiente para sistemas de tempo real.","Wireless sensor networks are formed by mobile devices that collect and process data from an enviroment, and transmit them to a data center wich is responsible for taking decisions. This work aims to analyze the signal reconstruction in these networks using geostatistic techniques. Three processes of kriging are used: simple, ordinary and bayesian. Three approaches to simple krigingwere found in the literature, according to the way themean of the data is estimated,were assessed themall. A newBayesian approach is proposed: use general least square to estimate the mean, and set it as a constant into the Bayesian inference. The effect of clustering techniques is assessed, namely without clusters and with clusters formed by LEACH and SKATER algorithms. Bayesian kriging presents the best qualitative results in almost all scenarios, but it is not available to systems that require fast aswers; in this case we recommend ordinary kriging. The proposed variant of Bayesian kriging reduces the time required, without hampering the quality of the reconstructed signal, but the time reduction is not enough for real-time systems","('Geostatistics', 'Computer network', 'Wireless sensors', 'Signal reconstruction', 'Clustering', 'Geoestatística', 'Redes de computação', 'Sensores sem fios', 'Reconstrução de sinais', 'Algoritmo de agrupamento')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/833","2010-05-28","https://www.repositorio.ufal.br/bitstream/riufal/833/1/Reconstru%c3%a7%c3%a3o%20de%20sinais%20em%20redes%20de%20sensores%20sem%20fios%20com%20t%c3%a9cnicas%20de%20geoestat%c3%ad%c2%adstica.pdf","Signal Reconstruction in Wireless Sensor Networks with Geotatistics Techniches.",""
"Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/817","Campus A.C. Simões","Instituto de Computação","Dissertação","Um modelo de processo baseado em conhecimento para apoiar a solução extrajudicial de conflitos.","('Séfora Junqueira dos Santos',)","('Evandro de Barros Costa',)","('Henrique Pacca Loureiro Luna', 'María Del Rosario Girardi Gutiérrez')","O trabalho apresenta a definição de um modelo de jogo adaptado para representar os processos de solução extrajudicial de conflitos, a partir do qual propôe-se um modelo abstrato em que o procedimento de solução de conflitos é dividido em etapas. Através da descrição geral de cada etapa, identificam-se os objetivos e as ações necessárias para atingi-los. Com base nas pesquisas apresentadas no enquadramento teórico, para cada etapa são identificadas ações em que técnicas de Inteligência Artificial são ou poderiam ser utilizadas, pelos próprios negociadores ou pelos terceiros neutros, para auxiliá-los na condução do procedimento. Finalmente, além das possibilidades já estudadas ou em estudo por outros autores envolvendo recuperação de informações, modelos de argumentação e sistemas de negociação, entre outros temas, são apresentadas duas novas perspectivas, identificadas ao longo da pesquisa.Tratam da construção de conceitualizações e do uso de filtragem.","This research presents the definition of a game model, adapted to represent the alternative dispute resolution processes, according to which an abstract model is proposed, splitting the negotiation in steps. By the description of each step, the objectives, and necessary tasks to achieve them, are identified. Based on the researches presented, for each step, tasks are identified that could use Artificial Intelligence techniques, to support negotiators or third neutrals to lead the processes. Besides the possibilities presented by other authors, related to information retrieval, argumentation models, negotiation systems, among other subjects, two new approaches are presented: a conceptualization building system and the use of information filtering for recommender systems","('Artificial intelligence', 'Alternative dispute resolution', 'Decision support systems', 'Game theory', 'Inteligência artificial', 'Solução extrajudicial de conflitos', 'Sistema de apoio à decisão', 'Teoria dos jogos')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/817","2008-05-26","https://www.repositorio.ufal.br/bitstream/riufal/817/1/Dissertacao_SeforaJunqueira_2008.pdf","A knowledge based process model to support alternative conflict resolution.",""
"Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/820","Campus A.C. Simões","Instituto de Computação","Dissertação","Um modelo de negociação para aquisição de habilidades cognitivas no contexto da educação matemática","('Allan Gomes dos Santos',)","('Fábio Paraguaçu Duarte da Costa',)","('Arturo Hernández-Domínguez', 'Guilherme Ataíde Dias')","Este trabalho de pesquisa tem como pressuposto o construtivismo piagetiano, segundo o qual, a construção do conhecimento constitui-se em compreender o desenvolvimento intelectual de uma pessoa (PIAGET, 1973).Trata-se de um estudo acerca de um dos grandes desafios da Educação Matemática, que está em usar a disciplina como instrumento para atingir os objetivos maiores da Educação (D AMBROSIO, 2004). Nas relações de hipóteses assumimos que a negociação na aprendizagem, busca de toda relação humana, de certo modo é uma negociação, pois envolve compromissos e condições (MATOS, 1983). E, corroborando com essa idéia, Frant e Castro (2001) defendem que a aprendizagem se dá na relação entre os sujeitos por negociação. Além disso, enfoca-se também a persuasão na aprendizagem, que trata o envolvimento do orador e do auditório durante a interlocução: o objetivo do orador com esse envolvimento é conseguir do auditório a adesão á sua tese (PERELMAN & OLBRECHTS, 2002). A partir de então, surgem os chamados modelos mentais, que são como blocos de construção cognitivos que podem ser combinados e recombinados conforme necessÃ¡rio (JOHNSON, 1983). Esta pesquisa se baseia nesses princípios teóricos. As implicações teóricas buscam apresentar uma proposta de mudança no processo de aprendizagem na Educação Matemática, por meio da modelagem de um Ambiente de Aprendizagem Sistemática (Projeto Paragua). Assim, na procura de melhorar a qualidade de ensino, este ambiente propõe, à luz da teoria do construtivismo, favorecer a construção do conhecimento e construir novas habilidades cognitivas. Na aprendizagem da matemática este ambiente é a possibilidade de consolidar o ensino-aprendizagem , obtendo um ensino mais lúdico e atraente, baseado em mecanismos como a negociação e a persuasão na aprendizagem e modelos mentais, dentro de um fator de confiabilidade entre os principais agentes do contexto educacional, o professor e o aluno.","This work of research has as presupposition the constructivism piagetiano, according to which, the construction of the knowledge constitutes in understanding the intellectual development of a person (PIAGET, 1973). It is about a study concerning one of the great challenges for Mathematical Education that is in using the subject it a way to reach the biggest point of the Education (D'AMBROSIO, 2004). In the relations of hypotheses we assume that, the negotiation in the learning search that all relation human being is, in certain way, a negotiation, therefore it involves commitments and they established conditions (MATOS, 1983). E, corroborating with this idea (FRANT & CASTRO, 2002), they defend that the learning is in the relation between the citizens for negotiation. Moreover, the persuasion in the learning is also focused, that deals with the envolvement to the speaker and the audience during the interlocution, envolvement in which the objective from the speaker is to obtain from the audience the adhesion to his thesis (PERELMAN & OLBRECHTS, 2002). Since then, there are so-called mental models, that are as cognitive blocks of construction that they can be combined and be recombined as necessary (JOHNSON, 1983). This research is based on theoretical principles. The theoretical implications search to present a proposal of change in learning process of Mathematical Education, through the modeling of an Environment of Systematic Learning (Paragua Project). Thus, in the search to improve the quality of education, this environment considers, the light of the theory of the constructivism, to favor the construction of the knowledge and to construct new cognitive abilities. On learning of mathematics this environment is the possibility ""to consolidate the teachlearning"", getting an education more playful and attractive based on mechanisms as the negotiation and persuasion in the learning and mental models, inside of a trustworthiness factor that envolves the main agents of the educational context, the professor and the student.","('Mathematical education', 'Negotiation and persuasion in the learning', 'Models mental', 'Educação matemática', 'Negociação e persuasão na aprendizagem', 'Modelos mentais')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/820","2008-05-21","https://www.repositorio.ufal.br/bitstream/riufal/820/1/Dissertacao_AllanGomesdosSantos_2008_Completa.pdf","A model of negotiation for the acquisition of cognitive abilities in the context of mathematics education.",""
"Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/850","Campus A.C. Simões","Instituto de Computação","Dissertação","Um modelo de eletrocardiógrafo portátil de baixo consumo","('Paulo César do Nascimento Cunha',)","('Cleumar da Silva Moreira',)","('Roberta Vilhena Vieira Lopes', 'Leandro Dias da Silva', 'Rômulo Pires Coelho Ferreira', 'Pedro de Lemos Menezes')","Apesar do rápido desenvolvimento da medicina, as doenças cardiovasculares ainda são uma das principais causa de morte no mundo. A identificação do paciente que apresenta um quadro de risco que pode decorrer a morte súbita é ainda um desafio. Os sistemas de monitoramento de sinais vitais vêem crescendo nos últimos anos, com aparelhos cada vez mais compactos, e uma gama de parâmetros que auxiliam a equipe médica a acompanhar o desenvolvimento do quadro clínico de seus pacientes. Este trabalho apresenta o modelo e o desenvolvimento de um Eletrocardiógrafo portátil, de baixo consumo para ser usado como entrada do sistema de monitoração dos sinais cardíacos, gerado no PROCAD NF-1493/2007. O objetivo desse aparelho é de promover a comunicação com o computador, possibilitando a análise do sinal do eletrocardiograma através de softwares desenvolvidos para pesquisas nesta área. Trabalhou-se neste projeto com um sistema de comunicação sem o utilizando a tecnologia Zigbee com a faixa de comunicação de 2,4GHz, e um alcance de aproximadamente 70 metros sem barreira, Isso favorece a análise do sinal ECG com o paciente em locomoção. Para embasar a construção do referido sistema, o presente trabalho apresenta uma revisão de arquiteturas, estado da arte, em hardware, bem como um estudo e uma especificação do modelo de um ECG portátil de baixa potência, usado neste trabalho para auxiliar as pesquisas voltadas a monitoração de sinais vitais. Por fim, uma análise qualitativa do hardware construído é fornecida.","In spite of the fast development of the medical sector, cardiovascular diseases are still the major cause of death in the world. The identification of the patient who presents a risk situation that may result in death is still a challenge. The number of systems to monitor vital signs has increased in the last years, with more compact devices, and a range of parameters that help the medical team to monitor the development of the patients\' clinical situation. This work presents the modeling and development of a low-power portable ECG to be used as input of the system to monitor cardiac signals, generated in PROCADNF-1493/2007. The aim of this device is to promote a communication with a computer enabling the analysis of the ECG signal using a software for research in this area. It was used a wireless communication system using the Zigbee technology with the band of 2.4GHz and a range of approximately 70 meters without a wall. This promotes the analysis of the ECG in movement, in which the patient has the possibility to move. To support the construction of such system, this work presents an architecture review, a state-of-the-art in hardware, as well as a study and a model specification of a low-power portable ECG used to aid the research that aim the monitoring of vital signs. Finally, a qualitative analysis of the constructed hardware is provided.","('Microcontroller', 'ZIGBEE', 'Low power', 'Microcontrolador', 'ECG', 'Eletrocardiograma', 'Sistemas computacionais de diagnóstico')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/850","2012-04-14","https://www.repositorio.ufal.br/bitstream/riufal/850/1/Um%20modelo%20de%20eletrocardi%c3%b3grafo%20port%c3%a1til%20de%20baixo%20consumo.pdf","A model of low power portable electrocardiograph",""
"Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/843","Campus A.C. Simões","Instituto de Computação","Dissertação","Um modelo baseado em princípios da persuasão para a classificação e construção de sítios educacionais","('Paulo José Tenório Cavalcante',)","('Fábio Paraguaçu Duarte da Costa',)","('Patrick Henrique da Silva Brito', 'Cleide Jane de Sá Araujo Costa', 'Lynn Rosalina Gama Alves')","A Persuasão tecnológica está crescendo rapidamente, produtos de informática, como aplicativos móveis e websites, estão sendo desenvolvidos para mudar o que as pessoas sentem e fazem (UNIVERSITY STANFORD, 2009; FOGG, 2003). Esta dissertação apresenta um modelo baseado nos princípios analisados por Cialdini (2006), objetivando a construção e classificação de sítios educacionais qualificando-os em totalmente, parcialmente e não persuasivos. O modelo elaborado, utilizando mapas conceituais, tem como objetivo servir de métrica para avaliação e consequente classificação dos sites educacionais. O modelo foi testado a partir da elaboração de um protótipo chamado AWEP (Análise de Web Sites Educacionais Persuasivos) o que possibilitou um estudo comparativo de três sites educacionais que foram resultado dos conceitos estabelecidos no contexto do modelo. Verificou-se, após o teste, que protótipo AWEP assim como os mecanismos de persuasão previstos no modelo se tornaram efetivos na análise e classificação dos sites educacionais estudados.","The Persuasion technology is growing quickly, computer products, such as mobile applications and websites are being developed to change what people feel and do (STANFORD UNIVERSITY, 2009, FOGG 2003). This dissertation presents a model based on the principles discussed by Cialdini (2006), aiming at the construction and classification of educational sites by qualifying them as fully, partially and not persuasive. The model was designed using conceptual maps, aiming to serve as a metric for evaluation and subsequent classification of educational sites. The model was tested through the development of a prototype named APEWEBS (Analysis of Persuasive Educational Web Sites), which allowed a comparative study of three educational web sites developed as a result of the established concepts in the context of the model. It was found, after testing the APEWEBS prototype as well as the mechanisms provided in the persuasion model, to be an effective tool in the analysis and classification of the considered educational web sites.","('Education -sites of web', 'Persuasion (Psychology)', 'Educational Technology', 'Captology', 'Educação -Sites da web', 'Distance education', 'Persuasão (Psicologia)', 'Tecnologia educacional', 'Educação a distância')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/843","2011-04-04","https://www.repositorio.ufal.br/bitstream/riufal/843/1/Dissertacao_PauloJoseTenorioCavalcante-2011-BDTD.pdf","A model based on principles of persuasion for the classification and construction of educational sites",""
"Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/848","Campus A.C. Simões","Instituto de Computação","Dissertação","Modelagem computacional da interdependência entre o fenômeno enos e a precipitação pluviométrica na Região Leste do Estado de Alagoas","('Jorge Silvestre da Silva',)","('Henrique Pacca Loureiro Luna',)","('Marcus de Melo Braga', 'Manoel Ferreira do Nascimento Filho', 'Rafael Piatti Oiticica de Paiva')","Alguns fenômenos estocásticos podem de alguma forma, causar danos significativos à natureza e ao ser humano. Entre esses fenômenos se encontra a variável meteorológica precipitação pluviométrica, que é a mais importante para as atividades agrícolas e ambientais desenvolvidas nas regiões tropicais. Embora seu registro seja tido como um dos mais simples torna-se difícil, em alguns locais, a sua medição dada a falta de uma rede de estações pluviométricas bem distribuídas na maioria das regiões ou pela ocorrência de erros de medição causados por instrumentos mal calibrados. A modelagem computacional tem sido cada vez mais aceita e empregada como uma técnica que permite aos analistas dos mais diversos segmentos, verificarem ou encaminharem soluções, com a profundidade desejada, aos problemas com os quais lidam diariamente, nas mais diversas áreas de atividades humanas. A precipitação pluviométrica, pela sua relevância no contexto sócio-econômico, principalmente em regiões onde predominantemente se convive com uma economia agrícola, a falta de chuva acarreta grandes perdas no setor produtivo e também acarreta o êxodo rural. Nesse contexto, a variável precipitação pluviométrica é estudada neste trabalho de pesquisa, utilizando-se de técnicas de modelagem computacional, monitorada ao longo de cem anos, de 1911 a 2010, como forma de melhor entender o seu comportamento, podendo assim, gerar informações pertinentes para a tomada de decisão","Some stochastic phenomena can some way cause meaningful damages to the nature and human being as well. Among these phenomena there is the variable meteorological rainfall, which is the most important one for the agricultural and environmental activities developed in the tropical regions. Although its record has been taking as one of the simplest ones it s difficult, in some places, its measurement due to the lack of a well distributed pluviometer station net in most of the regions or due to mistakes occurred during the measured caused by badly calibrated instruments. The computational model has been more and more accepted and applied as a technique that allows to the analysts from different segments to verify or offer solutions with the efficiency required to the problems with whom they deal with daily in several areas of the human activities. The rainfall, through its relevance in the socio-economical context, mainly in regions where people live predominantly with an agricultural economy, the lack of rain causes a large loss in the productive sector and also causes the rural exodus. In this context, the variable rainfall is studied in this research work, using computational model techniques, monitored throughout 100 years, from 1911 to 2010, as a way to better understand its behavior, making possible that way, to generate appropriated information for the decision making","('Stochastic variables', 'Rainfall', 'Computational modeling', 'Rain Monitoring', 'Variáveis estocásticas', 'Precipitação pluviométrica', 'Modelagem computacional', 'Monitoramento de chuva')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/848","2012-05-31","https://www.repositorio.ufal.br/bitstream/riufal/848/1/Dissertacao_%20Jorge_Silvestre_da_Silva.pdf","Computer modeling of the interdependence between enso and rainfall in the eastern State of Alagoas","('Silvio Chagas da Silva',)"
"Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/842","Campus A.C. Simões","Instituto de Computação","Dissertação","Modelagem de um ambiente para análise de DNA em genética forense","('Felipe José de Queiroz Sarmento',)","('Eliana Silva de Almeida',)","('Alejandro César Frery Orgambide', 'Alexandre Plastino de Carvalho')","Os avanços da biologia molecular vêm favorecendo a geração de uma enorme quantidade de informações genéticas em um tempo cada vez menor. Essa capacidade de geração de dados permite que os pesquisadores acelerem o ritmo de suas pesquisas, exigindo a utilização de ferramentas eficientes para o gerenciamento desses dados. Outra necessidade está relacionada com o desenvolvimento de ferramentas computacionais com capacidade de auxiliar na tarefa de analisar e dar um significado biológico a estes dados em um breve espaço de tempo para os pesquisadores. Este trabalho propõe a modelagem de um ambiente de apoio à análise e ao estudo do DNA Forense, cujo principal repositório seja o DNA autossômico. Este ambiente visa dar suporte a identificação de pessoas condenadas ou suspeitas de ter realizado algum tipo de crime contra a sociedade, bem como auxiliar no estudo de paternidade e na busca de pessoas desaparecidas. Este ambiente irá atender ao Laboratório de DNA Forense, da UFAL, que vêm realizando estas atividades. O modelo do ambiente aqui proposto, possui quatro módulos, estudo de paternidade , criminal , desaparecido e o banco de frequência das populações . Os módulos foram modelados de forma que funcionem independentemente, atendendo as especificações inerentes à análise sobre vínculo genético. O sistema foi desenvolvido na linguagem de programação JAVA com banco de dados PostgreSQL. Ambas as ferramentas possuem característica de software aberto e uma relação custo/benefício excelentes","The advances in molecular biology have increased the production of enormous amount of genetic information in a small period of time. This capacity of data production motivated the researchers to increase the rhythm of their researches. This necessity demands the use of efficient softwares in order to manage these data. Besides this, it also demands the development of good softwares in order to assist the researchers in the task of analyzing the data and giving them a biological meaning in a brief space of time. This work proposes a software model that will support the study of Forensic DNA, whose main repository is the autossomic DNA. This software intends to support the researchers in the identification of condemned persons or persons that are suspected of a crime. It also intends to assist the researchers in the study of paternity and the search for disappeared persons. The results of this work will be applied in the Forensic DNA Laboratory of UFAL. The software modeled here has four modules study of paternity , criminal , disappeared people and the bank of populational frequencies . The modules were modeled independently from each other, considering the specifications related to the analysis of genetic links. The software was developed using the JAVA programming language together with PostgreSQL database. Both are free software and have an excellent relationship between cost and benefit usage","('Bioinformatic', 'System recovery of the information', 'Data base', 'Population data base', 'Autossomic DNA -Profile', 'Forensic genetics', 'Forensic DNA', 'Identification human', 'Bioinformática', 'Sistema de recuperação da informação', 'Banco de dados', 'Banco de dados populacional', 'DNA autossômico -Perfil', 'Genética forense', 'DNA forense', 'Identificação humana')","Teoria da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/842","2006-05-12","https://www.repositorio.ufal.br/bitstream/riufal/842/1/Modelagem%20de%20um%20ambiente%20para%20an%c3%a1lise%20de%20DNA%20em%20gen%c3%a9tica%20forense.pdf","","('Luiz Antonio Ferreira da Silva',)"
"Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/839","Campus A.C. Simões","Instituto de Computação","Dissertação","Modelagem da Programação não Linear para Televisão Digital Interativa.","('Fabiana Toledo Vanderlei de Azevedo',)","('Henrique Pacca Loureiro Luna',)","('Thais Vasconcelos Batista', 'Rodrigo de Barros Paes')","Desde a implantação da Televisão Digital no Brasil que o termo interatividade ficou ainda mais presente. Entender como o telespectador comporta-se diante da televisão é objeto de estudo em diversas áreas. Assim, pensando na necessidade de entender o comportamento interativo do telespectador ou de uma população diante da televisão, e avaliando a evolução das ferramentas que proporcionam a interatividade, este trabalho propõe o mapeamento da interatividade, com o registro de todos os passos do telespectador diante da televisão e armazenado em seu set-top box. Com estes registros propõe-se uma avaliação dos dados por meio de uma modelagem expressa em forma de grafos subjacentes Ã teoria de questionários descrita por Picard nos anos sessenta","Since the beginning of the digital TV in Brazil that the expression interactivity is even more present in our lives. Understanding how the viewer behaves in front of the TV is the aim of many surveys in different areas. Therefore, thinking about the need to understand the interactive behavior of the viewer or the whole population in front of the TV, and also evaluating the evolution of the tools that allow the interactivity, this research suggests the map of the interactivity, registering all the reactions of the viewer in front of the TV and storing it in the set-top box. After gathering all this data we suggest an evaluation by modeling expressed in the underlying graph to the teoria de questionÃ¡rios written by Picard in sixties","('Digital Television', 'Interactivity', 'Modeling knowledge', 'Nonlinear programming', 'Televisão digital', 'Interatividade', 'Programação não-linear', 'Modelagem computacional')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/839","2009-11-27","https://www.repositorio.ufal.br/bitstream/riufal/839/1/Dissertacao_FabianaToledo%20Vanderlei%20de%20Azevedo_2009.pdf","Nonlinear Programming Modeling for Interactivity Digital Television","('Evandro de Barros Costa',)"
"Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/847","Campus A.C. Simões","Instituto de Computação","Dissertação","Um modelo classificador da lista de e-mail do Projeto Apache que combina dicionário neurolinguístico com ontologia","('Mário André de Freitas Farias',)","('Evandro de Barros Costa',)","('Patrick Henrique da Silva Brito',)","Listas de e-mails e grupos de discussão são normalmente usados por programadores para discutir e aperfeiçoar tarefas a serem executadas durante as fases de desenvolvimento de projetos de software. Projetos de softwares Open Source utilizam essas listas como uma ferramenta primária para a colaboração e cooperação. Em projetos dessa natureza, normalmente, os desenvolvedores estão em todas as partes do mundo. Desta forma, meios de interação e comunicação são necessários para garantir a colaboração entre os mesmos, bem como a eficácia no processo de construção e manutenção de projetos desse porte. Listas de e-mails podem ser uma importante fonte de dados para a descoberta de informações úteis acerca de padrões de comportamento de desenvolvedores para gerentes de projetos. O Neurominer é uma ferramenta de mineração de texto que determina o Sistema de Representação Preferencial de desenvolvedores de software em um contexto específico. A ferramenta apresenta como inovação a utilização da teoria da Programação Neurolinguística -PNL combinada com técnicas de mineração e estatística. Nesse contexto, é proposta a extensão dessa ferramenta através da aplicação de técnicas de ontologia ao seu dicionário, permitindo a combinação de predicados sensoriais a termos da engenharia de software, proporcionando um poder maior de contextualização ao seu dicionário. Sob esse prisma, a mineração de texto combinada com técnicas de PNL e ontologia surge como candidata natural para compor uma solução que objetiva melhorar a garimpagem de informações textuais, através de listas de discussões, com o propósito de apoiar gerentes de projetos de softwares na tomada de decisão. Essa combinação conduziu a resultados bastante significativos, propondo uma solução eficiente e eficaz.","Electronic mailing lists and discussion groups are normally used by programmers to discuss and improve tasks to be performed during software projects development. Open Source Software (OSS) projects use this lists as the primary tool for collaboration and cooperation. In project like that, normally, the developers are around the world. Thus, means of interaction and communication are needed to ensure collaboration between them, as well as efficiency in the construction and maintenance of projects this size. Mailing lists can be an important data source to discovery information useful about patterns of behavior of developer aimed at project manager. The Neurominer is a text mining tool that determines the Preferred Representational System (PRS) of software developers in a specific context. The tool has a new approach which is a combination between the Neuro-Linguistic Programming NLP theory, text mining and statistic technique. In this context, we propose the extension of this tool by applying of techniques of ontology to dictionary, allowing the combination of sensory predicates with software engineering terms, providing a greater power in the context of the dictionary. This way, the text mining matched with NLP theory and ontology appears as natural candidate that consists a solution that aiming to improve the mining of textual information through mailing lists, in order to support software project managers in making decision. This matching showed significant outcomes, proposing a efficient and effective solution.","('Text mining', 'Neuro-linguistic', 'Ontology', 'Software comprehension', 'Mineração de texto', 'Neurolinguística', 'Ontologia', 'Compreensão de software')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/847","2011-12-23","https://www.repositorio.ufal.br/bitstream/riufal/847/1/Dissertacao_MarioAndreDeFreitasFarias_2011.pdf","A classifier model from the e-mail list of Apache Project that combines neurolinguistic dictionary with ontology","('Methanias Colaco Rodrigues Junior',)"
"Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/823","Campus A.C. Simões","Instituto de Computação","Dissertação","Uma interpretação nebulosa dos mapas de Kohonen","('Andrilene Ferreira Maciel',)","('Luís Cláudius Coradine',)","('Manoel Agamemnon Lopes', 'Manoel Eusebio de Lima', 'Antônio Fernando de Sousa Bezerra')","As técnicas de mineração de dados baseadas nos mapas auto organizáveis de Kohonen tem sido bastante utilizada na classificação de sinais nas mais diversas Áreas de conhecimento. Geralmente,a rede SOM (Self-Organizing Maps) são usada para especificar relações de similaridade entre objetos abordando análise de agrupamentos. O custo computacional, a preparação dos dados e modelagem matemática poderão influenciar na interpretação dos resultados, entre suas limitações encontram-se aquelas provenientes da avaliação das classes. Os mapas de Kohonen não permite avaliar de forma detalhada a classe dos objetos, os quais poderão está definidos pelo limite da classe, ou seja, definir uma medida que possa relacionar quando um objeto que pertençam a uma classe particular possa migrar de uma classe para outra. Para adotar essa abordagem a solução proposta nesta dissertação de mestrado têm como objetivo aplicar os mapas auto-organizáveis de Kohonen e a lógica nebulosa para gerar as vizinhanças entre as classes visando aplicação dessas técnicas em dois estudos de casos na classificação dos sinais provenientes dos sistemas elétricos de potência e sinais biomédicos adotando uma interpretação nebulosa dos mapas de Kohonen. O trabalho se divide basicamente em três etapas: na primeira, será realizada uma revisão das técnicas de mineração de dados e da lógica nebulosa mostradas na literatura; na segunda, concentra-se aplicar o algoritmo classificador utilizando redes neurais artificiais, especificamente redes neurais SOM como técnica de mineração de dados para efetuar a classificação dos sinais; na terceira etapa demonstramos a abordagem multidisciplinar da rede SOM e da lógica nebulosa como uma ferramenta alternativa aos métodos de mineração de dados.","The Data Mining techniques, based on the Kohonen self-organizing maps have been largely used for classifying signals in several areas of expertise. Generally, the SOM network (Self-Organizing Maps) is used to specify similarity relationships between objects by adopting cluster analysis. The computational cost, data preparation and mathematical modeling can influence the interpretation of results, in which those from the evaluation classes are among its limitations. The Kohonen maps do not permit detailed evaluation of the class of objects, which may however be defined by the class limits, in other words defining a measure that can link when an object belonging to a particular class can migrate from one class to another . To adopt this approach the solutions proposed in this Masters dissertation are designed to implement the Kohonen self-organizing maps and the fuzzy logic to generate neighborhoods between classes aimed at applying these techniques on a two-case study for classifying signals from potencial power systems and Biomedical output signals adopting an interpretation of the Kohonen nebula maps. The work is basically divided into three stages: the first which would be followed by a review of the data-mining techniques and fuzzy logic shown in literature; the second focuses on applying the classifier algorithm using artificial neural networks, specifically the usage of neural networks as SOM data mining techniques to enable the classification of signals while the third step demonstrates the SOM network fuzzy logic multidisciplinary approach as an alternative tool of the data-mining methods.","('Data Mining', 'Self-organizing maps', 'Fuzzy logic', 'Power flow', 'Diabetes mellitus', 'Mineração de dados', 'Mapas auto-organizáveis', 'Lógica nebulosa', 'Fluxo de potência')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/823","2008-11-12","https://www.repositorio.ufal.br/bitstream/riufal/823/1/Dissertacao_AndrileneFerreiraMaciel_2008.pdf","An interpretation of the Kohonen nebula maps","('Roberta Vilhena Vieira Lopes',)"
"Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/835","Campus A.C. Simões","Instituto de Computação","Dissertação","Um modelo de explicação baseado em casos para jogos colaborativos","('Marcelo Machado Cunha',)","('Fábio Paraguaçu Duarte da Costa',)","('Roberta Vilhena Vieira Lopes', 'Filomena Maria Gonçalves da Silva Cordeiro Moita')","Com o advento da tecnologia, os jogos eletrônicos com fins educacionais se tornaram mais uma opção de recurso a serem utilizados pelos educadores no processo de ensino, sendo um excelente recurso para a criação, desenvolvimento e prática do conhecimento, facilitando o processo de aprendizagem e ainda sendo prazerosos, interessantes e desafiantes. Com o surgimento da inteligência artificial, especificamente, a técnica de raciocínio baseado em casos é possível recuperar informações que poderão ser utilizadas para atingir os objetivos da aprendizagem, principalmente se forem trabalhadas de forma colaborativa, já que conforme os pensamentos Vygotskyano o indivíduo adquire conhecimento através da internalização durante a aprendizagem. Este trabalho propõe apresentar uma arquitetura para desenvolvimento de jogos eletrõnicos com fins educacionais que desenvolva o processo de explicação de conteúdos, utilizando a técnica de raciocínio baseado em casos, e que vise a colaboração entre os jogadores. Com o intuito de validar a arquitetura proposta foi desenvolvido um jogo eletrônico intitulado de Vida Marinha, que visa ensinar crianças conhecimentos referente aos seres marinhos de forma divertida e colaborativa, utilizando-se de recursos como imagens, vídeos, sons e mapas conceituais presentes no jogo. O seu desenvolvimento foi utilizando a tecnologia Flash, não exigindo assim uma estrutura sofisticada para sua implantação, possibilitando ser utilizado em diferentes espaços de aprendizagem, tornando-o uma ferramenta interessante de apoio à explicação de conteúdos no meio educacional.","With the advent of the technology, the electronic games with educational objectives had become a valuable resource to be used for educators in the teaching and learning process, being an excellent tool for the creation, practice and development of knowledge, facilitating the pleasant, interesting and challenging process of learning. With the artificial intelligence, specifically, the technique of case-based reasoning, is possible to index information that could be used to reach the objectives of the learning, specially, when working collaboratively, since Vygotsky says that the student acquires knowledge through internalizing the learning. This work presents architecture for development of electronic games with educational proposal, based on the process of explanation of contents, using the technique of case-based reasoning, and that promotes the collaboration between players. To validate the architecture proposal, an electronic game named Sea Life was developed, that aims teaching children the marine life-beings using collaborative and entertainment tools, images, videos, sounds and conceptual maps. Its development uses Flash technology, thus not demanding a sophisticated structure for its implementation, making possible to be used in different spaces of learning, becoming it an interesting tool of support the explanation of contents in the educational environment.","('Games', 'Educational Technology', 'Interactive learning environment', 'Jogos eletrônicos', 'Tecnologia Educacional', 'Ambiente Interativo de Aprendizagem')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/835","2010-03-26","https://www.repositorio.ufal.br/bitstream/riufal/835/1/Um%20modelo%20de%20explica%c3%a7%c3%a3o%20baseado%20em%20casos%20para%20jogos%20colaborativos.pdf","A model of case-based explanation for collaborative games.",""
"Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/841","Campus A.C. Simões","Instituto de Computação","Dissertação","Gungnir: uma ferramenta para geração e execução automática de testes de conformidade utilizando autômatos temporizados","('Rodrigo José Sarmento Peixoto',)","('Leandro Dias da Silva',)","('Angelo Perkusich', 'Patrick Henrique da Silva Brito')","Oobjetivo neste trabalho é aumentar a confiança no funcionamento de sistemas da automação através do uso de uma ferramenta de geração e execução automática de testes de conformidade. A ferramenta desenvolvida chama-se Gungnir e utiliza modelos formais, cujo padrão utilizado é o formalismo de Autômato Temporizado (AT). Os sistemas de controle são constituídos por Controladores Lógicos Programáveis (CLP) e normalmente são desenvolvidos nas linguagens Ladder e Function Block Diagram (FBD). A atividade da Gungnir é verificar se a implementação do sistema de controle desenvolvida na linguagem Ladder é compatível com a especificação modelada utilizando o padrão ISA 5.2. Para isso são utilizadas ferramentas de tradução de programas Ladder e diagramas ISA 5.2 para modelos de AT, definidos critérios de cobertura e criadas heurísticas as quais asseguraram menor custo computacional durante a execução dos testes","The aim of this work is to increase the dependability of automation systems through the use of a tool for automatic generating and executing conformance tests. The developed tool calledGungnir uses formalmodels to performits actions,whose standard used is the formalism of Timed Automata (TA). The control systems consists of programmable logic controllers (PLC) and are often developed with Ladder and Function Block Diagram (FBD) languages. The Gugnir s key activity is to verify if the implementation of the control system developed in Ladder is compatible with the specification defined using the ISA 5.2 standard. To do so we used translation tools (from Ladder and ISA 5.2. to TA models), define coverages criteria and heuristics to ensure that the model was well tested","('Software -Data collect system', 'Computational model -Tests', 'Timed Automatas', 'Control systems', 'Software -Sistema de coleta de dados', 'Modelos computacionais -Testes', 'Autômatos temporizados', 'Sistemas de controle')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/841","2010-10-28","https://www.repositorio.ufal.br/bitstream/riufal/841/1/Gungnir%3a%20uma%20ferramenta%20para%20gera%c3%a7%c3%a3o%20e%20execu%c3%a7%c3%a3o%20autom%c3%a1tica%20de%20testes%20de%20conformidade%20utilizando%20aut%c3%b4matos%20temporizados.pdf","Gungnir: a tool for executing and generating conformance tests using timed automatas.",""
"Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/811","Campus A.C. Simões","Instituto de Computação","Dissertação","Ferramenta de autoria colaborativa para construção de conhecimento e concepção de documentos baseados em mapas conceituais aplicados ao contexto de ensino a distância.","('Alex Coelho',)","('Fábio Paraguaçu Duarte da Costa',)","('Anderson de Barros Dantas',)","O processo de construção de conhecimento e aprendizagem através da utilização de recursos tecnológicos consiste em um tema complexo e muito debatido, tanto no contexto psicopedagógico quanto computacional, uma vez que, deve ser levado em consideração todo o processo cognitivo associado a aprendizagem. Diversas metodologias e experiências têm sido utilizadas com o intuito de fazer com que todo o processo de aprendizagem seja enriquecido com as atuais possibilidades que a tecnologia e principalmente a Internet passaram a propiciar. Assim, neste trabalho é proposta a criação de modelos de interação e o protótipo de um ambiente colaborativo como proposta para o processo de construção de conhecimento através da utilização de mapas conceituais, além de recursos de comunicação e vídeo, subsidiando todo o processo de aprendizagem, sendo uma ferramenta diferenciada das demais soluções encontradas atualmente, uma vez que todo o processo passa a ser regido por um modelo negociável e gerenciado, o que não ocorre nos demais ambientes existentes, auxiliando no processo de avaliação e mensuração do conteúdo internalizado pelos usuários através de relatórios, utilizando um modelo síncrono de comunicação para todo o processo. São consideradas técnicas de Inteligência Artificial para a construção deste ambiente, sendo utilizados mecanismos como as redes de petri, princípios de raciocínio diagramático, linguagens de representação de conhecimento, além de levar em consideração aspectos vinculados a estudos sobre a colaboração em aprendizagem com suporte computacional, mais conhecido como CSCL (Computer Suport Collaborative Learning), tendo como produto final os modelos provados através da construção do ambiente interativo.","The knowledge and learning building process through the technologic resources use, and consist in a complex and talked about subject. Both in the context psycho-educational as computational should be taken into consideration the entire process associated with the cognitive process. Several methodologies and experience have been used to enrich the learning process with the current possibilities that technology and especially the Internet can provide. Thus, this proposed work is a prototype of a collaborative environment as a new solution to the knowledge building process through the use of conceptual maps and resources for communication and video, subsidizing all learning process, being a different tool of others solutions currently. The process to become managed by a negotiable model, which does not exist in current environments, aids in the evaluation and measurement of learned content by using a synchronous communication model for the entire process. Techniques used for artificial intelligence in the environment construction could be considered and mechanisms used as the preti s networks, diagrammatic reasoning principles, languages of knowledge representation, and take into account aspects linked with studies on the collaboration learning with computational support, better known as CSCL (Computer Suport Collaborative Learning).","('Knowledge building', 'Collaborative learning', 'Conceptual maps', 'CSCL', 'Construção de conhecimento', 'Aprendizado colaborativo', 'Mapas conceituais', 'CSCL')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/811","2007-12-19","https://www.repositorio.ufal.br/bitstream/riufal/811/1/Dissertacao_Alex_Coelho_final.pdf","Author collaborative tool for kwnoledge build and documents base don conceptual maps to distance education.",""
"Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/832","Campus A.C. Simões","Instituto de Computação","Dissertação","Estudos sobre a conectividade em redes de sensores sem fios: análise de plataformas e resultados de percolação no plano contínuo.","('Marcelo Gabriel Almiron',)","('Alejandro César Frery Orgambide',)","('Antônio Alfredo Ferreira Loureiro', 'Eliana Silva de Almeida')","Apresentamos a caracterização do raio de transmissão mánimo necessário para garantir conectividade, CTR (Critical Transmission Range), num cenário de controle de topologia em RSSF homogêneas e estacionárias. Dada a complexidade de se trabalhar com modelos analíticos, por meio de experiências Monte Carlo obtemos um estimador da distribuição do CTR sobre processos pontuais espaciais que descrevem o posicionamento dos nós sensores no ambiente para diferentes níveis de atratividade. Propomos modelos de otimização práticos que consideram diversos fatores conhecidos a priori pelo projetista como, por exemplo, os preços de diversos sensores, o raio de transmissão máximo disponível pelo sensor, os custos de posicionamento no ambiente (função da atratividade), o orçamento total do projeto, a probabilidade de conectividade mínima admissível e o exponente de path loss do ambiente. O modelo determina quais e quantos sensores devem ser comprados, com que raio de transmissão devem ser configurados e qual o preço conveniente a pagar pelo posicionamento (função da atratividade), para maximizar o tempo de vida de uma RSSF. Para guiar a escolha da plataforma de simulação e análise de dados, vários resultados a respeito de precisão numérica são apresentados, obtidos aplicando protocolos de avaliação já consolidados. Desta análise, determinamos que R (http://www.r-project.org) é a melhor escolha.","We study the minimum radius required for connectivity (CTR Critical Transmission Range) within homogeneous stationary Wireless Sensor Networks (WSN) topology control, considering different levels of attractivity within the sensors. Due to the complexity of dealing with this problem from a theoretical viewpoint, a Monte Carlo experience is devised for estimating the CTR distribution. With this information, we propose optimization procedures that, using as additional input a few known parameters (overall available budget, sensor cost, maximum available transmission radius, minimum probability of connectivity, environmental path loss and deployment cost) leads to the decision of the number and type of sensors to be acquired, their optimal communication radius and the ideal deployment strategy that maximize the WSN lifetime. As a previous result, the accuracy of several computational platforms for statistical computing was assessed, being the main conclusion that R (http://www.r-project.org) is the best choice","('Wireless sensor network', 'Spatial point processes', 'Topology control', 'Redes de computação', 'Sistemas de Comunicação sem fio', 'Processos pontuais espaciais', 'Sensores sem fio', 'Conectividade')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/832","2009-03-02","https://www.repositorio.ufal.br/bitstream/riufal/832/1/Dissertacao_Marcelo%20Gabriel%20Almiron_2009.pdf","",""
"Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/812","Campus A.C. Simões","Instituto de Computação","Dissertação","Detecção de pele humana em imagens veiculadas na web","('Heitor Soares Ramos Filho',)","('Alejandro César Frery Orgambide',)","('Roberto Marcondes Cesar Junior', 'Glauber Jose Ferreira Tomaz da Silva')","A detecção de pele humana em imagens digitais é utilizada para diversas aplicações como detecção de faces, reconhecimento de gestos e detecção de pornografia. A forma mais comum de detecção de pele encontrada na literatura é através da cor. A variação de iluminação pode redundar em efeitos nocivos à detecção de pele, pois a aparência da cor de um objeto é diretamente relacionada com a forma em que ele é iluminado. Para a detecção de pele pela cor exclusivamente, estratégias robustas às variáves de iluminação e modelos descrevam corretamente o agrupamento das cores da pele devem ser utilizados. Ao enfrentarmos o problema de detecção de pele em ambientes onde não há¡ controle sobre as características da imagem, não encontramos resultados satisfatórios na literatura, principalmente quando se refere à tentativa de minimizar os efeitos da variação de iluminação. As estratégias de correção de cor presentes na literatura melhoram consideravelmente a detecção de pele em algumas situações específicas, mas degradam esta classificação em outras situações. Neste trabalho, avaliamos o desempenho de sete diferentes modelos de detecção de pele, com quatro diferentes tipos de dados de entrada e propusemos uma estratégia para escolha das imagens que serão submetidas à correção de cor e o tipo de técnica de correção de cor mais adequado para esta imagem. A técnica que utiliza um modelo gaussiano bivariado, utilizando as duas primeiras componentes após aplicarmos transformação de componentes principais ao dados RGB da amostra de pele utilizada para treinamento resultou na melhor técnica abordada nesse trabalho ao utilizarmos a correção de cor proposta. Os resultados obtidos são comparados por meio de diversas métricas derivadas da matriz de confusão, e se mostram pelo menos tão bons quanto os alcançados por técnicas disponíveis na literatura.","Face detection, gesture recognition and pornography content assessment are some of the applications that require the detection of human skin in digital imagery. Most methods employ color as the main feature for this task. Whenever the acquisition conditions are controlled, there is available information about illumination, resolution and geometry, making the skin detection problem a relatively easy task for which there are plenty of results in the literature. The problem becomes more challenging in less structured conditions, mainly because of the influence illumination conditions have on the apparent color of objects. There are proposals for color correction that lead to both good and bad classification results, depending on the input data. When dealing with Web imagery, little can be assumed about their content or about the conditions in which they were acquired, and robust techniques are needed for skin detection. This MSc thesis makes a qualitative assessment of seven skin detection models and of four different types of input data. A heuristic is proposed for deciding if an image requires color correction and, if needed, which is the best suited technique. Results are compared by means of measures derived from confusion matrices, and our approach produces competitive classification products.","('Skin detection', 'Web imagery', 'Processamento de imagens', 'Modelagem computacional', 'Detecção de pele', 'Análise estatística')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/812","2006-02-13","https://www.repositorio.ufal.br/bitstream/riufal/812/1/Detec%c3%a7%c3%a3o%20de%20pele%20humana%20em%20imagens%20veiculadas%20na%20web.pdf","Skin detection in web imagery.",""
"Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/822","Campus A.C. Simões","Instituto de Computação","Dissertação","Descoberta e composição de serviços web semânticos através de algoritmo genético baseado em tipos abstratos de dados","('Elvys Alves Soares',)","('Evandro de Barros Costa',)","('Leliane Nunes de Barros', 'Henrique Pacca Loureiro Luna')","A Web Semântica é uma ampliação da web atual onde a disposição da informação viabiliza a cooperação entre homens e, sobretudo, entre máquinas. O surgimento de padrões web que expressam significado compartilhado possibilitam a construção de aplicações que resolvem problemas de integração, colaboração e automação já identificados pela comunidade científica e mercado consumidor de tecnologias. A utilização de Serviços Web trouxe grandes ganhos neste sentido, e sua anotação em termos semâticos, tornando-os Serviços Web Semânticos, viabiliza a proposta da Web Semântica. Diversas tecnologias viabilizam a construção de tais elementos e sua consequente utilização como blocos básicos do desenvolvimento de aplicações cujo escopo é embarcado na web. Assim, dado o rápido crescimento da quantidade de serviços, tornam-se necessárias abordagens que resolvam de forma efetiva, com garantias de qualidade e tempo de resposta aceitável, a integração e posterior utilização destes. Este trabalho propõe a modelagem de uma solução de software para o problema da Descoberta e Composição de Serviços Web Semânticos através do uso do Algoritmo Genético Baseado em Tipos Abstratos de Dados. Também proposta uma implementação utilizando OWL, OWL-S e a OWL-S API. São apresentadas a definição formal do problema, as expectativas da comunidade científica quanto às soluções elaboradas e os resultados obtidos com respeito à viabilidade da proposta.","The Semantic Web is an extension of the current Web, where the availability of information is expected to enable the cooperation between man and, above all, machines. The creation of standards which express shared meaning enable the construction of applications to solve integration, collaboration and automation problems which were already been identified by scientific community and technology consumers. The use of Web Services has brought several advances in this sense, and their annotation in semantic terms, transforming them into Semantic Web Services, enables the Semantic Web intent. Several technologies also enable the creation of such elements and their inherent use as basic blocks of application development whose scope is embedded on Web. This way, due to the fast growing of the number of services, some approaches to effectively solve the problem of services integration and use become necessary. This work proposes a modeling of a software solution to the discovery and composition of Semantic Web Services problem through the use of a genetic algorithm based on abstract data types. It is also proposed a tool implementation using OWL, OWL-S and OWL-S API languages and frameworks as well as the formal problem definition along with the scientific community expectations to the given solution.","('Genetic algorithm', 'Semantic web', 'Semantic web services', 'Algoritmo genético', 'Web semântica', 'Serviço web semântico')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/822","2009-11-13","https://www.repositorio.ufal.br/bitstream/riufal/822/1/Dissertacao_ElvysAlvesSoares_2009%20.pdf","Discovery and composition of semantic web services through genetic algorithms based on abstract data types.","('Roberta Vilhena Vieira Lopes',)"
"Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/819","Campus A.C. Simões","Instituto de Computação","Dissertação","Uma implementação em paralelo para decomposição de benders aplicada a sistemas eixo raio com múltipla atribuição","('Raquel da Silva Cabral',)","('Henrique Pacca Loureiro Luna',)","('Gilberto de Miranda Junior', 'Leonardo Viana Pereira')","Sistemas do tipo eixo raio, tornaram-se uma importante área de pesquisa da teoria de localização nas últimas décadas. Esse destaque deve-se em grande parte ao sucesso de sua utilização em sistemas logísticos, tanto de transporte de passageiros quanto de cargas, e em redes de telecomunicações. Ao invés de servir cada par origem destino de demanda com uma conexão direta, sistemas do tipo eixo raio substituem essas conexões diretas por uma rede de concentradores. Esses concentradores permitem que o tráfego seja agrupado e transportado através de um meio de transporte compartilhado, para ser então entregue aos respectivos destinos. Sendo um problema NP, é necessário o uso de métodos eficientes para sua resolução. Neste trabalho, é desenvolvida uma implementação em paralelo do método de Decomposição de Benders para o problema de localização de concentradores de alocação múltipla não capacitados. A implementação em paralelo do método de Decomposição de Benders para o problema eixo raio não é conhecido na literatura, entretanto os bons resultados obtidos pelo algoritmo paralelo desenvolvido revelam que a abordagem paralela é aplicável e mais eficiente. Nos experimentos realizados, o algoritmo paralelo apresentou um tempo de resposta até 70% menor que o tempo de resposta do algoritmo sequencial.","Hub and Spoke systems, is a important research area in localization theory. This occur, because of these systems are very used in logistics problems, e.g., telecommunication networks and transport of passenger and load.To serve the demand of each pair source destination, basically, the Hub and Spoke system replaces direct connections between the pairs for a hubs network. These hubs group the traffic sharing the transportation medium. To get the best hubs configuration is necessary efficient methods, because this problem, hubs allocation, is a NP-problem. In this work was developed an parallel implementation of the Benders Decomposition method for the uncapacitated multiple allocation hub location problem. In our implementation we use the Skorin-Kapov model. The parallel implementation of Benders Decomposition for hub and spoke problem is not known in literature. The results show that the parallel approach is applicable and more efficient that nonparallel one. The experiments reveals that the parallel algorithm had a time execution 70% minor when compared with the nonparallel one.","('Hub and spoke systems', 'Parallel programing', 'Benders decomposition', 'Sistemas eixo-raio', 'Programação paralela', 'Decomposição de Benders')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/819","2006-02-23","https://www.repositorio.ufal.br/bitstream/riufal/819/1/Uma%20implementa%c3%a7%c3%a3o%20em%20paralelo%20para%20decomposi%c3%a7%c3%a3o%20de%20benders%20aplicada%20a%20sistemas%20eixo%20raio%20com%20m%c3%baltipla%20atribui%c3%a7%c3%a3o.pdf","A parallel Benders decoposition implmentation for multiple hub and spoke system allocation",""
"Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/815","Campus A.C. Simões","Instituto de Computação","Dissertação","Estimação do erro em redes de sensores sem fios","('José Alencar Feitosa Neto',)","('Alejandro César Frery Orgambide',)","('Antônio Alfredo Ferreira Loureiro', 'Marcio Nunes de Miranda')","Apresentamos as redes de sensores sem fios no contexto da aquisição de informação, e propomos um modelo genérico baseado nos processos de amostragem e de reconstrução de sinais. Utilizando esse modelo, definimos uma medida de desempenho do funcionamento das redes através do erro de reconstrução do sinal. Dada a complexidade analítica de se calcular esse erro em diferentes cenários, propomos e implementamos uma experiência Monte Carlo que permite avaliar quantitativamente a contribuição de diversos fatores no desempenho de uma rede de sensores sem fios. Esses fatores são (i) a distribuição espacial dos sensores (ii) a granularidade do fenômeno sob observação (iii) a forma em que os sensores amostram o fenômeno (funções características constantes sobre células de Voronoi e sobre círculos), (iv) as características de comunicação entre sensores (por vizinhança entre células de Voronoi e pelo raio de comunicação), (v) os algoritmos de clusterização e agregação (LEACH e SKATER), e (vi) as técnicas de reconstrução (por Voronoi e por Kriging). Os resultados obtidos permitem concluir que todos esses fatores influem significativamente no desempenho de uma rede de sensores sem fios e, pela metodologia de trabalho, foi possível medir essa influência em todos os cenários considerados.","Wireless Sensor Networks (WSNs) are presented in the constext of information acquisition and we propose a generic model based on the processes of signal sampling and reconstruction.We then define a measure of performance using the error when reconstructiong the signal.The analytical assessment of this measure in a variety of scenarios is unfeasible, so we propose and implement a Monte Carlo experiment for estimating the contribution of six factors on the performance of a WSN, namely: (i) the spatial distribution of sensors, (ii) the granularity of the phenomenon being monitored, (iii) the way in which sensors sample the phenomenon (constant characteristic functions defined on Voronoi cells or on cicles), (iv) the communication between sensors (either among neighboring Voronoi cells or among sensors within a range), (v) the clustering and aggregation algorithms (LEACH and SKATER), and (vi) the reconstruction techniques (by Voronoi cells and by Kriging). We conclude that all these factors have significative influence on the performance of a WSN, and we are able to quantitatively assess this influence.","('Monte Carlo, Method of', 'Modeling', 'Simulation', 'Multiple sensors data integration', 'Error', 'Performance', 'Reconstruction', 'Sistems design', 'Monte Carlo, Método de', 'Modelagem', 'Simulação', 'Integração de dados de múltiplos sensores', 'Erro', 'Desempenho', 'Reconstrução', 'Projetos de sistemas')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/815","2008-06-16","https://www.repositorio.ufal.br/bitstream/riufal/815/1/Estima%c3%a7%c3%a3o%20do%20erro%20em%20redes%20de%20sensores%20sem%20fios.pdf","Error estimation in wireless sensor networks.",""
"Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/851","Campus A.C. Simões","Instituto de Computação","Dissertação","Especificação e implementação de um sistema evolutivo de apoio à análise de demonstrações contábeis SEADC para fins de tomada de decisão","('Cleonábula Maria Maranhão Neves',)","('Roberta Vilhena Vieira Lopes',)","('Manoel Agamemnon Lopes', 'Aldemar de Araújo Santos')","Este trabalho descreve a especificaçãoo e a implementação de um sistema computacional, intitulado de Sistema Evolutivo de Apoio À Análise de Demonstrações Contábeis (SEADC), que visa otimizar a tomada de decisão, e utiliza variações do algoritmo genético de Holland. Possui em sua especificação uma população formada por cromossomos que são vetores sobre um alfabeto ternário, com tamanho correspondente ao número de contas contábeis contidas no tipo de análise escolhida pelo usuário. O SEADC faz o diagnóstico da situação financeira e econômica de empresas comerciais, industriais ou prestadoras de serviço, sejam elas classificadas como micro, pequena, média, média-grande ou grande empresa. O diagnóstico realizado pelo SEADC foi baseado nas análises de liquidez, endividamento, rentabilidade, valor adicionado, prazos médios, análises vertical e horizontal; e no diagnóstico da combinação das análises de liquidez, rentabilidade e endividamento com a análise vertical, mostrando, como justificativa, a influência de cada uma das contas ou grupo de contas contábeis envolvidos. O sistema recebe como entrada um conjunto de índices, valores dos saldos das contas ou grupos de contas contábeis de demonstrações padronizadas da empresa que será analisada, em um determinado período, composto por anos consecutivos, sendo considerado o mínimo de três anos. Para validar o SEADC foram realizados testes com dados obtidos de demonstrações contábeis de empresas nos anos de 2008, 2009 e 2010. O sistema foi implementado no compilador eclipse, usando-se linguagem de programação JAVA. Os resultados alcançados no cálculo dos quocientes obtidos em todos os sete tipos de análises realizadas alcançaram 100% de corretude. Conclui-se, portanto, que o SEADC infere conhecimento à tomada de decisão, através dos relatórios de diagnósticos gerados.","This paper describes the specification and implementation of a computational system entitled Evolutionary Support System for the Analysis of Accounting Statements (ESAAS), which aims to optimize decision making, and uses variations of the genetic algorithm from Holland. In its specification, there is a population formed by chromosomes that are vectors over a ternary alphabet with size corresponding to the number of account statements contained in the type of analysis chosen by the user. The ESAAS diagnoses the financial and economic situation of commercial, industrial companies or service providers, whether they are classified as micro, small, average, average-large or large companies. The diagnosis done by ESAAS was based on the analyzes of liquidity, debt profitability, added value, average terms, vertical and horizontal analyzes; and in the diagnosis of the analytical combination of liquidity, profitability and debt with the vertical analysis, showing as a justification, the influence of each of the accounts or group of financial accounts involved. The system receives as input a set of indexes, total values of the accounts or groups of accounts of financial accounting standards of the company that will be considered in a determinted period, consisting of consecutive years, being considered the minimum of three years. To validate the ESAAS, tests were performed with data obtained from the financial statements from companies in the years 2008, 2009 and 2010. The system was implemented in the eclipse compiler, using the JAVA programming language. The results achieved in the calculation of the quotients obtained in all the seven types of analyzes performed achieved 100% of correctness. Therefore concluding that the ESAAS infers knowledge to decision-making, through diagnostic reports generated.","('Evolutionary computation', 'Genetic algorithm', 'Accounting analysis', 'Computational modeling', 'Economic and financial indicators', 'Computação evolutiva', 'Algoritmo genético', 'Modelagem computacional', 'Análise contábil', 'Indicadores econômicos e financeiros')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/851","2012-07-03","https://www.repositorio.ufal.br/bitstream/riufal/851/1/Especifica%c3%a7%c3%a3o%20e%20implementa%c3%a7%c3%a3o%20de%20um%20sistema%20evolutivo%20de%20apoio%20%c3%a0%c2%a0%20an%c3%a1lise%20de%20demonstra%c3%a7%c3%b5es%20cont%c3%a1beis%20%20%20SEADC%20para%20fins%20de%20tomada%20de%20decis%c3%a3o.pdf","Specification and implementation of a evolutionary system to support financial statement analysis -ESAAS for decision making","('Marta Veronica de Souza Correia',)"
"Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/852","Campus A.C. Simões","Instituto de Computação","Dissertação","Classificação de informação usando ontologias","('Eunice Palmeira da Silva',)","('Frederico Luiz Gonçalves de Freitas',)","('Evandro de Barros Costa', 'Guilherme Bittencourt')","Apesar dos aspectos positivos que a Internet possui e do potencial que permite, existe a problemática, que consiste em encontrar a informação necessária em meio a uma enorme quantidade de documentos disponíveis na rede. Faltam, ainda, ferramentas capazes de tratar semanticamente a informação contida em documentos que seguem uma estrutura preocupada apenas com a exibição dos seus dados. O sistema MASTERWeb, resolve o problema da extração integrada de pá¡ginas-conteúdo pertencentes às classes que integram um grupo (cluster ). Neste contexto propomos a extensão dessa ferramenta para a classificação de artigos científicos baseada em ontologias. Para isso foi construída uma ontologia do domínio de Inteligência Artificial e adotadas estratégias de classificação utilizando sistemas de regras. A abordagem apresentada aqui, emprega esta ontologia e técnicas de classificação textual para extrair dos artigos informações úteis, e daí inferir sobre os temas tratados nestes artigos. Essa combinação conduziu a resultados bastante significativos: por exemplo, o sistema é capaz de identificar no texto as subáreas de IA que ele aborda e deriva conclusões, distinguindo os assuntos tratados pelo artigo daqueles que são brevemente citados no texto. A aplicação de técnicas simples e uma ontologia bem formada levam a resultados de classificação promissores, independentemente da estrutura do documento, propondo uma solução eficiente e plausível.","Although the positive aspects that Internet possesses and the potential it permits, there is a problematic that consists on finding needed pieces of information among the deluge of available documents on the web. Tools that are able to semantically treat the information contained in the documents which follows a structure only focused on data presentation are still lacking. The MASTER-Web system solves the problem of integrated extraction of content-pages that belong to classes which form a cluster. In this context, we propose the extension of this tool to the scientific articles classification based on ontologies. To achieve this goal, an ontology for the Artificial Intelligence domain was constructed and rule-based classification strategies were adopeted. The approach presented here employs this ontology and textual classification techniques to extract useful pieces of information from the articles in order to infer to which themes it is about. This combination led to significative results: e.g. in the texts, the system is able to identify the specific subdivisions of AI and entails conclusions, distinguishing correctlly the themes of the articles from the ones that are briefiy mentioned in the texts. The application of simple techniques and a detailed ontology lead to promising classification results, independently of the document structure, proposing an eficient and plausible solution.","('Artificial intelligence', 'Information classification', 'Ontologies', 'Inteligência artificial', 'Sistemas de recuperação da informação -Classificação', 'Ontologia', 'Sistemas multiagentes')","Teoria da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/852","2006-09-28","https://www.repositorio.ufal.br/bitstream/riufal/852/1/Classifica%c3%a7%c3%a3o%20de%20informa%c3%a7%c3%a3o%20usando%20ontologias.pdf","Information classification using ontologies",""
"Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/846","Campus A.C. Simões","Instituto de Computação","Dissertação","Aplicação do modelo de algoritmo genético baseado em tipos abstratos de dados (GAADT) na adaptação de cenários bidimensionais de MMORPGs","('Leonardo Filipe Batista Silva de Carvalho',)","('Roberta Vilhena Vieira Lopes',)","('Geber Lisboa Ramalho', 'Manoel Agamemnon Lopes')","A importância do uso de recursos de Inteligência Artificial em jogos eletrônicos cresce em resposta a necessidade de jogos que apresentem comportamentos e elementos mais próximos da realidade. Uma necessidade que aliada ao alto nível de interação com o usuário e uma grande variedade de jogos, que oferecem a possibilidade de simular diferentes situações e comportamentos em ambientes complexos controlados, caracteriza os jogos eletrônicos como um importante nicho a ser explorado para a aplicaçã de diferentes técnicas de inteligência artificial. Este foi o conceito inicial do qual partiu a idéia de utilizar um jogo de MMORPG como pano de fundo para demonstrar a aplicação de técnicas de inteligência artificial, um gênero de jogo que preza por um ambiente rico, interativo e com eventos significativos ocorrendo de forma simultânea, similarmente ao que ocorre no mundo real. Tomando proveito do contexto do MMORPG, esta dissertação irá demonstrar a aplicação do algoritmo genético baseado em tipos abstratos de dados (GAADT) para proporcionar a alteração das características de um mapa de jogo em razão da passagem do tempo, de forma similar ao que ocorreria no mundo real. Um conceito ainda pouco explorado em jogos eletrônicos, sobretudo em MMORPGs. Espera-se ainda que a aplicação criada aqui para a validação do modelo do GAADT a este problema possa ser refinada, de modo a proporcionar aos educadores uma ferramenta que lhes permitam utilizar o cenário de jogo de um MMORPG como um meio para traçar paralelos didáticos entre a ambientação do jogo e o conteúdo de sala de aula.","The importance of using Artificial Intelligence in video games is growing in response to the need that videogames have of showing behaviors and other game elements in a closer regard to what is witnessed at the real world. This need combined with a high level of user interaction and a large variety of games offering different situations and behaviors in complex controlled environments, places the videogames as an invaluable exploring niche for the application of different artificial intelligence techniques. This was the initial concept that led to the idea of using a MMORPG as background for demonstrating the application of artificial intelligence techniques, a game genre which values a rich environment, full of interactivity and with significant events happening simultaneously, in a similar manner to what is witnessed at the real world. Taking advantage of the MMORPG context, this essay will demonstrate the application of the genetic algorithm based on abstract data type (GAADT) to provide the modification of a game map features due to the course of time, closely resembling what would happen at the real world. A concept that is thus far, little explored in videogames, particularly in MMORPGs. In addition, it is expected that the application created here for validating the GAADT s algorithmic model for the problem presented here can be refined, thus, providing educators with a tool that allows them to use a MMORPG game scenario as a way to draw didactic parallels between the game environment and the content seen at the classroom.","('Artificial intelligence', 'GAADT', 'Games', 'RPG', 'MMORPG', 'Inteligência artificial', 'GAADT', 'Jogos', 'RPG', 'MMORPG')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/846","2011-03-28","https://www.repositorio.ufal.br/bitstream/riufal/846/1/Dissertacao_LeonardoFilipeBatistaSilvaDeCarvalho_2011.pdf","Application of the genetic algorithm based on abstract data types (GAADT) to the adaptation of two-dimensional scenarios of MMORPGs","('Fábio Paraguaçu Duarte da Costa',)"
"Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/827","Campus A.C. Simões","Instituto de Computação","Dissertação","Análise de sinais eletrocardiográficos atriais utilizando componentes principais e mapas auto-organizáveis.","('Paulo Silva Coutinho',)","('Luís Cláudius Coradine',)","('João Marcos Travassos Romano', 'Maria Alayde Mendonça da Silva', 'Manoel Agamemnon Lopes')","A análise de sinais provenientes de um eletrocardiograma (ECG) pode ser de grande importância para avaliação do comportamento cardíaco de um paciente. Os sinais de ECG possuem características específicas de acordo com os tipos de arritmias e sua classificação depende da morfologia do sinal. Neste trabalho é considerada uma abordagem híbrida utilizando análise de componentes principais (PCA) e mapas auto-organizáveis (SOM) para classificação de agrupamentos provenientes de arritmias como a taquicardia sinusal e, principalmente, fibrilação atrial. Nesse sentido, O PCA é utilizado como um pré-processador buscando suprimir sinais de atividades ventriculares, de maneira que a atividade atrial presente no ECG seja evidenciada sob a forma das ondas f. A Rede Neural SOM, é usada na classificação dos padrões de fibrilação atrial e seus agrupamentos","","('Eletrocardiograsm ECG', 'Atrial Fibrillation AF', 'Artificial Networks Neural ANN', 'Principal Component Analysis PCA', 'Self-Organizing Maps SOM', 'Eletrocardiograma ECG', 'Fibrilação Atrial FA', 'Redes Neurais Artificiais', 'Análise de Componentes Principais PCA', 'Mapas Auto-Organizáveis -SOM')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/827","2008-11-21","https://www.repositorio.ufal.br/bitstream/riufal/827/1/Dissertacao_PauloSilvaCoutinho_2008.pdf","Atrial eletrocardiographics signals analysis using principal components and self-organizing maps.",""
"Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/814","Campus A.C. Simões","Instituto de Computação","Dissertação","Concepção e realização de um modelo computacional de jogos interativos no contexto da aprendizagem colaborativa","('Fabio de Melo Silva',)","('Fábio Paraguaçu Duarte da Costa',)","('Lynn Rosalina Gama Alves', 'Arturo Hernández-Domínguez')","Durante muito tempo, os jogos foram associados a atividades de entretenimento,limitados a recreação. Os jogos eletrônicos tem como pioneiro Willy Higinbotham,um físico do Brookhaven Nacional Laboratories que criou em 1958 um simples jogo de tênis que era executado em um osciloscópio. De lá para cá ocorreram alguns fracassos na aceitação desses produtos, porém, com o advento de novos mundos virtuais, visualmente mais ricos e interativos, aptos a possibilitar uma comunicação rica, os atuais games on-line multi-player se tornam uma ferramenta valiosa para a prática da aprendizagem colaborativa. A colaboração, por si, é um objetivo forte na educação. Esse objetivo precisa ser fomentado e exercitado através dos meios disponíveis. Sob esse contexto, os jogos de computador merecem muita atenção. As interações cada vez mais presentes e efetivamente ricas que os caracterizam reúnem condições favoráveis a um processo de construção do conhecimento através de atividades efetivamente colaborativas.Este trabalho propõe um modelo para a construção de jogos colaborativos baseado na hipótese de que a colaboração entre pares leva à aprendizagem. Para tanto, o conceito da Zona de Desenvolvimento Proximal (ZDP) definido por Vygotsky é essencial para a compreensão de suas idéias sobre as relações entre desenvolvimento e aprendizado. Nesta dissertação, o estudo da relação jogo e educação, e das contribuições teóricas da aprendizagem colaborativa foram primordiais para a criação do modelo. A partir disso, é possível verificar que os jogos colaborativos podem ser um bom caminho na tentativa de subjugar os efeitos maléficos da competição excessiva presente nos jogos.","For a long time, games were associated to entertainment activities, limited to recreation. The electronic games have as pioneer Willy Higinbotham, a physicist from Brookhaven National Laboratories that created in 1958 a simple game of tennis that was implemented in an oscilloscope. Since then, some failures occurred in the acceptance of such products. However, with the advent of new virtual worlds, more interactive and visually rich, capable of providing a rich communication, the current games online multi-player become a valuable tool for practice of collaborative learning. The collaboration, per se, is a strong goal in education that needs to be encouraged and exercised. This goal needs to be encouraged and exercised by the means available. In this context, the computer games deserve a lot of attention. The increasing presence and richness of the computer games gather favorable conditions to a process of knowledge construction through effectively collaborative activities. This paper proposes a model for building collaborative games, based on the assumption that cooperation leads to peer learning. The concept of the Zone of Proximal Development (ZPD) defined by Vygotsky is essential to the understanding of their ideas about the relationship between development and learning. The study of the relationship game and education, and theoretical contributions of collaborative learning were essential to the creation of the model in this dissertation. Based on this work, one can see that the collaborative games can be a good way in an attempt to subjugate the evil effects of excessive competition in this games.","('Digital game', 'Education', 'Interaction', 'Collaborative learning', 'Jogos digitais', 'Educação', 'Interação', 'Aprendizagem colaborativa')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/814","2008-09-05","https://www.repositorio.ufal.br/bitstream/riufal/814/1/Dissertacao_FabiodeMeloSilva.pdf","Conception and accomplishment of a computational model of interactive games in the context of collaborative learning.",""
"Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/837","Campus A.C. Simões","Instituto de Computação","Dissertação","Arquitetura e modelos de interações cooperativas e adaptativas entre agentes humanos e artificiais no domínio de fração.","('Maria Aparecida Amorim Sibaldo',)","('Evandro de Barros Costa',)","('Crediné Silva de Menezes', 'Leandro Dias da Silva')","Este trabalho apresenta um ambiente interativo de aprendizagem sobre Frações, dotado de mecanismos de suporte a interações cooperativas e adaptativas oferecidas por seus agentes tutores aos aprendizes humanos, focando principalmente em atividades de resolução de problemas. Para isso, propõe-se uma arquitetura baseada em agentes de software e serviços Web semânticos, daí, pôde-se verificar a viabilidade funcional da proposta e, posteriormente, apresentar uma revisão de tal arquitetura para suprir alguns requisitos anteriormente não visados, além de modelos que dão suporte às referidas interações. No que diz respeito Ã s interações, o aprendiz receberá suporte pedagógico tanto de um agente tutor, quanto de algum de seus pares que fazem parte do ambiente. Particularmente, um agente tutor conta com um modelo aberto do aprendiz, a partir do qual passa a dispor de informações úteis para orientar suas ações. A idéia deste modelo ser aberto é a de permitir que o aprendiz possa ver qual a avaliação que o sistema tem a seu respeito, tendo ainda a oportunidade de discordar de tal avaliação, e assim contribuir para o refinamento do conteúdo de tal modelo. Palavras-chave: Modelagem Aberta do Aprendiz; Sistemas Tutores Inteligentes; Sistemas Multi-agentes","This work presents an interactive environment for learning about fractions, with mechanisms to support cooperative and adaptive interactions offered by tutors agents to human learners, focusing mainly on activities to solve problems. For this purpose, an architecture based on software agents and semantic Web services was proposed, therefore, we verify the functional viability of the proposal and, posteriorly, to present a revision of that architecture to suply some requirements not previously covered, beyond models that support to those interactions. With respect to interactions, the learner will receive support from both a pedagogical agent tutor, as some of their peers who are part of the environment. Particularly, a tutor agent has an open learner model, from which it obtains information to guide their actions. The idea of this model be opened is to allow the learner seeing the evaluation that the system has about him, and also the opportunity to disagree with this assessment, and thus contribute to the refinement of the content of such a model","('Open Learner Model', 'Intelligent Tutor Systems', 'Multiagent Systems', 'Modelagem Aberta do Aprendiz', 'Sistemas Tutores Inteligentes', 'Sistemas Multi-Agentes')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/837","2010-11-13","https://www.repositorio.ufal.br/bitstream/riufal/837/1/Arquitetura%20e%20modelos%20de%20intera%c3%a7%c3%b5es%20cooperativas%20e%20adaptativas%20entre%20agentes%20humanos%20e%20artificiais%20no%20dom%c3%ad%c2%adnio%20de%20fra%c3%a7%c3%a3o.pdf","Architecture and Models of Cooperative and Adaptive Interactions between human and Artificial Agents on Domain Fraction.","('Patrick Henrique da Silva Brito',)"
"Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/818","Campus A.C. Simões","Instituto de Computação","Dissertação","Um arcabouço baseado em componentes para engenharia de ambientes em sistemas multiagentes abertos","('Marcilio Ferreira de Souza Júnior',)","('Evandro de Barros Costa',)","('Arturo Hernández-Domínguez', 'María Del Rosario Girardi Gutiérrez')","Sistemas Multiagentes (SMA) são considerados um alto nível de abstração para projeto e engenharia de sistemas complexos, tendo sido caracterizados por estruturas de organização e processos de coordenação cada vez mais articulados e dinâmicos. Geralmente, agentes cooperam e coexistem dentro de um ambiente. Há um consenso geral na comunidade de agentes que os ambientes são parte essencial dos SMA dinâmicos e abertos. Contudo, diante das características dinâmicas presentes em tais SMA, apenas a utilização do paradigma de agentes no desenvolvimento de software não garante a flexibilidade e escalabilidade do projeto frente a inevitáveis mudanças de requisitos do mesmo. Por sua vez, o desenvolvimento baseado em componentes tem sido apontado como promissor na construção de aplicações com maior capacidade de adaptação a mudanças nos seus requisitos. Este trabalho tem como objetivo o desenvolvimento de um arcabouço para engenharia de ambientes de SMA abertos baseado no conceito de composição dinâmica de software. O arcabouço é baseado em uma especificação que procura mapear os conceitos de agentes em componentes para garantir a flexibilidade e reutilização provida na abordagem de componentes. Agentes e recursos são utilizados para compor o software, componentes são utilizados para compor agentes, e objetos e aspectos são utilizados para implementar as características funcionais e não-funcionais dos componentes. Os resultados favoráveis da presente proposta foram verificados nos experimentos realizados em quatro estudos de casos.","Multiagent systems (MAS) are considered a high level abstration for design and engineering of complex systems. Such systems are characterized by organization structures and coordination process more articulated and dynamic. Usually, agents cooperate and coexist in an environment. In addition, there is a general consense in the research community that an environment is an essential part of open and dynamic MAS. However, given the dynamic characteristics present in complex systems, only the use of the agent-based paradigm in the software development does not guarantee the flexibility and scalability of the project ahead of the inevitable changes on requirements. For this reason, the component-based development have been identified as promising in the building of applications with greater ability to adapt to the changes of its requirements. This work aims at developing a component-based framework for engineering open MAS enviroments. The framework is based on the concept of dynamic software composition and supported by a specification that demand mapping from agents concepts to components in order to ensure the flexibility and reusability provided in the component approach. In addition, i) agents and resources are used to compose the software, ii) components are used to compose agents, and iii) objects and aspects are used to develop the functional and non-functional components requirements. The favorable results of this proposal were checked in experiments developed in four case studies.","('Environments engineering', 'Multiagents systems', 'Software engineering', 'Engenharia de ambientes', 'Sistema multiagente', 'Engenharia de sotware')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/818","2007-10-26","https://www.repositorio.ufal.br/bitstream/riufal/818/1/Um%20arcabou%c3%a7o%20baseado%20em%20componentes%20para%20engenharia%20de%20ambientes%20em%20sistemas%20multiagentes%20abertos.pdf","A components-based framewoek for engineering environments in open multiagents systems.",""
"Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/849","Campus A.C. Simões","Instituto de Computação","Dissertação","Uma arquitetura para aprendizagem colaborativa utilizando a integração web e TV digital integrativa","('Maurí\xadcio Vieira Dias Júnior',)","('Fábio Paraguaçu Duarte da Costa',)","('Mario Antonio Ribeiro Dantas', 'Marcus de Melo Braga', 'Luis Paulo Leopoldo Mercado')","A TV Digital Interativa (TVDi) surge na sociedade, como um recurso importante para a promoção da aprendizagem, principalmente a colaborativa, em resposta à evolução tecnológica da televisão, e como uma forma de atender à necessidade de fortalecer a educação no mundo. Diante desta percepção, partindo de uma das áreas das ciências da aprendizagem intitulada CSCL (Computer-Supported Collaborative Learning), foi concebido um projeto de pesquisa, fundamentado em componentes colaborativos, cujo resultado é caracterizado por uma arquitetura para interação, utilizando a Web e a TV digital via canal de retorno online, com o objetivo de tornar as aulas virtuais e presenciais mais dinâmicas e facilitar o aprendizado extraclasse do aluno, sem abrir mão do meio de entretenimento que a televisão proporciona ao aprendiz em seu contexto familiar e social. O ambiente T-questions proposto possibilita interações virtuais e F2F (face a face), favorecendo um tipo particular de aprendizagem mista (b-learning) no meio em que o aluno está inserido, potencializando a colaboração a fim de motivá-lo a aprender. Desta forma, nesta dissertação, foi desenvolvida uma arquitetura colaborativa associando as linguagens NCL e LUA, com o apoio do emulador do middleware brasileiro Ginga, composta de dois módulos: Web-Professor e TVDi-Aluno, projetados para o ambiente de TV Digital brasileiro. A adoção do ambiente proposto neste trabalho como um recurso de aprendizagem em uma instituição educacional poderá auxiliar e favorecer no processo ensino-aprendizagem com a aplicação desta ferramenta de apoio a educação a distância e presencial, contribuindo para a inclusão social e digital por meio do uso dessa mídia já tão familiarizada na sociedade.","The Interactive Digital TV (TVDi) arises in society as an important resource for the promotion of learning, collaborative mainly, in response to technological developments television, and as a way to attend the need to strengthen education in the world. Given this perception, starting from one of the areas of learning sciences entitled CSCL (Computer-Supported Collaborative Learning), designed a research project, based on collaborative components, the result of which is characterized by an architecture for interaction using the Web and TV digital return channel via online, in order to make lessons more dynamic and virtual classroom learning and facilitate extracurricular student, without sacrificing entertainment medium that television provides the learner in his family and social context. The T-questions proposed environment enables virtual interactions and F2F (face to face), favoring a particular type of blended learning (b-learning) in the environment where the student is inserted, enhancing collaboration in order to motivate him to learn. Thus, in this dissertation, was developed a collaborative architecture combining NCL and LUA languages, with the support of the Brazilian middleware emulator -Ginga, composed of two modules: Web-Teacher-Student and TVDi, designed for the environment of Brazilian Digital TV. The adoption of this proposed work environment as a learning resource in an educational institution can assist and facilitate the teaching-learning process by applying this tool to support distance education and classroom, contributing to the social and digital inclusion through the use this media already so familiar in society.","('Collaborative learning', 'B-Learning', 'Middleware Ginga', 'NCL-Lua', 'T-Learning', 'Aprendizagem colaborativa', 'B-learning', 'Middleware Ginga', 'NCL-Lua', 'T-Learning')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/849","2012-09-28","https://www.repositorio.ufal.br/bitstream/riufal/849/1/Uma%20arquitetura%20para%20aprendizagem%20colaborativa%20utilizando%20a%20integra%c3%a7%c3%a3o%20web%20e%20TV%20digital%20integrativa.pdf","An architecture for collaborative learning using the integration web and integrative TV digital",""
"Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/810","Campus A.C. Simões","Instituto de Computação","Dissertação","Um ambiente interativo de aprendizagem em fração","('Rosemeire Lima Secco',)","('Evandro de Barros Costa',)","('Arturo Hernández-Domínguez', 'Elton Casado Fireman', 'Edilson Ferneda')","Neste trabalho é proposto um ambiente interativo de aprendizagem no domínio de fração, oferecendo ferramentas ao estudante e ao professor. Para o estudante, o ambiente fornece agentes de software que implementam de forma distribuída um resolvedor de problemas e um avaliador de soluções, permitindo tanto avaliar a solução proposta pelo estudante, quanto resolver problemas colocados pelo estudante, além de oferecer suporte pedagógico durante o processo de solução de problemas. Já o professor possui suporte na construção de ambientes específicos, tendo a sua disposição ferramentas para definir um espaço de problemas ou aceitar os problemas já contidos no ambiente. O ambiente foi projetado de acordo com o modelo conceitual do MATHEMA e do arcabouço ForBile, adotando a Aprendizagem Baseada em Problemas-PBL como abordagem pedagógica. O sistema faz uso de algumas funcionalidades comuns aos STI s clássicos, tendo sido implementado usando a tecnologia Java. Foi realizado um experimento com o protótipo desenvolvido e os primeiros resultados dão indícios quanto à qualidade pedagógica do ambiente proposto, assim como a sua aceitação pelos estudantes.","This work proposes an Interactive Learning Environment oriented to the Fraction domain. It offers support to both student and teacher. In favour of the student the environment offers software agents that implements a distributed problem solver yielding respective explanations and an appraiser of solutions, and an evaluator module to evaluate the solution of the student. The system also provides the student with adequate feedback concerning his solution. The teachers have support in the environment construction by means of tools to make the news problems and accept the problems of the environment. The environment was designed in accordance with the conceptual model of the MATHEMA and ForBILE, adopting the Problem Based Learning -PBL as a pedagogical methodology. The system uses some functionalities common of classic STI, having been implemented using the Java technology. A preliminary experiment of the environment indicates some pedagogical quality, as well as its acceptance by the students.","('Interactive learning environmental', 'Math (Study and teaching)', 'Fraction (Mathematics)', 'Tecnologia educacional', 'Ambiente interativo de aprendizagem', 'Matemática -Estudo e ensino', 'Fração (Matemática)')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/810","2007-10-25","https://www.repositorio.ufal.br/bitstream/riufal/810/1/Um%20ambiente%20interativo%20de%20aprendizagem%20em%20fra%c3%a7%c3%a3o.pdf","An interactive learning environmental in fraction.",""
"Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/840","Campus A.C. Simões","Instituto de Computação","Dissertação","Algoritmos Evolucionários Aplicados ao Problema do Caixeiro Viajante Multiobjetivo.","('Max Santana Rolemberg Farias',)","('Henrique Pacca Loureiro Luna',)","('Reinaldo Morabito Neto', 'João Inácio Soletti')","Este trabalho apresenta uma visão geral sobre os principais conceitos da otimização combinatória multiobjetivo, onde apresentamos as técnicas mais utilizadas para a resolução de problemas desta natureza. Ao falarmos das técnicas, discutiremos também aspectos importantes quanto aos parâmetros envolvidos em cada técnica, mostrando as principais abordagens utilizadas. Inicialmente, implementamos e testamos o Multiple Objective Genetic Algorithm (MOGA) para gerar um conjunto de soluções dominantes próximo ao conjunto de Pareto ótimo para o problema do caixeiro viajante biobjetivo. Em uma segunda fase, implementamos o Strength Pareto Evolutionary Algorithm (SPEA) aplicado ao caixeiro viajante biobjetivo","This work presents a general vision about the main concepts of combinatorial multi-objective optimization, where we present the more used technique for the resolution of problems of this nature. To the speech of the techniques we will also argue important aspects how much to the involved parameters in each technique, swing the main used boardings. Initially we implement and test the Multiple Objective Genetic Algorithm MOGA to generate a set of dominant solutions near to the Pareto optimal set for the biobjective Traveling Salesman Problems. In a second phase, we will go to implement the Strength Pareto Evolutionary Algorithm (SPEA) applied to biobjective Traveling Salesman Problems","('Evalutionary algorithms', 'Multiple objetive', 'Optmizations', 'Traveling salesman', 'Algoritmos evolucionários', 'Otimização combinatória', 'Multiobjetivo', 'Problema do caixeiro viajante')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/840","2008-03-14","https://www.repositorio.ufal.br/bitstream/riufal/840/1/Dissertacao_MaxSantanaRolembergFarias_2008.pdf","","('Marco Cesar Goldbarg',)"
"Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/825","Campus A.C. Simões","Instituto de Computação","Dissertação","Ambiente interativo de aprendizagem para o apoio ao estudante no diagnóstico de paciente de acidente vascular cerebral","('Elba Maria Quirino de Almeida Mangueira',)","('Fábio Paraguaçu Duarte da Costa',)","('Arturo Hernández-Domínguez', 'Edilson Ferneda')","Este trabalho tem como objetivo apresentar um Ambiente Interativo de Aprendizagem utilizando o Computador de apoio ao diagnóstico e auxílio no tratamento de pacientes que apresentam disfunções neurológicas. A pesquisa propõe uma arquitetura que facilite as atividades dos estudantes da área da saúde, na tomada de decisão, para o aconselhamento fisioterápico dos pacientes de acidente vascular cerebral. Utilizou-se a abordagem de Raciocínio Baseado em Casos (RBC) que tem como idéia geral a utilização de experiências passadas para a solução de novos problemas. Este trabalho se concentrou nas fases de indexação, representação e recuperação dos casos, com a utilização de métricas de similaridade como a Contagem de Características e a Regra do Contraste de Tversky. Um protótipo foi construído para a validação dessas métricas, provando a eficiência na recuperação dos casos na base de casos","This paper aims to provide an Interactive Learning Environment using the computer to support aid in the diagnosis and treatment of patients with neurological disorders. The study proposes an architecture which facilitates the activities of students in the health area, in decision making, for the advice of physiotherapy for stroke patients. It was used the approach of Case-Based Reasoning (CBR) that has, like general idea, the use of past experiences to the solution of new problems. This work focused on the stages of indexing, representation and retrieval of cases, with the use of metrics, similar characteristics as the Count Features and Tversky s Contrast Model. A prototype was built for the validation of these metrics, proving the efficiency in the recovery of the cases on the basis of cases","('Interactive Learning Environment', 'Case-Based Reasoning', 'Cerabral Vascular Accident', 'Medical Informatics', 'Ambiente interativo de aprendizagem', 'Raciocínio baseado em casos', 'Acidente vascular cerebral', 'Informática médica')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/825","2008-08-21","https://www.repositorio.ufal.br/bitstream/riufal/825/1/Dissertacao_ElbaMariaQuirinodeAlmeidaMangueira_2008.pdf","Interactive Learning Environment to help students to diagnosis of stroke.",""
"Computação gráfica","https://www.repositorio.ufal.br/handle/riufal/1028","Campus A.C. Simões","Instituto de Matemática","Dissertação","A rigidez da curvatura de Ricci do hemisfério S&#8319;+","('Ana Maria Menezes de Jesus',)","('Hilário Alencar da Silva',)","('Fernando Codá dos Santos Cavalcanti Marques', 'Walcy Santos')","Nesta dissertação apresentamos a demonstração de um teorema obtido por F. Hang e X. Wang, o qual estabelece que uma variedade (Mn,g) Riemanniana compacta com bordo não-vazio, curvatura de Ricci maior ou igual a (n-1)g, e com bordo isométrico à esfera (n-1)-dimensional e segunda forma fundamental não-negativa, é isométrica ao hemisfério . Este artigo foi publicado em 2009 no Journal of Geometric Analysis, com o título Rigidity Theorems for Compact Manifolds with Boundary and Positive Ricci Curvature.","In this work we demonstrate a theorem obtained by F. Hang and X. Wang, which ensures that a compact Riemannian manifold (Mn,g) with nonempty boundary, Ricci curvature greater or equal to (n-1)g, boundary isometric to the (n-1)-dimensional sphere and second fundamental form nonnegative, is isometric to the hemisphere . That result was published in this year in Journal of Geometric Analysis with the title Rigidity Theorems for Compact Manifolds with Boundary and Positive Ricci Curvature.","('Curvatura de Ricci', 'Esfera', 'Segunda forma fundamental', 'Variedade compacta com bordo', 'Ricci curvature', 'Sphere', 'Second fundamental form', 'Compact manifold with boundary')","Matemática","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/1028","2009-12-04","https://www.repositorio.ufal.br/bitstream/riufal/1028/1/Dissertacao_AnaMariaMenezesdeJesus_2009.pdf","Rici curvature rigidity of the hemisphere S&#8319;+",""
"Computação gráfica","https://www.repositorio.ufal.br/handle/riufal/1052","Campus A.C. Simões","Instituto de Matemática","Dissertação","Registro automático de superfícies usando spin-image","('Thales Miranda de Almeida Vieira',)","('Adelailson Peixoto da Silva',)","('Luiz Carlos Pacheco Rodrigues Velho', 'Thomas Maurice Lewiner')","Este trabalho descreve um método baseado em três etapas para reconstrução de modelos a partir de malhas capturadas de scanners 3D. Malhas obtidas a partir de diferentes pontos de visão de um scanner têm sua representação em sistemas de coordenadas local. Portanto, para a reconstrução final do modelo, é necessário realizar um alinhamento dessas malhas, ou registro. O algoritmo mais famoso para realizar registro de nuvens de pontos é o algoritmo ICP. Porém, um dos requisitos desse algoritmo é uma estimativa inicial do alinhamento das malhas, que muitas vezes é feita manualmente. Para automatizar esse processo, este trabalho utiliza descritores spin-image para identificar regiões de sobreposição entre as malhas e estimar seus alinhamentos. Após este registro inicial, o alinhamento é refinado através do algoritmo ICP, e finalmente o modelo é reconstruído usando uma técnica chamada VRIP.","This work describes a method based on three stages for reconstructing a model from a given set of scanned meshes obtained from 3D scanners. Meshes scanned from different scanner s view points have their representation in local coordinate systems. Therefore, for final model reconstruction, an alignment of the meshes is required. The most popular algorithm for cloud data registration is the ICP algorithm. However, ICP requires an initial estimate of mesh alignment, which is, many times, done manually. To automate this process, this work uses a surface representation called spin-images to identify overlap areas between the meshes and to estimate their alignment. After this initial registration, the alignment is refined by the ICP algorithm, and finally the model is reconstructed using a method called VRIP.","('Registro de superfícies', 'Spin-images', 'Reconstrução 3D', 'Malhas', 'Range-images', 'Surface registration', 'Spin-images', '3D reconstruction', 'Meshes', 'Range-images')","Matemática","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/1052","2007-02-06","https://www.repositorio.ufal.br/bitstream/riufal/1052/1/Dissertacao_Thales_Da_Capa_ate_Cap_5.pdf","Automatic surface registration using spin-images",""
"Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/816","Campus A.C. Simões","Instituto de Computação","Dissertação","Alinhamento múltiplo de proteínas via algoritmo genético baseado em tipos abstratos de dados.","('Danielle Furtado dos Santos',)","('Roberta Vilhena Vieira Lopes',)","('Manoel Agamemnon Lopes', 'Cicero Eduardo Ramalho Neto', 'Roberto Lins de Carvalho')","Este trabalho apresenta um novo modelo capaz de realizar o alinhamento múltiplo de proteínas utilizando algoritmo genético baseado em tipos abstratos de dados, denominado GAADT, no qual o cromossomo se dispõe em genes que por sua vez é composto de unidades elementares denominadas bases. Cada cromossomo representa um possível alinhamento entre as sequências de proteínas e a adaptação do cromossomo é calculada conforme as bases se dispõem no alinhamento. O modelo se difere de outros métodos de alinhamento múltiplo por alinhar as sequências como um todo, avaliando as colunas (genes) que compõem o alinhamento (cromossomo), ao invés de alinhar sequencias duas a duas progressivamente ou hierarquicamente. As potenciais características do modelo dizem respeito a estrutura de dados organizada, operações genéticas bem definidas sobre os tipos modelados e a convergência para uma solução próxima às encontradas por outras ferramentas, apesar desse algoritmo usar uma quantidade menor de conhecimento frente aos algoritmos existentes. A justificativa de que o modelo é válido foi realizada analisando sua performance com alinhamentos referência, utilizando como estudo de caso um subgrupo de famílias de proteínas.","This works presents a new model to the multiple protein alignment problem using genetic algorithm based on abstract data types -GAADT. This model uses a structure called chromosome, which is a set of gene that in turn is composed of basic units called bases. Each chromosome is a possible alignment of the input sequences and the chromosome fitness is calculated according with the bases order in alignment. This model is different from other paradigms of multiple alignment by aligning the input sequences as a whole instead of a progressive pairwise alignment approach. Some characteristics of this model concern to the data structure, well-defined genetic operations and the convergence to a solution close to that found in other tools. The validation was performed comparing reference alignments of protein families subset with the results of the model.","('Genetic algorithms', 'Abstract data types', 'Population', 'Chromosome', 'Algoritmos genético', 'Tipos abstratos de dados', 'População', 'Cromossomos')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/816","2008-11-07","https://www.repositorio.ufal.br/bitstream/riufal/816/1/Alinhamento%20m%c3%baltiplo%20de%20prote%c3%ad%c2%adnas%20via%20algoritmo%20gen%c3%a9tico%20baseado%20em%20tipos%20abstratos%20de%20dados.pdf","Multiple proteins alignment by genetic algorithms based on abstract data types.",""
"Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/838","Campus A.C. Simões","Instituto de Computação","Dissertação","A-TVDBR: um modelo de atividades de aprendizagem no contexto de educação a distância para a tv digital brasileira","('Mozart de Melo Alves Júnior',)","('Arturo Hernández-Domínguez',)","('Lynn Rosalina Gama Alves', 'Fábio Paraguaçu Duarte da Costa')","Em 2003, a partir do decreto nº 4.901, foi instituída a TV Digital brasileira, cujas características preponderantes são de proporcionar a interatividade e o desenvolvimento de novas tecnologias oferecendo entretenimento à população, promovendo a educação, a cultura, e a inclusão social, diante desta nova realidade, precisam-se viabilizar meios de utilização desta tecnologia para diminuição das barreiras sociais principalmente no que tange a educação. Neste contexto, poucos modelos de atividades de aprendizagem para TV digital brasileira têm sido propostos na literatura, o presente trabalho apresenta um modelo de atividades de aprendizagem para TV Digital brasileira (A-TVDBR) que possibilita de forma ativa e principalmente interativa o aprendizado e a formação através da TV Digital. O modelo proposto foi especificado baseado em componentes de software e implementado para GINGA-NCL, utilizando-se da linguagem declarativa Nested Context Language. O modelo implementado foi usado numa aplicação de TV Digital que teve como público alvo, alunos portadores de deficiência física que possuem limitação motora da associação dos deficientes físicos do estado de Alagoas (ADEFAL)","In 2003, since issued the decree number 4.901, the Brazilian Digital Television was established. Its main features are to provide interactivity and new technologies development, offering the population entertainment and education, promoting culture and social inclusion. Therefore, there is an immediate need for the creation of ways of making this new technology available for the whole population, despite economical status. And if this is to become true, it is extremely important that the Brazilians stop thinking on Digital TV only as an improvement of image and sound quality, but as an interactive tool for education and learning for all. Ignoring this new circumstances would be neglectful to the society, due to the loss of uncountable educational opportunities. A very small number of suggestions on Brazilian Digital TV learning activities models are being proposed recently. For that reason, this work presents a learning activity model for Brazilian Digital TV (A-TVDBR), which relies on an interactive ways of tutoring through Digital TV, aiming disabled students with locomotion difficulties. The model was specified and implemented for GINGA-NCL, using Nested Context Language declarative language","('Digital TV', 'Virtual Learning Environment', 'TV Digital', 'Ambiente Virtual de Aprendizagem', 'GINGA', 'NCL')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/838","2010-09-30","https://www.repositorio.ufal.br/bitstream/riufal/838/1/A-TVDBR%3a%20um%20modelo%20de%20atividades%20de%20aprendizagem%20no%20contexto%20de%20educa%c3%a7%c3%a3o%20a%20dist%c3%a2ncia%20para%20a%20tv%20digital%20%20brasileira.pdf","A-TVDBR: A Learning Activity Model for Brazilian Digital TV",""
"Computação gráfica","https://www.repositorio.ufal.br/handle/riufal/1030","Campus A.C. Simões","Instituto de Matemática","Dissertação","Hipersuperfícies em Rp+q+2 de curvatura escalar nula invariantes por O(p+1) x O(q+1).","('Rodrigo Fernandes de Moura Melo',)","('Fernando Enrique Echaiz Espinoza',)","('Fernando Codá dos Santos Cavalcanti Marques', 'Hilário Alencar da Silva')","Esta dissertação está baseada no artigo de Jocelino Sato e Vicente de Souza Neto intitulado Complete and Stable O(p+1) x O(q+1) -Invariant Hypersurfaces with Zero Scalar Curvature in Euclidean Space Rp+q+2, publicado na revista Annals of Global Analysis and Geometry, volume 29, em 2006. O principal resultado desta dissertação é o Teorema de Classicação, que afirma o seguinte: Uma hipersuperfície Mp+q+1 que é invariante pela açãoao do grupo O(p + 1) x O(q + 1), p; q > 1, com curvatura escalar identicamente nula deve pertencer a uma das seguintes classes: (1) Cones com uma singularidade na origem de Rp+q+2; (2) Hipersuperfícies possuindo uma órbita de singularidades e assintotando ambos os cones C&#945; e C&#946;; (3) Hipersuperfícies regulares que assintotam o cone C&#945;; (4) Hipersuperfícies regulares que assintotam o cone C&#946;; (5) Hipersuperfícies regulares que assintotam ambos os cones C&#945; e C&#946;. A demonstração do teorema requer um estudo de uma equação diferencial ordinária envolvendo as coordenadas das curvas, no plano, que geram estas hipersuperfícies. Esta equação diferencial, por sua vez, está associada a um campo de vetores X : R2 &#8594; R2 no plano. O estudo do retrato de fase deste campo é fundamental. Através dele, foi possível traduzir o comportamento das trajetórias de X em informações com respeito às curvas geratrizes e desta maneira obter o teorema.","This dissertation has as base Jocelino Sato and Vicente de Souza Neto's paper called Complete and Stable O(p + 1) x O(q + 1)-Invariant Hypersurfaces with Zero Scalar Curvature in Euclidean Space Rp+q+2, published on the Annals of Global Analysis and Geometry -29 in 2006. The main result of this dissertation is the Classi_cation Theorem, which states: The O(p+1) x O(q+1)-Invariant Hypersurfaces in Rp+q+2, p; q > 1, with zero scalar curvature belong to one of the following classes: (1) Cones with a singularity at the orign of Rp+q+2; (2) Hypersurfaces having one orbit of singularity and asymptoting both of the cones C&#945; and C&#946;; (3) Regular hypersurfaces asymptoting the cone C&#945;; (4) Regular hypersurfaces asymptoting the cone C&#946;; (5) Regular hypersurfaces asymptoting both of the cones C&#945; and C&#946;. It was reached by the studies of the ordinary differential equation on R2, involving the coordenate curves that generate these hypersurfaces. Such differential equation, in its turn, is associated with a vector field X : R22 &#8594; R2 on the plan. The study of the orbits space in this field is essential; after all, because of it, it was possible to translate the X orbits' behavior into information concerning the profile curves and, finally, reach the theorem.","('Cone', 'Hypersurface', 'Lie group', 'Profile curve', 'Scalar curvature', 'Cone', 'Curvatura escalar', 'Curva geratriz', 'Grupo de Lie', 'Hipersuperfície')","Matemática","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/1030","2009-12-18","https://www.repositorio.ufal.br/bitstream/riufal/1030/1/Dissertacao_RodrigoFernandesdeMouraMelo_2009.pdf","O(p+1) x O(q+1) Invariant hypersurfaces with zero scalar curvature in Euclidean space Rp+q+2.",""
"Computação gráfica","https://www.repositorio.ufal.br/handle/riufal/1054","Campus A.C. Simões","Instituto de Matemática","Dissertação","Propriedades ergódicas do modelo geométrico do atrator de Lorenz","('Rafael Nóbrega de Oliveira Lucena',)","('Krerley Irraciel Martins Oliveira',)","('Maria Jose Pacifico', 'Fernando Pereira Micena')","Este trabalho tem sua motivação no modelo geométrico construído para aproximar o comportamento das soluções das equações de Lorenz. Simultaneamente Afraimovich em [17] e Guckenheimer e Williams [18] construíram um modelo geométrico. Essencialmente ele consiste na construção de medidas físicas e ergódicas para dois tipos de aplicações, uma unidimensional que é seccionalmente expansora (piecewise expanding) e outra bidimensional que contrai as folhas de uma folheação invariante. A primeira faz uso de um operador (operador de transferência) agindo no espaço das funções de variação limitada, enquanto que a segunda utiliza o teorema de representação Riesz bem como algumas outras propriedades topológicas.","This work has its motivation in the study of the ergodic properties of the Lorenz geometric model, constructed to approximate the behavior of solutions of the Lorenz equations. Simultaneously, Afraimovich in [17] and Guckenheimer and Williams [18], constructed a geometric model that mimics the dynamics of the original Lorenz equations. Here, we build ergodic physical measures for two types of applications that arise from the Lorenz geometric model. The first one is a piecewise expanding one-dimensional map and the second is a two-dimensional application wich contracts the leaves of an invariant foliation. To construct the ergodic physical measure for the one dimensional Lorenz map, we make use of an operator (transfer operator) acting in the space of bounded variation functions, while the second uses the Riesz representation theorem and some other topological properties.","('Lorenz', 'Ergódica', 'Geométrico', 'Ergodic', 'Geometric', 'Lorentz')","Matemática","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/1054","2011-03-15","https://www.repositorio.ufal.br/bitstream/riufal/1054/1/Dissertacao_RafaelNobregaDeOliveiraLucena_2011.pdf","Ergodic properties of the geometric model of Lorentz attrator",""
"Computação gráfica","https://www.repositorio.ufal.br/handle/riufal/1019","Campus A.C. Simões","Instituto de Matemática","Dissertação","Métodos de renderização não-fotorrealística.","('Daniel Nicolau Brandão',)","('Adelailson Peixoto da Silva',)","('Vinicius Moreira Mello', 'Dimas Martínez Morera')","Nesta dissertação são discutidos os principais conceitos envolvidos nas técnicas de renderização não-fotorrelística e propõe um esquema geral para implementação de tais técnicas. É discutido também um estilo de renderização não-fotorrealística de desenhos de linha para modelos 3D apresentado por Stéphane Grabli e colaboradores, cujos estilos de linha sejam programáveis. Também apresentamos uma implementação de parte do trabalho de Grabli.","This dissertation dicusses the main concepts involved in the non-photorealistic rendering techniques and proposes a general scheme to implement such techniques. The work discusses also a non-photorealistic rendering style from line drawing to 3D models presented by Stéphane Grabli et al, in such a way that the line styles are programmable. We also present an implementation from portion of the work of Grabli.","('Matemática', 'Matemática aplicada', 'Computação gráfica', 'Renderização', 'Renderização de modelos 3D', 'Mathematic', 'Applied mathematics', 'Computer graphics', 'Rendering', 'Rendering for 3D model')","Matemática","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/1019","2008-02-29","https://www.repositorio.ufal.br/bitstream/riufal/1019/1/Dissertacao_Daniel_Nicolau_Brandao.pdf","Non-photorealistic rendering methods.",""
"Computação gráfica","https://www.repositorio.ufal.br/handle/riufal/1029","Campus A.C. Simões","Instituto de Matemática","Dissertação","Incompressibilidade de toros transversais a fluxos axioma A.","('Alexsandro da Silva Néo',)","('Enoch Humberto Apaza Calla',)","('Krerley Irraciel Martins Oliveira', 'Vilton Jeovan Viana Pinheiro')","Provaremos que um toro transversal a um campo de vetores Axioma A que não exibe poço, fonte e órbita periódica homotópica a um ponto sobre uma variedade tridimensional, fechada, irredutível é incompressível.","We prove that a torus transverse to an Axiom A vector field that does not exhibit sinks, sources or null homotopic periodic orbits on a closed irreducible 3-manifold is incompressible.","('Variedade irredutível', 'Campo de vetores Axioma A', 'Toro incompressível', 'Irreducible manifold', 'Axiom A vector field', 'Incompressible tori')","Matemática","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/1029","2009-12-18","https://www.repositorio.ufal.br/bitstream/riufal/1029/1/Dissertacao_AlexsandrodaSilvaNeo_2009.pdf","Incompressibility of tori transverse to axiom A flows",""
"Computação gráfica","https://www.repositorio.ufal.br/handle/riufal/1046","Campus A.C. Simões","Instituto de Matemática","Dissertação","O problema de Dirichlet em domínios limitados","('Adalgisa Mendonça Mota',)","('Adán José Corcho Fernández',)","('Julio Cesar de Souza Almeida', 'Pablo Gustavo Albuquerque Braz e Silva')","Nesta dissertação usamos duas abordagens diferentes para provar a existência de soluções para o Problema de Contorno de Dirichlet Clássico em domínios limitados. Aplicamos o primeiro método quando estamos trabalhando com domínios cuja fronteira é duas vezes continuamente diferenciável. Essa abordagem baseia-se na Teoria dos Potenciais de Camadas Simples e Dupla, onde a teoria de operadores compactos tem um papel fundamental. O segundo método usa o Princípio Variacional de Dirichlet para resolver o problema em domínios do plano com fronteiras menos regulares que no caso anterior; a saber, fronteiras que satisfazem a condição do triângulo exterior.","In this work we use two approach to prove the existence of solutions for the Classical Dirichlet Problem on bounded domains. The first method is applied to domains with smooth boundary and is based on the Single and Double Layer Potentials Theory. The second method uses the Variational Dirichlet Principle to solve the Dirichlet Problem in plane domains with boundary less regular than the previous case; more precisely, boundary satisfying the property of the outer triangle.","('Análise funcional', 'Teoria do potencial', 'Problema de Dirichlet', 'Functional analysis', 'Potential theory', 'Dirichlet problem')","Matemática","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/1046","2011-04-15","https://www.repositorio.ufal.br/bitstream/riufal/1046/1/Dissertacao_Adalgisa%20Mendonca%20Mota_2011.pdf","The Dirichlet problem on bounded domains",""
"Computação gráfica","https://www.repositorio.ufal.br/handle/riufal/1040","Campus A.C. Simões","Instituto de Matemática","Dissertação","O problema de Cauchy para as equações KdV e mKdV","('Carlos Alberto Silva dos Santos',)","('Amauri da Silva Barros',)","('Lucas Catão de Freitas Ferreira', 'Adán José Corcho Fernández')","Neste trabalho demonstraremos que o problema de Cauchy associado as equações de Korteweg-de Vries, denotada por KdV, e de Korteweg-de Vries modificada, denotada por mKdV, com dado inicial no espaço de Sobolev Hs(|R), é bem posto localmente em Hs(|R), com s>3/4 para a KdV e s&#8805;1/4 para a mKdV, onde a noção de boa postura inclui a existência, unicidade, a propriedade de persistência da solução e dependência contínua da solução com relação ao dado inicial. Este resultado é baseado nos trabalhos de Kenig, Ponce e Vega. A técnica utilizada para obter tais resultados se baseia no Teorema do Ponto Fixo de Banach combinada com os efeitos regularizantes do grupo associado com a parte linear.","In this work we will demonstrate that the Cauchy problem associated with the Korteweg-de Vries equation, denoted by KdV, and Korteweg-de Vries modified equation, denoted by mKdV, with initial data in the space of Sobolev Hs(|R), is locally well-posed on Hs(|R), with s>3/4 for KdV and s&#8805;1/4 for mKdV, where the notion of well-posedness includes existence, uniqueness, persistence property of solution and continuous dependence of solution with respect to the initial data. This result is based on the works of Kenig, Ponce and Vega. The technique used to obtain these results is based on fixed point Banach theorem combined with the regularizantes effects of the group associated with the linear part.","('Cauchy', 'Equação KdV', 'Equação mKdV', 'Boa colocação local', 'Ponto fixo de Banach', 'Efeitos regularizantes', 'Cauchy', 'KdV', 'mKdV', 'Well-posedness', 'Fixed point Banach', 'Smoothing effects')","Matemática","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/1040","2009-02-12","https://www.repositorio.ufal.br/bitstream/riufal/1040/1/Dissertacao_Carlos%20Alberto%20Silva%20dos%20Santos_2009.pdf","The Cauchy problem for KdV and mKdV equations",""
"Computação gráfica","https://www.repositorio.ufal.br/handle/riufal/1036","Campus A.C. Simões","Instituto de Matemática","Dissertação","Operador laplaciano discreto via triangulação de Delaunay intrínseca.","('José Borges dos Santos Filho',)","('Vinicius Moreira Mello',)","('Adelailson Peixoto da Silva', 'Perfilino Eugenio Ferreira Junior')","O objetivo desta disserta¸c ao ´e apresentar um an´alogo discreto do operador laplaciano, ou seja, um operador linear definido no conjunto das fun¸c oes lineares por partes em uma malha de tri angulos que possua o m´aximo de propriedades an´alogas ao operador laplaciano cont´&#305;nuo sobre uma superf´&#305;cie. Em particular, mostraremos que se a malha satisfaz ao crit´erio de Delaunay, o laplaciano obedece a uma vers ao discreta do princ´&#305;pio do m´aximo, que possui import ancia semelhante ao princ´&#305;pio do m´aximo na teoria das fun¸c oes harm onicas. Apresentamos ainda tr es aplica¸c oes do laplaciano discretizado: a primeira tem como objetivo obter parametriza¸c oes de malhas para efeito de mapeamento de textura; a segunda consiste na suaviza¸c ao de malhas por meio do processo de difus ao; a terceira e ´ultima aplica¸c ao visa identificar formas e simetrias de objetos por meio das curvas de contorno associadas `as autofun¸c oes do laplaciano.","The main goal of this work is to present a discrete analogous of the laplacian operator, that is, a linear operator on the set of piecewise linear functions over a triangular mesh that has similar properties to the continuous laplacian over a surface. Particularly, we will show that if the mesh satisfies a Delaunay criterion, the laplacian obeys a discrete version of the maximum principle, which importance in the discrete setting is similar to the importance of the maximum principle in the theory of harmonic functions. We also present three applications of the discrete laplacian: the first one has as objective to get parametrizations of meshes for texture mapping; the second one consists of mesh smoothing by a diffusion process; the third and last application aims to identify forms and symmetries of objects by means of the contour curves associated to the eigenfunctions of the laplacian operator.","('Computação gráfica', 'Operador laplaciano', 'Triangulação de Delaunay', 'Computer graphics', 'Delaunay triangulation', 'Delaunay triangulation')","Matemática","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/1036","2008-08-29","https://www.repositorio.ufal.br/bitstream/riufal/1036/1/Dissertacao_JoseBorgesdosSantosFilho_2008.pdf","Discrete laplacian operator via an intrinsic Delaunay triangulation.",""
"Computação gráfica","https://www.repositorio.ufal.br/handle/riufal/1024","Campus A.C. Simões","Instituto de Matemática","Dissertação","Uma introdução aos operadores de Schrödinger com ênfase no caso unidimensional.","('Priscila Santos Ramos',)","('Ediel Azevedo Guerra',)","('Adán José Corcho Fernández', 'Ramón Orestes Mendoza Ahumada')","O objetivo principal desta dissertação é fornecer uma introdução aos operadores de Schrödinger do tipo H = -&#8710; + V, onde &#8710; denota o laplaciano do R&#8319; e V denota o operador de multiplicação pela função V ambos definidos em um subespaço conveniente do L²(R&#8319;), no que diz respeito à determinação de sua auto-adjunticidade e do seu espectro.","The main objective of this dissertation is to give an introduction to Schrödinger operators of the type H = -&#8710; + V. In these operators, &#8710; denotes the Laplacian of R&#8319; and V denotes the operator of multiplication by a function V both defined in a suitable subspace of L²(R&#8319;) with respect to the determination of its selfadjointess and of its spectrum.","('Operador auto-adjunto', 'Operador de Schrödinger', 'Espectro', 'Selfadjoint operator', 'Schrödinger operator', 'Spectrum')","Matemática","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/1024","2009-02-26","https://www.repositorio.ufal.br/bitstream/riufal/1024/1/Dissertacao_PriscilaSantosRamos_2009.pdf","An Introduction to Schrödinger operators with emphasis on one-dimensional case.",""
"Computação gráfica","https://www.repositorio.ufal.br/handle/riufal/1050","Campus A.C. Simões","Instituto de Matemática","Dissertação","Formalismo termodinâmico do conjunto irregular para médias de Birkhoff e expoentes de Lyapunov","('Giovane Ferreira Silva',)","('Krerley Irraciel Martins Oliveira',)","('Nivaldo Costa Muniz', 'Marcus Augusto Bronzi')","Neste trabalho, estudamos o conjunto X &#775;(&#966;,f) de pontos tal que as médias de Birkhoff não existe. Seguindo Thompson, nosso resultado principal aqui é mostrar que a pressão topológica de X &#775;(&#966;,f) é total. Como corolário, damos o mesmo resultado para o conjunto Irregular de Oseledets para os expoentes de Lyapunov em dimensão um. Para dimensões maiores, esta questão está em aberto.","In this work, we study the set X &#775;(&#966;,f) of points such that the Birkhoff averages do not exist. Following Thompson, our main result here is to show that the topological pressure of X &#775;(&#966;,f) is total. As corollary, we get the some result for the Oseledets Irregular set for Lyapunov exponent in one dimension. For higher dimensions, this question is still open.","('Pressão topológica', 'Propriedade de especificação', 'Conjunto irregular', 'Médias de Birkhoff', 'Expoente de Lyapunov', 'Topological pressure', 'Specification property', 'Irregular set', 'Birkhoff average', 'Lyapunov exponent')","Matemática","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/1050","2011-03-22","https://www.repositorio.ufal.br/bitstream/riufal/1050/1/Dissertacao_Giovane%20Ferreira%20Silva_2011.pdf","Thermodynamic formalism of the irregular set averages of Birkhoff and Lyapunov exponents",""
"Computação gráfica","https://www.repositorio.ufal.br/handle/riufal/1034","Campus A.C. Simões","Instituto de Matemática","Dissertação","Estimativas sobre o primeiro autovalor não-nulo de Steklo","('Claudemir Silvino Leandro',)","('Hilário Alencar da Silva',)","('Walcy Santos',)","Este trabalho visa obter estimativas para o primeiro autovalor não-nulo de Steklo. Nos concentramos, basicamente, em três artigos de J. F. Escobar, publicados nos anos 1997, 1999 e 2000. Nestes artigos, são obtidas estimativas para o primeiro autovalor não-nulo de Steklo em função da geometria da variedade Riemanianna. Inicialmente, demonstramos um teorema afirmando que para o problema de Steklo em uma superfície compacta, com curvartura Gaussiana não-negativa e curvatura geodésica da fronteira limitada inferiormente por uma constante positiva c, o primeiro autovalor não-nulo de Steklo é necessariamente maior ou igual a c e, além disso, a igualdade ocorre se, e somente se, a superfície é o disco Euclidiano. Este resultado é obtido usando a fórmula de Bochner-Lichnerowicz e o princípio do máximo. No problema de Steklo em variedades Riemannianas n-dimensionais, com n 3, mostramos uma estimativa para o primeiro autovalor não-nulo de Steklo em função do primeiro autovalor não-nulo do Laplaciano no bordo da variedade dada. Apresentamos também uma conjectura feita por Escobar afirmando que o teorema descrito no parágrafo anterior tambám é verdadeiro para dimensões maiores ou igual a três. Esta conjectura se encontra em aberto e mostramos uma contribuição para a mesma exibindo uma estimativa aproximada, embora não tão ótima, feita por Escobar em 1999.","","('Autovalor', 'Steklo', 'Laplaciano')","Matemática","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/1034","2005-12-19","https://www.repositorio.ufal.br/bitstream/riufal/1034/1/Estimativas%20sobre%20o%20primeiro%20autovalor%20n%c3%a3o-nulo%20de%20Steklo.pdf","","('Fernando Codá dos Santos Cavalcanti Marques',)"
"Computação gráfica","https://www.repositorio.ufal.br/handle/riufal/1025","Campus A.C. Simões","Instituto de Matemática","Dissertação","Hipersuperfícies com curvatura média constante e hipersuperfícies com curvatura escalar constante na esfera.","('Isadora Maria de Jesus',)","('Hilário Alencar da Silva',)","('Marcos Petrucio de Almeida Cavalcante', 'Abdênago Alves de Barros')","Nesta dissertação apresentamos dois teoremas que caracterizam as hipersuperfícies na esfera unitária de dimensão n+1. O primeiro resultado, obtido por H. Alencar e M. do Carmo, classifica as hipersuperfícies com curvatura média constante na esfera. Este resultado foi publicado em abril de 1994 no Proceedings of The American Mathematical Society, volume 120, número 4 com o título Hypersurfaces With Constant Mean Curvature.O segundo resultado provado nesta dissertação foi obtido por Li Haizhong no artigo Hypersurfaces With Constant Scalar Curvature in Spaces Forms, publicado em 1996 no Mathematische Annalen, volume 305. O Teorema de Li Haizhong caracteriza as hipersuperfícies com curvatura escalar constante na esfera. Demonstraremos o Teorema de Li Haizhong utilizando os resultados obtidos por H. Alencar e M. do Carmo.","In this work we prove two theorems that characterize the hypersurfaces in the unitary sphere of dimension n+1. The first result, obtained by H. Alencar and M. do Carmo, classifies hypersurfaces with constant mean curvature in the sphere. This result was published in April 1994 in Proceedings of The American Mathematical Society, volume 120, number 4 with the title Hypersurfaces with Constant Mean Curvature. The second result was obtained by Li Haizhong in the article Hypersurfaces with Constant Scalar Curvature in Space Forms, published in 1996 in the journal Mathematisch Annalen, volume 305. The theorem of Li Haizhong characterizes hypersurfaces with constant scalar curvature in the sphere. We prove the theorem of Li Haizhong using the results obtained by H. Alencar and M. do Carmo.","('Geometria diferencial', 'Curvatura media', 'Curvatura scalar', 'Hipersuperfície', 'Laplaciano', 'Alencar do Carmo, teorema de', 'Li Haizhong, teorema de', 'Differential geometry', 'Mean curvature', 'Scalar curvature', 'Hypersurfaces', 'Laplacian', 'Alencar and do Carmo s, theorem', 'Li Haizhong s, theorem')","Matemática","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/1025","2009-08-04","https://www.repositorio.ufal.br/bitstream/riufal/1025/1/Dissertacao_IsadoraMariadeJesus_2009.pdf","Hypersurfaces with constant mean curvature and hypersurfaces with constant scalar in curvature sphere.",""
"Computação gráfica","https://www.repositorio.ufal.br/handle/riufal/1043","Campus A.C. Simões","Instituto de Matemática","Dissertação","Fórmulas integrais para a curvatura r-média e aplicações","('Viviane de Oliveira Santos',)","('Hilário Alencar da Silva',)","('Abdênago Alves de Barros', 'Walcy Santos')","Nesta dissertação, descrevemos resultados obtidos por Hilário Alencar e A. Gervasio Colares, publicado no Annals of Global Analysis and Geometry em 1998. Inicialmente, obtemos fórmulas integrais para a curvatura r-média, as quais generalizam fórmulas de Minkowski. Além disso, usando estas fórmulas, caracterizamos as hipersuperfícies compactas imersas no espaço Euclidiano, esférico ou hiperbólico cujo conjunto de pontos nestes espaços que não pertencem as hipersuperfícies totalmente geodésicas tangentes às hipersuperfícies compactas é aberto e não vazio. Outrossim, obtemos ainda resultados relacionados com a estabilidade. As demonstrações destes resultados são obtidas através da fórmula integral de Dirichlet para o operador linearizado da curvatura r-média de uma hipersuperfície imersa no espaço Euclidiano, esférico ou hiperbólico, bem como do uso de um resultado recente provado por Hilário Alencar, Walcy Santos e Detang Zhou no preprint Curvature Integral Estimates for Complete Hypersurfaces. Ressaltamos que esta dissertação foi baseada na versão corrigida por Hilário Alencar do artigo publicado no Annals of Global Analysis and Geometry.","","('Geometria diferencial', 'Fórmula integral', 'Operador linearizado', 'Curvatura r-média', 'Hipersuperfície', 'Estabilidade', 'Sphere', 'Lie algebra', 'Lie groups', 'De Rham cohomology group', 'Bi-invariant metric')","Matemática","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/1043","2010-01-29","https://www.repositorio.ufal.br/bitstream/riufal/1043/1/Dissertacao_Viviane%20de%20Oliveira%20Santos_2010.pdf","Spheres that admit a Lie group structure",""
"Computação gráfica","https://www.repositorio.ufal.br/handle/riufal/1027","Campus A.C. Simões","Instituto de Matemática","Dissertação","Existência e estabilidade de Soluções do tipo ondas solitárias para a equação Korteweg-de Vries (KdV)","('Isnaldo Isaac Barbosa',)","('Amauri da Silva Barros',)","('Adán José Corcho Fernández', 'Claudianor Oliveira Alves')","Neste trabalho demonstraremos um teorema de Boa Colocação Local e em seguida de Boa Colocação Global para a Equação Korteweg-de Vries nos espaços de Sobolev fazendo uso das leis de conservação desta equação, das propriedades do grupo associada a mesma e de algumas estimativas obtidas por Kenig, Ponce e Vega em [6]. Demonstraremos ainda a existência e estabilidade de soluções tipo ondas solitárias para a Equação Korteweg-de Vries, para obter o resultado de estabilidade usamos o Lema de Compacidade Concentrada de P. Lions, nesta parte o resultado de boa colocação global é utilizado de forma essencial, assim como as leis de conservação para esta equação, pois para utilizar esta técnica resolvemos um problema variacional de minimização. A última parte desta dissertação esta baseada no trabalho de Jonh Albert [20].","In this paper we demonstrate a theorem of Well-Posedness Local and followed by Well-Posedness Global Equation Korteweg-de Vries in Sobolev spaces by making use of conservation laws of this equation, the properties of the group associated with it, and some estimates obtained by Kenig , Ponce and Vega in [6]. We also demonstrated the existence and stability of solitary wave type solutions for Equation Korteweg-de Vries, to obtain the result of stability we use the lemma Concentrated compactness of P. Lions, in part the result of good global placement is used in a critical, and the conservation laws for this equation, because using this technique to solve a variational minimization problem. Latter part of this thesis is based on the work of John Albert [20].","('Equações diferenciais', 'Ondas (Matemática)', 'Diferential equations', 'Waves (Mathematics)')","Matemática","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/1027","2009-10-06","https://www.repositorio.ufal.br/bitstream/riufal/1027/1/Dissertacao_IsnaldoIsaacBarbosa_2009.pdf","Existence and stability of solutions of type solitary waves in equation Korteweg-de Vries (KdV)",""
"Computação gráfica","https://www.repositorio.ufal.br/handle/riufal/1045","Campus A.C. Simões","Instituto de Matemática","Dissertação","O grupo de Schrödinger em espaços de Zhidkov","('Fábio Henrique de Carvalho',)","('Adán José Corcho Fernández',)","('Amauri da Silva Barros', 'Mahendra Prasad Panthee')","Este trabalho é dedicado ao estudo da boa colocação local e global do Problema de Cauchy associado à equação não linear de Schrödinger, com dado inicial não nulo no infinito.","This work is dedicated to the local and global well-possednes study of Cauchy s Problem associated to the nonlinear Schrödinger equation, to the initial data nonzero at infinity.","('Equações diferenciais parciais', 'Equações de evolução', 'Equação de Schrödinger', 'Espaços de Zhidkov', 'Partial differential equations', 'Evolution equations', 'Schrödinger equation', 'Zhidkov spaces')","Matemática","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/1045","2010-03-16","https://www.repositorio.ufal.br/bitstream/riufal/1045/1/Dissertacao_Fabio%20Henrique%20de%20Carvalho_2010.pdf","Schrödinger group on Zhidkov spaces",""
"Computação gráfica","https://www.repositorio.ufal.br/handle/riufal/1041","Campus A.C. Simões","Instituto de Matemática","Dissertação","Um estudo sobre a boa colocação local da equação não linear de Schrödinger cúbica unidimensional em espaços de Sobolev periódicos","('Darliton Cezario Romão',)","('Adán José Corcho Fernández',)","('Jose Felipe Linares Ramirez', 'Ediel Azevedo Guerra')","Neste trabalho, fazemos um estudo detalhado do problema de Cauchy para a equação não-linear cúbica de Schrödinger, com dados iniciais em espaços de Sobolev no toro. Especificamente, provaremos que este modelo é localmente bem posto para dados em Hsper, com s &#8805; 0. Em particular, para dados iniciais em L2 o modelo é globalmente bem posto, devido à lei de conservação da equação neste espaço. Além disso, provaremos que os resultados obtidos são os melhores possíveis, visto que exibiremos exemplos que mostram que o fluxo da equação não é localmente uniformemente contínuo para dados iniciais com regularidade menor que L2.","In this work we study, in details, the Cauchy problem of the nonlinear Schrödinger equation, with initial datas in periodic Sobolev spaces. Specifically, we prove that this problem is locally well posed for datas in Hsper, with s &#8805; 0. Particularly, for initial datas in L2 the problem is globally well posed, due to the conservation law of the equation in this space. Moreover, we prove the this result is the best one, seeing we expose examples that show that the equation flow is not locally uniformly continuous for initial datas with regularity less than L2.","('Problemas de Cauchy', 'Espaço de Sobolev', 'Equação não linear de Schrödinger', 'Boa colocação local', 'Má colocação', 'Cauchy problem', 'Sobolev spaces', 'Nonlinear Schrödinger equation', 'Locally well posed', 'Ill posed')","Matemática","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/1041","2009-03-25","https://www.repositorio.ufal.br/bitstream/riufal/1041/1/Dissertacao_Darliton%20Cezario%20Romao_2009.pdf","A study about the locally well posed of cubic nonlinear Schrödinger equation in periodic Sobolev spaces",""
"Computação gráfica","https://www.repositorio.ufal.br/handle/riufal/1023","Campus A.C. Simões","Instituto de Matemática","Dissertação","Estimativas de Strichartz e a equação não linear de Schrödinger em espaços euclidianos.","('Alex Santana dos Santos',)","('Adán José Corcho Fernández',)","('Carlos Matheus Silva Santos', 'Ediel Azevedo Guerra')","Neste trabalho estudaremos a boa colocação local e global para equação não linear de Schrödinger, com dados iniciais em L2(RN), a saber iut(t,x) + &#916;u(t,x) = &#947;&#9474;u(t,x)&#9474;&#945; u(t, x) u(x,0) = &#966;(x) L2(RN), x RN, t R. onde u é uma função de valores complexos e &#945; < 4/N.","In this work we will study local and global well-posedness to Schrödinger nonlinear equation, with initial data L2(RN), that is iut(t,x) + &#916;u(t,x) = &#947;&#9474;u(t,x)&#9474;&#945; u(t, x) u(x,0) = &#966;(x) L2(RN), x RN, t R. where u is a complex value function and 0 < &#945; <4/ N .","('Harmonic Analysis', ""Schrödinger's equation"", 'Análise Harmônica', 'Estimativas de Strichartz', 'Equação de Schrödinger')","Matemática","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/1023","2009-02-04","https://www.repositorio.ufal.br/bitstream/riufal/1023/1/Dissertacao_AlexSantanadosSantos_2009.pdf","Strichartz's estimate and the Schrödinger's nonlinear equation in euclidian spaces.",""
"Computação gráfica","https://www.repositorio.ufal.br/handle/riufal/1037","Campus A.C. Simões","Instituto de Matemática","Dissertação","Estabilidade de hipersuperfícies com curvatura média constante","('Sofia Carolina da Costa Melo',)","('Hilário Alencar da Silva',)","('Fernando Codá dos Santos Cavalcanti Marques', 'Walcy Santos')","Descrevemos um resultado obtido por João Lucas Barbosa e Manfredo Perdigão do Carmo, publicado na Mathematische Zeitschrift em 1984, sobre estabilidade de hipersuperfícies com curvatura média constante não-nula imersas no espaço Euclidiano de dimensão n + 1. A motivação principal deste trabalho é a demonstração do seguinte resultado: Sejam M uma variedade Riemanniana de dimensão n, compacta, orientável e x uma imersão com curvatura média constante não-nula da variedade M no espaço Euclidiano de dimensão n + 1. Então x é estável se, e somente se, a imagem de M por x é uma esfera redonda. Fazemos a demonstração deste resultado em duas partes, na primeira mostramos, através de um exemplo, que a esfera redonda é uma hipersuperfície estável. Na segunda parte, demonstramos que todos os pontos de uma hipersuperfície com essas características são umbílicos e pela compacidade da hipersuperfície, é a esfera redonda. Observamos que muitos outros trabalhos se originam do artigo de Barbosa e do Carmo dentre eles, citamos dois trabalhos, um de Barbosa, do Carmo e Eschenburg de 1988 e o outro de Wente de 1991. O primeiro, trata de uma generalização do Teorema de Barbosa e do Carmo, e o segundo, traz uma nova demonstração do mesmo resultado usando uma variação paralela.","","('Hipersuperfície', 'Curvatura média constante', 'Estabilidade')","Matemática","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/1037","2005-12-20","https://www.repositorio.ufal.br/bitstream/riufal/1037/1/Estabilidade%20de%20hipersuperf%c3%adcies%20com%20curvatura%20m%c3%a9dia%20constante.pdf","",""
"Computação gráfica","https://www.repositorio.ufal.br/handle/riufal/1039","Campus A.C. Simões","Instituto de Matemática","Dissertação","Dimensão de Hausdorff de conjuntos numéricos","('José Arnaldo dos Santos',)","('Krerley Irraciel Martins Oliveira',)","('Vilton Jeovan Viana Pinheiro', 'Vitor Domingos de Araújo')","Nosso trabalho está dedicado ao estudo de uma classe de conjuntos que do ponto de vista da medida de Lebesgue são desprezíveis, isto é, possuem medida de Lebesgue zero. Vamos mostrar que esses conjuntos mesmo tendo medida de Lebesgue zero, ainda são conjuntos grandes no sentido da teoria da dimensão. Para cumprir nossos objetivos vamos fazer uso de resultados e definições da teoria da medida e teoria ergódica, além do conceito e resultados de nossa principal ferramenta que é a dimensão de Hausdorff","","('Dimensão fractal', 'Dimensão de uma medida', 'Pontos regulares')","Matemática","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/1039","2006-07-25","https://www.repositorio.ufal.br/bitstream/riufal/1039/1/Dimens%c3%a3o%20de%20Hausdorff%20de%20conjuntos%20num%c3%a9ricos.pdf","",""
"Computação gráfica","https://www.repositorio.ufal.br/handle/riufal/1042","Campus A.C. Simões","Instituto de Matemática","Dissertação","As esferas que admitem uma estrutura de grupo de Lie","('Kennerson Nascimento de Sousa Lima',)","('Ediel Azevedo Guerra',)","('Ramón Orestes Mendoza Ahumada', 'Feliciano Marcílio Aguiar Vitório')","Mostraremos que as únicas esferas euclidianas conexas que admitem uma estrutura de grupo de Lie são S1 e S3, para todo n maior ou igual a 1. Faremos isso por intermédio do estudo de propriedades dos grupos de cohomologia de De Rham das esfereas Sn e dos grupos de Lie compactos e conexos.","We will show that the only connected Euclidean spheres admitting a structure of Lie group are S1 and S3, for all n greater than or equal to 1. We will do this through the study of properties of the De Rham cohomology groups of sphere Sn and of compact connected Lie groups.","('Esfera', 'Álgebra de Lie', 'Grupos de Lie', 'Grupos de cohomologia de De Rham', 'Métrica bi-invariante', 'Sphere', 'Lie algebra', 'Lie groups', 'De Rham cohomology group', 'Bi-invariant metric')","Matemática","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/1042","2010-03-02","https://www.repositorio.ufal.br/bitstream/riufal/1042/1/Dissertacao_Kennerson%20Nascimento%20de%20Sousa%20Lima_2010.pdf","Spheres that admit a Lie group structure",""
"Computação gráfica","https://www.repositorio.ufal.br/handle/riufal/1055","Campus A.C. Simões","Instituto de Matemática","Dissertação","Difeomorfismos que preservam volumee problemas elípticos","('Julio Cesar de Souza Almeida',)","('Adán José Corcho Fernández',)","('Amauri da Silva Barros', 'Marco Aurelio Soares Souto', 'Krerley Irraciel Martins Oliveira')","O fato de que o problema de Neumann possui solução única quando estudo em adequados espaços de Holder, nos permite resolver problemas elípticos até agora tratados com dados iniciais infinitamente diferenciáveis. De posse da existência e da unicidade da solução do problema de Neumann, encontra-se uma função que se anula na fronteira do conjunto onde esta função está definida e cujo divergente é igual a uma função dada. Esta ultima afirmação nos permite determinar um difeomorfismo que preserva a fronteira e tal que o determinante da diferencial é igual a uma função inicial. A partir daí, dados um domínio limitado do espaço euclidiano de dimensão n e duas n-formas tais que suas funções coeficientes são positivas, então, sob algumas hipóteses de regularidade, existe um difeomorfismo definido nesse domínio tal que o pull-back de uma das formas por esse difeomorfismo é proporcional à segunda forma. A constante de proporcionalidade vem dada pelo quociente das integrais das formas, calculadas em todo o domínio. O resultado acima pode ser escrito em uma forma mais analítica. Após essa reformulação, verifica-se que o mesmo é uma conseqüência do resultado descrito a seguir. Dados um domínio limitado e uma função positiva definida no fecho deste de forma tal que a integral da mesma neste domínio seja igual ao volume do mesmo, então, adicionando algumas hipóteses de regularidade, existe um difeomorfismo tal que, para todo ponto do interior do conjunto, o determinante da derivada desse difeomorfismo é igual à função dada. Além disso, esse difeomorfismo preserva pontualmente a fronteira do conjunto. Como conseqüência podemos construir difeomorfismos que preservam volume com valor de fronteira dado.","","('Análise funcional', 'Equações elípticas')","Matemática","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/1055","2007-02-15","https://www.repositorio.ufal.br/bitstream/riufal/1055/1/Dissertacao_Julio_Cesar_2007.pdf","",""
"Computação gráfica","https://www.repositorio.ufal.br/handle/riufal/1033","Campus A.C. Simões","Instituto de Matemática","Dissertação","Estabilidade de variações que preservam áreas em formas espaciais.","('Arlyson Alves do Nascimento',)","('Fernando Enrique Echaiz Espinoza',)","('Henrique Fernandes de Lima', 'Marcos Petrucio de Almeida Cavalcante')","O objetivo desta dissertação é estudar as hipersuperfícies compactas sem bordo e imersas em formas espaciais com Sr+1 / S1 constante, onde Sr+1 é a (r + 1)-ésima função simétrica das curvaturas principais. Tais hipersuperfícies são os pontos críticos de um problema variacional que preserva área. Demonstraremos que tais imersões são r-estáveis se, e somente se, elas forem hipersuperfícies totalmente umbílicas.","In this dissertation, we deal with compact hypersurfaces without boundary immersed in space forms such that Sr+1/S1 is constant. They are critical points for an area-preserving variational problem. We show that they are r-stable if and only if they are totally umbilical hypersurfaces.","('R-ésima curvatura média', 'R-estáveis', 'Variações que preservam área', 'Rth mean curvatures', 'R-stability', 'Area-preserving variation')","Matemática","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/1033","2009-04-23","https://www.repositorio.ufal.br/bitstream/riufal/1033/1/Dissertacao_ArlysonAlvesdoNascimento_2009.pdf","Stability of área-preserving variations in space forms.",""
"Computação gráfica","https://www.repositorio.ufal.br/handle/riufal/1038","Campus A.C. Simões","Instituto de Matemática","Dissertação","Estados de equilíbrio","('Márcio Henrique Batista da Silva',)","('Krerley Irraciel Martins Oliveira',)","('Marcelo Miranda Viana da Silva', 'Ali Tahzibi')","Provaremos a existência de Estados de equilíbrio, incluindo medidas de entropia máxima, para uma classe robusta (aberta) de transformações expansoras e nãouniformemente expansoras sobre uma variedade compacta e conexa.","We prove existence of Equilibrium states, including measures of maximal entropy, for a robust (open) class of expanding and non-uniformly expanding maps on compact and connect manifolds","('Teoria ergódica', 'Estados de equilíbio', 'Não-uniformemente expansor', 'Ergodic theory', 'Equilibrium states', 'Non-uniformly')","Sistemas Dinâmicos","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/1038","2005-12-08","https://www.repositorio.ufal.br/bitstream/riufal/1038/1/Estados%20de%20equil%c3%adbrio.pdf","Equilibrium states",""
"Computação gráfica","https://www.repositorio.ufal.br/handle/riufal/1021","Campus A.C. Simões","Instituto de Matemática","Dissertação","Aproximação isotópica suave de curvas e superfícies implícitas.","('Leonardo de Oliveira Carvalho',)","('Adelailson Peixoto da Silva',)","('Thomas Maurice Lewiner', 'Vinicius Moreira Mello')","Esta dissertação contém um estudo a respeito de curvas planas e superfícies. São vistas as duas formas mais usuais de se definirem estes elementos: a definição paramétrica e a implícita, com ênfase nesta última. São analisadas algumas formas de representação de curvas planas e superfícies, o que vem a ser uma tarefa relativamente simples ao se utilizar a definição paramétrica, porém com a definição implícita isto exige um maior número de operações. São apresentados alguns métodos para encontrar aproximações de curvas e superfícies definidas implicitamente que mantenham a sua topologia e que geram objetos suaves o suficiente. Isto é feito basicamente subdividindo-se o plano (respectivamente o espaço), que é utilizado para aproximar a curva (respectivamente a superfície) de forma linear por partes, e então subdivide-se essa aproximação para que o resultado seja suave. No caso das superfícies a saída é uma malha triangular. São realizados também tratamentos para aumentar a qualidade desta malha.","This dissertation contains a study about plane curves and surfaces. The two most common way to define this elements are reviewed: the parametric and the implicit definition, with emphasis on the latter. An analysis of some methods to represent plane curves and surfaces is made. One notices that this job is relatively simple when the parametric definition is used, however with the implicit definition this requires a larger number of operations. This works also presents some methods to find approximations of curves and surfaces implicitly defined that preserves the topology and that generate objects smooth enough. This is achieved basically by a subdivision of the plane (respectivelly the space), which is used to find a piecewise linear approximation of the curve (respectivelly the surface), then this approximation is subdivided to make the result smooth. In the case of surfaces the output is a triangular mesh. Some treatments are also made to improve the quality of the mesh.","('Superfícies implícitas', 'Curvas implícitas', 'Aproximação isotópica', 'Implicit curves', 'Implicit surfaces', 'Isotopic approximation')","Matemática","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/1021","2008-12-05","https://www.repositorio.ufal.br/bitstream/riufal/1021/1/Dissertacao_LeonardodeOliveiraCarvalho_2008.pdf","Smooth isotopic approximation of implicit curves and surfaces",""
"Computação gráfica","https://www.repositorio.ufal.br/handle/riufal/1035","Campus A.C. Simões","Instituto de Matemática","Dissertação","Aproximações de funções preservando formas simpléticas","('Thiago Fontes Santos',)","('Krerley Irraciel Martins Oliveira',)","('Jairo da Silva Bochi', 'Leonardo Magalhães Macarini')","Mostraremos que é possível aproximar um difeomorfismo simplético com derivada contínua por um difeomorfismo simplético, infinitamente diferenciáveis, sobre uma variedade simplética compacta. Além disso, provamos o Teorema de Darboux e Moser.","","('Difeomorfismo simplético', 'Variedades simpléticas', 'Aplicações que preservam volume', 'Symplectic diffeomorphism', 'Symplectic manifold', 'Functions preserving symplectic volume')","Matemática","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/1035","2006-12-21","https://www.repositorio.ufal.br/bitstream/riufal/1035/1/Dissertacao_Thiago_Fontes_2007.pdf","Approaches of functions preserving symplectic forms of volumes",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/9541","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Otimização na seleção de alvos em uma interceptação telefônica","('Larissa Artemis Luna Monteiro',)","('Rian Gabriel Santos Pinheiro',)","('André Luiz Lins de Aquino', 'Bruno Costa e Silva Nogueira')","Neste trabalho foi proposta uma forma de modelar os relacionamentos entre membros de um organização criminosa (ORCRIM) que possuem autorização judicial para quebra de sigilo telefônico e dados cadastrais. A motivação para tal proposta veio durante a Operação Flashback I, na qual foram percebidos diversas chamadas duplicadas provocadas pela forte interação entre os alvos interceptados, o que leva ao desperdício de recursos humanos (tempo) e computacionais (como o armazenamento das chamadas no servidor, a alocação do canal que desvia a chamada telefônica para agência, etc). A fim de minimizar tais efeitos, os relacionamentos entre os indivíduos monitorados foram representados usando grafos a partir dos extratos reversos fornecidos pelas operadoras de telefonia. Na modelagem, os vértices dos grafos representam os interlocutores e as arestas representam as chamadas efetuadas. Cada aresta contém um peso que representa o total de horas das chamadas dos indivíduos que se comunicaram. A partir do grafo de relacionamento, foi utilizada uma variação do problema de cobertura de vértices ao grafo para obter a sugestão de um conjunto de indivíduos a serem monitorados no ciclo de interceptação seguinte. Esta variante, conhecida como k-cobertura de vértice máxima, tem como entrada um grafo ponderado e um inteiro k, o objetivo do problema é encontrar a k-cobertura (subconjunto com k vértices) que maximize a soma dos pesos das arestas. Assim, considerando que este problema é NP-completo, não é conhecido um algoritmo que resolva este problema em tempo polinomial, porém, há estratégias que o fazem em tempo viável. Neste trabalho, foi projetada uma solução a partir da formulação matemática de programação linear inteira. Com a solução proposta, foi possível encontrar soluções ótimas em instâncias reais e sintéticas (até 50 vezes maior que as reais) com um baixo custo computacional. Portanto, de maneira sucinta, as contribuições deste trabalho incluem (i) um modelo matemático para a seleção de alvos a serem monitorados, (ii) uma forma de quantificar numericamente quanto da rede formada pela organização criminosa e seus interlocutores está sendo acompanhada e (iii) um algoritmo de que maximize o peso da k-cobertura de vértices do grafo formado pelos indivíduos monitorados e seus interlocutores, cujo objetivo é sugerir indivíduos a serem monitorados no ciclo de interceptação seguinte.","In this study, a way to model the relations between members of a criminal organization who have judicial authorization to break telephone secrecy and registration data was proposed. The motivation for this proposal came during Operation Flashback I, in which several duplicate calls were noticed caused by the strong interaction between the intercepted targets, which leads to a waste of human (time) and computational resources (such as the storage of calls on the server, the allocation of the channel that diverts the telephone call to the branch, etc.). For the purpose of minimize such effects, the relation between monitored individuals were represented using graphs from reverse extracts provided by telephone operators. In the modeling, the vertices of the graphs represent the interlocutors and the edges represent the calls made. Each edge contains a weight that represents the total hours of calls from individuals who communicated. From the relation graph, a variation of the problem of coverage of vertices to the graph was used to obtain the suggestion of a set of individuals to be monitored in the following interception cycle. This variant, known as k-maximum vertex coverage, takes as input a weighted graph and an integer k, the objective of the problem is to find the k-coverage (subset with k vertices) that maximizes the sum of the edge weights. Therefore, considering that this problem is NP-complete, an algorithm that solves this problem in polynomial time is not known, however, there are strategies that do it in viable time. In this work, a solution was designed based on the mathematical formulation of integer linear programming. With the proposed solution, it was possible to find optimal solutions in real and synthetic instances (up to 50 times larger than the real ones) with a low computational cost. Accordingly, succinctly, the contributions of this work include (i) a mathematical model for the selection of targets to be monitored, (ii) a way to numerically quantify how much of the network formed by the criminal organization and its interlocutors is being monitored and (iii) ) an algorithm that maximizes the weight of the k-coverage of vertices of the graph formed by the monitored individuals and their interlocutors, whose objective is to suggest individuals to be monitored in the following interception cycle.","('Programa linear interna (PLI)', 'Interceptação telefônica', 'Criminofísica', 'Modelos de redes', 'Método simplex', 'Cobertura de vértices', 'Thelephone interception', 'Criminophysics', 'Criminal organizations', 'Graphs', 'Vertex cover', 'Integer linear programming')","Engenharia de Software","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/9541","2022-02-22","https://www.repositorio.ufal.br/bitstream/123456789/9541/1/Otimiza%c3%a7%c3%a3o%20na%20sele%c3%a7%c3%a3o%20de%20alvos%20em%20uma%20intercepta%c3%a7%c3%a3o%20telef%c3%b4nica.pdf","",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/9735","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Modelagem dinâmica e estática do braço robótico UR5","('Valdir de Souza Júnior',)","('Erick de Andrade Barboza',)","('Thiago Damasceno Cordeiro', 'João Raphael Souza Martins')","Existe um grande impedimento no trabalho conjunto entre academia e indústria a respeito de produções envolvendo manipuladores robóticos, pois os detalhes físicos de um robô não são facilmente disponibilizados, inviabilizando a aplicação de novas tecnologias na indústria. Esse trabalho produz um modelo matemático de um robô para viabilizar uma maior aproximação entre academia e indústria. É descrito o procedimento para realizar uma análise cinemática e dinâmica de um braço robótico de 6 graus de liberdade. Foi escolhido como estudo de caso o Manipulador Robótico UR5, desenvolvido pela Universal Robots, que é um manipulador muito presente na indústria e que possui recursos que o permite trabalhar colaborativamente com seres humanos. Durante a análise, foram escolhidos os parâmetros de Denavit-Hartenberg para representar a construção do Manipulador Robótico, e a equação de Euler-Lagrange é utilizada para derivar a equação de dinâmica. Utilizando técnicas de otimização não lineares, é definido um controlador proporcional e derivativo para controlar o robô. A fim de validar a modelagem é elaborada uma trajetória, e são elaborados testes sendo executados em malha aberta e em malha fechada utilizando um controlador.","There is a great impediment in the joint work between academy and industry regarding works involving robotic manipulators, because the physical details of the robot are not easily available, making it difficult to apply new technologies in the industry. This work produces a mathematical model for a robot to enable a closer relationship between the academy and industry. It is described the procedure to perform kinematic and dynamic analysis of a robotic arm with 6 degrees-of-freedom. The UR5 Robotic Manipulator, developed by Universal Robots, was chosen as a case study, which is a manipulator very present in the industry and has resources that allow it to work collaboratively with human beings. During the analysis, the DenavitHartenberg parameters were chosen to represent the construction of the Robotic Manipulator, and the Euler-Lagrange equation is used to derive the dynamics equation. Using nonlinear optimization techniques, a proportional and derivative controller is defined to control the robot. In order to validate the modeling, a trajectory was elaborated, and tests were elaborated and executed in open loop and closed loop using a controller.","('Modelagem matemática', 'Robótica', 'UR5 (Manipulador robótico)', 'Robotics', 'Robot Manipulator', 'Euler-Lagrange')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/9735","2021-01-22","https://www.repositorio.ufal.br/bitstream/123456789/9735/1/Modelagem%20din%c3%a2mica%20e%20est%c3%a1tica%20do%20bra%c3%a7o%20rob%c3%b3tico%20UR5.pdf","Dynamic and Static Modeling of the UR5 Robotic Arm",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/9421","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","SLAM com associação de dados conhecidos: uma aplicação usando EKF e mapa com grade de ocupação","('Alan Pereira da Silva',)","('Leonardo Viana Pereira',)","('André Luiz Lins de Aquino', 'Heitor Judiss Savino')","Localização e mapeamento simultâneos (SLAM) tem sido um tópico de muita pesquisa nas últimas duas décadas nas comunidades de visão computacional e robótica, e recentemente recebeu a atenção de empresas de alta tecnologia. As técnicas de SLAM criam um mapa de um ambiente desconhecido e localizam o robô nesse mapa, com um forte foco na operação em tempo real. Entre as diferentes modalidades de sensores, as câmeras são baratas e fornecem informações ricas do ambiente que permitem um reconhecimento local robusto e preciso. Portanto, as soluções visuais SLAM, nas quais o sensor principal é uma câmera, são de grande interesse. Este trabalho apresenta uma implementação de localização e mapeamento simultâneo (SLAM) baseado no filtro de Kalman estendido (EKF). Para a implementação foi utilizada a linguagem de programação python, o conjunto de bibliotecas e ferramentas do robot operating system (ROS) e a biblioteca de visão computacional OpenCV. O trabalho foi desenvolvido no simulador de código aberto Gazebo, onde criamos um ambiente para o robô, simulamos o robô nesse ambiente, e então construímos um mapa desse ambiente. O resultado foi comparado com o mapa original e considerado relativamente preciso. O mapa resultante mostra algumas imprecisões, mas a forma geral é aceitável.","Simultaneous location and mapping (SLAM) has been a topic of much research over the past two decades in the computer vision and robotics communities, and has recently received the attention of high-tech companies. SLAM techniques create a map of an unknown environment and locate the robot on that map, with a strong focus on real-time operation. Among the different sensor modalities, cameras are inexpensive and provide rich information of the environment that allows for robust and accurate local recognition. Therefore, visual SLAM solutions, in which the main sensor is a camera, are of great interest. This work presents an implementation of simultaneous location and mapping (SLAM) based on the extended Kalman filter (EKF). For the implementation, the programming language python, the set of libraries and tools of the robot operating system (ROS) and the computer vision library OpenCV were used. The work was developed in the open source simulator Gazebo, where we created an environment for the robot, simulated the robot in that environment, and then built a map of that environment. The result was compared with the original map and found to be relatively accurate. The resulting map shows some inaccuracies, but the overall shape is acceptable.","('SLAM', 'Python (Linguagem de programação)', 'Visão computacional', 'Extended Kalman Filter (EKF)', 'Robótica móvel', 'Python (Programming language)', 'Computer vision', 'Mobile robotics')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/9421","2021-09-23","https://www.repositorio.ufal.br/bitstream/123456789/9421/1/SLAM%20com%20associa%c3%a7%c3%a3o%20de%20dados%20conhecidos%3a%20uma%20aplica%c3%a7%c3%a3o%20usando%20EKF%20e%20mapa%20com%20grade%20de%20ocupa%c3%a7%c3%a3o.pdf","SLAM with known data association: An application using EKF and occupancy grid map",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/9095","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","A proposet network topology for low cost scenarios in a large scale network within a smart city","('Abigail Musa',)","('Rodrigo José Sarmento Peixoto',)","('Thiago Damasceno Cordeiro', 'Davi Bibiano Brito')","Este estudo tem como objetivo explorar algumas das diferentes tecnologias e topologias de rede que podem ser usadas para gerenciar muitos nós em uma cidade inteligente. Além disso, o estudo se concentrou mais naqueles que ofereciam baixos custos. O estudo procura responder à pergunta de pesquisa “Qual é a topologia proposta mais adequada para cenários de baixo custo em uma cidade inteligente? O objetivo aqui é indicar as várias topologias disponíveis, compará-las e contrastá-las, determinando o melhor para alguns cenários muito específicos. Desde o advento da IoT, as pessoas sempre tiveram que escolher a melhor topologia adequada para um determinado conjunto de nós, de modo a alavancar a comunicação entre eles e reduzir custos. Com a evolução da IoT, mais topologias foram criadas, algumas foram feitas para casos muito específicos, enquanto outras foram mais generalizadas. Nos últimos anos, houve ondas constantes dessas topologias usadas em vários casos em uma configuração de cidade inteligente. Por esse motivo, pesquisadores e engenheiros de sistemas embarcados realizaram vários estudos analisando diferentes aspectos das topologias de rede, como a faixa de comunicação, o número máximo de nós, as taxas de transmissão e recepção de dados e assim por diante, mas uma coisa que não foi estudada é se existe ou não um superior a todos os outros em termos de eficácia. Este estudo incluirá uma pesquisa aprofundada sobre as topologias de rede, seus recursos e os contrastes entre elas. Serão apresentados cenários de casos de uso específicos, nos quais será necessário empregar a técnica de topologia mais abrangente para ajustar-se ao aplicativo.","This study aims to explore some of the different network technologies and topologies that can be used tomanage many nodes in a smart city. In addition, the study focused more on those that offered low costs. The study seeks to answer the research question “ What is themost adequate proposed topology for low costs scenarios in a smart city? ” The goal here is to state the various topologies available, compare and contrast them, thereby ascertaining the best for some very specific scenarios. Since the advent of IoT, people have always had to choose the most suitable topology for a given set of nodes, so as to leverage the communication between them and cut down costs. With the evolution of IoT, more topologies have been created, some were made for very specific cases while others were more generalised. There have been constant waves of these topologies over the last few years used in several cases in a smart city setup. Because of this, researchers and embedded systems engineers have performed numerous studies analysing different aspects of network topologies such as the communication range, the maximum number of nodes, the transmission and reception data rates and so on, but one thing that hasn’t been studied is whether or not there’s one that is superior to all the others in terms of efficacy. This study is going to include an in depth research into the network topologies, their features, and the contrasts between them. Specific use case scenarios will be given, whereby it will necessary to employ the most encompassing topology technique to fit the application.","('Redes de computadores', 'Topologias de rede', 'Internet das coisas', 'Sistemas embarcados (Computadores)', 'Computer networks', 'Network topologies', 'Internet of Things', 'Embedded systems (Computers)')","Sistemas de Computação","eng","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/9095","2020-03-06","https://www.repositorio.ufal.br/bitstream/123456789/9095/1/A%20proposet%20network%20topology%20for%20low%20cost%20scenarios%20in%20a%20large%20scale%20network%20within%20a%20smart%20city.pdf","","('Lucas Benevides Viana de Amorim',)"
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/10322","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Previsão de geração fotovoltaica a partir de dados meteorológicos utilizando rede LSTM","('Ícaro Gabriel Paiva Bastos',)","('Ícaro Bezerra Queiroz de Araújo',)","('Erick de Andrade Barboza', 'Davi Bibiano Brito', 'Tiago Figueiredo Vieira')","A natureza estocástica e não linear das condições climáticas, tais como radiação solar, temperatura ambiente, velocidade do vento, influencia diretamente a geração de energia fotovoltaica. Além disso, a estimação da quantidade de energia gerada é de suma importância para a qualidade da produção, podendo evitar problemas na rede elétrica. Com base nessa problemática, este trabalho apresenta uma aplicação de redes LSTM (Long Short-Term Memory) para previsão de dados de geração (potência) em painéis fotovoltaicos a partir da utilização de dados meteorológicos. Os dados foram coletados a partir de uma estação solarimétrica de baixo custo próxima a usina de produção. As informações obtidas pela estação incluem: radiação solar, temperatura dos painéis, temperatura ambiente, umidade, velocidade do vento, quantidade de chuva, tensão e corrente. Estas informações são utilizadas para alimentar a rede neural cuja função é a predição de um vetor correspondente aos próximos segundos de potência gerado pelos painéis solares da usina de produção. Os resultados mostraram que a rede LSTM apresenta bons valores de estimação com erros médio absolutos baixos.","The stochastic and nonlinear nature of some meteorological factors, such as the local solar radiance, ambient temperature, wind speed, directly influence photovoltaic energy generation. Furthermore, estimating the produced energy amount is fundamentally important to production quality, which can avoid problems on the electrical network. Based on this problem, this article presents an application of LSTM (LongShort-Term Memory) networks for forecasting generation (power) data on photovoltaic panels using meteorological data. The data were collected from a low-cost solarimetric station close to the production plant. The obtained information includes solar radiance, panels temperature, ambient temperature, humidity, wind speed, rain amount, voltage, and current. It is used to feed a neural network, whose function is the prediction of the next five seconds of power produced by the solar panels. Results show that the LSTW Network presents good estimation values, having a low mean absolute error for each second.","('Energia solar fotovoltaica', 'Long Short-Term Memory', 'Curto prazo', 'Photovoltaic Solar Energy', 'LSTM', 'Short-term Forecast')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/10322","2020-07-24","https://www.repositorio.ufal.br/bitstream/123456789/10322/1/Previs%c3%a3o%20de%20gera%c3%a7%c3%a3o%20fotovoltaica%20a%20partir%20de%20dados%20meteorol%c3%b3gicos.pdf","",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/12378","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Prevendo a flutuação de preço do Ether através da análise de sentimento do twitter","('Rodolfo Wagner Vieira Leite Moreira',)","('Bruno Almeida Pimentel',)","('Luís Felipe Vieira Silva', 'Eduardo Moraes de Miranda Vasconcellos')","As criptomoedas, tecnologia inovadora que tem ganhado bastante adesão e visibilidade, ainda são cercadas de desconfianças, mas, à medida que o impacto social e econômico das criptomoedas continua a crescer rapidamente, o número de artigos em sites de notícias, reportagens televisivas e comentários nas redes sociais também crescem. Com a popularização e crescimento da rede social Twitter, as opniões e sentimentos expressos em forma de tweets, representam uma grande quantidade de dados que podem ser estudados. Neste trabalho, analisamos tweets com o objetivo de estabelecer se o sentimento destes é uma ferramenta útil para previsão de flutuações de preços numa criptomoeda chamada ETH. O conjunto de dados é constituído por 34.558 tweets recolhidos utilizando a biblioteca TWINT que consiste em tweets contendo o sinal ""ETH"". Os tweets recolhidos são convertidos em pontuações que representam sua positividade/negatividade, isto é feito por uma ferramenta de análise chamada VADER. A pontuação dos tweets é então somada para representar um sentimento coletivo por hora, funcionando como uma variável de predição para o preço da criptomoeda. Utilizamos em nossos experimentos técnicas de aprendizagem supervisionada treinando Random Forest e para efeitos de comparação, treinamos também modelo utilizando Regressão Linear Múltipla.","Cryptocurrencies, an innovative technology that has gained a lot of traction and visibility, are still surrounded by mistrust, but as the social and economic impact of cryptocurrencies continues to grow rapidly, the number of articles on the web, television reports, and comments on social networks are also growing. With the popularization and growth of the social network Twitter, the opinions and sentiments expressed in the form of of tweets represent a large amount of data that can be studied. In this paper, we analyze tweets with the aim of establishing whether their sentiment is a useful tool for predicting price fluctuations in a cryptocurrency called ETH. The dataset consists of 34,558 tweets collected using the TWINT library, which consists of tweets containing the ""ETH""sign. The collected tweets are converted into scores that represent positivity/negativity of the tweet, this is done by an analysis tool called VADER. The scores of the tweets are then summed up to represent a collective sentiment per hour, acting as a predictor variable for the price of cryptocurrency price. We use in our experiments supervised learning techniques training a Random Forest Classifier and for comparison purposes, we also trained a model using Multiple Linear Regression.","('Criptomoeda', 'ETH (Ether)', 'Aprendizado de máquina', 'Análise de sentimento', 'Twitter', 'Valence aware dictionary and entiment reasoner and humans apart (VADER)', 'Cryptocurrencies', 'Machine learning', 'Sentiment analysis')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/12378","2022-12-02","https://www.repositorio.ufal.br/bitstream/123456789/12378/1/Prevendo%20a%20flutua%c3%a7%c3%a3o%20de%20pre%c3%a7o%20do%20Ether%20atrav%c3%a9s%20da%20an%c3%a1lise%20de%20sentimento%20do%20twitter.pdf","Forecasting Ether price fluctuations by twitter sentiment analysis",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/1766","Campus A.C. Simões","Instituto de Computação","Dissertação","Visualização de matrizes de covariância complexas: uma aplicação em dados PolSAR","('Antônio Marcos Larangeiras Lima',)","('Alejandro César Frery Orgambide',)","('Eliana Silva de Almeida', 'Leonardo Melo de Medeiros')","O monitoramento do nosso planeta através de sensores imageadores pode ser empregado para inspecionar: desmatamentos e desertificação de florestas; o ciclo da água; crescimento urbano entre outras. Entre as tecnologias de sensoriamento remoto, PolSAR (Polarimetric Synthetic Aperture Radar) vem se destacando. O PolSAR possibilita o sensoriamento remoto em quase todas as condições meteorológicas. Cada célula de resolução na imagem PolSAR está associada a uma matriz de espalhamento complexa. Uma maneira, de caracterizar os dados PolSAR single-look é utilizar a matriz de covariância complexa. A matriz de covariância é de extrema importância em AnáliseMultivariada pois permite mensurar e avaliar o grau de dependência entre as variáveis que compõem o conjunto de dados. Este trabalho apresenta uma abordagem de visualização de dados multivariados para visualizar informações contidas em matrizes de covariância complexa. As informações sobre que tipo de região homogênea está contida na imagem PolSAR a ser estudada, pode ser obtida analisando a abordagem de visualização de dados fornecida neste trabalho. Para a validação da abordagem, aplicamos a nossa ferramenta em imagens PolSAR -não simuladas – sobre amostras homogêneas, ou seja, amostras que seguem uma determinada família de distribuição de probabilidade. Em seguida, a proposta foi aplicada em três alvos distintos, à saber: região desértica, região urbana e região aquática. Portanto, a abordagem de visualização implementada no R permite discriminar os alvos.","The monitoring of our planet through image sensors can be used to inspect: deforestation and desertification of forests; the water cycle; urban growth, among others. Among the technologies of remote sensing, PolSAR (Polarimetric Synthetic Aperture Radar) has been highlighting. The PolSAR enables remote sensing in almost all weather conditions. Each resolution cell in the PolSAR image is associated with a complex scattering matrix. One way to characterize the single-look PolSAR data is to use the complex covariance matrix. The covariance matrix is of extreme importance inMultivariate Analysis because it allows measure and evaluate the degree of dependence between the variables that compose the data set. This work presents a multivariate data visualization approach to visualize information contained in complex covariance matrices. The information aboutwhat type of homogeneous region is contained in the PolSAR image to be studied can be obtained by analyzing the data visualization approach provided in this work. For the validation of the approach, we applied our tool in non-simulated PolSAR images based homogeneous samples, i. e., samples that follow a certain of probability distribution. After that, the proposal was applied in three distinct targets, namely: a desertic region, a urban region and an aquatic region. Therefore, the implemented visualization approach in the R permits to discriminate the targets.","('Imagens PolSAR', 'Estatística multivariada', 'Visualização', 'PolSAR images', 'Multivariate statistics', 'Visualization', 'Effective dependence', 'Effective variance')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1766","2017-03-24","https://www.repositorio.ufal.br/bitstream/riufal/1766/1/Visualiza%c3%a7%c3%a3o%20de%20matrizes%20de%20covari%c3%a2ncia%20complexas%3a%20uma%20aplica%c3%a7%c3%a3o%20em%20dados%20PolSAR.pdf","Visualization of Complex Covariance Matrices: an application in PolSAR data","('Raydonal Ospina Martínez',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/5936","Campus A.C. Simões","Instituto de Computação","Dissertação","Validação de conformidades de usabilidade em ambientes virtuais de aprendizagem baseada em ontologias","('Dalgoberto Miquilino Pinho Júnior',)","('Ig Ibert Bittencourt Santana Pinto',)","('Patrick Henrique da Silva Brito', 'Edilson Ferneda')","Alguns problemas de usabilidade comumente identificados nos ambientes virtuais de aprendizagem são referenciados na literatura, no entanto precisamos pensar nas validações das funções pedagógicas para facilitar a usabilidade e o sucesso da constituição de uma comunidade virtual de aprendizagem diante do processo de ensino-aprendizagem. O presente trabalho apresenta um sistema de validação de conformidades de usabilidade em ambientes virtuais de aprendizagem baseada em ontologias que objetiva a automatizar tal processo. A ontologia elaborada mapeia as heurísticas de usabilidade em Ambientes Virtuais de Aprendizagem para representar o domínio. O agente valida as heurística de usabilidade. A página de questionário web viabiliza a interação com o usuário no levantamento da usabilidade pedagógica. Este trabalho estabelece, na forma de um sistema computacional, uma ferramenta de apoio às validações de usabilidade no intuito de garantir o máximo de heurísticas válidas conforme baseline definido como ideal.. O sistema proposto neste trabalho, não tem a pretensão de excluir a intervenção humana na validação da usabilidade assim como de eliminar a subjetividade da inspeção propriamente dita.","Some usability problems commonly identified in virtual learning environments are cited in the literature, however we need to think about the validation of pedagogical functions to facilitate the usability and success of the establishment of a virtual learning community on the process of teaching and learning. This paper presents a validation system in conformance usability virtual learning environments based on ontology that aims to automate this process. The ontology developed maps of usability heuristics in Virtual Learning Environments to represent the area. The agent validates the usability heuristics. The questionnaire web page enables the user interaction in the lifting of pedagogical usability. This work establishes, in the form of a computer system, a tool to support usability validation in order to ensure maximum heuristic baseline defined as valid as ideal. The system proposed in this paper do not purport to exclude human intervention in the validation of usability as well as to eliminate the subjectivity of the inspection itself.","('Usabilidade', 'Ambientes virtuais de aprendizagem', 'Ontologia', 'Usability', 'Virtual Learning Environments', 'Ontology')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/5936","2011-04-11","https://www.repositorio.ufal.br/bitstream/riufal/5936/1/Valida%c3%a7%c3%a3o%20de%20conformidades%20de%20usabilidade%20em%20ambientes%20virtuais%20de%20aprendizagem%20baseada%20em%20ontologias.pdf","Validation of compliace of usability in virtual envirinments based on ontology learning","('Rodrigo de Barros Paes',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/2500","Campus A.C. Simões","Instituto de Computação","Dissertação","Utilização da aprendizagem de máquina e seleção de atributos para o diagnóstico de ceratocone a partir de parâmetros biomecânicos da córnea","('Pedro Barreto Dantas',)","('Aydano Pamponet Machado',)","('Jorge Artur Peçanha de Miranda Coelho', 'Alberto Diniz Filho')","O presente estudo objetiva estudar a grande lacuna que ainda existe no diagnóstico precoce do ceratocone, uma vez que essa é uma doença com importantes repercussões na vida do paciente. Utilizamos a avaliação biomecânica do Corvis ST, onde são avaliados seis gráficos, e suas propriedades submetidas à avaliação a inteligência artificial, por meio da aprendizagem de máquina e seleção de atributos, a fim de criar um classificador que possa ajudar no diagnóstico.Utilizamos base de dados com 382 olhos normais e 192 olhos com ceratocone graus I ou II, todos avaliados por umúnico médico colaborador do estudo (R.A.J.) em uma clínica do Rio de Janeiro. Utilizamos o algoritmo Support Vector Machine associado a Backward Elimination, e conseguimos um resultado de área abaixo da curva ROC de 0.933, configurando um bom classificador.","The present study aims to study the great gap that still exists in the early diagnosis of keratoconus, since this is a disease with important repercussions in the life of the patient. We used the biomechanical evaluation of Corvis ST, where six graphs were evaluated, and their properties submitted to the analisys of artificial intelligence, through machine learning and selection of attributes, in order to create a classifier that can help achieve the diagnosis. We used a database of 382 normal eyes and 192 eyes with keratoconus grades I or II, all evaluated by a single study collaborator (R.A.J.) at a clinic in Rio de Janeiro. We used the Support Vector Machine algorithm associated with Backward Elimination, and we obtained an area result below the ROC curve of 0.933, setting up a good classifier.","('Inteligência artificial – Aplicações médicas', 'Aprendizagem de máquina', 'Doenças da córnea – Diagnóstico por imagem', 'Ceratocone – Diagnóstico por imagem', 'Keratoconus', 'Cornea', 'Refractive', 'Artificial inteligence', 'Machine learning', 'Ophtalmology')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/2500","2017-06-16","https://www.repositorio.ufal.br/bitstream/riufal/2500/1/Utiliza%c3%a7%c3%a3o%20da%20aprendizagem%20de%20m%c3%a1quina%20e%20sele%c3%a7%c3%a3o%20de%20atributos%20para%20o%20diagn%c3%b3stico%20de%20ceratocone%20a%20partir%20de%20par%c3%a2metros%20biomec%c3%a2nicos%20da%20c%c3%b3rnea.pdf","Use of machine learning and selection of attributes for the diagnosis of keratoconus from biomechanical parameters of the cornea","('João Marcelo de Almeida Gusmão Lyra',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/1729","Campus A.C. Simões","Instituto de Computação","Dissertação","Utilizando o processo automático de descoberta de conhecimento para caracterização do perfil das submissões dos pesquisadores do Instituto Federal de Sergipe: um estudo de caso sobre dados do congresso Norte-Nordeste de pesquisa e inovação","('Fausto Bernard Melo Soares',)","('Aydano Pamponet Machado',)","('Evandro de Barros Costa', 'Silvano Alves Barbosa')","Em crescente desenvolvimento no Brasil, a atividade de pesquisa vem se tornando cada vez mais presente no cotidiano das instituições de ensino no país. Dessa maneira os Institutos Federais de Educação Ciência e Tecnologia têm adequado sua realidade para atender a essa demanda pela qual passa a sociedade. Isso porque, após a transformação ocorrida no ensino técnico e tecnológico no Brasil, por meio da conversão dos Centros Federais de Educação Tecnológica para Institutos Federais de Educação Ciência e Tecnologia, percebeu-se a necessidade de fortalecer o desenvolvimento da pesquisa nessas instituições, até então voltadas fortemente para a formação de mão de obra. Nesta senda, investimentos têm sido feitos pelo Governo Federal na promoção de programas de incentivo à pesquisa. No Instituto Federal de Sergipe (IFS), em específico, pode-se citar a aplicação de recursos em programas institucionais de importante elevo tais como o Programa Institucional de Bolsas de Iniciação Científica (PIBIC), Programa Institucional de Bolsas de Iniciação em Tecnologia e Inovação (PIBITI) e o Programa Institucional de Apoio a Pesquisa ao Técnico Administrativo (PPTA). Por conta disso, o presente trabalho, utilizando-se do Processo de Descoberta de Conhecimento (KDD) através do algoritmo de agrupamento de dados denominado x-means, propõe, mediante o uso da base de dados de avaliações das submissões de artigos no VI CONNEPI (Congresso Norte Nordeste de Pesquisa e Inovação), ocorrido no ano de 2011, um modelo para o perfil dos trabalhos submetidos nesse congresso pelos pesquisadores do Instituto Federal de Sergipe (IFS) e pelos demais pesquisadores dos Institutos Federais de Educação Ciência e Tecnologia de todo o país. O enfoque precípuo é que, através dos modelos obtidos, se realize uma análise comparativa a fim de mapear características dos pesquisadores dessas instituições e propor, assim, ações em auxílio à tomada de decisão por parte da gestão dessa atividade no IFS, realizada no atual momento pela Pró-Reitoria de Pesquisa e Inovação (PROPEX).","In ascending development in Brazil, research activity is becoming more common in everyday life of educational institutions in the country. This way the Federal Institute of Science and Technology Education has adequate its reality to attend this demand through which passes society. Because after the transformation that occurred by technical and technological education in Brazil, through the conversion of Federal Center of Technology Education to Federal Institute of Science and Technology Education, realized the need to strengthen the research development in institution, focused on the formation of labor. So the Federal Government made investments in encouraging research activities programs. In the Federal Institute of Sergipe (IFS) we can mention the application of resources in important institutional programs as the Institutional Program of Initiation Scholarships in Technology and Innovation (PIBIC) and the Institutional Program of Support to Activity Research of Administrative Technician (PPTA). So this dissertation, through of Knowledge-Discovery in Databases (KDD) by means of the clustering algorithm, x-means, proposes by using of the database of evaluations of submitted scientific paper to VI CONNEPI (VI North Northeast Research and Innovation Congress), ocurred in 2011, a model to profile of submitted scientific paper in this congress to researchers of IFS and other researchers of Federal Institute of Science and Technology Education in Brazil. The essential approach is that, through the obtained models, a comparative analysis is performed with the objective to map features of the researchers these institutions and propose actions to the aid to decision-making to IFS, performed by Pró-Reitoria de Pesquisa e Inovação (PROPEX).","('Pesquisa', 'Inovação', 'Algoritmos', 'Research', 'Innovation', 'Algorithms')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1729","2015-09-04","https://www.repositorio.ufal.br/bitstream/riufal/1729/1/Utilizando%20o%20processo%20autom%c3%a1tico%20de%20descoberta%20de%20conhecimento%20para%20caracteriza%c3%a7%c3%a3o%20do%20perfil%20das%20submiss%c3%b5es%20dos%20pesquisadores%20do%20Instituto%20Federal%20de%20Sergipe.pdf","Using the automatic process of knowlwdge discovery to characterite the profile of submissionsof the ifs researches : a case study on connepi",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/1826","Campus A.C. Simões","Instituto de Computação","Dissertação","Uso de algoritmos de aprendizagem de máquina e estratégias de seleção de atributos para otimizar a identificação de ceracotone a partir de propriedades biomecânicas da córnea","('Bruna Vieira Oliveira Carvalho Ventura',)","('Aydano Pamponet Machado',)","('Evandro de Barros Costa', 'Bruno Machado Fontes')","Objetivou-se com o presente estudo avaliar a performance do Ocular Response Analyzer (ORA) em diferenciar graus I e II de ceratocone de córneas normais usando cada um dos seus 41 parâmetros individualmente, o possível beneficio do uso conjunto de todos os parâmetros, e a influência da espessura corneal mais fina (ECF). Adicionalmente, investigar o uso de algoritmos de aprendizagem de máquina e estratégias de seleção de atributos para otimizar a identificação de formas precoce de ceratocone. Foram incluídos 68 olhos de pacientes com formas precoce de ceratocone (graus I e II) e 136 olhos normais de pacientes pareados pela idade. Todos os olhos tinham uma espessura corneal central entre 500 e 600 μm. A média de valores dos 41 parâmetros do ORA foi comparada entre os grupos, e entre os subgrupos criados utilizando como ponto de corte uma ECF de 500 μm. Calculou-se a área sob a curva do receiver operating characteristic (ASC) obtida por cada um dos 41 parâmetros isoladamente e por todos juntos ao separar os grupos. Os parâmetros foram estudados usando algoritmos de aprendizagem de máquina [máquina de vetores de suporte (MSV), árvore de decisão, rede neural de função de base radial e perceptron multicamadas] e estratégias de seleção de atributos (forward selection, backward elimination, e algoritmos genéticos). A performance dos algoritmos foi expressa através da sensibilidade, especificidade e acurácia obtidas usando testes de validação cruzada 10-fold. A maioria dos parâmetros teve uma média estatisticamente menor no grupo de ceratocone, apesar da grande sobreposição de valores entre os grupos. Vinte e dois parâmetros não foram influenciados pela ECF. Quatro parâmetros (p1area, p1area1, p2area e p2area1) obtiveram uma ASC maior que 0,900 ao serem usados isoladamente. O p2area atingiu a maior ASC individualmente (0,931). A ASC aumentou para 0,978 ao se analisar todos os parâmetros juntos. Dos algoritmos estudados, a MSV atingiu a melhor performance sem o uso de estratégias de seleção de atributos: sensibilidade de 86,8%, especificidade de 91,9% e acurácia de 90,3% ± 5,2%. Todos os algoritmos tiveram um melhor desempenho na identificação de formas precoce de ceratocone com o uso de estratégias de seleção de atributos. A maior sensibilidade, especificidade e acurácia obtida foi 94,1%, 95,6% e 95,1% ± 4,5%, respectivamente. Essa performance foi obtida pela associação da MSV e do algoritmo genético, através do uso de um subgrupo de 23 parâmetros do ORA: CRF, CH, aindex, p1area, p2area, aspect1, uslope2, dslope1, dslope2, w1, h2, mslew1, mslew2, slew1, slew2, p1area1, p2area1, uslope11, uslope21, dslope21, w11, path11 e path21. Em conclusão, quatro parâmetros do ORA foram os melhores para identificar graus I e II de ceratocone quando usados individualmente. O uso conjunto de todos os parâmetros melhorou a performance do exame. O uso de algoritmos de aprendizagem de máquina e estratégias de seleção de atributos otimizou a identificação de formas precoce de ceratocone.","The purpose of the present study was to evaluate the Ocular Response Analyzer’s (ORA’s) performance in differentiating grades I and II keratoconus from normal corneas using each of its 41 parameters individually, and to assess the effect of analyzing all parameters together and the influence of the corneal thinnest point (CTP). In addition, investigate the use of machine learning algorithms and feature selection search strategies to optimize mild keratoconus identification. This study included 68 eyes with mild keratoconus (grades I and II) and 136 healthy agematched control eyes. All eyes had a central corneal thickness between 500 and 600 μm. The mean value of the 41 ORA parameters were compared between the groups, and between the subgroups created based on a CTP greater or lower than 500 μm. The area under the receiver operating characteristic curve (AUC) when separating both groups was calculated for each of the 41 parameters independently and for all of the parameters together. The 41 parameters were assessed using machine learning algorithms [support vector machine (SVM), decision tree, radial basis function neural network, and multi-layer perceptron] and feature selection strategies (forward selection, backward elimination, and genetic algorithm search). The algorithms’ performance was expressed as the sensitivity, specificity and accuracy obtained on the 10-fold cross-validation tests. Most parameters had a statistically lower mean value in the keratoconus group, although there was a large measurement overlap between both groups. Twenty-two parameters were not influenced by the CTP. When analyzed individually, 4 parameters (p1area, p1area1, p2area, and p2area1) had an AUC greater than 0.900. The p2area was the parameter that achieved the largest AUC individually (0.931). The AUC increased to 0.978 when analyzing all parameters together. Of the machine learning algorithms, SVM achieved the best performance when no feature selection strategies were used: sensitivity of 86.8%, specificity of 91.9%, and accuracy of 90.3% ± 5.2%. All algorithms had a better performance in mild keratoconus detection with the use of feature selection strategies. The highest sensitivity, specificity, and accuracy attained were of 94.1%, 95.6%, and 95.1% ± 4.5%, respectively. This performance was achieved with a subset of 23 ORA parameters selected by associating SVM with the genetic algorithm. This subset of parameters consisted of CRF, CH, aindex, p1area, p2area, aspect1, uslope2, dslope1, dslope2, w1, h2, mslew1, mslew2, slew1, slew2, p1area1, p2area1, uslope11, uslope21, dslope21, w11, path11 and path21. In conclusion, four ORA parameters were the best for identifying grades I and II keratoconus when used individually. The combination of all parameters improved the exam’s performance. The use of machine learning algorithms and feature selection search strategies optimized ORA’s detection of mild keratoconus.","('Algorítmos computacionais', 'Ceratocone', 'Córnea -Biomecânica', 'Computational algorithms', 'Keratoconus', 'Cornea-Biomechanics')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1826","2013-11-04","https://www.repositorio.ufal.br/bitstream/riufal/1826/1/Uso%20de%20algoritmos%20de%20aprendizagem%20de%20m%c3%a1quina%20e%20estrat%c3%a9gias%20de%20sele%c3%a7%c3%a3o%20de%20atributos%20para%20otimizar%20a%20identifica%c3%a7%c3%a3o%20de%20ceracotone%20a%20partir%20de%20propriedades%20biomec%c3%a2nicas%20da%20c%c3%b3rnea.pdf","Construção automática de classificadores para a otimização da identificação de ceratocone a partir de propriedades biomecânicas da córnea.;Use of machine learning algorithms and feature selection search strategies to optimize keratoconus identification using corneal biomechanical properties","('João Marcelo de Almeida Gusmão Lyra',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/5514","Campus A.C. Simões","Instituto de Computação","Dissertação","O uso de controlabilidade estrutural na avaliação de disseminação de dados em redes veiculares","('Filipe Emanuel Silva Costa',)","('Raquel da Silva Cabral',)","('André Luiz Lins de Aquino', 'Eunice Palmeira da Silva')","As Redes Ad Hoc Veiculares (VANETs) estabelecem um novo paradigma na computação móvel, que consiste em possibilitar a comunicação sem fio entre os veículos. Este trabalho mapeou a topologia das VANETs em uma Rede Complexa para identificar nós influenciadores da rede. Para isso foi usada uma métrica de controlabilidade estrutural com a finalidade de avaliar a complexidade de controle das redes em intervalos temporais. A controlabilidade estrutural é uma métrica utilizada no contexto de Redes Complexas, sua finalidade é identificar vértices importantes para o controle de uma rede. Para a realização da avaliação, foram utilizados cinco cenários reais, sendo quatro cenários utilizando comunicação somente entre veículos (V2V) e um cenário utilizando comunicação de veículos para infraestruturas (V2I). A análise da controlabilidade nas redes veiculares foi executada de forma segmentada, permitindo avaliar cada momento da linha do tempo em particular. Conjuntamente, foi realizada uma análise de controlabilidade considerando diferentes raios de comunicação entre veículos, objetivando compreender a influência da topologia no controle das redes. A análise também foi realizada considerando um grafo agregado para cada cenário. Os resultados revelaram como se deu o comportamento de controle de cada cenário, considerando a evolução temporal da rede. Além disso, foi possível compreender que existem momentos em que a rede possui um melhor controle proporcionando um momento apropriado para disseminação de informação. À vista disso, foi constatado que para obter o controle total das redes aqui analisadas, é necessário alcançar cerca de 70% do total de nós da rede.","Vehicle Ad Hoc Networks (VANETs) establish a new paradigm in mobile computing, which is to enable wireless communication between vehicles. This work mapped the topology of VANETs in a Complex Network to identify nodes influencing the network. For this, a structural controllability metric was used in order to evaluate the complexity of network control at time intervals. Structural controllability is a metric used in the context of Complex Networks, its purpose is to identify important vertices for the control of a network. In order to carry out the evaluation, five real scenarios were used, four scenarios using communication between vehicles only (V2V) and a scenario using vehicle communication for infrastructures (V2I). The analysis of the controllability in the vehicular networks was executed in a segmented way, allowing to evaluate each moment of the particular time line. Together, a controllability analysis was performed considering different radii of communication between vehicles, aiming to understand the influence of the topology in the control of the networks. The analysis was also performed considering an aggregate graph for each scenario. The results revealed how the control behavior of each scenario occurred, considering the temporal evolution of the network. In addition, it was possible to understand that there are times when the network has a better control providing na appropriate moment for dissemination of information. In view of this, it was found that to obtain total control of the networks analyzed here, it is necessary to reach about 70% of the total nodes of the network.","('Redes complexas -Controlabilidade', 'Redes veiculares', 'VANETs', 'Disseminação de dados', 'Complex Networks -Controlability', 'Vehicle Networks', 'Data Dissemination')","Teoria da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/5514","2019-02-26","https://www.repositorio.ufal.br/bitstream/riufal/5514/1/O%20uso%20de%20controlabilidade%20estrutural%20na%20avalia%c3%a7%c3%a3o%20de%20dissemina%c3%a7%c3%a3o%20de%20dados%20em%20redes%20veiculares.pdf","The use of structural controlability in the evaluation of dissemination and data in vehicle networks",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/1605","Campus A.C. Simões","Instituto de Computação","Dissertação","Uso da transformada de Wavelet e técnicas de aprendizado de máquina para criação de modelo computacional de auxílio ao diagnóstico de ceratocone baseado em parâmetros biomecânicos da córnea","('Guilherme Barreto de Oliveira Ribeiro',)","('Aydano Pamponet Machado',)","('Renato Ambrósio Júnior', 'Evandro de Barros Costa')","O presente trabalho objetivou criar modelos computacionais de auxílio ao diagnóstico de ceratocone, utilizando um algoritmo de segmentação de borda, transformadas de wavelet e técnicas de aprendizagem de máquina, baseados em parâmetros biomecânicos da córnea derivados do CorVis ST. Foram incluídos 102 olhos normais, e 73 olhos com ceratocone grau I e II para o treinamento e validação dos modelos criados. Inicialmente foram estudados os 31 parâmetros originais do equipamento, para avaliar seu poder em separar os grupos de controle e pesquisa. Foi então utilizado o algoritmo Canny para segmentação das bordas das imagens selecionadas, para que 400 pontos centrais extraídos dessas imagens pudessem ser processados com as transformadas de wavelet e posteriormente com técnicas de aprendizado de máquina. O melhor resultado foi alcançado utilizando a transformada de Wavelet do tipo Haar e uma Rede Neural Multilayer Perceptron, alcançando a sensibilidade de 84.93%, uma especificidade de 89.22% e uma Area Under de ROC Curve (AUC) de 0.932. Conclui-se que os modelos desenvolvidos podem contribuir para tornar o diagnóstico de ceratocone mais precoce.","This study aimed to create computer models to aid the diagnosis of keratoconus using an edge segmentation algorithm, wavelet transforms and machine-learning techniques based on biomechanical parameters of the cornea derived from Corvis ST. 102 normal eyes, and 73 eyes with keratoconus grade I and II for training and validation of the models were included. Initially the 31 original equipment parameters were studied to assess its power in separating the control groups and research group. Then, it was used the Canny algorithm for edges segmentation of the selected images, so that 400 central points of these images could be processed with the wavelet transforms and later with machine learning techniques. The best result was achieved using the Haar wavelet transform and a Multilayer Perceptron Neural Network, reaching the sensitivity of 84.93%, a specificity of 89.22% and an Area Under the ROC Curve (AUC) of 0932. It concludes that the developed models can help make the diagnosis of early keratoconus.","('Córnea', 'Ceratocone -Diagnóstico', 'Biomecânica corneal', 'Diagnóstico por imagem', 'Keratoconus', 'Corneal biomechanics', 'Diagnostic Imaging')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1605","2015-11-27","https://www.repositorio.ufal.br/bitstream/riufal/1605/1/Uso%20da%20transformada%20de%20Wavelet%20e%20t%c3%a9cnicas%20de%20aprendizado%20de%20m%c3%a1quina%20para%20cria%c3%a7%c3%a3o%20de%20modelo%20computacional%20de%20aux%c3%ad%c2%adlio%20ao%20diagn%c3%b3stico%20de%20ceratocone%20baseado%20em%20par%c3%a2metros%20biomec%c3%a2nicos%20da%20c%c3%b3rnea.pdf","The use of Wavelet transform and learning machine techniques for the creation of a computational model to help keratoconus diagnosis based on biomechanical corneal parameters","('João Marcelo de Almeida Gusmão Lyra',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/3559","Campus A.C. Simões","Instituto de Computação","Dissertação","Uso de modelagem computacional, gamificação e PBL no processo de ensino e aprendizagem do protocolo de classificação de risco do sistema Manchester","('Alessandra Nascimento Pontes',)","('Evandro de Barros Costa',)","('Fábio Paraguaçu Duarte da Costa', 'Thiago José Matos Rocha')","No Brasil, a área de urgência e emergência é considerada pelo Ministério da Saúde (MS) um importante componente da assistência à saúde. Nos últimos anos nos deparamos com um aumento considerável na demanda por atendimentos de urgência e emergência, principalmente devido ao crescimento populacional e ao aumento do número de acidentes. Desde 2007 o Ministério da Saúde adotou o sistema Manchester, como protocolo padrão para classificação de risco e prioridade clínica em todo o sistema nacional de urgência e emergência, seja ele público ou privado. Dessa forma, o uso de meios facilitadores computacionais para o aprendizado do sistema de classificação de risco Manchester consiste em duas partes: Modelagem computacional do sistema Manchester em um modelo dinâmico; e uso de aprendizagem baseada em problemas PBL e gamificação para favorecer o aprendizado do sistema de classificação de risco. O modelo dinâmico possibilita simulação como meio de visualizar as etapas do funcionamento do protocolo, destacando os critérios-chave que justificam a classificação. Além de utilizar a Rede de Petri, uma técnica de modelagem que permite a representação de sistemas, utilizando como alicerce uma forte base matemática. O objetivo norteador foi produzir um game como cenário da Classificação de Risco do Protocolo Manchester para profissionais responsáveis pela triagem (médicos e enfermeiros), oferecer uma experiência da classificação o mais próximo da realidade possível. Sabe-se também que hoje, o acesso à informação é muito mais fácil, e a utilização da linguagem dos jogos para promover a aprendizagem torna o método de ensino mais lúdico e divertido. Conclui-se que, apesar da importância desse protocolo, através de uma revisão da literatura e de uma pesquisa semi-estruturada, a atual pesquisa constatou que o referido protocolo ainda não é abordado adequadamente na grade formativa dos cursos de enfermagem e medicina, delegando tal conhecimento para as experiências práticas dos estágios obrigatórios, ou do início da vida profissional.","In Brazil, the emergency and emergency area is considered by the Ministry of Health (MS) an important component of health care. In recent years, we have seen a considerable increase in the demand for emergency and emergency services, mainly due to the population growth and the increase in the number of accidents. Since 2007 the Ministry of Health has adopted the Manchester system as the standard protocol for risk classification and clinical priority throughout the national emergency and emergency system, be it public or private. Thus, the use of computational facilitators to learn the Manchester risk classification system consists of two parts: Computational modeling of the Manchester system in a dynamic model; and use of problem-based learning PBL and gamification to favor learning the system of risk classification. The dynamic model allows simulation as a means of visualizing the steps of the protocol operation, highlighting the key criteria that justify the classification. In addition to using the Petri Net, a modeling technique that allows the representation of systems, using as a foundation a strong mathematical base. The guiding objective was to produce a game as a scenario of the Manchester Protocol Risk Classification for professionals responsible for screening (doctors and nurses), offering a rating experience as close to reality as possible. It is also known that today, access to information is much easier, and the use of the language of games to promote learning makes the teaching method more playful and fun. It is concluded that, despite the importance of this protocol, through a review of the literature and a semi-structured research, the current research found that the protocol is not yet approached adequately in the nursing and medical training curriculum, delegating such knowledge of the practical experience of compulsory traineeships or the beginning of working life.","('Modelagem computacional', 'Gamificação', 'Aprendizagem baseada em problemas', 'Jogos interativos', 'Sistema Manchester (Protocolo)', 'Computational modeling', 'Gamification', 'Problem-based learning', 'Interactive Games', 'Manchester System (Protocol)')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/3559","2018-09-17","https://www.repositorio.ufal.br/bitstream/riufal/3559/1/Uso%20de%20modelagem%20computacional%2c%20gamifica%c3%a7%c3%a3o%20e%20PBL%20no%20processo%20de%20ensino%20e%20aprendizagem%20do%20protocolo%20de%20classifica%c3%a7%c3%a3o%20de%20risco%20do%20sistema%20Manchester.pdf","","('Patrick Henrique da Silva Brito',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/2311","Campus A.C. Simões","Instituto de Computação","Dissertação","Teste para verificação da hipótese de ruído branco utilizando teoria da informação","('Marcelo Queiroz de Assis Oliveira',)","('Alejandro César Frery Orgambide',)","('Osvaldo Aníbal Rosso', 'Juliana Gambini')","O nosso ponto de partida é o desejo de analisar se é viável verificar no plano (H £C), dentro de uma abordagem estatística, se sequências de observações são ruído branco. Na literatura encontramos diversos trabalhos que fazem isso de forma “ad hoc”, verificando se o ponto característico de uma sequência nesse plano é próximo ao ponto (1,0). Contudo, tal como afirma Bandt (2017), não encontramos análises detalhadas que permitam atribuir significância estatística a tais afirmações. Para elucidar essa questão, e diante da impossibilidade de contar com sequências infinitamente longas e que garantidamente sejam ruído branco, coletamos sequências de três fontes diferentes: duas físicas e uma algorítmica considerada de qualidade. Verificamos se é possível considerá-las ideais para os nossos fins. Analisamos a dispersão dos pontos característicos dessas sequências no plano (H £C) utilizando quatro fatores: o tamanho da sequência (N), o tamanho da palavra (D), o delay (¿) e a fonte geradora, observando a distância dos pontos característicos ao ponto de referência. Sugiram então evidências de que a fonte geradora seria umfator irrelevante para a análise. Com o intuito de consolidar essa possibilidade, aplicamos o teste de Kolmogorov-Smirnov a pares de sequências comparáveis, porém verificamos que apenas duas das fontes geradoras são realmente irrelevantes, as duas fontes físicas. Agrupamos, então os dados das fontes físicas e passamos a tratá-los como nossa referência, em seguida procuramos por regiões de confiança. Adotamos uma abordagem não-paramétrica por não termos nenhuma evidência teórica acerca da distribuição que segue a distância do ponto característico ao de referência quando é analisada uma sequência finita de ruído branco. Calculamos então os quantis, respeitados os fatores tamanho da sequência (N), tamanho da palavra (D) e delay (¿), que servem como regiões de confiança para o teste que deu origem a este trabalho. Concluímos a dissertação verificando que sequências produzidas por geradores aceitos pela comunidade geram pontos característicos dentro de regiões de confiança, enquanto que umgerador que foi descartado pelas estruturas que as suas sequências apresentam leva a pontos fora dessas mesmas regiões. Analisamos também sequências estacionárias e não estacionárias, e para as primeiras fazemos uma análise preliminar do poder do teste.","We want to verify if sequences of observations are white noise in the plane (H £C). In the literature, we find several works that do this in an “ad hoc” way, checking if the characteristic point of a sequence in that plane is close to the point (1,0). However, as Bandt (2017) states, we do not found detailed analyzes to assign statistical significance to such statements. To elucidate this question, and in the face of the impossibility of counting infinitely long sequences that are guaranteed to be white noise, we gather candidate sequences from three different sources: two physical and one algorithmic considered as a good source. We checked, if we may consider them ideals for our purposes. We analyze the dispersion of the characteristic points of these sequences in the plane (H £C) using four factors: the size of the sequence (N), the size of the word (D), the delay (¿) and the generating source, observing the distance from the characteristic points to the reference point. We observe that the generating source would be an irrelevant factor to the analyses. To verify this hipothesis, we applied the Kolmogorov-Smirnov test to pairs of comparable sequences, however we verify that only two sources are equivalents, the both physical. Therefore, we grouped the data from physical sources, and it became our groundtruth, then in sequence, we searched for trust regions. We adopted a non-parametric approach because we did not have no theoretical evidence about the distribution that follows the distance from the characteristic point to our groundtruth when a finite sequence of white noise candidate is analyzed. We then calculated the quantiles, respecting the factors sequence size (N), size of the word (D) and delay (¿), which serve as confidence regions for the test that gave rise to this work. We conclude the dissertation by verifying that sequences produced by community accepted generators generate characteristic points within confidence regions, while a generator that has been discarded by the structures that its sequences present leads to points outside these regions. We also applied the test to stationary and nonstationary sequences and, for the former, we make a preliminary assessment of the test power.","('Teoria da Informação', 'Geradores de números aleatórios', 'Processamento de dados -Testes teóricos', 'Matemática computacional – Testes estatísticos', 'Random number generators', 'Theoretical tests', 'Information theory', 'Statistical tests')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/2311","2017-11-09","https://www.repositorio.ufal.br/bitstream/riufal/2311/1/Teste%20para%20verifica%c3%a7%c3%a3o%20da%20hip%c3%b3tese%20de%20ru%c3%addo%20branco%20utilizando%20teoria%20da%20informa%c3%a7%c3%a3o.pdf","Test for verification of the white noise hypothesis using information theory","('Heitor Soares Ramos Filho',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/5878","Campus A.C. Simões","Instituto de Computação","Dissertação","A supervised learning approach to detect gender stereotype in online educational technologies","('Josmário de Albuquerque Silva',)","('Ig Ibert Bittencourt Santana Pinto',)","('Leonardo Brandão Marques', 'Sheyla Christine Santos Fernandes', 'Wayne Holmes')","Tecnologia educacional (Edtech) tem impactado o modo como aprendemos e ensinamos, por exemplo, melhorando o engajamento de alunos, reforçando a colaboração, aumentando a retenção de aprendizado e ajudando professores a criar e distribuir novos conteúdos. No entanto, pesquisadores destacam que questões relacionadas à igualdade de gênero, como os estereótipos de gênero, precisam ser abordadas para promover contextos de aprendizagem plurais e inclusivos. De fato, descobertas recentes mostram que os estereótipos afetam vários aspectos no processo de aprendizagem, por exemplo, desempenho, engajamento, confiança, auto-imagem e ansiedade. No entanto, para abordar essas questões, precisamos antecipadamente descobrir se uma dada tecnologia educacional é estereotipada ou não. Diante desse cenário, propomos uma abordagem baseada em classificadores de aprendizagem supervisionada para detectar estereótipos de gênero em ambientes educacionais online. O método consiste na coleta de pistas situacionais de ameaça de estereótipos, isto é, conteúdos textuais e esquemas de cores de páginas Web para desenvolver e validar um modelo preditivo de aprendizagem de máquina. Além disso, a fim de validar o problema e reunir mais informações sobre o impacto dos estereótipos de gênero em tais contextos, realizamos uma revisão sistemática para destacar evidências e destacar as descobertas entre diferentes tipos de tecnologias educacionais e nos últimos 20 anos. A revisão também mostra abordagens metodológicas ao longe desses anos e as limitações de tais estudos. Em relação aos modelos preditivos, nossa abordagem mostrou uma alta precisão na previsão de ameaças de estereótipos de gênero em ambientes online. Também implementamos a abordagem e a aplicamos às páginas Web de universidades que se destacam no ranking mundial e os resultados sugerem a presença de estereótipos masculinos nas mesmas. Discutimos esses achados e apresentamos uma agenda de pesquisa para sublinhar os pontos que carecem de uma atenção especial na investigação de estereótipos de gênero e tecnologias educacionais.","Educational Technology (Edtech) has impacted the way humans learn and teach, e.g., improving students’ engagement, bolstering collaboration, increasing learning retention, and assisting teachers in creating and delivering new contents. However, researchers have highlighted that issues related to gender equality like gender stereotypes need to be addressed in order to promote plural and inclusive learning settings. In fact, recent findings show stereotypes have impacted several aspects in the learning process, e.g., performance, engagement, confidence, self-image, and anxiety. However, to address those issues, we require in advance to find out whether a given educational technology is stereotyped. Given that scenario, we propose an approach based on supervised learning classifiers to detect gender stereotypes in online educational environments. The method consisted of gathering situational cues of stereotype threat, i.e., textual contents and color schemes from web pages to develop and validate a machine learning predictive model. In addition, in order to validate the problem and gather more information about the impact of gender stereotypes in such settings, we primarily performed a systematic review to highlight evidence in the field and summarized the findings among different types of educational technologies and their implications in the last 20 years. The review also shows methodological approaches used along with those years and the limitations of such studies. Regarding predictive models, our approach showed a high precision on predicting gender stereotype threat in online settings. We also implemented the approach and applied it towards top-ranked universities’ web pages and the results suggest the presence of male bias in such settings.We discuss those findings and present a research agenda to underline research points that should be concerned when investigating gender stereotypes and educational technologies.","('Tecnologia educacional', 'Identidade de gênero na educação', 'Estereótipos (Psicologia)', 'Educational technology', 'Gender identity in education', 'Stereotypes (Psychology)')","Ciência da Computação","eng","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/5878","2019-06-21","https://www.repositorio.ufal.br/bitstream/riufal/5878/1/A%20supervised%20learning%20approach%20to%20detect%20gender%20stereotype%20in%20online%20educational.pdf","Uma abordagem de aprendizagem supervisionado para detectar o estereótipo de gênero em tecnologias educacionais online","('Jorge Artur Peçanha de Miranda Coelho',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/5937","Campus A.C. Simões","Instituto de Computação","Dissertação","Um sistema evolutivo para alocação de serviços de acordo com o perfil dos funcionários","('Euzebio Lourenço da Silva',)","('Roberta Vilhena Vieira Lopes',)","('Mônica Ximenes Carneiro da Cunha', 'Marcus de Melo Braga')","O problema de alocação de serviços de acordo com o perfil dos funcionários pertencentes a uma determinada repartição de uma empresa, parece uma tarefa trivial, mas se analisada com mais cautela apresenta objetivos e restrições conflitantes, o que a torna bastante complexa. Para realizar esta alocação deve-se considerar: a limitação do número de funcionários da repartição, a heterogeneidade de formação e experiência dos funcionários, a existência de material para execução da tarefa, o tempo de execução do serviço, o tempo ocioso dos funcionários, etc. Existem no mercado alguns sistemas utilizados na industria, que se propõem a realizar a tarefa de alocação de serviços, utilizando abordagens computacionais tanto convencionais (grafos e programação matemática), como inteligentes (algoritmos de busca, redes neurais e algoritmo genético). Porém independente da abordagem adotada tais sistemas trabalham a alocação do serviço, não levando em consideração as características intrínsecas a unidade alocada para cada serviço, de modo a otimizar o trabalho a ser realizado. Esta dissertação apresenta a especificação de um sistema baseado em Computação Evolutiva, mais especificamente em uma variação do Algoritmo Genético de Holland, para auxiliar o setor de manutenção da Coordenação de Gestão de Tecnologia de Informação, podendo ser expandido para toda Universidade, na tarefa de designar um profissional capacitado ao tipo de problema apresentado por um computador pertencente ao acervo computacional do Instituto de Ciências Humanas, Comunicação e Artes da Universidade Federal de Alagoas.","The problem of service allocation according to the profile of employees that belonging to a particular division of a company seems a trivial task, but if analyzed more cautiously it presents some conflicting objectives and constraints, which makes it very complex. To accomplish this allocation should be considered: the maximum number of employees in the division, the staff heterogeneity of training and experience, if there is enough material to accomplish the job, the time needed do finish the service, the employee’s idle time, etc. There are on the market some systems used by the industry, they propose to allocate services using both computational approaches the conventional ones (using graphs and mathematical programming) an the intelligent ones (search algorithms, neural networks and genetic algorithms). But regardless of the adopted approach this systems do not take into account the allocated unit intrinsic characteristics for each service, to optimize the realized work. This paper presents the specification of a system based on evolutionary computation, more specifically on a variation of Holland’s Genetic Algorithm, to assist the maintenance section of the Coordenação de Gestão e Tecnologia da Universidade Federal de Alagoas, and can be expanded to all the university, in the task to designate a skilled professional to fix a problem presented by a computer owned by the Instituto de Ciências Humanas, Comunicação e Artes da Universidade Federal de Alagoas.","('Algoritmos genéticos', 'Alocação de serviços', 'Serviços -Otimização', 'Genetic Algorthm', 'Service Allocation', 'Services -Optimization', 'Job Scheduling')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/5937","2013-12-19","https://www.repositorio.ufal.br/bitstream/riufal/5937/1/Um%20sistema%20evolutivo%20para%20aloca%c3%a7%c3%a3o%20de%20servi%c3%a7os%20de%20acordo%20com%20o%20perfil%20dos%20funcion%c3%a1rios.pdf","A system for service allocation according to the employee profile","('Elvys Alves Soares',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/1837","Campus A.C. Simões","Instituto de Computação","Dissertação","Um sistema evolutivo para a construção da taxonomia dos seres vivos (SETAX)","('Luis Henrique Leme Pacheco',)","('Roberta Vilhena Vieira Lopes',)","('Manoel Agamemnon Lopes', 'Gildemberg Amorim Leal Junior', 'Guilherme de Alencar Barreto')","Este trabalho apresenta um sistema que utiliza uma abordagem evolutiva para construção de árvores Filogenéticas denominado SETAX. Neste sistema o algoritmo genético baseado em tipos abstratos de dados (Genetic Algorithm Based on Abstract Data Types -GAADT) foi instanciado para encontrar a menor distância entre os grupos taxonômicos investigados, gerando um conjunto de árvores logenéticas com o mesmo valor para o somatório das distância taxonômica entre as sub-árvores binárias que a compõe. Também é aqui apresentado, um estudo de árvores logenéticas, os principais algoritmos para construção de árvores inspirados em métodos de inteligência arti cial; um resumo biológico para o entendimento da construção de uma árvore logenética, a instanciação do GAADT para construção de árvores logenéticas de seres vivos bem como alguns resultados obtidos com o sistema proposto e comparações com os demais métodos.","This work presents a system that use evolutionary approach to Phylogenetic tree construction called SETAX. In this system, the genetic algorithm based on abstract types of data (Genetic Algorithm Based on Abstract Data Types -GAADT)was instantiated to found the minimum distance between taxonomic groups investigated, generating a set of Phylogenetic trees with the same value for the sum of taxonomic distance between binary subtrees which composes it. Also report here, a study of Phylogenetic trees, the main algorithm for construction trees inspired by methods arti cial intelligence; a biological summary for the knowledge of Phylogenetic trees contruction, the instanciation of GAADT to Phylogenetic tress of living beings as well as some results acquired by the proposed system and comparison with other methods.","('Algoritmos', 'Otimização combinatória', 'Algorithms', 'Combinatorial Optimization')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1837","2011-03-18","https://www.repositorio.ufal.br/bitstream/riufal/1837/1/Um%20sistema%20evolutivo%20para%20a%20constru%c3%a7%c3%a3o%20da%20taxonomia%20dos%20seres%20vivos%20SETAX.pdf","A system evolutionary comput for construction taxonomic of taxonomic of organisms living","('Evandro de Barros Costa',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/123456789/10762","Campus A.C. Simões","Instituto de Computação","Dissertação","Um sistema evolutivo para auxiliar o diagnóstico da cifose e lordose","('Antonio Carlos de Lima Filho',)","('Evandro de Barros Costa',)","('Fábio Paraguaçu Duarte da Costa', 'Leandro Dias da Silva')","Este trabalho propõe a implementação de uma variação do algoritmo genético de Holland, para acompanhar a evolução da postura de um paciente através da análise de exames realizados pelo próprio paciente com a ajuda de um dispositivo móvel. O objetivo desse sistema é auxiliar o paciente a identificar a presença de alterações na coluna denominadas de cifose e lordose, momento em que o paciente precisará procurar ajuda médica. Para tanto, o sistema deverá receber informações sobre os limites dos ângulos da coluna considerados normais, aceitáveis e críticos para a cifose e lordose. Em seguida, o sistema passará a auxiliar mensalmente a realização do diagnóstico, gerado a partir de uma foto de perfil do paciente tirada por um dispositivo móvel, da qual é extraída um conjunto de informações, as quais são registradas em uma base de dados, para serem analisadas por um algoritmo genético. O algoritmo genético gera várias possibilidades de evolução para a coluna do paciente baseado nas informações registradas na base de dados, se estas informações conduzirem o algoritmo genético a encontrar uma situação considerado crítica para o paciente nos próximos mês, o sistema irá exibir uma mensagem na tela do celular informando ao paciente a necessidade do mesmo procurar um médico para avaliar sua coluna. Para validar a implementação do referido sistema, foram feitas simulações com imagem geradas com o photoshop. Os resultados obtidos com essas simulações demonstram a capacidade do sistema em prever com antecedência alterações na postura do paciente que podem levar a uma cifose ou lordose.","This work proposes the implementation of a variation of Holland's genetic algorithm to monitor the evolution of a patient's posture through the analysis of exams performed by the patient with the aid of a mobile device. The purpose of this system is to help the patient to identify the presence of changes in the spine called kyphosis and lordosis, at which time the patient will need to seek medical help. Therefore, the system must receive information about the limits of the spine angles considered normal, acceptable and critical for kyphosis and lordosis. Then, the system will monthly assist in making the diagnosis, generated from a photo of the patient's profile taken by a mobile device, from which a set of information is extracted, which is recorded in a database, to be analyzed by a genetic algorithm. The genetic algorithm generates several evolution possibilities for the patient's spine from the information recorded in the database, if this information leads the genetic algorithm to find a situation considered critical for the patient in the coming months, the system will display a message on the screen cell phone informing the patient of the need to see a doctor to have their spine evaluated. To validate the implementation of this system, simulations were carried out with images generated with photoshop. The results obtained with these simulations demonstrate the system's ability to predict in advance changes in the patient's posture that can lead to kyphosis or lordosis.","('Algoritmos genéticos', 'Coluna vertebral', 'Cifose', 'Lordose', 'Genetic algorithm', 'Spine', 'Pathologies', 'App', 'Kyphosis', 'Lordosis')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/10762","2021-06-21","https://www.repositorio.ufal.br/bitstream/123456789/10762/1/Um%20sistema%20evolutivo%20para%20auxiliar%20o%20diagn%c3%b3stico%20da%20cifose%20e%20lordose.pdf","","('Roberta Vilhena Vieira Lopes',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/831","Campus A.C. Simões","Instituto de Computação","Dissertação","Um Sistema Tutor Móvel no contexto de um Framework de Sistemas de Ensino On-line","('Luiz Claúdio Ferreira da Silva Júnior',)","('Arturo Hernández-Domínguez',)","('Fábio Paraguaçu Duarte da Costa', 'Edilson Ferneda')","Desde a sua concepção e desenvolvimento, o FA_PorT, um framework que permite a criação de sistemas de ensino on-line via Internet, tem mostrado ser uma ferramenta de grande potencial no desenvolvimento de aplicações no contexto de educação a distância através da Internet. Porém, notou-se que, nos sistemas instanciados pelo FA_PorT, seria necessário um tratamento diferenciado/personalizado junto aos alunos com desempenho não satisfatório em uma sessão de ensino on-line. Assim, a idéia foi a possibilidade de criarem-se sessões personalizadas de reforço a esses alunos. Dessa forma, foi proposto que um tutor móvel fosse incrementado ao FA_PorT, possibilitando a execução de uma sessão de ensino off-line na máquina do aluno. O sistema tutor móvel possibilita fornecer uma assistência ao aluno com desempenho insatisfatório, já que o conteúdo das sessões da assistência será configurado considerando o desempenho obtido pelo aluno durante uma sessão de ensino on-line. Um sistema tutor móvel é migrado, através do uso de um agente móvel, para o computador do aluno, proporcionando sessões de ensino sem a necessidade de manter uma conexão com o sistema on-line. Uma vez concluída a tarefa do tutor móvel, o agente móvel voltará ao computador de origem. A nova funcionalidade no FA_PorT foi projetada e o sistema tutor móvel foi implementado utilizando o a tecnologia Jade para agentes móveis.","Since its conception and development, the FA_PorT, a framework that allows the creation of systems education via the Internet, has been shown to be a tool of great potential in the development of applications in the context of distance education via the Internet. However, it was noted that in systems instantiated by FA_PorT, would require a different treatment/custom among the students with unsatisfactory performance in a session of teaching on-line. So the idea was the possibility to set up build custom sessions to these students. Thus, it was proposed that a mobile tutor be increased to FA_PorT, enabling the run of a training session off-line on the machine of the student. The mobile tutoring system allows providing to learners, particularly with unsatisfactory performance, on assistance, since the content of the sessions of the assistance will be set considering the performance obtained by the learner during an on-line teaching session. A mobile tutoring system is migrated through the use of a mobile agent for the learner's computer, providing teaching sessions without having to maintain a connection with the on-line system. Having completed the task of the mobile tutoring system, the mobile agent will come back to the origin computer. The mobile tutoring system was implemented using the Jade for mobile agents.","('Mobile agents', 'Tutoring systems', 'Distance education', 'Agentes móveis', 'Framework', 'Sistemas tutores', 'Educação à distância')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/831","2009-09-18","https://www.repositorio.ufal.br/bitstream/riufal/831/1/Um%20Sistema%20Tutor%20M%c3%b3vel%20no%20contexto%20de%20um%20Framework%20de%20Sistemas%20de%20Ensino%20On-line.pdf","A Mobile Tutoring System in the Contexto of a On-line Education System Framework",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/844","Campus A.C. Simões","Instituto de Computação","Dissertação","Um sistema portfólio-tutor baseado no reuso de software","('Douglas Afonso Tenório de Menezes',)","('Arturo Hernández-Domínguez',)","('Fábio Paraguaçu Duarte da Costa', 'Edilson Ferneda')","Com a grande popularização da internet, a EAD vem sendo bastante difundida pelo fato da grande facilidade de acesso, onde o aluno independente do local onde reside, poderá organizar seus horários, ampliando o alcance da modalidade de ensino presencial. O objetivo do presente trabalho é o projeto e desenvolvimento de um Sistema Portfólio-Tutor Baseado no Reuso de Software através de técnicas de reutilização de software, objetivando o máximo de redução de trabalho por parte dos professores, melhorando consideravelmente a análise de dados e diminuindo as atividades repetitivas. Contudo, o sistema será capaz de integrar todas as partes que podem ser envolvidas no processo de aprendizagem. Um portfólio é uma pasta onde ficam armazenadas as evidências da habilidade de cada aluno, sendo possível um acompanhamento cronológico de seu desempenho. Um portfólio eletrônico pode ser dividido em portfólio do aluno e portfólio do professor. É possível desenvolver atualmente dois tipos de portfólios de alunos: o Portfólio de Trabalho, onde são armazenados os trabalhos dos alunos e o Portfólio de Apresentação, onde é armazenado o melhor que o aluno produziu.","","('Eletronic portfolio', 'Distance education', 'Reuse of software', 'Portfólio eletrônico', 'Educação à distância', 'Reuso de software')","Teoria da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/844","2009-10-08","https://www.repositorio.ufal.br/bitstream/riufal/844/1/Um%20sistema%20portf%c3%b3lio-tutor%20baseado%20no%20reuso%20de%20software.pdf","A system portfolio-tutor based in the reuse of software",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/6020","Campus A.C. Simões","Instituto de Computação","Dissertação","Sistema de recomendação personalizada para ambientes de TV digital","('Valdick Barbosa de Sales Júnior',)","('Evandro de Barros Costa',)","('Henrique Pacca Loureiro Luna', 'Anderson de Barros Dantas', 'Francisco de Assis Tenório de Carvalho')","Com a chegada do padrão Digital, abre-se um novo horizonte de oportunidades e facilidades para o telespectador. Ele terá em sua frente uma variedade de programas em diversos canais transmitindo uma enorme quantidade de informações. Neste contexto, surge o problema da sobrecarga de informações (information overload). Esta dissertação apresenta uma proposta para o ambiente de TV Digital com o objetivo de reduzir o problema da sobrecarga de informações. Utilizando as técnicas de personalização e modelagem do usuário mostramos uma forma dinâmica de relacionar as informações exibidas na televisão ao perfil do telespectador. Algumas técnicas de Recomendações foram utilizadas para fornecer ao telespectador uma programação dirigida que atenda seus interesses. Estereótipos também se fizeram necessários para suprir a ausência total de dados sobre o telespectador evitando o problema de ―partida a frio‖ (cold-start problem). Apresentamos, então, este trabalho na área de TV Digital com objetivo de recomendar uma programação personalizada para o telespectador no ambiente da TV Aberta.","The advent of digital TV brought with it new horizons for the TV watchers, full of new opportunities and possibilities. They will have at their disposal a wide variety of information. On the other hand, a new problem arises: information overload. The present dissertation presents a approach for the Digital TV environment, aiming at lowering information overload. By using customing and modeling techniques, it is shown a dynamic way of relating information shown on TV and the watcher‘s profile. Some advise techniques were used in order to offer a customized scheduling to the watcher, aiming at satisfying his interests. Stereotypes proved necessary as well, in oder to compensate the unavailability of data about the watcher, in order to avoid cold-start problem. This dissertation therefore has as its key objective the proposal of a custom scheduling to the Digital TV watcher.","('Televisão digital', 'Perfil do usuário', 'Mineração de dados (Computação)', 'Digital TV', 'User Profile Modeling', 'Data Mining (Computing)')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/6020","2008-12-01","https://www.repositorio.ufal.br/bitstream/riufal/6020/1/Sistema%20de%20recomenda%c3%a7%c3%a3o%20personalizada%20para%20ambientes%20de%20TV%20digital.pdf","",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/4820","Campus A.C. Simões","Instituto de Computação","Dissertação","Sistema de recomendação de vídeos educacionais: um estudo de caso no You tube","('Roberth Raphael Araujo Pinheiro',)","('Evandro de Barros Costa',)","('Arturo Hernández-Domínguez', 'Cleyton Caetano de Souza')","Sistemas de Recomendação vem sendo tema de pesquisas com aplicações em diversas áreas, tais como: comércio, saúde e educação. Aqueles voltados para a educação permitem a recomendação de livros, artigos e ate vídeos educacionais, levando em consideração os interesses dos usuários. A quantidade de vídeos educacionais disponíveis na Internet vem crescendo com o passar do tempo. Tanto as iniciativas privadas como as autônomas disponibilizam, na rede de computadores mundialmente interligada, vídeos sobre diversas áreas do conhecimento. No YouTube, por exemplo, é possível encontrar vários canais educativos, com níveis e temas diversificados. No entanto, com a facilidade de disponibilização desses vídeos, tem-se uma sobrecarga de informações, tornando a escolha dos usuários difícil e árdua. Assim, faz-se necessária a criação de ferramentas que auxiliem na escolha desses vídeos educacionais, levando em consideração aspectos significativos para cada usuário. Este trabalho propõe uma apresentação tanto das funcionalidades como das técnicas, de forma detalhada, utilizadas para a recomendação de vídeos educacionais. Para a prova de conceito, utilizou-se o site do YouTube como repositório de vídeos, visto que este e um dos principais sites de vídeos da Internet.","Systems of Recommendation have been the subject of researches with applications in several areas, such as: commerce, health and education. Those focused on education allow the recommendation of books, articles and educational videos, taking into account the interests of users. The amount of educational videos available on the Internet hás been growing over time. Both private and autonomous initiatives provide videos in the world-wide network of computers with videos on various areas of knowledge. On YouTube, for example, you can find various educational channels, with varying levels and themes. However, with the ease of making these videos available, there is na overload of information, making the choice of users difficult and arduous. Thus, it is necessary to create tools that help in the selection of these educational videos, taking into account significant aspects for each user. This work proposes a presentation of both the functionalities and the techniques, in a detailed way, used for the recommendation of educational videos. For proof of concept, the YouTube site was used as a repository of videos, as this is one of the main video sites on the Internet.","('Modelagem computacional', 'Vídeo educativo -Recomendação', 'YouTube (Recursos eletrônico)', 'Computational modeling', 'Educational video -Recommendation', 'YouTube (Electronic Resources)')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/4820","2018-10-11","https://www.repositorio.ufal.br/bitstream/riufal/4820/1/Sistema%20de%20recomenda%c3%a7%c3%a3o%20de%20v%c3%addeos%20educacionais%20um%20estudo%20de%20caso%20no%20You%20tube.pdf","Educational video recommendation system: a case study on You tube","('Patrick Henrique da Silva Brito',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/6526","Campus A.C. Simões","Instituto de Computação","Dissertação","Redes de Coautoria da Base SciELO: avaliação da colaboração científica por medidas de centralidade de redes complexas","('Vitor Luiz Pereira Ribeiro',)","('Alejandro César Frery Orgambide',)","('Osvaldo Aníbal Rosso', 'Leonardo Melo de Medeiros')","Na área de bibliometria, estudos vêm sendo realizados para mensurar quantitativa e qualitativamente a evolução da produção do conhecimento científico. Nesta direção, as redes de coautoria é uma das formas de indicar a interação entre autores, pelo esforço colaborativo entre pessoas, instituições e países para a geração e publicação de um trabalho científico. Este trabalho busca a propositura de uma análise investigativa a partir de base de dados de indexação de artigos científico SciELO, utilizando para tal, propriedades emétricas da teoria dos grafos e redes complexas, tais como degree centrality, betweeness centrality e closeness centrality, propondo uma avaliação da rede global de coautoria das Universidades Federais do Brasil e da rede local, definida como vértice focal aUniversidade Federal de Alagoas, para série temporal de 2008 à 2017 nas áreas deHealth Sciences -Ciências da Saúde, Agricultural Science -Ciências Agrárias, Exact and Earth Sciences -Ciências Exatas e da Terra. Este trabalhou baseouse em uma metodologia que consistiu nas etapas: a) definição da rede, b) tratamento de dados, c) determinação das características estruturais, d) inspeção visual. Os resultados foram gerados numérica e graficamente, permitindo avaliações e interpretações do comportamento das redes estudadas com base nas medidas de centralidade utilizadas neste trabalho.","In bibliometrics field, studies have been carried out to quantitatively and qualitativelymeasure the evolution of the production of scientific knowledge. In this direction, co-authorship networks is one way of indicating the interaction between authors, through the collaborative effort between people, institutions and countries for the production and publication of a scientific work. This work seeks the proposition of an investigative analysis based on the index database of SciELO scientific articles, using for that purpose, properties and metrics of graph theory and complex networks, such as degree centrality, betweeness centrality and closeness centrality, proposing a evaluation of the global co-authoship network of the Federal Universities of Brazil and the local network, defined as focal point at the Federal University of Alagoas, for a time series from 2008 to 2017 in the areas of Health Sciences, Agricultural Sciences, Exact and Earth Sciences. This work was based on amethodology that consisted of the steps: a) definition of the network, b) data treatment, c) determination of structural characteristics, d) visual inspection. The results were generated numerically and graphically, allowing evaluations and interpretations of the behavior of the networks studied based on the centralitymeasures used in this work.","('Bibliometria', 'Autoria e coautoria na publicação científica', 'Redes complexas', 'Medidas de centralidade', 'Bibliometrics', 'Networks Co-authorship', 'Centrality Measures')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/6526","2019-07-01","https://www.repositorio.ufal.br/bitstream/riufal/6526/1/Redes%20de%20Coautoria%20da%20Base%20SciELO%3a%20avalia%c3%a7%c3%a3o%20da%20colabora%c3%a7%c3%a3o%20cient%c3%adfica%20por%20medidas%20de%20centralidade%20de%20redes%20complexas.pdf","Co-autoring Networks in Scielo database: science collaboration evaluation by complexity networks with centrality measures",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/1852","Campus A.C. Simões","Instituto de Computação","Dissertação","Um sistema adaptativo para detecção de ondas de eletrocardiografia","('Bruno Raphael Pastor de Melo',)","('Roberta Vilhena Vieira Lopes',)","('Manoel Agamemnon Lopes', 'Guilherme de Alencar Barreto')","A eletrocardiografia (ECG) é um importante exame para o apoio no diagnóstico de problemas cardíacos que proporcionou importantes avanços na forma como os problemas cardíacos são monitorados e diagnosticados, possibilitando avanços na medicina e na construção de ferramentas de auxílio no tratamento de pacientes. Os sistemas de monitoramento destinados aos exames eletrocardiográficos permitem que os pacientes sejam acompanhados por médicos e enfermeiros de forma ininterrupta e mais precisa, possibilitando um tratamento mais eficaz. Como estes sistemas não apresentam uma garantia de 100% de acerto, este trabalho propõe um novo algoritmo que tem como objetivo ajudar a melhorar o percentual de acerto nas detecções das ondas que compõe este tipo de exame. Esta dissertação apresenta o emprego do algoritmo genético baseado em tipos abstratos de dados (GAADT) para a construção de um algoritmo e sistema de detecção de diferentes tipos de ondas de um exame eletrocardiográfico, o qual poderá, entre outros fins, ser aproveitado em um sistema de monitoramento de arritmias cardíacas. O sistema foi desenvolvido utilizando as amostras de exames obtidas através do MIT-BIH Database. Os resultados obtidos foram analisados e comparados com os de outros trabalhos e softwares, o que possibilitou uma avaliação da qualidade dos resultados e, consequentemente, do algoritmo construído.","The electrocardiography (ECG) is an important exam to support the diagnosis of heart problems which provided important advances in how heart problems are diagnosed and monitored, making possible advances in medicine and building tools to aid in the treatment of patients. Monitoring systems for electrocardiographic examinations allow patients to be monitored by doctors and nurses on an ongoing basis and more accurate, allowing a more e ective treatment. As these systems do not have a guarantee of 100 % accuracy, this paper proposes a new algorithm that aims to help improve the percentage of correct detections in the waves that make up this type of examination. This paper presents the use of genetic algorithm based on abstract data types (GAADT) for the construction of an algorithm and system for detecting di erent types of waves of an ECG examination, which may, inter alia, be used in a system monitoring of cardiac arrhythmias. The system was developed using samples obtained from examinations of the MIT-BIH Database. The results were analyzed and compared with those of other works and software, which allowed an assessment of the quality of results and, consequently, the algorithm built.","('Algorítmos genéticos', 'Processamento de sinais', 'Bioinformática', 'Eletrocardiografia', 'Genetic algorithms', 'Signal processing', 'Bioinformatics', 'Electrocardiography')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1852","2011-09-22","https://www.repositorio.ufal.br/bitstream/riufal/1852/1/Um%20sistema%20adaptativo%20para%20detec%c3%a7%c3%a3o%20de%20ondas%20de%20eletrocardiografia.pdf","An adaptive system for detection of electrocardiographic waves","('Luís Cláudius Coradine',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/1765","Campus A.C. Simões","Instituto de Computação","Dissertação","Reconhecimento de atividades humanas através de um smartphone","('Gustavo José Barbosa Silva',)","('Leandro Dias da Silva',)","('Aydano Pamponet Machado', 'Robert Fischer', 'Kyller Costa Gorgônio')","O reconhecimento de atividades humanas é uma área de pesquisa em expansão (ZHANG; SAWCHUK, 2013) e tem como objetivo capturar o estado do usuário e do seu ambiente utilizando sensores heterogêneos (DAVIES; SIEWIOREK; SUKTHANKAR, 2008). Atrav és de um monitoramento não-intrusivo das atividades de um indivíduo, pode-se aferir, por exemplo, se o mesmo está levando uma vida saudável, com prática frequente de atividades dinâmicas (andar, correr, subir e descer escadas), ou se está levando uma vida sedentária, na qual o indivíduo passa a grande maioria do seu tempo executando atividades estáticas (sentar, deitar ou car em pé). Considerando-se o viés médico, a assistência pervasiva tem um potencial signi cativo para aumentar a e ciência dos prestadores de assistência médica, mas tem como um de seus principais problemas o reconhecimento automático de atividades humanas diárias (ORWAT; GRAEFE; FAULWASSER, 2008). Além disso, um histórico com informações sobre as atividades executadas por um indiv íduo durante um dado período pode ajudá-lo a ter uma vida mais saudável e menos sedentária. Propõe-se, neste trabalho, a criação de uma prova de conceito que consiga identi car, com um grau de certeza elevado, atividades comuns sendo executadas pelo usuário, a partir de dados coletados de um smartphone qualquer. Almeja-se, também, permitir a criação de alertas para o usuário, ou para um responsável indicado, quando certas condições customizáveis forem atendidas. Por m, disponibilizar um histórico de todas as atividades executadas, inclusive com informações da posição geográ ca do usuá-rio, quando cada atividade foi identi cada. Antes do desenvolvimento propriamente dito, criou-se um conjunto de dados com 10 voluntários que realizaram um circuito de atividades pré-de nido. Em seguida, três abordagens foram utilizadas para gerar um modelo con ável de aprendizagem de máquina: impessoal, que usa dados de nove usuários para treinamento e de um para teste, que teve 89.4% de acurácia; pessoal, que é voltada para um único indivíduo, treinando e testando o modelo com dados distintos do mesmo, e que teve a melhor acurácia com 98.5%; e híbrida, que utiliza dados distintos de todos os dez voluntários para treinamento e para teste, e que obteve 98.16% de acurácia. Uma vez gerado o modelo, desenvolveu-se a prova de conceito proposta que foi testada por um voluntário no seu dia-a-dia apresentando resultados satisfatórios.","Human activity recogntion is an expanding research area (ZHANG; SAWCHUK, 2013) and aims to capture the user state and its environment using heterogeneous sensors (DAVIES; SIEWIOREK; SUKTHANKAR, 2008). Through non-intrusive activities monitoring of an individual, we might infer, for instance, if he is leading a healthy lifestyle, practicing frequently dynamic activities (like walking, running, climbing and descending stairs), or if he is leading a sedentary one, spending the majority of his time static (sitting, lying or standing). Considering the health bias, the pervasive care has signi -cant potential to increase the e ciency of health care providers, but it has as one of its main problems the automatic recognition of daily human activities (ORWAT; GRAEFE; FAULWASSER, 2008). Moreover, a report with information on the activities performed by an individual during a given period can help him have a healthier and less sedentary life. It is proposed the construction of a proof of concept that can identify, with a high accuracy, common activities being performed by the user, based on data collected from a smartphone. It is also desired the generation of alerts to the user, or to other person de ned by him, when certain customizable conditions are met. And, nally, provide a history of all activities performed, including geographical information from the user, when each activity was identi ed. Before the development itself, a data set was created with 10 volunteers who performed a pre-de ned activities circuit. Three approaches were used to generate a reliable model of machine learning: impersonal, which uses data from nine users for training and one for testing, which achieved 89.4% accuracy; personal, that is focused on a single individual, training and testing the model with di erent data from him, it had the best accuracy, 98.5%; and hybrid, which uses di erent data from all ten volunteers for training and testing, and obtained 98.16% accuracy. Once generated the model, the proposed proof of concept was developed, and then tested by a volunteer in his everyday, and overall achieved satisfactory results.","('Interação homem-máquina', 'Smartphones', 'Aprendizado do computador', 'Man-machine interaction', 'Computer learning')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1765","2014-03-10","https://www.repositorio.ufal.br/bitstream/riufal/1765/1/Reconhecimento%20de%20atividades%20humanas%20atrav%c3%a9s%20de%20um%20smartphone.pdf","Human activity recognition using a smartphone",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/1895","Campus A.C. Simões","Instituto de Computação","Dissertação","Um sistema de gerenciamento e controle operacional de fluxo de potência utilizando técnicas de algoritmos genéticos","('Roberto José Correia da Silva',)","('Roberta Vilhena Vieira Lopes',)","('Luís Cláudius Coradine', 'Franklin Martins Pereira Pamplona')","Esta dissertação de mestrado visa desenvolver um sistema computacional, baseado em técnicas de inteligência artificial-IA, para a otimização do gerenciamento e controle fluxo de potencia do sistema de subtransmissão de energia elétrica da CEAL em 69 KV da regional Maceió e diminuição do seu custo operacional. Esta ferramenta computacional, através da utilização dos algoritmos evolucionários, na abordagem de uma variação de algoritmo genético de Holland, apresenta-se como um Framework que tem a capacidade de desenvolvimento da técnica de reuso para a determinação rápida e eficaz das soluções (cromossômicas) factíveis para o problema de balanceamento de tensões nodais e atender as condições operacionais normais e emergenciais do sistema em regime permanente. O preceito será integrado ao sistema VTS da CEAL em uma rede de estações de trabalho nos centros de controle operacionais (COD/COS), para compartilhar o maior número de recursos oferecidos na analise e gerenciamento do sistema elétrico, como também propor um conjunto de ações a serem tomadas, no menor tempo possível.","This work reports about the development of computational system based in Intelligence Artificial-IA to optimization load flow management and control of electric subtransmission system in 69 KV of Energetic Company of Alagoas – CEAL at minimum cost operational. This computational tool, through the use of evolutionary algorithms, in addressing a range of genetic algorithm of Holland, is a framework that has the ability to reuse the development of technology for the rapid and efficient determination of solutions (chromosome) feasible to the problem of balancing the tension and nodal meet the operating conditions of normal and emergency system on a permanent basis. The provision will be integrated with the CEAL VTS system on a network of workstations in the centers of operational control (COD / COS), to share the greatest number of features offered in analyzing and managing the electrical system, but also propose a set of actions to be taken in the shortest possible time.","('Inteligência artificial', 'Algorítmos genéticos', 'Sistemas de energia elétrica', 'Artificial intelligence', 'Genetic algorithms', 'Electric power systems')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1895","2008-12-17","https://www.repositorio.ufal.br/bitstream/riufal/1895/3/Um%20sistema%20de%20gerenciamento%20e%20controle%20operacional%20de%20fluxo%20de%20pot%c3%aancia%20utilizando%20t%c3%a9cnicas%20de%20algoritmos%20gen%c3%a9ticos.pdf","A system of management and control operational to load flow based in genetic s algorithms","('Manoel Agamemnon Lopes',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/824","Campus A.C. Simões","Instituto de Computação","Dissertação","Um sistema de ensino na WEB baseados em padrões pedagógicos dando ênfase na aprendizagem significativa","('Alex Melo da Silva',)","('Arturo Hernández-Domínguez',)","('Fábio Paraguaçu Duarte da Costa', 'Luis Paulo Leopoldo Mercado', 'Edilson Ferneda')","As Tecnologias da Informação e Comunicação (TICs) apresentam diversos cenários de aplicação no contexto educacional, criando a necessidade de modelos que permitam adaptar esses recursos tecnológicos numa prática pedagógica de ensino e aprendizagem. O uso da tecnologia na Educação a Distância (EAD) permite ao aluno ter uma flexibilidade com relação a tempo e localidade. No qual a EAD, faz com que o professor reveja sua pratica pedagógica (estratégias) e o material de aprendizagem a ser utilizado via Internet. Este trabalho objetiva a utilização da Teoria da Aprendizagem Significativa, considerando os seguintes aspectos: Organizadores Prévios, Subsunçores, Assimilação, Diferenciação Progressiva e Reconciliação Integrativa, modelados em conjunto com os Padrões Pedagógicos RCLAP (Leitura, Critica, Exposição Teórica, Atividade e Apresentação com Discussão) e LEASPE (Exposição Teórica, Exemplos, Atividade, Apresentação do Estudante e Avaliação) como estratégia no desenvolvimento de um sistema de ensino na Web. A estratégia proposta é utilizada na definição de sessões de ensino online no contexto de um sistema de ensino Web. Para a construção e implementação do sistema foi utilizado o framework FA_PorT, que permite a criação de sistemas de ensino online via Internet. O FA_PorT permite a definição de sessões de ensino através do uso de estratégias que são representadas por um conjunto de táticas.","The information and communication technologies (ICT) had presented several uses at educational context, creating the need of models which allow to adapt these technological resources in the context of learning and teaching pedagogical practice. The use of the (DE) Distance Education gives to student flexibility in relation to time and place. DE makes the teacher reviews his pedagogical practice and the learning material to be used by internet. This work aims the usage of meaningful learning theory, considering the following aspects: Previous Organizers, Subsumer, Assimilation, Progressive Differentiation, and Integrated Reconciliation. In this work is also taken into account the following pedagogical patterns: RCLAP (Reading, Critique, Lecture, Activity and Presentation with Discussion) and LEASPE (Lecture, Examples, Activity, Student Presentation and Evaluation). RCLAP and LEASPE pedagogical patterns are considered as strategy in the context of a web teaching system. This strategy is used to define online teaching sessions related to a web teaching system. Framework FA_PorT was used to build a web teaching system by internet. The FA_PorT allows to define teaching sessions through the usage of strategies which are represented by a group of tactics.","('Distance education', 'Meaningful learning', 'pedagogical patterns', 'software reuse', 'Educação à distancia', 'Aprendizagem significativa', 'Padrões pedagógicos', 'Reuso de software')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/824","2008-11-28","https://www.repositorio.ufal.br/bitstream/riufal/824/1/Um%20sistema%20de%20ensino%20na%20WEB%20baseados%20em%20padr%c3%b5es%20pedag%c3%b3gicos%20dando%20%c3%aanfase%20na%20aprendizagem%20significativa.pdf","A web teaching system, based in pedagogical patterns giving emphasis in meaningful learning",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/2113","Campus A.C. Simões","Instituto de Computação","Dissertação","Um Sistema de Informação para o Gerenciamento de Banco de Dados do Germoplasma da Cana-de-Açúcar da UFAL/RIDESA","('Bruno Fernando Costa do Nascimento',)","('Roberta Vilhena Vieira Lopes',)","('Patrick Henrique da Silva Brito', 'Paulo Vanderlei Ferreira', 'Fernando da Fonseca de Souza')","Com a incessante busca por novas fontes de energia renováveis, o Brasil vem se destacando devido as suas várias fontes alternativas para produção de energia, na qual a cana-de-açúcar destaca-se por sua alta produção de energia tanto com o álcool combustível, como na reutilização de seus subprodutos. Os países investem em técnicas e tecnologias que visam produzir energia com uma menor taxa de poluição e reaproveitamento de materiais que poderiam servir de fonte de poluição para o meio ambiente. Contudo, essas fontes utilizadas, por outros países, não conseguem sobrepor a produção e a viabilidade econômica para produção energética que a cana-de-açúcar possui. Desta forma, o Brasil se destaca no âmbito internacional de produção de energia renovável, pois é o maior produtor mundial de cana-deaçúcar. O sistema proposto nesta dissertação é um sistema de informação para o gerenciamento de banco de dados, que armazenará os dados do germoplasma da cana-de-açúcar, visando auxiliar no desenvolvimento de novas variedades de cana-de-açúcar, armazenando os dados obtidos nas diversas fases de produção de uma variedade, bem como, armazenar os dados tecnológicos destas variedades que são produzidos nas usinas e destilarias, de cana-de-açúcar, ligados a Rede Interuniversitária para o Desenvolvimento do Setor Sucroenergético (RIDESA). Desta forma, o processamento destes dados possibilitará uma redução no tempo de produção de uma nova variedade, desta forma, diminuindo o custo para obtenção de uma variedade, bem como, aumentando a velocidade de resposta e dando confiabilidade nas informações processadas dos dados.","With the incessant search for new sources of renewable energy, Brazil has been highlighted due to its various alternative sources for energy production, in which the sugar cane stands out for its high energy production with both alcohol fuel as reuse of byproducts. Countries invest in techniques and technologies to produce energy with a lower rate of pollution and reuse of materials that could serve as a source of pollution to the environment. However, these sources used by other countries, can not override the production and economic viability for energy production that cane sugar has. Thus, Brazil stands out internationally for producing renewable energy, it is the world's largest producer of cane sugar. The proposed system in this paper is an information system for managing the database, which will store the data of germplasm of cane sugar, aiming to assist in the development of new varieties of cane sugar, storing the data obtained in various stages of production of a variety, as well as store data technology that these varieties are produced in mills and distilleries, cane-sugar, bound Interuniversity Network for the Development of sugarcane industry (RIDESA). Thus, the processing of these data will allow a reduction in production time of a new variety thus reducing the cost for obtaining a variety as well as increasing the response speed and reliability of the information providing processed data.","('Rede Interuniversitária para o Desenvolvimento do Setor Sucroenergético (RIDESA)', 'Saccharum', 'Melhoramento Vegetal', 'Banco de dados', 'Banco de Sementes', 'Plant Improvement', 'Database', 'Seed bank')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/2113","2012-06-22","https://www.repositorio.ufal.br/bitstream/riufal/2113/1/Um%20sistema%20de%20informa%c3%a7%c3%a3o%20para%20o%20%20gerenciamento%20de%20banco%20de%20dados%20para%20o%20germoplasma%20da%20cana-de-a%c3%a7%c3%bacar%20da%20UFAL-RIDESA.pdf","Um sistema de gerenciamento de banco de dados para o germoplasma da cana-de-açúcar;An information system for the germplasm database management of sugarcane UFAL/RIDESA","('Manoel Agamemnon Lopes',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/3254","Campus A.C. Simões","Instituto de Computação","Dissertação","pRRoject: um ambiente de suporte ao desenvolvimento e acompanhamento de pesquisas quantitativas reprodutíveis","('Ana Maria Aquino dos Santos',)","('Alejandro César Frery Orgambide',)","('Heitor Soares Ramos Filho', 'Leonardo Melo de Medeiros', 'Paolo Ettore Gamba')","Pesquisadores da área computacional enfrentam dificuldades para publicar resultados precisos dos seus artigos e isso tem sido um dos motivos cruciais para se pensar em Reproducible Research (RR). RR é uma sistematização de boas práticas em metodologia científica voltada especialmente para a ciência computacional quantitativa. Boas práticas de RR se relacionam com boas práticas de gerência de projetos colaborativos. Diante disso, apresentamos o pRRoject, um ambiente computacional comprometido em auxiliar o pesquisador a adotar boas práticas de RR do início ao fim do projeto de pesquisa, através do uso de ferramentas para gerenciamento de projetos.","Computational researchers are confronted with difficulties to publish accurate and reproducible results, and this is been one of the crucial reasons for thinking about Reproducible Research (RR). RR is a systematization of good practices in scientific methodology focused especially to quantitative computational science. Good RR practices relate to good collaborative project management practices. Therefore, we present pRRoject, a computational environment committed to help researchers adopting good RR practices from the start until the end of the research project, through the use of tools for projectmanagement.","('Reproducible research', 'Ambiente computacional', 'Projetos – Gerência', 'Pesquisa computacional quantitativa', 'Computational environment', 'Projects – Management', 'Quantitative computational research')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/3254","2017-11-17","https://www.repositorio.ufal.br/bitstream/riufal/3254/1/pRRoject%20-%20um%20ambiente%20de%20suporte%20ao%20desenvolvimento%20e%20acompanhamento%20de.pdf","pRRoject: na environment supporting the development and monitoring of reproducible quantitative research",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/5738","Campus A.C. Simões","Instituto de Computação","Dissertação","Proposição de um modelo de aprendizagem baseado em problemas adaptado à ambientes virtuais de aprendizagem: um estudo de caso no curso de Extensão de Informática Básica da UFAL","('Helenilson Beserra de Melo',)","('Fábio Paraguaçu Duarte da Costa',)","('Arturo Hernández-Domínguez', 'Elton Casado Fireman')","O presente trabalho propõe um Modelo de Aprendizagem Baseada em Problemas que se adapte aos Ambientes Virtuais de Aprendizagem capaz de ser aplicado como metodologia de ensino nos cursos à distância. Os Ambientes Virtuais de Aprendizagem (AVA), quando não são adaptados à problematização reproduzem uma imagem onde o estudante assume um papel passivo, apenas de absorção no processo de ensino-aprendizagem, impossibilitando que o mesmo construa seu próprio conhecimento. Diante disso, percebeu a necessidade de se construir um modelo de ensino baseado em problemas, com uma abordagem diferenciada, que pudesse ser aplicado na Educação à Distância através do AVA de forma autônoma e independente, dando aos alunos a possiblidade de assumirem um papel ativo e colaborativo no processo de aprendizagem. O Modelo proposto é baseado nas sete etapas da PBL -Problem-Based Learning (Aprendizagem Baseada em Problemas) e utiliza as ferramentas disponibilizadas no AVA que mais se adequa a cada etapa. Como estudo de caso, por meio de uma abordagem qualitativa essa pesquisa avalia a aplicação do Modelo no curso de Extensão de Informática Básica, modalidade à distância, ofertado pela Universidade Federal de Alagoas – UFAL através do AVA Moodle. O curso foi destinado aos alunos de graduação da universidade e teve como objetivo analisar a resolução de problemas destinados a softwares de edição de textos, apresentação e planilha de cálculos. A fase de levantamento e tratamento dos dados ocorreram através da observação e análise das produções dos alunos no AVA, para isso foram coletados dados por meio de questionários avaliativos aplicados aos participantes do curso afim de avaliar a metodologia de ensino aplicada e sua integração com o AVA Moodle. A partir da análise dos dados foi possível constatar que a maioria dos alunos avaliaram a metodologia aplicada como inovadora, por incentivar a participação ativa no processo de ensino e aprendizagem, além disso, para eles estabelecem uma autonomia na aquisição do conhecimento. Dessa forma, o uso da PBL através do AVA Moodle mostrou-se eficiente como um recurso metodológico para construção de conhecimentos e para promoção de habilidades e atitudes no que se refere ao aprendizado adquirido durante o curso o que prova a eficácia do modelo proposto.","This work proposes a problem-based learning model that fits the virtual learning environments capable of being applied as a teaching methodology in distance courses. The Virtual learning Environments (AVA), when they are not adapted to problematization reproduce an image where the student assumes a passive role, just absorbing in the teaching-learning process, making it impossible to build his own knowledge. Faced with this, it realized the need to construct a problem-based educational model, with a differentiated approach, which could be applied in distance education through AVA in an autonomous and independent manner, giving students the possibility to assume an active role and collaborative in the learning process. The proposed model is based on the seven stages of PBL-problem-based learning (problem-based learning) and utilizes the tools available in AVA that suits each step. As a case study, through a qualitative approach this survey evaluates the application of the model in the course of basic computing, distance modality, offered by the Federal University of Alagoas – UFAL through AVA Moodle. The course was destined for undergraduate students at the university and aimed to analyze the resolution of problems aimed at editing software, presentation and spreadsheet of calculations. The phase of surveying and processing of the data occurred through the observation and analysis of the students ' productions in AVA, for this were collected data through evaluation questionnaires applied to the participants in the course in order to evaluate the methodology of applied education and their Integration with AVA Moodle. From the analysis of the data it was possible to note that most students assessed the methodology applied as innovative, by encouraging active participation in the teaching and learning process, in addition, for them to establish a certain autonomy in the acquisition of the Knowledge. Thus, the use of PBL through AVA Moodle proved to be efficient as a methodological resource for knowledge building and promoting skills and attitudes towards learning acquired during the course which proves the effectiveness of the proposed model.","('Aprendizagem baseada em problemas', 'Ambiente virtual de aprendizagem', 'Educação à distância', 'Modelo de ensino', 'Problem-Based Learning', 'Virtual Learning Environments', 'Distance Learning', 'Teaching model')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/5738","2018-07-09","https://www.repositorio.ufal.br/bitstream/riufal/5738/1/Proposi%c3%a7%c3%a3o%20de%20um%20modelo%20de%20aprendizagem%20baseado%20em%20problemas%20adaptado%20%c3%a0%20ambientes%20virtuais.pdf","Proposition of a problem-based learning model adapted to virtual learning environments: a case study in UFAL basic Computer Science course","('Cleide Jane de Sá Araujo Costa',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/5933","Campus A.C. Simões","Instituto de Computação","Dissertação","Proposição de modelos de gamificação para sistemas de educação online: uma abordagem baseada na educação baseada em evidências","('Amaury Nogueira Neto',)","('Alan Pedro da Silva',)","('Marcus de Melo Braga', 'Patrícia Leone Espinheira Ospina')","O presente trabalho tem a proposta de investigar os efeitos de elementos específicos de gamificação, abordando gamificação não apenas como um conceito abrangente, mas buscando analisar a eficácia do uso das mecânicas de jogo mais utilizadas no contexto da educação. Ao isolar mecânicas de jogo específicas e utilizar métodos adequados para avaliação de sua eficácia em sala de aula, obteve-se uma melhor compreensão de como criar um sistema ideal de gamificação que promova e mantenha o engajamento e contribua de maneira positiva para o aprendizado dos alunos. A partir da realização de um estudo controlado, onde foram analisados os elementos Ponto, Troféu e Ranking, tanto de maneira isolada quanto de maneira combinada, pôde-se perceber que o uso de tais elementos pode apresentar contribuições estatisticamente significativas no que se refere ao engajamento dos alunos. Diante das conclusões obtidas, buscou-se analisar de que maneira os resultados poderiam contribuir para os campos de estudo da Informática na Educação e Gamificação, buscando informações que subsidiassem a criação do modelo proposto visando sua aplicação no contexto do ensino da disciplina Matemática para alunos do ensino médio no Brasil. A adoção do modelo proposto pode contribuir para um maior engajamento dos alunos auxiliando-os nas disciplinas fundamentais do ensino médio.","This work is the proposal to investigate the effects of specific elements of gamification, gamification addressing not only as a comprehensive concept, but trying to analyze the effectiveness of the use of the most used game mechanics in the context of education. By isolating specific game mechanics and use appropriate methods for evaluating their effectiveness in the classroom, we obtained a better understanding of how to create an ideal of gamification system that promotes and maintains the engagement and contribute positively to student learning. From conducting a controlled study, where the elements Point, Trophy and Ranking were analyzed, both in isolation as a combined way, could be seen that the use of such elements may show statistically significant contributions with regard to engagement from the students. In the face of findings, it sought to analyze how the results could contribute to the Information fields of study in Education and gamification, seeking information that subsidize the creation of the proposed model for their application in Mathematics discipline of teaching context for students high school in Brazil. The adoption of the proposed model can contribute to a greater engagement of students helping them in the core disciplines of high school.","('Informática educativa', 'Educação lúdica', 'Tecnologia da informação e comunicação', 'Valor educativo do jogo', 'Tecnologia educacional', 'Computing in education', 'Ludic education', 'Information and communication technology', 'Educational value of the game', 'Educational technology', 'Virtual learning environments')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/5933","2016-06-27","https://www.repositorio.ufal.br/bitstream/riufal/5933/1/Proposi%c3%a7%c3%a3o%20de%20modelos%20de%20gamifica%c3%a7%c3%a3o%20para%20sistemas%20de%20educa%c3%a7%c3%a3o%20online%20uma%20abordagem%20baseada%20na%20educa%c3%a7%c3%a3o%20baseada%20em%20evid%c3%aancias.pdf","","('Ig Ibert Bittencourt Santana Pinto',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/1764","Campus A.C. Simões","Instituto de Computação","Dissertação","Proposição de modelo de sistema de recomendação para uma alimentação saudável baseado na medicina Ayurvédica","('Renata Tânia Brito Morais',)","('Fábio Paraguaçu Duarte da Costa',)","('Patrick Henrique da Silva Brito', 'Guilherme Ataíde Dias')","O principal objetivo deste trabalho consistiu em desenvolver um Sistema de Recomendação para uma alimentação saudável utilizando informações contextuais da Medicina Ayurvédica. Buscando organizar um quadro referencial para uma dieta fundamentada nos sabores dos alimentos, teve-se como eixo comum integrar ensino e saúde, dentro de uma área específica do conhecimento, a educação alimentar. De acordo com essa proposta educativa, o Sistema subsidia os usuários com informações adequadas, a partir dos doshas identificados previamente. Com a utilização de técnicas de filtragem baseada em conteúdo, são sugeridas, aos usuários, estratégias para a promoção das práticas alimentares saudáveis. Nesse contexto, a aprendizagem ocorre quando se ajuda a tornar a informação significativa, a escolher as verdadeiramente importantes e a compreendê-las de forma cada vez mais abrangente e profunda. Procurando desenvolver o conhecimento e a compreensão como parte dessa prática, tomou-se como princípio metodológico desta pesquisa de natureza aplicada, o suporte e a diretriz da pesquisa-ação. Optou-se pelo método qualitativo de abordagem para se analisar as interações reais entre as pessoas e o Sistema, utilizando-se, para tanto, o questionário para a coleta de dados. Participaram da investigação, três terapeutas e vinte e duas pessoas que avaliaram o Sistema de Recomendação proposto. Os resultados evidenciaram que o Sistema de Recomendação, tal como aqui apresentado, constitui-se uma forma facilitadora de aprendizagem que auxilia no hábito de uma alimentação saudável.","The main objective of this work was to develop a Recommender System for healthy eating using contextual information of Ayurvedic Medicine. Searching to organize a frame of reference for a diet based on the flavors of food, it had as common axis integrating health and education, within a specific area of knowledge, food education. According to this educational proposal, the system subsidizes the users with appropriate information from previously identified doshas. With the use of filtering techniques based on content, strategies for promoting healthy eating practices are suggested to users. In this context, learning occurs when it helps make the information meaningful to choose the truly important and to understand them in an ever broader and deeper way. Seeking to develop their knowledge and understanding as part of this practice, it was taken as a methodological principle in this applied nature research, the support and guidance of action research. We chose the qualitative method approach to analyze the actual interactions between people and the system, using to this end, the questionnaire for data collection. Three therapists participated in the investigation and twenty-two people evaluated the proposed Recommendation System. The results showed that the Recommendation System, as presented here, constitutes a form of learning facilitator that assists in the habit of healthy eating.","('Medicina ayurvédica', 'Dieta Saudável', 'Ayurvedic medicine', 'Healthy Diet')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1764","2014-04-14","https://www.repositorio.ufal.br/bitstream/riufal/1764/1/Proposi%c3%a7%c3%a3o%20de%20modelo%20de%20sistema%20de%20recomenda%c3%a7%c3%a3o%20para%20uma%20alimenta%c3%a7%c3%a3o%20saud%c3%a1vel%20baseado%20na%20medicina%20ayurv%c3%a9dica.pdf","Proposition of a recommendation system model for a healthy diet based on ayurvedic medicine","('Cleide Jane de Sá Araujo Costa',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/2209","Campus A.C. Simões","Instituto de Computação","Dissertação","Uma proposta de modelo de processo para publicação de dados abertos conectados governamentais","('Thiago José Tavares Ávila',)","('Ig Ibert Bittencourt Santana Pinto',)","('Marcus de Melo Braga', 'Bernadette Farias Lóscio')","Nos últimos anos, governos tem sido estimulados e obrigados a ampliar a disponibilidade de seus dados na Web mediante obrigações legais bem como alianças internacionais como a ""Parceria para o Governo Aberto"". A disseminação do conceito de dados abertos governamentais está contribuindo para uma ampliação desta oferta de dados na Web, entretanto sem garantias que tais dados estejam adequados para reuso, processamento automatizado, bem como subsidiar a geração de conhecimento. O conceito de dados conectados, apresentado em 2006 por Tim Berners-Lee, vem ao encontro desta necessidade de aprimorar a qualidade dos dados, mediante a adoção de princípios para estruturar e conectar conjuntos de dados na Web. Em 2014, o W3C estabeleceu um conjunto de 10 melhores práticas para a publicação de dados conectados. Na esfera governamental, apesar da existência de alguns processos voltados à publicação de dados abertos conectados, estes priorizam os atores técnicos e não consideram o nível de maturidade da instituição publicadora, sendo aparentemente insuficientes para ampliar a disponibilização de Dados Abertos Conectados Governamentais (DACG). Como solução para estes desafios, esta dissertação propõe um modelo de processo para publicação de DACG que, mediante atividades incrementais, busca guiar instituições governamentais à publicarem seus dados em formatos abertos e conectados. O modelo considera o Esquema 5-Estrelas dos Dados Abertos como escala evolutiva, associando a este esquema, atividades obrigatórias e desejáveis que buscam implementar as melhores práticas para publicação de dados conectados. Como contribuições, a pesquisa apresenta uma revisão de literatura sobre quinze processos de publicação de dados abertos aplicáveis ao setor público que sistematiza atividades que podem ser consideradas na publicação de dados governamentais, bem como uma proposta de modelo de processo que poderá impulsionar a oferta de dados desta natureza, mediante a aprimoração de processos existentes associado às melhores práticas para publicação de dados conectados e incorporação de características iterativas de processos, permitindo a sua utilização em diversas finalidades","In recent years, governments have been encouraged and obligated to increase the availability of their data on the Web through legal obligations and international alliances as the ""Open Government Partnership"". The dissemination of the concept of open government data is contributing to an expansion of this data supply on the Web. However without guarantees that such data are suitable for reuse, automated processing, and support the production of knowledge. In this way, Linked Data concept, presented in 2006 by Tim Berners-Lee, meets the need to improve data quality, through the adoption of principles for structure and connect datasets on the Web. In 2014, the World Wide Web Consortium -W3C established a set of 10 best practices for publishing linked data. In the government sector, despite the existence of some processes directed to publishing linked open data, they give priority to the technical people and do not consider the maturity level of the publishing government agency, apparently being insu_cient to extend the availability of Government Linked Open Data (GLOD) on the Web. As a proposal solution, this research proposes a process model for GLOD publication that, through incremental activities, seeks to guide government agencies to publish their data in open and linked formats. The process model considers the 5-Stars Open Data scheme like as evolutionary scale, aggregating to this scheme, mandatory and desirable activities that seek to implement the Best Practices for Publishing Linked Data. As a contribution, the research presents a literature review on _fteen open data publishing procedures applicable to the public sector which organizes activities that can be considered when publishing government data. Another contribution is a proposal of process model that could boost the supply of this kind of data, by enhance existing processes associated with the best practices for publishing linked data and embedding iterative features, allowing its use for various purposes._____RESUMÉN: En los últimos años, los gobiernos han tenido que disponibilizar sus datos en la Web a través de las obligaciones legales y alianzas internacionales como la ""Alianza para el Gobierno Abierto"". El concepto de datos abiertos de gobierno, presentado por Tim Berners-Lee en 2006 cumple con esta necesidad de mejorar la calidad de los datos a través de la adopción de principios para estructurar y conectar conjuntos de datos en la Web. En 2014, el Consorcio World Wide Web -W3C estableció un conjunto de 10 mejores prácticas para la publicación de datos conectados. En la esfera gubernamental, a pesar de la existencia e algunos procesos encaminados para la publicación de los datos abiertos conectados, que dan prioridad a los actores técnicos y no tienen en cuenta el nivel de madurez de la institución editora, siendo aparentemente insuficientes para ampliar la disponibilidad de los datos gubernamentales abiertos conectados (DACG). A pesar que la difusión del concepto de datos de gobierno abierto contribuye a la expansión de esta fuente de datos de la Web, esto no garantiza que estos datos sean adecuados para su reutilización, tratamiento automatizado, apoyo a la generación de conocimiento y a la toma de decisión. Es por ello, que esta investigación se propone un modelo de proceso para su publicaci_on DACG que, a través de actividades incrementales, busca orientar a las instituciones gubernamentales a publicar sus datos en formatos abiertos y conectados. El modelo de proceso considera el Plan de 5-Estrellas de Open Data como escala evolutiva, la vinculación a este esquema, las actividades obligatorias y deseables que tratan de poner en práctica las 10 mejores prácticas para la publicación de los datos conectados. Como contribuciones, se presenta una revisión de la literatura sobre los procedimientos de publicación de quince de datos abierta aplicable al sector público que organiza las actividades que se pueden considerar al publicar los datos del gobierno, así como una propuesta de modelo de proceso que podría impulsar la oferta de los datos de esta naturaleza, por mejorar los procesos existentes relacionados con las mejores prácticas y la incrustación de características proceso iterativo, lo que permite su uso en diversas realidades.","('Modelos computacionais', 'Dados governamentais', 'Dados abertos', 'Dados abertos conectados', 'Dados abertos conectados governamentais', 'Modelo de processo', 'Computational model', 'Government data', 'Open data', 'Linked open data', 'Government linked open data', 'Process model', 'Modelo computacional', 'Datos abiertos de gobierno', 'Datos abiertos', 'Datos abiertos conectados', 'Datos abiertos conectados de gobierno', 'Modelo de proceso')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/2209","2015-11-25","https://www.repositorio.ufal.br/bitstream/riufal/2209/1/Uma%20proposta%20de%20modelo%20de%20processo%20para%20publica%c3%a7%c3%a3o%20de%20dados%20abertos%20conectados%20governamentais.pdf","A proposal of process model for publishing government linked open data","('Patrícia Leone Espinheira Ospina',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/123456789/8891","Campus A.C. Simões","Instituto de Computação","Dissertação","Protocolo de monitoramento para pais e profissionais de crianças com perda auditiva: metanálise de intervenção precoce e adaptação cultural do Success From the Start","('Suzana Cinthia Silva Oliveira',)","('Leonardo Brandão Marques',)","('Jorge Artur Peçanha de Miranda Coelho', 'Felipe Venâncio Barbosa', 'Aline Roberta Aceituno da Costa')","A identificação precoce da perda auditiva contribui para o desenvolvimento da linguagem oral e de outros marcos no desenvolvimento de crianças com perda auditiva. Após o diagnóstico, os pais acabam tendo que tomar diversas decisões no que concerne ao tratamento dos seus filhos. Na literatura brasileira não foi encontrado nenhum instrumento disponibilizado para fornecer suporte ao processo decisório dos pais. Visando atender a esse público, este trabalho tem por objetivo fazer a tradução e adaptação cultural de um protocolo de monitoramento para pais e profissionais de crianças com perda auditiva. Para isso, foi conduzido dois estudos, o primeiro consistiu em uma revisão sistemática da literatura e metanálise sobre as evidências da influência do momento da intervenção no desenvolvimento da linguagem oral de crianças com perda auditiva. Quinze estudos fizeram parte da síntese qualitativa e doze da síntese quantitativa. De acordo com os dados analisados, a idade de identificação e intervenção precoce demonstrou ajudar crianças a atingirem resultados da fala e da linguagem dentro dos marcos do desenvolvimento, dos quais podem ser avaliados pelas curvas de crescimento usando escores de linguagem padronizados. O segundo estudo consistiu na tradução e adaptação cultural de 452 itens do instrumento correspondentes as áreas de comunicação, atenção, escuta e vocalização. Foram selecionados 25% dos itens para serem avaliados por juízes nas categorias: 1) adequação cultural; 2) conceito apresentado e; 3) adequação ao público-alvo. A tradução reversa foi realizada durante essa fase da pesquisa. Após a compilação dos dados e as correções dos possíveis erros durante a fase de tradução, foi possível analisar os itens não inseridos para avaliação dos juízes e proposto uma nova avaliação com novos itens. Posteriormente, foram comparados os itens traduzidos com a versão revisada do instrumento que compõe 347 itens nas duas áreas de desenvolvimento. O instrumento foi avaliado qualitativamente por dois especialistas com o objetivo de validar seu conteúdo.","Early identification of hearing loss contributes to oral language development and other developmental milestones in children with hearing loss. After diagnosis, parents end up having to make several decisions regarding the treatment of their children. In the Brazilian literature, no instrument was found available to provide support for parents' decision process. To address this gap, this work aims to translate and culturally adapt a monitoring screening protocol for parents and professionals that targets children with hearing loss. For this, two studies were conducted. The first consisted of a systematic review of the literature and meta-analysis on the influence of the intervention on the oral language development of children with hearing loss. Fifteen studies were part of the qualitative synthesis and twelve of the quantitative synthesis. According to the summarized data, the age of identification and early intervention allowed children to achieve speech and language outcomes within developmental milestones, both of which can be obtained by growth curves using standardized language scores. The second study consisted of the cultural adaptation and adaptation of 452 items of the Success from the Star protocol, corresponding to all principal areas of language development: communication, listening, listening, and vocalization. Judges evaluated 25% of the items on the following categories: 1) cultural suitability, 2) conceptual clarity, and 3) suitability to the target audience. We proposed a back-translation to consolidate the final items. Subsequently, the translated items were compared with the revised version of the instrument, which comprises 347 items in the two areas of development. The instrument was qualitatively evaluated by two experts in order to validate its content.","('Perda auditiva -Identificação precoce', 'Transtornos do desenvolvimento da linguagem', 'Protocolos', 'Early Identification', 'Language', 'Hearing Loss', 'Protocol')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/8891","2021-12-09","https://www.repositorio.ufal.br/bitstream/123456789/8891/1/Protocolo%20de%20monitoramento%20para%20pais%20e%20profissionais%20de%20crian%c3%a7as%20com%20perda%20auditiva%20-%20metan%c3%a1lise%20de%20interven%c3%a7%c3%a3o%20precoce%20e%20adapta%c3%a7%c3%a3o%20cultural%20do%20Success%20From%20the%20Start.pdf","nitoring protocol for parents and professionals of children with hearing loss: meta-analysis of early intervention and cultural adaptation of success from the start","('Ig Ibert Bittencourt Santana Pinto',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/123456789/8619","Campus A.C. Simões","Instituto de Computação","Dissertação","Product Space Study in the State of Alagoas","('Juliana da Silva Leal',)","('Evandro de Barros Costa',)","('Marcus de Melo Braga', 'Baldoíno Fonseca dos Santos Neto', 'Francisco José Peixoto Rosário')","O objetivo deste estudo está dividido em dois: primeiro, visa analisar e interpretar as exportações de produtos brasileiros de 1997 a 2019. Segundo, visa reduzir o escopo ao estado de Alagoas -um dos estados mais pobres do país -para identificar possíveis oportunidades de crescimento nas exportações. Desse modo, o estudo foi realizado por meio do modelo Product Space, que pode nos mostrar, por meio de uma rede, se é possível às indústrias produzirem novos produtos a partir dos já produzidos por elas. Após analisar o Product Space, concluímos que Alagoas não está isolado na rede. Alagoas pode ampliar sua rede exportando mais de 50 produtos, como veículos automotores, celulose química e automóveis de passageiros. Tal crescimento pode promover novas parcerias públicas e privadas. Com isso, novas indústrias podem ser atraídas e impulsionar o crescimento econômico de Alagoas.","The objective of this study is twofold: First, it aims at analyzing and interpreting Brazilian products exportation from 1997 to 2019. Second, it seeks to reduce the scope to the Alagoas state – one of the nation’s poorest states – to identify possible exportation growth opportunities. Thereby, the study was conducted by using the model Product Space, which can show us, through a network, if it is possible to industries produce new products from those already produced by them. After analyzing the Product Space, we concluded that Alagoas is not isolated in the network. Alagoas can grow its network by exporting more than 50 products, such as motor vehicles, chemical wood pulp, and passenger cars. Such growth can promote new public and private partnerships. Thus, new industries might be attracted and boost Alagoas economic growth.","('Product space -Alagoas', 'Cesta de mercado', 'Market basket')","Ciência da Computação","eng","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/8619","2021-01-13","https://www.repositorio.ufal.br/bitstream/123456789/8619/1/Product%20space%20study%20in%20the%20state%20of%20Alagoas.pdf","Estudo do Product Space no Estado de Alagoas",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/5932","Campus A.C. Simões","Instituto de Computação","Dissertação","O problema de energy hole em redes de sensores sem fios: a influência da localização dos nós sensores no consumo de energia","('Alyson Leandro Costa Oliveira',)","('Alejandro César Frery Orgambide',)","('André Luiz Lins de Aquino', 'Leandro Aparecido Villas')","Apresentamos as Redes de Sensores sem Fios (RSSFs) como uma ferramenta de comunicação e processamento de informações. Com o propósito de buscar uma alternativa para aproveitar ao máximo esse pontencial, exploramos um dos principais desafios impostos pelas configurações desse tipo de rede: o consumo de energia. Mais especificamente, examinamos um problema conhecido na literatura como Problema do Energy Hole, com o objetivo de avaliar o comportamento do consumo energético entre os diversos nós sensores espalhados em um determinado ambiente de interesse. Baseado em: 1) RSSFs homogêneas e com comunicação por meio de múltiplos saltos; 2) uma modelagem de RSSFs, abordando algumas abstrações; e 3) definições de processos pontuais; propomos um processo pontual não-homogêneo para avaliar o que entendemos ser um dos pontos de principal ação no consumo de energia de uma RSSFs: a localização dos nós sensores e sua influência nas atividades de comunicação. Devido a complexidade de uma avaliação analítica, propomos e implementamos um experimento Monte Carlo que permite avaliar quantitativamente fatores como a relação entre a energia consumida ao longo de uma atividade de monitoramento e a densidade de nós sensores em uma região, assim como também a relação entre a taxa de cobertura e os cenários resultantes da aplicação do processo pontual proposto.","Wireless Sensor Networks (WSNs) are presented as a communication and information processing tool. In order to find a way to make the most of their potencial, we explore one of the central challenges imposed by the technical features of such networks: energy consumption. In particular, we explore the Energy Hole problem, in order to evaluate the behavior of energy consumption among sensor nodes scattered in an environment. Based on: 1) homogeneous WSNs and multihop communication; 2) a model for with some degree of abstraction; and 3) spatial point processes; we propose an inhomogeneous spatial point process to evaluate one of the most important factors in energy consumption: the distribution of sensors nodes and its influence on communication. Due to the complexity of dealing with this problem from an analytical viewpoint, a Monte Carlo experiment is devised to evaluate this influence. In particular, we study the relationship between energy expended and the sensor nodes density, and the relationship between the coverage and the resulting instances from the application of the proposed spatial point process.","('Energia – Consumo', 'Redes de computação', 'Sensores sem fio', 'Sistemas de comunicação sem fio', 'Modelagem computacional', 'Controle de topologia', 'Energy hole', 'Processos pontuais espaciais', 'Sinalgo', 'Método de Monte Carlo', 'Energy -Consumption', 'Computer networks', 'Wireless sensor networks', 'Wireless communication systems', 'Computing modeling', 'Topology control', 'Spatial point processes', 'Monte Carlo Experiment')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/5932","2013-12-20","https://www.repositorio.ufal.br/bitstream/riufal/5932/1/O%20problema%20de%20energy%20hole%20em%20redes%20de%20sensores%20sem%20fios%20a%20influ%c3%aancia%20da%20localiza%c3%a7%c3%a3o%20dos%20n%c3%b3s%20sensores%20no%20consumo%20de%20energia.pdf","The energy hole problem in wireless sensor in tworks: the influence of sensor distribution in energy consumption","('Heitor Soares Ramos Filho',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/7107","Campus A.C. Simões","Instituto de Computação","Dissertação","Predição de dados de sensoriamento visando eficiência energética através da redução de transmissão de dados em redes de sensores sem fio","('Charles Mariano Pedrosa de Almeida',)","('André Luiz Lins de Aquino',)","('Heitor Soares Ramos Filho', 'Wellinsílvio Costa dos Santos')","As redes de sensores sem fio (RSSF) já são objeto de interesse dos pesquisadores e estão se tornando cada vez mais integradas aos sistemas domésticos, comerciais, industriais, etc. No entanto, devido às suas próprias características, o problema da restrição e gerenciamento de energia na própria rede é um dos principais pontos a serem equalizados. Neste contexto, existem várias abordagens para proporcionar eficiência energética, e diante disso, este trabalho tem como objetivo comparar modelos de predição de dados de sensoriamento em redes de sensores sem fio com a finalidade de economizar energia na transmissão de dados. Modelos ARIMA, SVM, MLP/ANN e RNN/LSTM foram utilizados em uma aplicação de coleta de dados de temperatura e avaliados quanto à economia de energia proporcionada. As medições foram realizados por dispositivos reais e foi possível observar o desempenho dos modelos para um conjunto de dados de sensoriamento em um ambiente de escritório. Para este trabalho, o modelo SVM apresentou melhor desempenho em relação aos demais em termos de eficiência energética.","Wireless sensor networks (RSSF) are already of interest to researchers and are becoming increasingly integrated with home, commercial, industrial, etc. systems. However, due to its own characteristics, the problem of power restriction and management in the grid itself is one of the main points to be equalized. In this context, there are several approaches to provide energy efficiency, and in view of this, this work aims to compare prediction models of sensing data in wireless sensor networks in order to save energy in data transmission. ARIMA, SVM, MLP/ANN and RNN/LSTM models were used in a temperature data collection application and evaluated for the energy savings provided. The measurements were performed by real devices and it was possible to observe the performance of the models for a sensing data set in an office environment. For this work, the SVM model presented better performance compared to the others in terms of energy efficiency.","('Redes de sensores sem fio', 'Eficiência energética', 'Modelos de predição', 'RSSF', 'ARIMA', 'SVM', 'ANN', 'RNN', 'LSTM', 'Wireless sensor networks', 'WSN', 'Energy efficiency', 'Prediction models')","Matemática","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/7107","2019-12-20","https://www.repositorio.ufal.br/bitstream/riufal/7107/3/Predi%c3%a7%c3%a3o%20de%20dados%20de%20sensoriamento%20visando%20efici%c3%aancia%20energ%c3%a9tica%20atrav%c3%a9s%20da%20redu%c3%a7%c3%a3o%20de%20transmiss%c3%a3o%20de%20dados%20em%20redes%20de%20sensores%20sem%20fio.pdf","",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/5770","Campus A.C. Simões","Instituto de Computação","Dissertação","Perfil metabolômico das águas fecais de pacientes com carcinoma colorretal através de espectroscopia de ressonância nuclear magnética","('Arthur Dantas Vieira',)","('Manoel Álvaro de Freitas Lins Neto',)","('Edgar Valente de Lima Neto', 'Michelle Jacintha Cavalcante Oliveira', 'Jorge Artur Peçanha de Miranda Coelho')","O Carcinoma Colorretal (CCR) é uma das principais causas de mortalidade associada ao câncer em todo o mundo. No intuito de reduzir a morbimortalidade desta doença, técnicas de rastreio (screening) do paciente assintomático são extensamente estudadas na literatura. A videocolonoscopia com biópsia é largamente utilizada, mas apresenta uma taxa considerável de morbidade inerentes à procedimentos invasivos de diagnóstico. Diante do citado, a metabolômica têm surgido como alternativa viável e com aceitável sensibilidade e especificidade para diagnóstico do CCR. O estudo metabolômico de material fecal tem provado ter maior efetividade visto à proximidade com a mucosa do intestino grosso e por ser produto direto de interações entre compostos da dieta e microbiota intestinal. Na tentativa de distinguir um padrão metabólico de pacientes sadios em relação à pacientes portadores de CCR, foi realizada a análise das águas fecais destes grupos distintos através de espectroscopia por ressonância nuclear magnética (ERNM). Objetivos: procurar diferenciar um perfil metabólico típico de pacientes com CCR frente ao grupo controle (GC) e comparar estes resultados com uma revisão sistemática da literatura (RSL). Método: 11 pacientes do GC e 5 pacientes com CCR foram selecionados no ambulatório de coloproctologia do HUPAA. Relizou-se a análise de ERNM das águas fecais e posteriomente avaliação dos espectros de RNM por correlação estatística (STOCSY) pelo software SIMCA (umetrics.com). RSL foi efetuada nas bases PubMed, Web of Science, Cochrane e Scopus, usando palavras chaves relacionadas à câncer de cólon e ERNM, contemplando estudos publicados em inglês num período de 1992 à 2018. Resultados: os pacientes com CCR apresentaram redução em praticamente todas as vias metabólicas. Ácidos graxos de cadeia curta (acetato, propionato e butirato) e aminoácidos (alanina e glicina) apresentaram-se reduzidos frente ao GC (ANOVA, P < 0,05). Na RSL, identificou-se 386 estudos, dos quais 5 respondem diretamente à pergunta de pesquisa estabelecida, nos permitindo verificar que nas amostras fecais os AGCC e aminoácidos se apresentam em quantidades reduzidas em pacientes CCR. Conclusão: ERNM de águas fecais é um método factível para screenig do CCR. Porém, um aumento no interesse da comunidade científica em publicações em revistas de alto fator de impacto se faz necessário para estabelecê-lo como método gold standard de screening e diagnóstico precoce do câncer do cólon e reto.","Colorectal Carcinoma (CRC) is one of the leading causes of cancer-related mortality worldwide. In order to reduce the morbidity and mortality of this disease, screening techniques for asymptomatic patients are extensively studied in the literature. Biopsy by videocolonoscopy is widely used, but presents a considerable rate of morbidity inherent in invasive diagnostic procedures. In view of the above, metabolomics have emerged as a viable alternative and with acceptable sensitivity and specificity for CRC diagnosis. The metabolic study of faecal material has been shown to be more effective because of its proximity to the mucosa of the large intestine and because it is a direct product of interactions between dietary compounds and intestinal microbiota. In an attempt to distinguish a metabolic pattern of healthy patients in relation to patients with CRC, fecal analysis of these distinct groups was performed by magnetic resonance spectroscopy (MRE). Objectives: to differentiate a typical metabolic profile of CRC patients versus the control group (CG) and to compare these results with a systematic review of theliterature (SRL). Method: 11 patients from GC and 5 patients with CRC were selected at the HUPAA coloproctology outpatient clinic. Faecal MRE analysis and subsequent evaluation of MRI spectra by statistical correlation (STOCSY) were performed by SIMCA software (umetrics.com). SRL was performed in the PubMed, Web of Science, Cochrane and Scopus databases, using key words related to colon cancer and MRE, considering studies published in English from 1992 to 2018. Results: CRC patients showed reduction in practically all metabolic pathways. Short chain fatty acids -SCFA (acetate, propionate and butyrate) and amino acids (alanine and glycine) were reduced against CG (ANOVA, P <0.05). In the SRL, 386 studies were identified, of which 5 respond directly to the established research question, allowing us to verify that in the fecal samples the SCFA and amino acids are present in reduced amounts in CRC patients. Conclusions: MRE of faecal extract is a feasible method for CRC screening. However, an increase in the interest of the scientific community in publications in high impact factor journals is necessary to establish it as a gold standard method of screening and early diagnosis of colon and rectal cancer.","('Espectroscopia de ressonância magnética nuclear', 'Cancer colorretal – Diagnóstico', 'Metabolômica', 'Screening', 'Nuclear magnetic resonance spectroscopy', 'Colorectal Cancer – Diagnosis', 'Metabolomics')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/5770","2019-02-28","https://www.repositorio.ufal.br/bitstream/riufal/5770/1/Perfil%20metabol%c3%b4mico%20das%20%c3%a1guas%20fecais%20de%20pacientes%20com%20carcinoma%20colorretal.pdf","Metabolic profile of fecal waters of patients with colorectal carcinoma by magnetic resonance spectroscopy","('Luiz Carlos Caetano',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/1630","Campus A.C. Simões","Instituto de Computação","Dissertação","Onto-acits: uma ontologia para o processo de gerenciamento da disponibilidade e continuidade de serviços de tecnologia da informação","('Luam Leiverton Pereira dos Santos',)","('Marcus de Melo Braga',)","('Alan Pedro da Silva', 'Robson do Nascimento Fidalgo')","Este trabalho teve como objetivo desenvolver um modelo, baseado em ontologias, para a representação do conhecimento dos processos de disponibilidade e continuidade de serviços de Tecnologia da Informação, visando auxiliar o Gestor de Serviços de TI e constituir uma base de conhecimento do domínio, contribuindo para a aprendizagem organizacional em uma instituição federal de Ensino Superior. A ontologia proposta baseia-se em padrões e frameworks, tais como a ITIL e a ISO 20.000, que abrangem boas práticas reconhecidas pelo mercado, estabelecendo seu vocabulário, conceitos, propriedades, axiomas, restrições e fluxos recomendados para sua execução. O processo de desenvolvimento adotou a metodologia Methontology, associada à proposta de Gruninger e Fox, com a especificação formal dos axiomas nas linguagens OWL-DL e SPARQL. A implementação foi realizada com a ferramenta Protegé, com o auxílio da máquina de inferência Pellet, e a avaliação levou em consideração o compromisso ontológico, a abrangência e o escopo. A instanciação foi realizada atendendo à s questões de competência e homologada por gestores de serviços de TI, utilizando a metodologia FOCA, para a verificação das heurísticas de adequação aos requisitos de representação do conhecimento. A ontologia proposta, denominada Onto-ACITS, estabelece os elementos essenciais a serem considerados na descrição do domínio, na implementação e na operacionalização de atividades de manutenção relacionadas à Gestão de Disponibilidade e Continuidade de Serviços de TI, tornando esse conhecimento acessível inteligível e passível a processamento computacional.","This work has as its objective the development of a model, based on ontologies, for the knowledge representation of the availability and continuity of IT services management processes seeking to help IT service managers, and constituting a knowledge base for its domain, contributing to the organizational learning in a Federal Institution of Education. The proposed ontology is based on patterns and frameworks, like ITIL and ISO 20.000, that includes good practices recognized by the market, and establishes its own vocabulary, concepts, properties, axioms, restrictions and the flows recommended for its execution. Its development process adopted the Methontology methodology, associated with the Gruninger and Fox proposal, with the formal specification of the axioms in the OWL-DL and SPARQL languages. Its implementation was accomplished through the tool ProtegÃ© and the aid of the inference machine Pellet. Its evaluation took into account the ontologic commitment, the coverage and the scope. The instantiation was done with competence questions, the approval of services managers and the use of the FOCA methodology, to verify the heuristics for its adaptation to the requirements of knowledge representation. The final result of this work, the Onto-ACITS ontology, establishes the essential elements considered in the domain description, implementation and operationalization of the maintenance activities related to the availability and continuity IT service management, making this knowledge accessible, intelligible and subject to computational processing.","('Ontologias', 'Tecnologia da informação -Administração', 'Instituições de ensino superior', 'Ontology', 'Information technology', 'Higher education institution')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1630","2016-03-18","https://www.repositorio.ufal.br/bitstream/riufal/1630/1/Onto-acits%3a%20uma%20ontologia%20para%20o%20processo%20de%20gerenciamento%20da%20disponibilidade%20e%20continuidade%20de%20servi%c3%a7os%20de%20tecnologia%20da%20informa%c3%a7%c3%a3o.pdf","Onto-acits: an antology for the process of readiness and continuity of services of information technology management",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/1607","Campus A.C. Simões","Instituto de Computação","Dissertação","Otimização de rotas de helicópteros offshore utilizando algoritmo genético","('Allan Ronney Vianna Motta',)","('João Inácio Soletti',)","('Manoel Agamemnon Lopes', 'Mauro Antonio da Silva Sá Ravagnani')","Com a descoberta de petróleo na camada do pré-sal, em regiões oceânicas do Brasil, se desperta a necessidade de incrementar dispositivos tecnológicos de análise, para dar sustentabilidade ao sistema produtivo de combustível no país. A partir daí, vislumbra-se a problemática do controle de tráfigo aéreo de helicópteros offshore, que dão suporte logístico às plataformas de petróleo e a otimização de rotas. Então, neste trabalho propusemos minimizar rotas, diminuindo, portanto o consumo de combustível destas aeronaves, bem como otimizar o tempo gasto com as viagens entre plataformas e aeroportos, utilizando os métodos heurísticos de Algoritmos Genéticos. Para a realização de uma melhor análise, fizemos duas implementações, sendo a primeira com Algoritmo Genético de Holland e a segunda com Algoritmo Genético Baseado em Tipos Abstratos de Dados -GAADT, obtendo resultados com melhor desempenho na segunda implementação.","This with the discovery of oil in the Pre-Salt layer, in oceanic regions of Brazil, it is aroused the need to improve technological devices of analysis, to ensure the sustainability of the system of fuel production in the country. From there we conjecture about the problem of air traffic control of offshore helicopters, which give logistical support to oil platforms and to optimization of routes. In this job, we proposed to minimize routes, thus decreasing the fuel consumption of these aircraft, as well as to optimize the time spent on travel between airports and platforms, using the heuristics methods of Genetic Algorithms. To perform a better analysis, we made two deployments, the first with Holland's Genetic Algorithm and the second with Genetic Algorithm Based on Abstract Data Types -GAADT, getting results with better performance in the second implementation.","('Otimização de rotas', 'Helicóptero offshore', 'Algoritmo genético de Holland', 'GAADT', 'Optimization of routes', 'Offshore helicopters', ""Holland's Genetic Algorithm"")","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1607","2013-09-19","https://www.repositorio.ufal.br/bitstream/riufal/1607/1/Otimiza%c3%a7%c3%a3o%20de%20rotas%20de%20helic%c3%b3pteros%20offshore%20utilizando%20algoritmo%20gen%c3%a9tico.pdf","Optmization of routes of offshore helicopters using genetic algorithm","('Roberta Vilhena Vieira Lopes',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/123456789/10724","Campus A.C. Simões","Instituto de Computação","Dissertação","Otimização da atribuição de condutores em clínicas no Detran-AL","('Guilherme Peixoto de Souza',)","('Rian Gabriel Santos Pinheiro',)","('André Luiz Lins de Aquino', 'Luiz Satoru Ochi')","Em cumprimento ao art. 3º da resolução 1636/2002 do Conselho Federal de Medicina, deve-se distribuir exames clínicos e/ou psicológicos pertencentes aos processos do Departamento Estadual de Trânsito de Alagoas, de forma equitativa e imparcial em relação às clínicas credenciadas ao órgão, gerando assim o Problema de Atribuição do Detran (PAD). Com o objetivo de melhor alocar os candidatos para a realização de exames de forma equitativa nas clínicas, é estudada uma variante do Problema de Atribuição, um problema clássico de otimização, que tem como objetivo alocar n tarefas a m agentes, a fim de minimizar o custo total das atribuições. No caso do PAD, tem-se como entrada um conjunto de clínicas C e um conjunto de condutores M e como objetivo a atribuição de cada condutor a exatamente uma clínica de forma a minimizar o custo total de deslocamento. O que diferencia o PAD do problema clássico de atribuição é a restrição criada pela divisão equitativa entre as clínicas. Seja k = [M||C|] a razão entre a quantidade de condutores e a quantidade de clínicas, no PAD todas as clínicas devem receber exatamente k ou k +1 condutores. A partir da base de dados do órgão de 2018, foram propostos dois modelos de otimização, o primeiro resolve o PAD alocando os condutores em clínicas minimizando a distância total. Do ponto de vista teórico, foi provado que a matriz de coeficientes do PAD é totalmente unimodular, implicando que o problema pode ser resolvido em tempo polinomial. O segundo, nomeado PAD+, tem como objetivo sugerir a localização de uma nova clínica a ser credenciada ao DETRAN. Devido a erros de digitação nos endereços dos condutores, foi proposto um modelo de classificação com base em técnicas de rede neural para inferir o bairro de cada condutor. Foi constatado que o modelo utilizado de redes neurais conseguiu atingir uma acurácia de aproximadamente 92% na base. Com relação aos modelos de otimização, o modelo PAD reduziu em 30.07% o custo total de deslocamento dos candidatos para as clínicas. Já a sugestão de uma localidade, feita pelo modelo PAD+, diminuiu em até 67,16% o custo total em relação à alocação original. Por fim, por meio de uma análise de sensibilidade, é investigado o efeito na solução obtida do PAD em caso de variação nos parâmetros de entrada. Com isso, foi possível determinar as localidades das clínicas que mais influenciam no deslocamento dos candidatos.","In compliance with art. 3 of resolution 1636/2002 of the Federal Council of Medicine, clinical and/or psychological examinations belonging to the processes of the State Department of Traffic of Alagoas (Detran-AL) must be distributed, in an equitable and impartial way in relation to the clinics accredited to the agency, therefore generating the Detran Attribution Problem (PAD). In order to better allocate candidates for exams in an equitable manner in clinics, in this work studied a variant of the Attribution Problem (Assignment Problem), a classic optimization problem, which aims to allocate n tasks to m agents, in order to minimize the total cost of assignments. In the case of PAD, a set of clinics C and a set of conductors M are entered and the objective is to assign each driver to exactly one clinic in order to minimize the total cost of travel. What differentiates PAD from the classic attribution problem is the constraint created by the equitable division between clinics. Let k = [|M||C|] be the ratio between the number of drivers and the number of clinics, in the PAD all clinics should receive exactly k or k +1 drivers. Two optimization models have been proposed, the first one solves the PAD by allocating drivers in clinics, minimizing the total distance. From a theoretical point of view, it was proved that the PAD coefficient matrix is totally unimodular, implying that the problem can be solved in polynomial time. The second model, named PAD+, aims to suggest the location of a new clinic to be accredited to DETRAN. Due to typing errors in the driver’s addresses, a classification model was proposed based on recurrent neural network techniques to infer each driver’s neighborhood. It was found that the model used of neural networks managed to achieve an accuracy of approximately 92% on the validation basis. Regarding the optimization models, the first model proposed reduced by 30.07% the total cost of displacing candidates to the allocated clinics. The suggestion of a location, made by the second model, reduced the total cost by up to 67.16% in relation to the original allocation. Finally, through a sensitivity analysis, the effect on the solution obtained from the PAD in case of variation in the input parameters is investigated. Therefore, it was possible to determine the locations of the clinics that most influence the displacement of the candidates.","('Otimização linear', 'Algoritmo – Clínicas – Detran-AL', 'Redes neurais', 'Detran – Otimização', 'Optimization', 'Algorithm', 'Assignment problem', 'Public service')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/10724","2021-04-27","https://www.repositorio.ufal.br/bitstream/123456789/10724/1/Otimiza%c3%a7%c3%a3o%20da%20atribui%c3%a7%c3%a3o%20de%20condutores%20em%20cl%c3%adnicas%20no%20Detran-AL.pdf","",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/123456789/8864","Campus A.C. Simões","Instituto de Computação","Dissertação","Percepção de carga de trabalho na recomendação de recursos educacionais apoiada por inteligência artificial: um experimento controlado com professores","('Alexandre José Barros Machado',)","('Diego Dermeval de Medeiros da Cunha Matos',)","('Ranilson Oscar Araújo Paiva', 'Alan Pedro da Silva', 'Rafael Ferreira Leite de Mello')","A utilização das Tecnologias de Informação e Comunicação está cada vez mais evidente nos ambientes educacionais. As plataformas educacionais on-line podem ajudar os alunos e professores na complexidade formativa do ensino e aprendizagem em diversas áreas do conhecimento. Dentre as plataformas educacionais voltadas para o e-learning, temos os Sistemas Tutores Inteligentes -STI, que permitem um ambiente educacional adaptativo com suporte de recursos automatizados de recomendações, realizados por técnicas de inteligência artificial, tendo como objetivo a aprendizagem dos alunos de acordo com os seus perfis de utilização. Nesse sentido, pesquisadores têm se interessado cada vez mais em fornecer aos professores estratégias para monitorar e adaptar o design da gamificação no contexto de STIs de forma a utilizar as capacidades inerentemente humanas dos professores para ajustar o design da gamificação de acordo com o desempenho dos alunos. Contudo, essa dissertação investiga qual a percepção dos professores em relação ao seu esforço cognitivo e tempo de dedicação na criação e monitoramento de recomendações por missões em uma plataforma educacional simulada. Este estudo irá comparar três grupos de professores, utilizando um dos cenários (manual, automatizado e semi-automatizado) de acompanhamento de uma plataforma educacional simulada. Cada um dos cenários será utilizado em um experimento randomizado, onde os 151 professores participantes avaliaram através de um formulário qual é a sua percepção de esforço cognitivo e tempo dedicado para a criação de recomendações por missões e acompanhamento dos alunos na plataforma. Tendo resultados significantes nas hipóteses levantadas: a percepção dos professores que o cenário automatizado apresenta menor carga de trabalho menor que a do cenário manual. Ao avaliar os professores por gênero, os resultados indicaram que a percepção da demanda mental no cenário automatizado é significativamente diferente para as professoras que participaram do experimento, na percepção delas, o cenário automatizado apresenta a menor demanda mental. A percepção dos professores para o cenário manual é diferente de acordo com o nível de conhecimento sobres as Tecnologias da Informação e Comunicação (TIC), para os professores respondentes que possuem conhecimento avançado em TIC, o cenário manual é percebido como um cenário que demanda maior desempenho. A percepção de demanda mental para o cenário automatizado é significativamente diferente de acordo com o nível educacional que os professores ensinam, sendo que, para os professores de ensino médio profissionalizante/técnico o cenário automatizado é percebido como um cenário que precisa de maior demanda mental do que para os professores do ensino superior. Sendo contribuições importantes para entender a percepção dos professores ao utilizar plataformas educacionais em suas turmas.","The use of Information and Communication Technologies is increasingly evident in educational environments. Online educational platforms can help students and teachers in the formative complexity of teaching and learning in different areas of knowledge. Among the educational platforms aimed at e-learning, we have the Intelligent Tutoring Systems -STI, which allow an adaptive educational environment supported by automated resources of recommendations, carried out by artificial intelligence techniques, with the objective of learning students according to your usage profiles. In this regard, researchers have become increasingly interested in providing teachers with strategies to monitor and adapt gamification design in the context of STIs in order to utilize teachers' inherently human capabilities to adjust gamification design according to student performance. . However, this dissertation investigates the perception of teachers in relation to their cognitive effort and time of dedication in creating and monitoring mission recommendations in a simulated educational platform. This study will compare three groups of teachers, using one of the scenarios (manual, automated and semi-automated) to monitor a simulated educational platform. Each of the scenarios will be used in a randomized experiment, where the 151 participating teachers evaluated, through a form, what is their perception of cognitive effort and time dedicated to creating recommendations for missions and monitoring students on the platform. Having significant results in the raised hypotheses: the teachers' perception that the automated scenario presents a lower workload than the manual scenario. When evaluating the teachers by gender, the results indicated that the perception of mental demand in the automated scenario is significantly different for the teachers who participated in the experiment, in their perception, the automated scenario presentes the lowest mental demand. The teachers' perception of the manual scenario is diferente according to the level of knowledge about Information and Communication Technologies (ICT), for respondent teachers who have advanced knowledge in ICT, the manual scenario is perceived as a scenario that demands greater performance. The perception of mental demand for the automated scenario is significantly diferente according to the educational level that teachers teach, and for vocational/technical secondary school teachers the automated scenario is perceived as a scenario that needs greater mental demand from the than for higher education teachers. These are important contributions to understanding the perception of teachers when using educational platforms in their classes.","('Sistemas tutores inteligentes', 'Autoria', 'Ambiente educacional gamificado', 'Decisão baseada em dados', 'Percepção dos professores', 'Intelligent Tutoring Systems', 'Authorship', 'Gamified Educational Environments', 'Data-Based Decisions')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/8864","2021-11-30","https://www.repositorio.ufal.br/bitstream/123456789/8864/1/Percep%c3%a7%c3%a3o%20de%20carga%20de%20trabalho%20na%20recomenda%c3%a7%c3%a3o%20de%20recursos%20educacionais%20apoiada%20por%20intelig%c3%aancia%20artificial%20-%20um%20experimento%20controlado%20com%20professores.pdf","Workload perception in the recommendation of educational resources supported by intelligence artificial: a controlled experiment with teachers",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/1602","Campus A.C. Simões","Instituto de Computação","Dissertação","O papel da distância em projetos topológicos de redes de distribuição elétrica","('Paulo Wagner Lopes da Silva',)","('Henrique Pacca Loureiro Luna',)","('Evandro de Barros Costa', 'Elizabeth Ferreira Gouvêa Goldbarg', 'Carlos Antonio Alves de Oliveira')","O presente trabalho visa investigar sob quais condições a configuração ótima de uma rede de distribuição elétrica é uma árvore geradora mínima (AGM) e sob quais é uma árvore de caminhos mínimos (ACM). Utilizando, para isso, modelos matemáticos computacionais de otimização topológica de redes de utilidade pública. As redes de distribuição estudadas foram do tipo aérea radial primária protegida (ARPP) com nível de tensão em 13,8 kV. Os modelos utilizados prezam pelo equilíbrio entre o custo de investimento inicial (fixo) e os custos decorrentes da transferência de energia elétrica (variável). Os valores economizados através de uma configuração ótima da rede podem ser convertidos em investimentos para aumentar o número de pessoas com acesso aos recursos energéticos com eficiência e qualidade. A revisão bibliográfica foi dividida em três partes: teoria dos grafos, modelos de otimização de redes de acesso local e custos de redes de distribuição. A metodologia utilizada compreendeu as seguintes etapas: escolha do tipo de sistema de distribuição, determinação dos custos fixo e variável, escolha e implementação (GAMS) dos modelos, testes com exemplos de redes usando o solver CPLEX, análise das configurações resultantes e elaboração de gráficos para facilitar a avaliação dos resultados. Os resultados mostraram que a relação entre o custo fixo B e o custo variável Y exerce influência determinante na configuração ótima de uma rede de distribuição ARPP. Um valor baixo de B/Y, favorece a ACM. Já valores elevados de B/Y, conduzem a solução para uma AGM. No entanto, essa relação não e o único fator que determina a confïguração da rede, outros parâmetros como extensão, demanda dos nós e quantidade de possíveis arcos influenciam de forma significativa na solução apresentada.","This dissertation investigates in which conditions the optimal configuration of an electric power network is a minimum length spanning tree, and in which conditions it is shortest path tree configuration. For this purpose the dissertation, it applies computational optimization mathematical models of an optimal local access network design problem. The focus of the study is the 13.8 kV spacer cable primary radial networks. Applied models seek for the balance between fixed costs and variable costs. Saved values from an optimal network could be applied to increase the range of the network and people reached as well. The bibliographic research is compound by three parts: graph theory, local access network optimization models, and distribution network costs. Research methodology includes the choice of the distribution system, determination of fixed and variable costs, choice and implementation of the local access network optimization models, tests in hypothetical and realistic systems by using the CPLEX solver, analysis of the resulting configuration, and construction of graphics to facilitate the results evaluation. It was found that the relationship between fixed costs and variable costs inï¬‚uences the optimal configuration of the distribution network in such a way that a low value of the quotient between fixed costs and variable costs contributes to a shortest path tree. On the other hand, a high quotient between fixed costs and variable costs contributes to a minimum length spanning tree confïguration. However, others parameters must be considered to determine the network confïguration such as extension, arches demand and quantity of arches.","('Redes de distribuição -Configuração e Custos', 'Árvore de caminho mínimo', 'Árvore geradora mínima', 'Modelos de otimização de redes', 'Distribution networks conïfiguration', 'Shortest-path tree', 'Minimum length spanning tree', 'Local access network design models', 'Distribution networks costs')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1602","2015-05-20","https://www.repositorio.ufal.br/bitstream/riufal/1602/1/O%20papel%20da%20dist%c3%a2ncia%20em%20projetos%20topol%c3%b3gicos%20de%20redes%20de%20distribui%c3%a7%c3%a3o%20el%c3%a9trica.pdf","The role of distances in topological design of electrical distribution networks","('João Inácio Soletti',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/2980","Campus A.C. Simões","Instituto de Computação","Dissertação","Um padrão de agrupamento de cidades a partir da dinâmica social urbana extraída de dados provenientes de redes de sensores participativos","('Vilker Tenório Cabral Lobo',)","('Heitor Soares Ramos Filho',)","('André Luiz Lins de Aquino', 'Ivan César Martins', 'Thiago Henrique Silva')","A dinâmica das cidades vem sendo estudada ao longo dos anos, tendo diversas aplicações, como planejamento urbano, estudo de propagação de doenças, sistemas de previsão de tráfego, de recomendações para locais e estudos do comportamento social humano. No entanto, com a evolução tecnológica, em especial, a popularização do uso dos smartphones e a massificação do acesso à Internet, é apresentada uma nova oportunidade para se realizar tal tipo de estudo, o uso de dados de mídia social para o estudo populacional. Nesse contexto, este trabalho se propõe a apresentar uma nova maneira de se comparar cidades, utilizando como medida de similaridade o padrão de mobilidade social dos seus habitantes. Como modo de validar o estudo, foram utilizados 1.601.323 check-ins do Foursquare distribuídos por 10 cidades em um período de 33 dias, a fim de -utilizando as métricas propostas – apresentar diferentes padrões de agrupamento das cidades.","The dynamics of cities have been studied over the years, with various applications such as urban planning, disease propagation studies, traffic forecasting systems, local recommendations and studies of human social behavior. However, with the technological evolution, especially the popularization of the use of smartphones and the massification of Internet access, a new opportunity is presented to carry out such a study, the use of social media data for the population study. In this context, this paper aims to present a new way to compare cities, using as similarity measure the pattern of social mobility of its inhabitants. As a way to validate the study, 1.601.323 Foursquare check-ins were used spread over 10 cities in a period of 33 days in order to -using the proposed metrics -present different patterns of grouping the cities.","('Computação urbana', 'Redes de sensores participativos', 'Cadeias de Markov', 'Dinâmica das cidades', 'Urban Computing', 'Participatory Sensing', 'Markov Chain', 'Dynamics of Cities')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/2980","2017-09-29","https://www.repositorio.ufal.br/bitstream/riufal/2980/1/Um%20padr%c3%a3o%20de%20agrupamento%20de%20cidades%20a%20partir%20da%20din%c3%a2mica%20social%20urbana%20extra%c3%adda%20de%20dados.pdf","A pattern of city grouping from urban social dynamics extracted from data from participatory sensor networks",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/123456789/10811","Campus A.C. Simões","Instituto de Computação","Dissertação","Multivariate modeling to handle urban air pollution data observed trough vehicular sensor networks","('Israel Loureiro Cavalcante Vasconcelos',)","('André Luiz Lins de Aquino',)","('Raquel da Silva Cabral', 'Édler Lins de Albuquerque')","Este trabalho apresenta uma avaliação interdisciplinar analisando o monitoramento da qualidade do ar em ambientes urbanos. Este tipo de aplicação se enquadra adequadamente sob o paradigma das redes de sensores sem convencionais. No referido contexto, um conjunto robusto e diversificado de soluções vem sendo desenvolvido a medida que são aprimorados os recursos tecnológicos. A aplicação de modelagem proposta aproveita-se das Redes de Sensores Veiculares (VSN) ao incorporar nós sensores ao transporte público, utilizando no presente caso de estudo as linhas de ônibus disponíveis de modo que os veículos dispersem a atividade de amostragem pelos diferentes locais visitados durante seu percurso. Simultaneamente, as restrições de gerenciamento de energia, dimensões da embalagem (tamanho e peso) e problemas gerais de manutenção também são aliviadas. É realizada uma modelagem ambiental com base em dados reais considerando o comportamento multivariado temporal e espacial dos fenômenos observados. Consideramos a cidade de São Paulo em nosso estudo de caso e analisamos os dados meteorológicos para criar um mapa multivariado a partir das amostras, expondo o comportamento de cinco diferentes poluentes atmosféricos (CO, O3, PM10 , NO2 e SO2) simultaneamente variando em função do tempo. O arcabouço de modelagem proposto contempla os processos de tratamento dos dados de entrada, que apresentam informações não formatadas ou ausentes devido a serem originados por sensores reais, além da criação do mapa mencionado acima. Nossa metodologia aborda: 1) a simulação ambiental e urbana anteriormente mencionada, 2) distribuição dos nós sensores móveis e realização do processo de detecção, 3) implementação das atividades de rede e entrega de dados coletados, 4) visualização do ambiente monitorado com base em dados coletados, usando Diagramas de Voronoi para preencher dados em branco em áreas não atingidas. Por fim, alguns desdobramentos de nosso trabalho, na área de pesquisa, são a avaliação de desempenho em nível de sistema e suas restrições operacionais por meio de uma simulação baseada em eventos, levando em consideração uma descrição detalhada de estradas, linhas de ônibus, itinerários de veículos e informações gerais de tráfego.","This work presents an interdisciplinary assessment that looks in-depth at the tracking of air quality in urban environments. This kind of application is well suited to be approached with wireless sensor networks’ paradigm in their overall variations. Therefore a robust and diverse set of solutions have been developed following the technology capabilities advance. The proposed modeling application takes advantage of Vehicle Sensor Networks (VSN) by embedding sensor nodes to public transportation, addressing this study case with bus lines so that the mobiles spread the sampling activity through a large number of different places visited during the route. Simultaneously, it alleviates power management restrictions, packaging dimensions (size and weight), and general maintenance issues. We perform environmental modeling based on real data considering a temporal and spatial multivariate behavior on observed phenomena. We consider the city of São Paulo in our case study and parse the asserted data to create a multivariate map of samples, showing the behavior of five different air pollutants (CO, O3, PM10, NO2 and SO2) simultaneously while it also varies in time. The current development stage covers handling processes over input data that has unformatted or missing information due to being sourced from real sensors and creating the map mentioned above. Our methodology addresses: 1) the mentioned environmental simulation, 2) deploying mobile sensor nodes and perform sensing process, 3) implement network activity and delivery of collected data, 4) visualization of monitored environment based on gathered data using Voronoi Diagrams to fill blank data at non reached areas. Finally, some outspread of our work, in the research area, are the evaluation system-level performance and operational constraints through an eventbased simulation, taking into account a detailed description of roads, bus lines, vehicle itineraries, and general traffic information.","('Modelagem ambiental', 'Rede de sensores – Veículos', 'Análise multivariada', 'Environmental modeling', 'Vehicle sensor networks', 'Multivariate data analysis')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/10811","2021-01-29","https://www.repositorio.ufal.br/bitstream/123456789/10811/1/Multivariate%20modeling%20to%20handle%20urban%20air%20pollution%20data%20observed%20trough%20vehicular%20sensor%20networks.pdf","",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/1829","Campus A.C. Simões","Instituto de Computação","Dissertação","Um novo algoritmo para filtragem de speckle em imagens SAR de intensidade baseado em distâncias estocásticas","('Leonardo José Tenório Mourão Torres',)","('Alejandro César Frery Orgambide',)","('André Luiz Lins de Aquino', 'Osvaldo Aníbal Rosso', 'Corina da Costa Freitas')","Este trabalho apresenta um novo algoritmo para filtragem de ruído speckle com base em distâncias estocásticas e testes entre distribuições. Uma janela é definida em torno de cada pixel e amostras sobrepostas são comparadas. Apenas aquelas que passarem por um teste de significância são utilizadas para calcular o valor filtrado. Modificações nas janelas Nagao-Matsuyama foram usadas para definir as amostras. A técnica é aplicada a imagens de Radar de Abertura Sintética (SAR) de intensidade homogênea, usando o modelo gama ¡(L,L/λ) comnúmero variável de looks L permitindo asmudanças na heterogeneidade. A proposta é comparada como filtro de Lee, que é considerado umpadrão, utilizando umprotocolo baseado emMonte Carlo. Analisamos também, o comportamento do filtro emdados reais. Entre os critérios utilizados para quantificar a qualidade dos filtros estão: o número equivalente de looks (relacionada coma relação sinal-ruído), preservação da linha e preservação das bordas. Alémdisso, os filtros foramavaliados pelos Índice Universal de Qualidade de Imageme a Correlação de Pearson emregiões de bordas. Estasmedidas fizeramvaler a proposta emdados simulados, que apresentaram ótimos resultados nos cenários adotados. Em particular, o filtro proposto reduziu o speckle, preservou bordas e características de textura mantendo uma boa relação sinal-ruído em dados SAR. Também foram abordadas aplicações em imagens SAR reais, que foram validadas com medidas numéricas. O método é bastante geral e pode ser estendido para outras situações, desde que haja um modelo estatístico subjacente. Assim, o novo filtro foi estendido para atuar em imagens PolSAR modeladas pela distribuição Wishart Z ~W(Σ,L), em que L é o número equivalente de looks e Σ é uma matriz de covariância.","This dissertation work presents a new approach for filter design based on stochastic distances and tests between distributions. A window is defined around each pixel, overlapping samples are compared and only those which pass a goodness-of-fit test are used to compute the filtered value. Modified Nagao-Matsuyamawindows are used to define the samples. The technique is applied to intensity Synthetic Aperture Radar (SAR) data with homogeneous regions, using the Gamma model ¡(L,L/λ) with varying number of looks L allowing, thus, changes in heterogeneity. The proposal is compared with the Lee’s filter which is considered a standard, using a protocol based on Monte Carlo. We also analyzed the behavior of the filter on real data. Among the criteria used to quantify the quality of filters, we employ the equivalent number of looks (related to the signal-to-noise ratio), line contrast, and edge preservation. Moreover, we also assessed the filters by the Universal Image Quality Index and, the Pearson’s correlation on edges regions. Thesemeasuresmade use of the proposal on simulated data, which showed excellent results in the scenarios adopted. In particular, the proposed filter reduces the speckled, has preserved edges and texture features that keeps a good signal-to-noise in SAR data. Also been discussed applications in real SAR images, which were validated with numericalmeasurements. Method is quite general and can be extended to other conditions, provided that there is an underlying statisticalmodel. Thus, the new filter has been extended to operate in PolSAR images modeled by Wishart distribution Z ~W(Σ,L), where L is equivalent number of looks and Σ is a covariancematrix.","('Teoria da informação', 'Algoritmo', 'Speckle', 'Information theory', 'Algorithm')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1829","2012-06-01","https://www.repositorio.ufal.br/bitstream/riufal/1829/1/Um%20novo%20algoritmo%20para%20filtragem%20de%20speckle%20em%20imagens%20SAR%20de%20intensidade%20baseado%20em%20dist%c3%a2ncias%20estoc%c3%a1sticas.pdf","A new algorithm to speckle filtering on intensity SAR images based on stochastic distances",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/1159","Campus A.C. Simões","Instituto de Computação","Dissertação","Um modelo para o ensino do processo de negociação policial baseado em redes de Petri","('Sidney Pontes Viana',)","('Fábio Paraguaçu Duarte da Costa',)","('Evandro de Barros Costa', 'Guilherme Ataíde Dias')","Modelo de Ensino do Processo de Negociação Policial Baseado em Redes de Petri é um estudo que tem como meta auxiliar o ensino do processo de negociação estratégica em situações críticas envolvendo reféns, permitindo o aprimoramento de Policiais Militares do Estado de Alagoas em ocorrências policiais não rotineiras. Na construção metodológica desse estudo foram adotados dois tipos de pesquisas: a pesquisa bibliográfica, mediante fontes impressas e fontes eletrônicas, e a pesquisa de campo, questionários e entrevistas com Policiais Militares lotados no Centro de Gerenciamento de Crise, Direitos Humanos e Polícia Comunitária (CGCDHPC) do Estado de Alagoas. Inicialmente, abordam-se os Ambientes de Aprendizagem, enfocando esses como um sistema de apoio em aprendizagem. Definem-se formalmente estratégias de persuasão com a finalidade de aplicá-las no processo de negociação policial. Compreende-se o processo de negociação estratégica em situações envolvendo reféns. Estudam-se os diversos modelos de ensino do processo de negociação estratégica. Ao final da pesquisa foram alcançados os seguintes resultados: proposta de um modelo de funcionamento das técnicas de persuasão, proposta de um modelo organizacional do processo de negociação estratégica e formalização do modelo do processo de negociação, envolvendo reféns, baseado em Redes de Petri.","Teaching model of the Police Negotiation Process Based on Petri Nets is a study that aims to help the teaching process of strategic negotiation in critical situations involving hostages, allowing the improvement of the Military Police of the State of Alagoas in non-routine police reports. Two types of research were used in the methodology construction of this study: literature research through printed and electronic sources, as well as field research, questionnaires and interviews with military policemen working at the Center of Crisis Management, Human Rights and Community Police (CGCDHPC) in the State of Alagoas. Initially, it discussed the Learning Environment, focusing them as a support system to the learning process. Strategies of persuasion are formally defined in order to be applied in the police negotiation process. We understood the process of strategic negotiation in situations where hostages are involved. We studied different teaching models of the strategic negotiation process. At the end of the study the following results were achieved: proposal for a working model of the persuasion techniques, propose an organizational model of strategic negotiation process and formalization of the model of negotiation process where hostages are involved, based on Petri Nets.","('Ambientes Interativos de Aprendizagem', 'Tecnologia educacional', 'Negociação Policial', 'Sistemas Inteligentes', 'Redes de Petri', 'Persuasão', 'Interactive Learning Environments', 'Police Negotiation', 'Intelligent Systems', 'Petri Nets')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/1159","2010-06-25","https://www.repositorio.ufal.br/bitstream/riufal/1159/1/Um%20modelo%20para%20o%20ensino%20do%20processo%20de%20negocia%c3%a7%c3%a3o%20policial%20baseado%20em%20redes%20de%20Petri.pdf","Teaching model of the Police negotiation based on Petri nets",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/123456789/8939","Campus A.C. Simões","Instituto de Computação","Dissertação","Modelos computacionais baseados em inteligência artificial e estatística para o apoio à decisão médica na escolha das fórmulas biométricas em catarata","('Mateus Lins dos Santos',)","('Aydano Pamponet Machado',)","('Jorge Artur Peçanha de Miranda Coelho', 'Frederico Augusto de Souza Pereira')","A catarata é a maior causa de cegueira reversível no mundo, apesar do tratamento cirúrgico seguro, reprodutível e com capacidade de corrigir erros refrativos e prevenir fenômenos fotodistópicos através do cálculo adequado, por meio de fórmulas biométricas, do poder refrativo da nova lente intraocular. Os resultados destas técnicas são bons, porém apresentam resultados inadequados em pacientes com olhos de medidas biométricas atípicas. Neste estudo desenvolvemos e apresentamos múltiplos modelos computacionais capazes de prever a precisão de cada fórmula intraocular em determinados grupos de indivíduos, inclusive para diferentes lentes intraoculares e subgrupos biométricos. Os algoritmos desenvolvidos neste estudo são capazes de auxiliar o oftalmologista na tomada de decisão e trazer melhores resultados na cirurgia de catarata.","Cataract is the leading cause of reversible blindness in the world, despite the safe, reproducible surgical treatment capable of correcting refractive errors and preventing photodystopic phenomena through the proper calculation, by means of biometric formulae, of the refractive power of the new intraocular lens. The technical results are good, but they present inadequate results in patients with eyes with atypical biometric measurements. In this study, we developed and presented multiple computational models capable of predicting the accuracy of each intraocular formula in certain groups, including different intraocular lenses and subgroups of individuals with similar biometric measures. The algorithms developed in this study are able to help the ophthalmologist in the decision making and bring better results in cataract surgery.","('Lente intraocular', 'Erro refrativo', 'Fórmulas biométricas', 'Cirurgia de catarata', 'Intraocular lenses', 'Refractive error', 'Biometric formulae', 'Cataract surgery')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/8939","2021-11-19","https://www.repositorio.ufal.br/bitstream/123456789/8939/1/Modelos%20computacionais%20baseados%20em%20intelig%c3%aancia%20artificial%20e%20estat%c3%adstica%20para%20o%20apoio%20%c3%a0%20decis%c3%a3o%20m%c3%a9dica%20na%20escolha%20das%20f%c3%b3rmulas%20biom%c3%a9trica%20em%20catarata.pdf","Computational models based on artificial and statistical intelligence to support medical decisions in the choice of biometric formulas in cataract","('João Marcelo de Almeida Gusmão Lyra',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/2116","Campus A.C. Simões","Instituto de Computação","Dissertação","Um modelo para apoiar a gestão educacional das IES com descoberta de conhecimento baseado no processo de autoavaliação institucional (SINAES)","('Leopoldo Ramos de Oliveira',)","('Patrick Henrique da Silva Brito',)","('Fábio Paraguaçu Duarte da Costa', 'José Osman dos Santos')","A Autoavaliação institucional é uma questão atual e de grande relevância no contexto da educação superior do Brasil. O problema desta pesquisa investigou como ajudar os gestores das IES a detectar as fragilidades na autoavaliação, tendo em vista o grande volume de dados oriundos dos formulários da avaliação do SINAES. A análise destas informações visa a apoiar a tomada de decisão por parte dos gestores. Na tentativa de responder tal questionamento, o objetivo precípuo deste trabalho é elaborar um modelo para viabilizar a aplicação sistemática da política do Sistema Nacional de Avaliação da Educação Superior (SINAES). Na elaboração do referencial teórico desta pesquisa, procurou-se contextualizar a política definida pelo SINAES para implementar a autoavaliação e mostrar como os recursos da Estatística aliada ao Processo de Descoberta de Conhecimento (KDD) para coleta, análise e descobertas de novos conhecimentos podem contribuir no processo avaliativo das IES. A Metodologia utilizada consistiu na construção de instrumentos de avaliação para os discentes e gestores a fim de gerar as estatísticas e obter informações implícitas utilizando mineração de dados. A mineração de dados foi utilizada principalmente para obter a relevância dos atributos da base através do software Rapid Miner. O passo seguinte foi a elaboração da relevância dos atributos da base por um especialista em avaliação institucional, tendo como base documentos oficiais da IES. Os resultados obtidos nas três avaliações (discentes, gestores e especialista) foram consolidados num gráfico para análise das divergências e identificação de problemas para gerar um modelo de apoio à gestão visando a minimizar os pontos frágeis detectados. Em seguida foi realizado um seminário com o colégio de dirigentes da IES para avaliar os impactos na gestão face ao novo conhecimento obtido através da Mineração dos dados e estes consideraram os novos conhecimentos importantes como ferramenta de apoio à tomada de decisão da IES.","The Institutional Self-evaluation is a matter of great current relevance in the context of higher education in Brazil. The problem investigated in this research: How to help managers IES Detecting weaknesses in promoting self-assessment and corrective actions in the short, medium and long term. In attempting to answer this question the ultimate goal of this work is to develop a model to enable the systematic application of the policy of the National Assessment of Higher Education (SINAES). In developing the theoretical framework of this research sought to contextualize the policy defined by SINAES to implement self-evaluation and show how the combined resources of Statistical Process Knowledge Discovery (KDD) for collection, analysis and discovery of new knowledge can contribute to the process IES.A of evaluative methodology used was the construction of assessment tools for learners and managers to generate statistics and through this database to perform these mining and obtain the relevance of the attributes of a database by the software Rapid miner. The next step was the elaboration of the relevance of the attributes of the base by a specialist in institutional assessment based on official documents IES.Os results of the three assessments (students, managers and specialist) were consolidated in a graphic for analysis and identification of differences of problems to generate a model of recommendation to minimize the weaknesses detected. After that a seminar was held with the leaders of the college of IES to assess impacts in managing against the new knowledge obtained through data mining and new knowledge they considered important as a tool to support decision making of IES.","('Mineração de dados (Computação)', 'Sistemas de suporte de decisão', 'Data mining (computing)', 'Decision support systems')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/2116","2012-12-20","https://www.repositorio.ufal.br/bitstream/riufal/2116/1/Um%20modelo%20para%20apoiar%20a%20gest%c3%a3o%20educacional%20das%20IES%20com%20descoberta%20de%20conhecimento%20baseado%20no%20processo%20de%20autoavalia%c3%a7%c3%a3o%20institucional%20%28SINAES%29.pdf","A model to support the educational management of institutions of higher education with knowledge discovery based on institutional self-evaluation process (SINAES)",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/1821","Campus A.C. Simões","Instituto de Computação","Dissertação","Modelo para a construção de sistemas tutores multiagentes","('Marlos Tacio Silva',)","('Evandro de Barros Costa',)","('Frederico Luiz Gonçalves de Freitas', 'Hyggo Oliveira de Almeida', 'Leandro Dias da Silva', 'Patrick Henrique da Silva Brito')","Este trabalho se insere na linha de pesquisa Modelos Computacionais em Educação do Programa de Pós-graduação Interdisciplinar em Modelagem Computacional de Conhecimento, observando-se que um dos grandes desafios da área de Sistemas Tutores Inteligentes continua sendo abordar adequadamente a complexidade inerente à construção desses sistemas. Nesse contexto, pode-se abordar três aspectos relacionados a esta questão, a saber: (1) carência de diretrizes que guiem os construtores (i.e., autores e desenvolvedores) envolvidos no processo de construção dos ambientes; (2) a lacuna conceitual entre o conhecimento do autor e as ferramentas disponíveis para a construção do sistema; e (3) falta de uma arquitetura de software flexível e adequada para o desenvolvimento de entidades de software inteligentes. Assim, o presente trabalho tem o objetivo de apresentar uma sistemática, dotada de modelos, para auxiliar na construção de Sistemas Tutores Multiagentes baseados na arquitetura Mathema. Do ponto de vista do autor, essa sistemática visa auxiliar na modelagem do conhecimento do domínio via uma estrutura de grafo. A partir dessa estrutura deriva-se uma rede de Petri, para verificação tanto de propriedades estruturais quanto comportamentais, e uma base de conhecimento, que irá ser operacionalizada por um planejador pedagógico. Do ponto de vista do desenvolvedor, essa sistemática visa utilizar a estrutura de grafo definida pelo autor para identificar um conjunto de agentes tutores e, a partir daí, construir efetivamente tais agentes com base em uma arquitetura de software mais flexível. Para a avaliação empírica da proposta desenvolveu-se um estudo de caso que consiste na estruturação de um curso de Ciência da Computação. Além disso, foram desenvolvidos mais estudos específicos, um no contexto de Lógica Computacional e outro no contexto de Aprendizagem de Máquina. Esses estudos mostraram a viabilidade da utilização da proposta, conseguindo obter resultados satisfatórios nas soluções apresentadas para responder as questões de pesquisa abordadas.","This work is situated in an interdisciplinary research program on computational modeling of knowledge, focusing on one challenge in the field of Intelligent Tutoring Systems with respect to manage the complexity involved in effectively building such systems. In this context, three aspects related to the mentioned challenge were addressed: (1) lack of concrete guidelines to be used by the involved actors (i.e., authors and developers) in the process of building this environments; (2) conceptual lack between the author’s knowledge and the available tools for that end; and (3) lack of a flexible and adequate software architecture for building intelligent software entities. Thus, this work aims to present a systematic approach with models to help the construction of Multiagent Tutoring Systems based on Mathema’s architecture. From the author point of view, this systematic aims to modeling a given domain via a graph structure. Based on this structure we derive a Petri net, to check both structural and behavioral properties and a knowledge base, which will be operated by a pedagogical planner. From the viewpoint of the developer, this systematic aims to use the graph structure defined by the author to identify a set of tutor agents and, thereafter, builds these agents based on flexible software architecture. For the empirical evaluation, we develop a case study consisting in structuring a course of Computer Science. In addition, more specific studies were developed, one in the context of Computational Logic and another in the context of Machine Learning. These studies demonstrate the feasibility of using the proposal, obtaining satisfactory results in the solutions presented to answer the research questions addressed.","('Mathema', 'Petri, Redes de', 'Ontologia', 'Petri, Networks of', 'Ontology')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1821","2012-06-04","https://www.repositorio.ufal.br/bitstream/riufal/1821/1/Modelos%20para%20a%20constru%c3%a7%c3%a3o%20de%20sistemas%20tutores%20multiagentes.pdf","Models for building multiagent tutoring systems",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/2103","Campus A.C. Simões","Instituto de Computação","Dissertação","Modelos computacionais baseados em aprendizagem de máquina para classificação do ceratocone por meio dos sinais biomecânicos fornecidos pelo Ocular Responder Analyser","('Edileuza Virginio Leão',)","('Aydano Pamponet Machado',)","('Leandro Dias da Silva', 'Renato Ambrósio Júnior')","O presente trabalho destina-se a desenvolver modelos computacionais baseados em inteligência artificial para detecção do ceratocone, criando métodos capazes de predizer a presença do ceratocone utilizando aprendizagem de máquina. Estes modelos utilizaram dados biomecânicos da córnea, proveniente dos sinais de aplanação e pressão do exame Ocular Response Analyzer (ORA). O objetivo é construir modelos computacionais para auxiliar na decisão do cirurgião refrativo entre realizar ou não a cirurgia em casos susceptíveis. Os modelos foram criados utilizando árvore de decisão e redes neurais dos tipos MLP e RBF e também processamento de sinais wavelet. O experimento foi dividido em duas fases: a primeira para conhecer e entender os sinais, identificando as características e regiões mais importantes; a segunda utilizando o processamento de sinais wavelet para extrair a informação relevante do sinal. Os vários modelos desenvolvidos em ambas as fases foram estudados e comparados. Os melhores resultados encontrados foram: para a taxa total de acerto 93,03%, taxa de sensibilidade 93,95% e taxa de especificidade 99,26%. Tendo como conclusão que os modelos desenvolvidos podem contribuir com o cirurgião refrativo em sua decisão no diagnóstico do ceratocone grau I e II.","This work aims to develop computational models based on artificial intelligence to detect keratoconus, creating methods to predict the presence of keratoconus using machine learning. These models used corneal biomechanical data, from the signs of applanation and pressure the Ocular Response Analyzer exam (ORA). The goal is to build computational models to help the refractive surgeon decide between performing surgery or not in cases susceptible. The models were created using neural networks the types of MLP and RBF and tree decision and also Wavelet signal processing. The experiment was divided into two phases: the first to know and understand the signals identifying the most important features and regions, and the second using the wavelet signal processing to extract the relevant information signal. The various models developed in two phases were studied and compared. The best results were: for total accuracy rate of 93.03%, 93.95% rate of sensitivity and specificity rate of 99.26%. The conclusion is that the developed models can contribute to the refractive surgeon in his decision in the diagnosis of keratoconus grade I and II.","('Ceratocone', 'Biomecânica', 'Córnea', 'Ocular Responder Analyser', 'Keratoconus', 'Biomechanics')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/2103","2013-11-01","https://www.repositorio.ufal.br/bitstream/riufal/2103/1/Modelos%20computacionais%20baseados%20em%20aprendizagem%20de%20m%c3%a1quina%20para%20classifica%c3%a7%c3%a3o%20do%20ceratocone%20por%20meio%20dos%20sinais%20biomec%c3%a2nicos%20fornecidos%20pelo%20Ocular%20Responder%20Analyser.pdf","Computational models based on machine learning to classify keratoconus through biomechanical signals provided by Ocular Responder Analyser","('João Marcelo de Almeida Gusmão Lyra',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/1606","Campus A.C. Simões","Instituto de Computação","Dissertação","Modelos computacionais para otimização da escolha do anel intraestromal em pacientes com ceratocone utilizando dados tomográficos da córnea","('Daniela de Almeida Lyra Antunes',)","('Aydano Pamponet Machado',)","('Marcelo Costa Oliveira', 'Leonardo Torquetti Costa')","O presente trabalho destina-se a melhorar a previsibilidade da asfericidade e da ceratometria média no pós-operatório de implante de anel intraestromal (SAIC) em pacientes com ceratocone por meio da criação de modelos computacionais baseados em aprendizagem de máquina, utilizando dados tomográficos da córnea. Foram incluídos 209 olhos de 160 pacientes com graus I, II e III de ceratocone submetidos a cirurgia com implante de SAIC. Em todos os pacientes foi implantado anel de Ferrara com 160o de arco com variação de espessura entre 150 e 250 µm e presença de 1 ou 2 segmentos. A base foi composta por parâmetros da tomografia de córnea pentacam®, dados clínicos e dados do anel de Ferrara totalizando 39 parâmetros. Para criação dos modelos, foram utilizados os algoritmos Rede Neural do tipo multlayer perceptron (MLP) e regressão linear. Este estudo foi desenvolvido em 4 fases distintas: (1) Preparação da base de dados e definição dos valores a serem preditos de ceratometria média e asfericidade; (2) Cálculo da variação da ceratometria média e asfericidade e cálculo do erro do nomograma; (3) Aplicação dos algoritmos de aprendizagem de máquina e seleção de atributos; (4) Cálculo da variação da ceratometria média e da asfericidade prevista pelo algoritmo comparando com a variação do pré e pós operatório e cálculo do erro do algoritmo. Como resultado, o melhor valor do erro absoluto médio encontrado para asfericidade foi 0.19 e para ceratometria média foi 1.18. Comparando os valores do erro médio do nomograma e o erro médio do algoritmo, houve uma melhora de 0.11 para asfericidade e 0.09 para ceratometria média em relação ao nomograma atual, confirmando que a utilização de modelos computacionais é capaz de alcançar resultados mais precisos podendo contribuir para decisão cirúrgica na tentativa de melhorar a qualidade de visão de pacientes com ceratocone.","This work aims to improve the predictability of asphericity and average keratometry in keratoconus patients after implantation of intrastromal corneal ring segments (ICRS) by creating computational models based on machine learning, using tomographic data of the cornea. This study included 209 eyes of 160 keratoconus (grades I, II and III) implanted with ICRS. The Ferrara ICRS with 160 degrees of arch was implanted in all patients. The ICRS thickness varied from 150 to 250 micra. One or two segments were implanted. The base was composed of corneal tomography PentacamÂ® (Oculus, Wetzlar, Alemanha) parameters, clinical data and Ferrara ring data totaling 39 parameters. To create the models, neural network algorithms type multlayer perceptron (MLP) and linear regression were used. This study was conducted in four phases: (1) Preparation of the database and setting the values to be predicted mean keratometry and asphericity; (2) Calculation of the variation mean keratometry and asphericity and the nomogram calculation error; (3) Application of machine learning algorithms and attribute selection; (4) Mean keratometry and asphericity variation calculation provided for comparing algorithm with the variation of the preoperative and postoperative calculation of the algorithm and of the error. As a result, the best mean absolute error value found for asphericity was 0.19 and mean keratometry was 1.18. Comparing the mean absolute error values of the nomogram and the average absolute error of the algorithm, there was an improvement of 0.11 to asphericity and 0.09 to mean keratometry in relation to the current nomogram, confirming that the use of computational models can achieve more accurate results may contribute to surgical decision in an attempt to improve the quality of vision of keratoconus patients.","('Aprendizagem do computador', 'Pentacam', 'Ceratometria média', 'Asfericidade', 'Anel instraestromal', 'Anel de Ferrara', 'Intraestromal ring', 'Machine learning', 'Asphericity', 'Mean keratometry', 'Ring of Ferrara')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1606","2015-12-11","https://www.repositorio.ufal.br/bitstream/riufal/1606/1/Modelos%20computacionais%20para%20otimiza%c3%a7%c3%a3o%20da%20escolha%20do%20anel%20intraestromal%20em%20pacientes%20com%20ceratocone%20utilizando%20dados%20tomogr%c3%a1ficos%20da%20c%c3%b3rnea.pdf","Computational model to enhance intrastromal corneal ring choose in keratoconus using tomographic data from de córnea","('João Marcelo de Almeida Gusmão Lyra',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/1734","Campus A.C. Simões","Instituto de Computação","Dissertação","Um modelo semântico para engenharia de aplicação de linhas de produto de software para sistemas tutores inteligentes","('Walker Araújo Ataíde',)","('Alan Pedro da Silva',)","('Ig Ibert Bittencourt Santana Pinto', 'Ivo Augusto Andrade Rocha Calado', 'Sean Wolfgand Matsui Siqueira')","Sistemas Tutores Inteligentes (STIs) são softwares que buscam representar o comportamento humano inerente ao processo de ensino em algum domínio específico com o objetivo de dar suporte às atividades de professores e oferecer um ensino adaptado aos estudantes. Os STIs têm grande potencialidade tanto no ensino presencial quanto a distância, entretanto, sua construção é uma tarefa complexa e dispendiosa que demanda a presença de profissionais especializados em computação e domínio do sistema sendo agravado quando se necessita construir STIs em larga escala e adaptados a cada domínio. Nesse sentido, a abordagem de Linhas de Produto de Software (LPS) possibilita construir STIs em larga escala. De forma complementar, ontologias podem ser utilizadas para permitir que tal construção seja automaticamente adaptável para diferentes domínios. Porém, na fase de engenharia da aplicação da LPS, momento em que os STIs são instanciados, faz-se necessária a manipulação de ontologias e artefatos de software distintos, demandando a presença de profissionais com conhecimentos em ontologia e engenharia de software, o que dificulta a realização dessa tarefa por autores/projetistas. Com base no exposto propõe-se neste trabalho um modelo baseado em ontologia para automatizar a engenharia de aplicação de LPS para sistemas tutores inteligentes. De maneira específica pretende-se automatizar o processo de customização, instanciação e implantação de STIs de uma LPS, tornando transparente ao usuário a manipulação de ontologias e artefatos de software. O modelo proposto utiliza ontologias para representar as funcionalidades e restrições de uma LPS genérica, as funcionalidades específicas para STIs, as decisões do autor em termos de quais funcionalidades farão parte do STI a ser gerado e as informações do aluno. O processo de engenharia de aplicação da LPS é realizado por componentes que conduzem o autor pelas etapas de autenticação no sistema, seleção da LPS a ser instanciada, customização/configuração das funcionalidades do STI, validação, geração e implantação de um STI em um servidor Web. Para validar o modelo proposto foi construída uma ferramenta que automatiza a geração de produtos em uma LPS. Tal ferramenta foi utilizada em um estudo de caso abrangendo a engenharia de aplicação de um STI a partir de uma LPS. Os resultados obtidos mostram-se adequados apontando como principais contribuições a concepção e desenvolvimento de um modelo semântico para a engenharia de aplicação de LPS para STIs, este modelo guia o autor pelo processo tornando transparente o uso de ontologias e LPS, auxilia na redução da complexidade e do esforço empregado (i.e., carga de trabalho) na construção de STIs a partir de LPS semântica, reduz as qualificações exigidas para instanciar STIs ao qual pode possibilitar que mais pessoas realizem essa tarefa e permite validar corretamente a configuração das funcionalidades do STI a ser instanciado de forma que apenas produtos sem erros de configuração sejam gerados.","Intelligent Tutoring Systems (ITSs) are softwares that aims to represent human behavior inherent in the teaching process in any particular field in order to support the activities of teachers and offer a adapted teaching to students. ITSs have great potential both in the classroom teaching as the distance, however, its construction is a complex and expensive task that requires the presence of specialized professionals in computing and system domain being compounded when you need to build ITSs large-scale and adapted to each area. In this sense, the approach Software Product Lines (SPL) allows to build large-scale ITS. Complementarily, ontologies can be used to allow such a construction is automatically adaptable to different domains. However, in the application engineering phase of the SPL, when ITS are instantiated, is required manipulation of ontologies and different software artifacts, demanding the presence of professionals with expertise in ontology and software engineering, making it difficult the accomplishment of this task by authors / designers. Given the above, we propose an ontology-based model to automate the SPL application engineering for intelligent tutoring systems. Specifically, it is intended to automate the processes of customization, instantiation and deployment of an ITS of a SPL, making the manipulation of ontologies and software artifacts transparent to the user. The proposed model uses ontologies to represent the features and constraints of a generic SPL, the specific features for ITSs, the decisions of the author in terms of which features will be part of the ITS to be generated and the information of the student. The SPL application engineering process is performed by components that lead author by the steps of authentication in the system, selection of the SPL to be instantiated, customization/configuration of the features of ITS, validation, generation and deployment of ITS on a Web server. In order to validate the proposed model has been built a tool that automates the generation of products in a SPL. This tool was used on a case study involving the application engineering of an ITS from a SPL. The obtained results showed to be adequate singled out as major contributions, the design and development of a semantic model for the SPL application engineering for ITSs, this model guides the author through the process making transparent the use of ontologies and SPL, helps reduce complexity and effort (i.e., workload) in the construction of ITSs from semantic SPL, reduces the skills required to instantiate ITSs what can enable more people to perform this task and allows properly validate the configuration of the features of the ITS to be instantiated, allowing only products without misconfigurations can be generated.","('Sistemas Tutoriais Inteligentes', 'Ontologia', 'Software de aplicação -Desenvolvimento', 'Intelligent Tutoring Systems', 'Ontology', 'Application software -development')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1734","2015-08-04","https://www.repositorio.ufal.br/bitstream/riufal/1734/1/Um%20modelo%20sem%c3%a2ntico%20para%20engenharia%20de%20aplica%c3%a7%c3%a3o%20de%20linhas%20de%20software%20para%20sistemas%20tutores%20inteligentes.pdf","A semantic model for application engineering of software product lines intelligent tutoring systems","('Patrick Henrique da Silva Brito',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/1577","Campus A.C. Simões","Instituto de Computação","Dissertação","Um modelo matemático de otimização da mistura de diferentes variedades de açúcar para atender ao padrão de qualidade de países importadores","('Davi Prates Oliveira Barbosa',)","('João Inácio Soletti',)","('Sandra Helena Vieira de Carvalho', 'Rafael Piatti Oiticica de Paiva')","Neste trabalho foi desenvolvido um modelo matemático com o objetivo de estabelecer a proporção mássica de variedades de açúcar numa mistura voltada à exportação do produto, onde são preenchidos alguns requisitos de qualidade. Atualmente, o Brasil é um dos maiores exportadores de açúcar do mundo, com um volume de exportação estimado em 32,6 milhões de toneladas para a safra 2019. Para atender às exigências de qualidade dos países importadores, faz-se necessário combinar as variedades de açúcar com características diferentes. O modelo proposto apresenta uma função objetivo que minimiza o custo total da mistura, respeitando essas características mínima e máxima exigidas por cada mercado importador. O modelo matemático foi concebido como um problema de Programação Linear. Os resultados foram apresentados a partir da análise de um estudo de caso, onde os dados foram validados no software General Algebraic Modeling System (GAMS).","In this dissertation a mathematical model is developed to establish the weight ratio of sugar's varieties in a mixture directed to the export of the product, where are filled some quality requirements. Currently, Brazil is one of the world's largest sugar exporters, with an export volume estimated at 32.6 million tons for the harvest 2019. To meet the quality requirements of importing countries, it is necessary to combine the sugar's varieties with different characteristics. The proposed model presents an objective function that minimizes the total cost of the blend, respecting these minimum and maximum characteristics required for each export market. The mathematical model is designed as a Linear Programming problem. The results were presented from the analysis of a case study, where the data have been validated in the General Algebraic Modeling System software (GAMS).","('Programação linear', 'Otimização', 'Brasil -Produtos industrializados', 'Açúcar -Exportação', 'Linear programming', 'Optimization', 'Blend problem', 'Sugar')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1577","2016-08-24","https://www.repositorio.ufal.br/bitstream/riufal/1577/1/Um%20modelo%20matem%c3%a1tico%20de%20otimiza%c3%a7%c3%a3o%20da%20mistura%20de%20diferentes%20variedades%20de%20a%c3%a7%c3%bacar%20para%20atender%20ao%20padr%c3%a3o%20de%20qualidade%20de%20pa%c3%adses%20importadores.pdf","A mathematical model of optimization of the mixture of different varieties of sugar to meet the quality standards of importing countries","('Henrique Pacca Loureiro Luna',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/1759","Campus A.C. Simões","Instituto de Computação","Dissertação","Um modelo estratégico baseado em gamificação para apoio à gestão de desempenho de service desks","('Fábio Silva da Conceição',)","('Alan Pedro da Silva',)","('Jorge Artur Peçanha de Miranda Coelho', 'Ibsen Mateus Bittencourt Santana Pinto')","O atendimento e suporte em service desk exercemumpapel fundamental nos resultados de negócios, sob a gestão dos serviços de TI, cujo monitoramento e controle são geralmente realizados no processo de gerenciamento de incidentes do arcabouço ITIL, através do uso de indicadores de desempenho estabelecidos no SLA. Nesse cenário, devido a existência de múltiplos fatores estressores envolvidos no exercício das atividades de agentes de service desk, no decorrer do tempo, o desempenho no trabalho tende a cair. Para esse problema, o presente trabalho buscou investigar se o uso de gamificação podemelhorar o desempenho no trabalho em service desk. Nessa busca, foram realizados tanto uma revisão sistemática da literatura quanto um estudo experimental no service desk de uma organização governamental, cujos resultados apontaram a melhoria de desempenho, através do uso de gamificação. Em seguida, desenvolveu-se um modelo estratégico voltado à gestão de desempenho de service desks, com abordagem soft de dinâmica de sistemas, o qual foi construído através da interpretação de dados coletados na revisão sistemática da literatura, em entrevistas com especialistas de domínio e na pesquisa experimental. A construção desse modelo foi guiada pela metodologia de gestão de desempenho organizacional conhecida como Balanced Scorecard. Após construído, o modelo proposto foi validado por meio de sessões de entrevistas com especialistas de domínio.Desse modo, adotando a metodologia de pesquisa quanti-quali, o presente trabalho buscou contribuir com as comunidades de gestão dos serviços de TI e psicologia organizacional, propondo ainda sugestões para trabalhos futuros.","The assistance and support on service desk play a key role in the business results, under IT services management, whose monitoring and control are generally performed in ITIL framework’s incident management process, through the use of performance indicators established on SLA. In this scenario, due to the existence of multiple stressing factors involved in the exercises of service desk agents activities, over time, the performance at work tends to fall. For this problem, the present work sought to investigate if the use of gamification can improve the performance at work in service desk. In this pursuit, it was developed both a systematic literature review and an experimental study, in the service desk of an governmental organization, whose results pointed to the improvement of performance, by the use of gamification. Then, itwas developed a strategic model for service desk’s performance management, with system dynamics soft approach, which was built through interpretation of collected data from both systematic literature review, interviews with domain experts and the experimental study. The construction of the model was guided by the methodology of organizational performance management known as Balanced Scorecard. After the model was built, it was then validated athwart sessions with domain experts. Thereby, adopting the quanti-quali research methodology, the present work sought to contribute with either IT services management and organizational psychology communities, as well proposing suggestions for future works.","('Service desk', 'Desempenho no trabalho', 'Gamificação', 'Dinâmica de sistemas', 'Balanced scorecard', 'Performance atWork', 'Gamification', 'System dynamics')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1759","2017-04-19","https://www.repositorio.ufal.br/bitstream/riufal/1759/1/Um%20modelo%20estrat%c3%a9gico%20baseado%20em%20gamifica%c3%a7%c3%a3o%20para%20apoio%20%c3%a0%20gest%c3%a3o%20de%20desempenho%20de%20service%20desks.pdf","A strategic model based on gramificantion to support the performece management of service desks","('Tárcio Rodrigues Bezerra',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/7758","Campus A.C. Simões","Instituto de Computação","Dissertação","Um modelo de visão computacional para análise biomecânica do valgismo dinâmico","('Gerônimo Vicente dos Santos Júnior',)","('Aydano Pamponet Machado',)","('Jorge Artur Peçanha de Miranda Coelho', 'Rodrigo Freitas Monte Bispo')","Introdução: Lesões em membros inferiores são ocorrências frequentes em atividades físicas que demandem impacto nas extremidades. Grande parte dessas lesões acontece devido à falta de um alinhamento corporal correto durante a atividade realizada. Um preditor importante de avaliação global corporal para evitar esses tipos de lesões é a identificação do valgismo dinâmico, que é o deslocamento medial do joelho durante o impacto de membro inferior em atividades, como corrida e salto. Vários métodos são utilizados para a detecção do valgismo dinâmico durante o exame físico, dentre eles a análise do movimento por vídeo. Entretanto, esse tipo de análise possui certas limitações relacionadas principalmente à utilização de marcadores por pontos fixos ou trajes específicos, que podem levar a dados incorretos e conclusões diagnósticas errôneas. Uma alternativa pode ser a utilização de “marcadores virtuais” por análise desenvolvida por softwares que modelem a biomecânica do movimento. Objetivos: Esse estudo tem por objetivo estabelecer um método padronizado, eficaz e acessível para análise e acompanhamento da evolução do valgismo dinâmico. Métodos: Os dados serão colhidos em forma de vídeo, capturado pela ferramenta Kinect v2®, e processados através do software específico desenvolvido pelos pesquisadores. Este software será voltado a realizar o teste para análise do valgo dinâmico de forma automatizada. No estudo será medida a variação de resultados, quantitativo, apresentados entre os avaliadores e o software desenvolvido. Para isso, será mensurada a média dos resultados de cada avaliador dos movimentos de tronco, quadril, joelho e tornozelo; durante os dois momentos de análise do valgo dinâmico. Após esse momento, as médias angulares interavaliadores e intra-avaliadores serão comparadas a partir do teste t pareado. Resultados: Foram coletadas 34 amostras. A avaliação realizada entre as análises do modelo computacional concebido e o especialista em nossa pesquisa não mostrou um índice de concordância significativo. Entretanto, o modelo apresentou resultados eficazes para a prática clínica. O software apresentou sete momentos com concordância significativa, enquanto que a avaliação pelo especialista houve 02 momentos de concordância significativa. Conclusão: No atual estudo ficou identificado que a captura e processamento de imagens avaliando o valgismo dinâmico a partir do modelo desenvolvido foi mais eficaz do que a análise pelos especialistas. Isso mostra que a utilização do nosso modelo, pode ser empregado na prática clínica básica.","Introduction: Injuries in the lower limbs are frequent occurrences in physical activities that demand an impact on the extremities. Most of these injuries occur due to the lack of correct body alignment during the activity performed. An important predictor of global body assessment to prevent these types of injuries is the identification of dynamic valgism, which is the medial displacement of the knee during the impact of the lower limb in activities such as running and jumping. Several methods are used for the detection of dynamic valgism during physical examination, among them the analysis of movement by video. However, this type of analysis has certain limitations related mainly to the use of markers for fixed points or specific suits, which can lead to incorrect data and erroneous diagnostic conclusions. An alternative may be the use of ""virtual markers"" for analysis developed by software that model the biomechanics of movement. Objectives: This study aims to establish a standardized, effective and accessible method for analyzing and monitoring the evolution of dynamic valgus. Methods: Data will be collected in the form of video, captured by the Kinect v2® tool, and processed using specific software developed by the researchers. This software will be used to perform the test to analyze the dynamic valgus in an automated way. In the study, the variation of results, quantitative, presented between the evaluators and the developed software will be measured. For this, the average of the results of each evaluator of the trunk, hip, knee and ankle movements will be measured; during the two moments of analysis of the dynamic valgus. After that, the inter-rater and intra-rater angles will be compared using the paired t-test. Results: 34 samples were collected. The evaluation carried out between the analyzes of the computational model designed and the specialist in our research did not show a significant agreement index. However, the model has shown effective results for clinical practice. The software presented seven moments with significant agreement, while the evaluation by the specialist, there were 02 moments of significant agreement. Conclusion: In the current study it was identified that the capture and processing of images evaluating the dynamic valgus from the developed model was more effective than the analysis by the specialists. This shows that the use of our model can be used in basic clinical practice.","('Geometria e modelagem computacional', 'Joelhos', 'Membros inferiores (Extremidades)', 'Biomecânica', 'Modeling', 'Knee', 'Lower extremity', 'Biomechanical phenomena')","Fisioterapia","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/7758","2020-01-22","https://www.repositorio.ufal.br/bitstream/riufal/7758/1/Um%20modelo%20de%20vis%c3%a3o%20computacional%20para%20an%c3%a1lise%20biomec%c3%a2nica%20do%20valgismo%20din%c3%a2mico.pdf","A computer vision model for biomechanical analysis of dynamic valgism",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/3206","Campus A.C. Simões","Instituto de Computação","Dissertação","Um modelo de avaliação de aprendizagem de História baseado em projetos e mapas conceituais","('Patricia Maria dos Santos',)","('Fábio Paraguaçu Duarte da Costa',)","('Cleide Jane de Sá Araujo Costa', 'Evandro de Barros Costa', 'Jenner Barretto Bastos Filho')","Esse estudo teve como foco pesquisar o estudo da disciplina de História com Ciência, auxiliada pela técnica de criação de Mapas Conceituais e da abordagem de Aprendizagem Baseada em Projetos -PBL que se apoia nas bases do construtivismo, que entende que o indivíduo aprende melhor praticando e interagindo com o meio e com outros indivíduos, onde cada um possui seu próprio conhecimento de forma a surgir inquietações e novos aprendizados entre seus pares. Logo, a proposta do referido trabalho é analisar se houve crescimento cognitivo através de uma avaliação do uso da abordagem da PBL, no conteúdo de História, em aprendizes de uma turma do 9º Ano da Escola Estadual Professor José da Silveira Camerino, em 2016. O estudo foi desenvolvido através de uma pesquisa qualitativa e de estudo de caso onde os resultados mostraram que houve o desenvolvimento da aprendizagem do conteúdo de História estudado pelos aprendizes, bem como o crescimento cognitivo deles através do desenvolvimento de projetos, da modelagem do conhecimento adquirido representado nos mapas Conceituais. A pesquisa também comprovou os benefícios alcançados com o uso da abordagem de PBL no desenvolvimento da aprendizagem dos aprendizes, através da criação de um Modelo Avaliativo de Aprendizagem Cognitiva do ensino de História, que explicita as etapas realizadas durante o desenvolvimento da aprendizagem do conteúdo de História pelos alunos.","This study focused on the study of the discipline of History with Science, aided by the technique of creation of Conceptual Maps and the Approach of Project Based Learning (PBL), which relies on the bases of constructivism, which understands that the individual learns better by practicing and interacting with the environment and with other individuals, where each one possesses his / her own knowledge in order to create restlessness and new learning among his / her peers. Therefore, the purpose of this study is to analyze if there was cognitive growth through an evaluation of the use of the PBL approach, in the content of History, in apprentices of a class of the 9th Year of the State School Professor José da Silveira Camerino in 2016. The study was developed through a qualitative research and case study where the results showed that there was the development of learning of the content of History studied by the learners, as well as their cognitive growth through the development of projects, the modeling of the acquired knowledge represented in the Conceptual maps. The research also demonstrated the benefits achieved through the use of the PBL approach in the development of apprenticeship learning through the creation of an Evaluation Model of Cognitive Learning of History teaching, which explains the steps taken during the development of learning the content of History by the students.","('Modelagem computacional', 'Aprendizagem baseada em projetos', 'História -Ensino e aprendizagem', 'Computational modeling', 'Project-based learning', 'History -Teaching and learning')","Ciência da Computação","por","Universidade federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/3206","2018-05-30","https://www.repositorio.ufal.br/bitstream/riufal/3206/1/Um%20modelo%20de%20avalia%c3%a7%c3%a3o%20de%20aprendizagem%20de%20Hist%c3%b3ria%20baseado%20em%20projetos%20e%20mapas%20conceituais.pdf","A model of evaluation of history learning based on conceptual projects and maps",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/1608","Campus A.C. Simões","Instituto de Computação","Dissertação","Um modelo de baixo custo para aulas de robótica educativa usando a interface arduino","('Alexandre José Braga da Silva',)","('Eliana Silva de Almeida',)","('Leonardo Viana Pereira', 'Roberto Jorge Vasconcelos dos Santos')","Este trabalho descreve um método de integração entre a interface de controle Arduino como base tecnológica e dispositivos de baixo custo que possuam um grau de simplicidade adequado para que seja usado por crianças, adolescentes e pessoas que estejam se iniciando em projetos de robótica, automação e controle. Este estudo se baseia em protótipos desenvolvidos em oficinas e aulas de robótica educativa em uma escola de Ensino fundamental e médio do estado de Alagoas. Os resultados alcançados através dos experimentos realizados, usando materiais reaproveitáveis, sucata e componentes eletrônicos de fácil aquisição no mercado, em conjunto com softwares integrados e utilizados pelos professores e alunos, demonstraram excelentes resultados em termos de aproveitamento das aulas, interesse, participação e melhorias nos conhecimentos ministrados, de acordo com as avaliações feitas por meio de questionários com os alunos.","This paper describes a method of integration between the control interface Arduino as a low cost technological base that has an appropriate degree of simplicity to be used by children, teenagers and people who are starting projects in robotics, automation and control devices. This study is based on prototypes developed in workshops and educational robotics classes at a school for elementary and middle level in the state of Alagoas. The results obtained through experiments using reusable materials, scrap and electronic components easy to purchase in the market, set of integrated circuits and used by teachers and students, software showed excellent results in terms of exploiting classes, interest, participation and improvements in knowledge given, according to the assessments made by questionnaires with students.","('Arduino', 'Robótica educativa', 'Interface', 'Controle', 'Educational robotics', 'Control')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1608","2014-05-16","https://www.repositorio.ufal.br/bitstream/riufal/1608/1/Um%20modelo%20de%20baixo%20custo%20para%20aulas%20de%20rob%c3%b3tica%20educativa%20usando%20interface%20arduino.pdf","A low cost models for education robotics class using the arduino interface","('Luiz Marcos Garcia Gonçalves',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/3481","Campus A.C. Simões","Instituto de Computação","Dissertação","Um modelo de atividades online para deficientes visuais","('Ronaldo Ribeiro Fernandes',)","('Arturo Hernández-Domínguez',)","('Fábio Paraguaçu Duarte da Costa', 'Flávio Mota Medeiros')","A sociedade moderna vive uma constante mudança de paradigmas decorrente do processo de globalização e do avanço das tecnologias nas áreas de comunicação e tecnologia da informação. Essas mudanças ocasionam uma série de dilemas para os modelos existentes na educação, principalmente nos desenvolvidos para quem possui alguma limitação como no caso dos deficientes visuais. O objetivo deste trabalho é propor um modelo de atividades online para cegos usando um ambiente virtual de aprendizagem inclusivo, com base no modelo de Salmon, como também propor uma metodologia em ambientes virtuais de aprendizagem. O modelo proposto é importante do ponto de vista da inclusão, já que objetiva trabalhar com o público-alvo os deficientes visuais no contexto de educação a distância. Com a finalidade de validar o modelo, foi aplicado quatro cursos de educação a distância para pessoas especiais (cegos), utilizando um ambiente virtual de aprendizagem acessível denominado Eduquito, o qual foi escolhido em virtude possuir os 3 selos de acessibilidade. Foi feito a formalização do modelo através da rede de Petri, a qual é uma importante ferramenta matemática e gráfica que permite analisar vários tipos de sistemas, onde apresenta dois tipos de vértices denominados lugar e transição. As transições são representadas por barras e os lugares por círculos, sendo direcionados sempre por arcos, de lugar para transição e de transição para lugar. Os resultados foram: o sistema atingiu os objetivos propostos como acessibilidade, motivação e obtenção do conhecimento; os alunos especiais (deficientes visuais) se mostraram satisfeitos ao participarem dos cursos e a maioria dos alunos aprovaram os cursos realizados. A presente pesquisa contribuiu na educação especial, pois ratificou que todos os seres humanos são iguais, sendo assim, não é necessário tratar as pessoas cegas como diferentes porque não conseguem enxergar. Afinal de contas, estas pessoas anseiam por um aprendizado, desejam construir coisas novas e desta forma, expandir as suas possibilidades para ampliar a sua comunicação, desenvolver suas habilidades e atingirem patamares cada vez mais altos.","Modern society is constantly changing paradigms resulting from the process of globalization and the advancement of technologies in the areas of communication and information technology. These changes give rise to a number of dilemmas for existing models in education, especially those developed for those with some limitations such as the visually impaired. The objective of this work is to propose a model of online activities for the blind using a virtual environment of inclusive learning, based on the Salmon model, as well as to propose a methodology in virtual learning environments. The proposed model is important from the point of view of inclusion, since it aims to work with the target audience of the visually impaired in the context of distance education. In order to validate the model, four distance learning courses were applied to special people (blind), using a virtual learning environment accessible called Eduquito, which was chosen because it has the 3 accessibility stamps. The model was formalized through the Petri network, which is an important mathematical and graphical tool that allows to analyze several types of systems, where it presents two types of vertices called place and transition. Transitions are represented by bars and places by circles, always being directed by arcs, from place to place, and from place to place. The results were: the system reached the objectives proposed as accessibility, motivation and knowledge acquisition; the special students (visually impaired) were satisfied and when they participated in the courses and the majority of the students approved the courses realized. This research contributed to special education, since it ratified that all human beings are equal, so it is not necessary to treat blind people as different because they can not see. After all, these people yearn for learning, they want to build new things and in this way expand their possibilities to broaden their communication, develop their skills and reach ever higher levels.","('Acessibilidade digital', 'Deficientes visuais', 'Ambiente virtual de aprendizagem', 'Educação à distância', 'Alunos especiais – Motivação', 'Digital accessibility', 'Visually impaired', 'Virtual learning environment', 'Distance education', 'Special students – Motivation')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/3481","2018-06-26","https://www.repositorio.ufal.br/bitstream/riufal/3481/1/Um%20modelo%20de%20atividades%20online%20para%20deficientes%20visuais.pdf","A model of online activities for visual impaired",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/1604","Campus A.C. Simões","Instituto de Computação","Dissertação","Modelo de apoio ao estudo de pacientes em oncologia pediátrica utilizando raciocínio baseado em casos e mineração de dados","('Jailton Cardoso da Cruz',)","('Fábio Paraguaçu Duarte da Costa',)","('Evandro de Barros Costa', 'Guilherme Ataíde Dias')","Este trabalho tem como objetivo propor um Modelo de Recomendação de itens de prescrição para Oncologia Pediátrica baseado na extração de dados do Prontuário Eletrônico do Paciente. Esses dados serão utilizados como casos indexados, para auxiliar os prestadores de serviço médico baseados na similaridade de prescrições, de acordo com o histórico do paciente. Do ponto de vista do apoio a educação médica, a modelagem objetiva apoiar o estudante ou o profissional de saúde no entendimento do processo de tomada de decisão durante a fase de prescrição de itens de tratamento médico oncológico, como, por exemplo: medicamentos, exames de laboratório ou de imagens, dieta, gases, cuidados, quimioterapia, radioterapia. Para o desenvolvimento do modelo, utilizou-se a abordagem de Raciocínio Baseado em Casos (RBC), através da representação de uma base de casos de prescrição médica, indexada por seus itens de tratamento. Durante a fase de recuperação de casos, utilizou-se a ferramenta de Mineração de Dados aplicando-se o modelo de regra de associação, em conjunto com o algoritmo ""apriori"" visando a obtenção da similaridade entre casos. Para a atualização da base de casos, foi desenvolvido um procedimento de banco de dados para execução do processo de Extração, Transformação e Carga da base de dados. O modelo desenvolvido foi aplicado na base de dados do Prontuário Eletrônico do Paciente da Santa Casa de Misericórdia de Maceió, baseado no sistema de gestão hospitalar MV Sistemas, implantado na unidade desde 2005. Para a apresentação dos resultados, utilizou-se a ferramenta Oracle Data Miner, que possibilitou o acesso ao banco de dados e a análise dos casos selecionados pela identificação de palavras chaves contidas na evolução do estado clínico do paciente. A aplicação dos experimentos permitiu validar a ocorrência de aplicação conjunta de itens de tratamento de acordo com as palavras chaves, o que pode ser utilizado como elemento para o processo de tomada de decisão médica e tutoria.","This work aims to propose a recommendation model of prescription items for Pediatric Oncology based on data extraction from Electronic Patient Record. These data are used as indexed cases to aid providers of medical service based on the similarity of prescriptions, according to the patient's history. From the viewpoint of aid medical education, the modeling objective support the student or health professional in understanding the decision-making process during the prescription items oncological medical treatment, for example drugs, laboratory exams or images exams, diet, gases, care, chemotherapy, radiotherapy. To develop the model, was used the approach of Case Based Reasoning (CBR), through the representation of prescription medical base-case, indexed by their treatment items. During the recovery phase of cases, we used the tool. Data Mining by applying the model of association rule, together with the algorithm ""apriori"" for obtaining the similarity between cases. To update the case base, a procedure database for performing the process of Extraction, Transformation and Load of the database was developed. The developed model was applied in the database of the Electronic Patient Record of the Santa Casa de Misericordia de Maceio, based on Hospital Management Systems ""MV Sistemas"", deployed in the unit since 2005. For the presentation of results, was used the Oracle Data Miner tool, which allowed access to the database and analysis of selected cases by identifying key words contained in the evolution of the clinical condition of the patient. The application of the experiments validate the occurrence of allowed combined application of items of treatment according to the keywords, which can be used as input in the process of making medical decision and tutoring.","('Mineração de dados -Computação', 'Documento eletrônico', 'Prontuários médico-hospitalares', 'Oncologia pediátrica -Pacientes', 'Data mining', 'Case based reasoning', 'Pediatric oncology', 'Health record', 'Mentoring', 'Decision support')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1604","2014-04-14","https://www.repositorio.ufal.br/bitstream/riufal/1604/1/Modelo%20de%20apoio%20ao%20estudo%20de%20pacientes%20em%20oncologia%20pedi%c3%a1trica%20utilizando%20racioc%c3%adnio%20baseado%20em%20casos%20e%20minera%c3%a7%c3%a3o%20de%20dados.pdf","Model study support for patients in pediatric oncology using case-based reasoning and data mining",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/5970","Campus A.C. Simões","Instituto de Computação","Dissertação","Um modelo de referência para ambientes virtuais de aprendizagem na Web: aproximando as perspectivas do autor e do desenvolvedor","('Hemilis Joyse Barbosa Rocha',)","('Evandro de Barros Costa',)","('Fábio Paraguaçu Duarte da Costa', 'Luis Paulo Leopoldo Mercado', 'Sérgio Crespo Coelho da Silva Pinto')","Muitas plataformas de Ambientes Virtuais de Aprendizagem têm sido desenvolvidas e disponibilizadas, tendo com isso atraído uma quantidade significativa e diversificada de usuários. Neste contexto, além da diversidade de usuários, ampliam-se as possibilidades tecnológicas, possibilitando-se a viabilização de diferentes propostas pedagógicas, eventualmente demandadas por esse público. Apesar disso, observam-se lacunas importantes no cenário de desenvolvimento ou mesmo customização dos AVAS para atender a requisitos específicos para um determinado uso, isso conduz a dificuldades apresentadas aos autores e, alguns casos, para os próprios desenvolvedores. Assim, investiu-se nesta dissertação em uma possível resposta para amenizar parte desses problemas, focalizando na definição de um modelo de referência que conta com um mapa conceitual destinado a auxiliar educadores a escolher serviços de um AVA que atenda suas necessidades e uma arquitetura de referência que se presta a ajudar os desenvolvedores a implementar as demandas dos usuários. Ademais, desenvolveu-se um sistema de recomendação baseado em conhecimento que visa aproximar a visão do educador da visão do desenvolvedor, mapeando as escolhas do educador, em o que o desenvolvedor precisa para desenvolvê-lo. Com isso, buscou-se oferecer um arcabouço adequado para realizar avaliações e comparações entre AVAs, além de servir para orientar e viabilizar o desenvolvimento de novos ambientes ou ainda customização de soluções atendendo demandas específicas de educadores. Uma avaliação para essa abordagem proposta foi feita por meio de um estudo de caso que serviu para explorar os recursos dos três principais componentes desenvolvidos, obtendo-se um primeiro resultado satisfatório, ainda que bem preliminar, sobre o trabalho aqui apresentado.","Many platforms Virtual Learning Environments have been developed and made available, and thereby attracted a significant amount of users and diverse. In this context, in addition to the diversity of users, expand the possibilities of technology, enabling the feasibility of different pedagogical eventually demanded by the public. Nevertheless, there are important gaps in the scenario development or customization of AVAS to meet specific requirements for a particular use, this leads to difficulties presented by the authors and, some cases, the developers themselves. So invested in this dissertation on a possible answer to alleviate some of these problems, focusing on defining a reference model that has a conceptual map designed to help educators choose the services of an AVA that meets your needs and a reference architecture that lends itself to help developers implement the demands of users. In addition, we developed a recommendation system based on knowledge that aims to bring the vision of the developer's vision educator, the educator mapping choices in what the developer needs to develop it. Therefore, we sought to provide a framework suitable to perform evaluations and comparisons between AVAs, and serves to guide and facilitate the development of new environments or customized solutions meeting the specific demands of educators. An assessment for the proposed approach was made through a case study that was used to explore the features of the three main components developed, obtaining a first satisfactory results, although very preliminary, on the work presented here.","('Ambientes virtuais de aprendizagem – Usabilidade', 'Mapa conceitual', 'Arquitetura de software', 'Virtual learning environments -Usability', 'Conceptual map', 'Software Architecture')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/5970","2012-07-02","https://www.repositorio.ufal.br/bitstream/riufal/5970/1/.pdf","A reference model for virtual learning environments web: bringing the perspectives of author and publisher","('Patrick Henrique da Silva Brito',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/1815","Campus A.C. Simões","Instituto de Computação","Dissertação","Um modelo de apoio à interação entre aprendizes em fóruns de discussão baseado em mapas conceituais","('Fernanda Josirene de Melo Ferreira',)","('Evandro de Barros Costa',)","('Patrick Henrique da Silva Brito', 'Cleide Jane de Sá Araujo Costa', 'Edilson Ferneda')","Este trabalho abordou um problema verificado em Fóruns de Discussão no contexto dos Ambientes Virtuais de Aprendizagem no que se refere a mecanismos que favoreçam a interação entre aprendizes. Mais especificamente, focou-se no baixo nível de freqüência de interação entre aprendizes, que acarreta na inibição de prováveis colaborações e desacordos, uma vez que eles desobedecem às regras do uso do fórum ou muitas vezes desconhece-as. Um exemplo disso são as constantes mensagens individuais ou voltadas apenas para o tutor. Para atenuar o referido problema, este trabalho propôs protocolos para controlar as interações e para oferecer suporte à negociação através de um modelo de fórum baseado em Mapas Conceituais. Para atingir estes objetivos foi realizada uma simulação por meio de um modelo em redes de Petri Coloridas usando a ferramenta CPN Tools. Com este modelo foi possível visualizar nos resultados finais da simulação, os tipos de interação do fórum conceitual de forma concisa, onde foi prevalecido o aprendiz como foco das interações, diminuindo com isso a posição hierárquica do tutor e conseqüentemente a sobrecarga de suas atividades. Por meio das discussões no cenário de uso, foi ilustrado um terço dos resultados possíveis do modelo. O trabalho também apresentou um Modelo de Aprendizagem, em um contexto de aprendizagem significativa, baseando-se na Teoria de Ausubel.","The present work addresses a problem observed in Discussion Forums regarding mechanisms that encourage the interaction among apprentices in Virtual Learning Environments. More specifically, attention has been given to the low frequency of apprentices interaction, resulting in an inhibition of possible collaborations and disagreements, since the apprentices show no respect for the forum rules, usually for unawareness. A good example of that situation is the high frequency of messages addressed to the tutor. In order to mitigate the aforementioned problem, the present work suggests protocols for interactions control and protocols for offer support negotiation through an forum model based on Concept Maps. To achieve these goals was realized a simulation through a model in Colored Petri nets using the CPN Tools. With this model it was possible to visualize in the final results of the simulation, the types of interaction of the conceptual forum concisely, where was prevailed the apprentice as focus of interactions, thereby decreasing the hierarchical position of the tutor and consequently the overload of his activities. Through discussions in usage scenario, was illustrated one third of possible outcomes of the model. It is also presented here a Learning Model, in a context of meaningful learning, based on the theory of Ausubel.","('Redes de computação -Protocolos', 'Petri, Redes de', 'Grupos de discussão pela Internet', 'Computer networks -Protocols', 'Petri, Networks of', 'Discussion groups on the Internet')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1815","2013-07-24","https://www.repositorio.ufal.br/bitstream/riufal/1815/1/Um%20modelo%20de%20apoio%20%c3%a0%20intera%c3%a7%c3%a3o%20entre%20aprendizes%20em%20f%c3%b3runs%20de%20discuss%c3%a3o%20baseado%20em%20mapas%20conceituais.pdf","A supporting model of interaction between apprentices in discussion forums based concept maps","('Fábio Paraguaçu Duarte da Costa',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/1838","Campus A.C. Simões","Instituto de Computação","Dissertação","Um modelo de tomada de decisão baseado na teoria da persuasão aplicado à classe de jogos MMORPG","('Helio Cavalcante Silva Neto',)","('Fábio Paraguaçu Duarte da Costa',)","('Arturo Hernández-Domínguez', 'Edilson Ferneda')","É notório que as pessoas a todo o momento têm de decidir diante de diferentes situações e sobre problemas dos mais diversos e utilizam, para isso, suas experiências passadas, valores, crenças, conhecimentos técnicos, suas habilidades e filosofias. Tomar decisões é algo crucial no âmbito dos jogos. Essa atividade acontece a todo o tempo e em vários níveis e influencia diretamente o desempenho do jogo, inclusive no âmbito do RPG, que é uma ferramenta onde há uma grande interação dos sujeitos em zonas de desenvolvimento proximal, pois que os jogadores têm que se unir para completar os objetivos do jogo (Quest), existindo, assim, uma maior troca do conhecimento prévio e social dos jogadores. Por se tratar de um jogo cooperativo que estimula a socialização, a interatividade e o desenvolvimento de habilidades comunicativas, surge, então, a motivação de trabalhar, na presente dissertação, com o RPG. Esta dissertação tem como objetivo construir, um modelo utilizando Rede de Petri e UML, com base na Teoria dos Jogos e na Teoria da Persuasão aplicado ao Massively Multiplayer Online Role-Playing Game, na busca de envolver o usuário em algum tipo de trama, trabalhando com elementos lúdicos, ao mesmo tempo, favoreça uma maior facilidade na tomada de decisão.","It is of common knowledge that at every moment, people have to make decisions over different matters regarding to a wide range of issues and that, in making such decisions, they use of previous experiences, values, beliefs, expertise, skills and even of their own philosophies. From a videogame perspective, decision-making is a crucial activity that happens at all times and at different levels of perception. Moreover, it has direct influence over a game‟s performance, a fact that also concerns to RPGs as they can act as tools to enhance the improvement of the proximal development zones of the involved individuals, due the need these individuals have to create groups and work together in order to complete different objectives of a game (known as quests). A need that results in higher exchanges of previously acquired knowledge, as well as their social knowledge. As the RPG has an inherent cooperative character that stimulates socialization, interaction and the improvement of communication skills, it was thought that it would be interesting to take advantage of the RPG to built a model using UML and Petri Net, based on the Game Theory and on a application of the Theory of Persuasion to an Massively Multiplayer Online Role-Playing Game environment, that involves the user in some kind of plot, at the same time that favors a greater ease in decision-making.","('Jogos para computador', 'Persuasão (Retórica)', 'Petri, Redes de', 'Teoria dos jogos', 'Jogos de fantasia', 'Computer games', 'Persuasion (Rhetoric)', 'Petri, Networks of', 'Game theory', 'Fantasy games')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1838","2011-04-14","https://www.repositorio.ufal.br/bitstream/riufal/1838/1/Um%20modelo%20de%20tomada%20de%20decis%c3%a3o%20baseado%20na%20teoria%20da%20persuas%c3%a3o%20aplicado%20%c3%a0%20classe%20de%20jogos%20MMORPG.pdf","A model of decision-making based on the theory of persuasion nused in class of games MMORPG","('Roberta Vilhena Vieira Lopes',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/6654","Campus A.C. Simões","Instituto de Computação","Dissertação","Um modelo de ambiente de aprendizagem social para a aprendizagem de programação baseado no conceito de planos de programação e esquemas de concepção de programas","('Jalves Mendonça Nicácio',)","('Fábio Paraguaçu Duarte da Costa',)","('Marcus de Melo Braga', 'Guilherme Ataíde Dias')","Este trabalho desenvolveu um modelo de suporte educacional para aprendizagem de conceitos de programação. Este modelo foi subsidiado pela implementação de um ambiente computacional de ensino que disponibiliza um conjunto de esquemas de concepção para a formação de modelos mentais de programação através da programação visual. Desta forma, a noção de scaffolding, conforme concebida por Vygotsky, foi fortemente utilizada com vistas a promover a aprendizagem dos conceitos iniciais de programação a partir das interações sociais. Um ambiente computacional de aprendizagem social foi construído e o conjunto de esquemas de concepção proposto foi incorporado a este ambiente, com o objetivo de verificar se o uso de tais ferramentas podem melhorar a metacognição do aluno em relação a aprendizagem de programação. Em seguida, um experimento foi conduzido com 37 alunos, ao longo de dois meses, e a análise dos dados obtidos aponta que a utilização do modelo sugerido neste trabalho favorece a compreensão dos conceitos iniciais de programação. Além disso, a interação com o conhecimento por meio destas ferramentas de scaffolding aumentou não apenas a participação individual dos alunos, mas também, a colaboração entre eles. Esses aspectos indicam o valor das atividades propostas neste estudo, no tocante a encorajar o maior engajamento dos alunos em disciplinas introdutórias de programação.","This work developed a model of educational support for learning programming concepts. This model was subsidized by the implementation of a computational teaching environment that provides a set of design schemes for the formation of mental models of programming through visual programming. In this way, the notion of scaffolding, as conceived by Vygotsky, was strongly used in order to promote the learning of the initial concepts of programming from social interactions. A computational environment of social learning was constructed and the set of proposed conception schemes was incorporated to this environment, with the purpose of verifying if the use of such tools can improve the metacognition of the student in relation to programming learning. Then, an experiment was conducted with 37 students over two months, and the analysis of the data points out that the use of the model suggested in this work favors the understanding of the concepts Programming initials. Moreover, the interaction with knowledge through these scaffolding tools has increased not only individual student participation but also collaboration among them. These aspects indicate the value of the activities proposed in this study, in order to encourage the greater engagement of students in introductory programming disciplines.","('Ambiente de aprendizagem social (Informática)', 'Scaffolding', 'Linguagem de concepção', 'Social learning environment (Informatics)', 'Design language', 'Social learning system')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/6654","2017-08-23","https://www.repositorio.ufal.br/bitstream/riufal/6654/1/Um%20modelo%20de%20ambiente%20de%20Aprendizagem%20Social%20para%20a%20aprendizagem%20de%20programa%c3%a7%c3%a3o%20baseado%20no%20conceito%20de%20planos%20de%20programa%c3%a7%c3%a3o%20e%20esquemas%20de%20concep%c3%a7%c3%a3o%20de%20programas.pdf","A Social Learning environment model for learning programs based on the concept of programming plans and program design schemes",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/2105","Campus A.C. Simões","Instituto de Computação","Dissertação","Um modelo de aferição de usabilidade de web sites, orientados ao usuário idoso","('Marcelo Santana Costa',)","('Fábio Paraguaçu Duarte da Costa',)","('Arturo Hernández-Domínguez', 'Roberta Vilhena Vieira Lopes', 'André Ricardo Magalhães')","Com o objetivo de apresentar uma Modelagem para aferir a usabilidade de uma web site orientada para o usuário idoso, a abordagem neste trabalho se destina à aferição a partir da perspectiva do usuário idoso se utilizando do método de investigação, combinado com a perspectiva de especialistas, se utilizando do método de inspeção. A aferição do ponto de vista do usuário está baseada no estudo do público a que o site está direcionado, considerando o nível do usuário quanto ao uso dos recursos da web e, o seu perfil quanto as suas necessidades, com a finalidade de poder estabelecer os requisitos de aferição de usabilidade mais adequados. A aferição de especialistas por sua vez, tem como base os métodos de inspeção, a fim de verificar o cumprimento de um conjunto de regras de usabilidade de web sites orientados para os usuários idosos. O Modelo apresentado neste trabalho prevê um processo sistemático e ordenado de aferição da usabilidade assim como a validação dos resultados obtidos para os métodos utilizados. Para dar suporte à modelagem de aferição construída e apresentada, são implementadas as orientações para a aferição da usabilidade num estudo de caso, baseadas nas expectativas e desejos dos idosos, matriculados na disciplina de introdução à informática do Projeto de Extensão -UNCISATI -Universidade da terceira Idade da Universidade Estadual de Ciências da Saúde de Alagoas -UNCISAL.","In order to present a method to assess the usability of web site targeted at elderly users, the approach presented in this paper is intended to verification from the user perspective using the old method of investigation, combined with the prospect of experts, using the method of inspection. The measurement from the point of view of the user is based on the study of the public to which the site is directed, considering the level of the user in the use of web resources and their profile as their needs in order to be able to establish the requirements for measuring usability more appropriate. The gauging specialists turn, is based inspection methods in order to verify compliance with a set of rules of usability of web sites geared to elderly users. The method presented in this paper provides a systematic and orderly assessment of usability as well as validation of the results obtained for the methods used. Finally, to support measurement methodology presented measurements are developed based on the expectations and desires of elderly users, attending the course of introduction to computer science Extension Project -UNCISATI -University of the Third Age University of Health Sciences Alagoas -UNCISAL.","('World Wide Web (Sistema de recuperação da informação)', 'Sites da Web -Avaliação', 'Sites da Web -Idosos', 'World Wide Web (information retrieval system)', 'Web sites-evaluation', 'Web sites-Seniors')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/2105","2013-10-11","https://www.repositorio.ufal.br/bitstream/riufal/2105/1/Um%20modelo%20de%20aferi%c3%a7%c3%a3o%20de%20usabilidade%20de%20web%20sites%2c%20orientados%20ao%20usu%c3%a1rio%20idoso.pdf","A model for measuring the usability of web sites geared to elderly users",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/2452","Campus A.C. Simões","Instituto de Computação","Dissertação","Um modelo computacional para classificação da motivação de estudantes em educação on-line","('Cheops Araujo Malta',)","('Alan Pedro da Silva',)","('Jorge Artur Peçanha de Miranda Coelho', 'Patrícia Augustin Jaques Maillard')","Em 2014, o Brasil contou com uma oferta de 25.166 cursos por meio da educação a distância. Este e outros dados mostram que a EAD não é um modismo,mas sim parte de um amplo e contínuo processo de mudança, bem como atestam a fase de consolidação desta modalidade de ensino, principalmente no ensino superior, onde seu crescimento tem sido expressivo e sustentado. No entanto, ainda são muitos os desafios sejam eles pedagógicos e/ou tecnológicos. Um destes desafios está relacionado com a motivação para aprender. Estudos evidenciam que conhecer os motivos e as metas que levam os alunos a envolver-se ou não com a aprendizagem é importante, tanto do ponto de vista motivacional, quanto ao fato de ser uma questão-chave para ajudar a compreender os processos de aprendizagem e as variáveis que os determinam. Neste sentido, propomos um modelo para a classificação automática da motivação dos estudantes da educação on-line, gerado com o auxílio de Instrumentos Psicométricos e Mineração dos Dados Educacionais. O modelo é desenvolvido em três etapas que ocorrem de modo sequencial, iniciando com a “construção da base de dados”, onde são coletados os dados dos alunos por meio de instrumentos psicométricos (questionários) e logs (registros de interação no ambiente virtual de aprendizagem). Na etapa seguinte, é realizado um experimento para “seleção do algoritmo para classificação” a ser utilizado na construção dos modelos. Finalmente, na etapa de “construção do modelo”, é construído e validado o modelo para classificação da motivação dos estudantes.","In 2014, Brazil offered 25,166 courses through distance education. Data show that the distance education (Educação a Distância -EAD, in portuguese) is not a fad, but rather part of a broad and continuous process of change, and attest the consolidation phase of this type of education, especially in higher education, showing significant and sustainable growth. However, there are still many pedagogical and technological challenges. One of these challenges is related to the motivation to learn. Studies show that the reasons and the goals that lead students whether to engage learning, or not, is important from a motivational point of view, as well as a key issue to help educators understanding the processes of learning and their most important constructs. In this sense, we propose a model to automatically classify the motivation to learn from students of online/distance education. The model is generated with the aid of Psychometric instruments and Educational Data Mining. It is developed in three stages that occur sequentially, starting from the ""construction of the database,"" where students’ data are collected through psychometric instruments (questionnaires) and logs (recorded actions and interactions in the virtual learning environment). In the next step, we carried out an experiment to ""algorithm selection for classification"" to be used in the construction of models. Finally, at the stage of ""model building"" is constructed and validated the model for student motivation classification.","('Programação de computadores – Ensino', 'Ferramenta de auxílio a aprendizagem', 'Motivação na educação', 'Mineração de dados educacionais', 'Motivation to Learn', 'Computer programming – Teaching', 'Motivation in education', 'Educational data mining', 'Distance education', 'Achievement goals')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/2452","2016-06-27","https://www.repositorio.ufal.br/bitstream/riufal/2452/1/Um%20modelo%20computacional%20para%20classifica%c3%a7%c3%a3o%20da%20motiva%c3%a7%c3%a3o.pdf","A computational model for the classification of the students’ motivation in online education","('Ig Ibert Bittencourt Santana Pinto',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/6962","Campus A.C. Simões","Instituto de Computação","Dissertação","Um modelo computacional para a classificação automática do tipo de personalidade de estudantes do ensino a distância","('David Medeiros Batinga',)","('Ranilson Oscar Araújo Paiva',)","('Diego Dermeval de Medeiros da Cunha Matos', 'Alan Pedro da Silva')","Nas últimas décadas, o papel dos traços de personalidade tem ganho relevância para compreender, explicar, e mais recentemente, prever padrões comportamentais que os indivíduos externalizam quando vivenciam diversas situações cotidianas, incluindo: tomar decisões, estabelecer relações interpessoais, lidar com questões financeiras, gerir carreira e trabalho, etc. Pesquisas têm demonstrado a importância e a aplicabilidade do conceito de personalidade no contexto educacional; tendo sido identificadas correlações entre a personalidade dos estudantes com vários assuntos de interesse para o processo de aprendizagem. Por exemplo, estudos anteriores identificaram uma forte correlação entre a personalidade dos estudantes e as pontuações obtidas por esses alunos nas provas de avaliação de aprendizagem; sendo possível, ao conhecer anteci-padamente o tipo de personalidade de um aluno, estimar com uma boa margem de segurança se ele obterá aprovação nas avaliações do seu curso. Entretanto, o diagnóstico dos traços de personalidade de um aluno não é uma atividade simples e geralmente é realizado por meio de entrevistas e observações, ou através do uso de questionários. Num ambiente de ensino à distância, a aplicação de ambas abordagens se mostra ainda mais complexa, então pesquisas têm buscado novos caminhos para viabilizar o diagnóstico dos traços de personalidade. Uma das alternativas é realizar o diagnóstico da personalidade com o auxílio de modelos matemáticos que são aplicados para análise dos comportamentos e dos padrões de interação dos alunos realizados no ambiente de ensino à distancia. O objetivo deste trabalho foi investigar a possibilidade de desenvolvimento e avaliação de um modelo computacional que se propõe a identificar os traços de personalidade de alunos através da análise das interações realizadas no ambiente virtual de aprendizagem. Para isso, delineou-se uma pesquisa experimental realizada no âmbito dos cursos de graduação à distância da Universidade Federal de Alagoas. No experimento, um questionário de personalidade foi aplicado a uma amostra de estudantes e, na sequência, um conjunto de algoritmos de classificação foi usado para analisar o uso do ambiente de aprendizagem, a fim de se obter possíveis correlações entre os traços de personalidade dos alunos e as suas interações no ambiente virtual de aprendizagem. Como resultado geral, foi observado que nenhum dos algoritmos de classificação obteve resultados satisfatórios.","In the last decades, the role of personality traits has gained relevance for understanding, ex-plaining and more recently, the behavioral patterns that people exhibit when they experience different situations, including everyday situations such as: making decisions, using interpersonal relationships, dealing with finance, career and work management issues, etc. Research has demonstrated the importance and applicability of the concept of personality in the educational context; correlations were identified between the students’ personality with various subjects of interest to the learning process. For example, previous studies have identified a strong correlation between students’ personality and the scores obtained by those students in the learning assessment tests; it is possible, when knowing in advance the personality type of a student, to estimate with a good safety margin whether he will pass his course evaluations. However, the diagnosis of a student’s personality traits is not a simple activity and is usually carried out through interviews and observations, or through the use of questionnaires. In a distance learning environment, the application of both approaches proves to be even more complex, so research has sought new ways to make the diagnosis of personality traits viable. One of the alternatives is to carry out the diagnosis of the personality with the aid of mathematical models that are applied to analyze the behaviors and interaction patterns of students carried out in the distance learning environment. The objective of this work was to investigate the possibility of developing and evaluating a computational model that proposes to identify the personality traits of students through the analysis of the interactions carried out in the virtual learning environment.For this, an experimental research was carried out in the context of distance undergraduate courses at the Federal University of Alagoas. In the experiment, a personality questionnaire was applied to a sample of students and, subsequently, a set of classification algorithms was used to analyze the use of the learning environment, in order to obtain possible correlations between students’ personality traits. and their interactions in the virtual learning environment. As a general result, it was observed that none of the classification algorithms obtained satisfactory results.","('Traços de personalidade', 'Aprendizagem', 'Educação à distância', 'Modelo computacional', 'Mineração de dados educacionais', 'Distance Education', 'Personality traits', 'Personality cassification', 'Educational data mining')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/6962","2020-01-15","https://www.repositorio.ufal.br/bitstream/riufal/6962/3/Um%20modelo%20computacional%20para%20a%20classifica%c3%a7%c3%a3o%20autom%c3%a1tica%20do%20tipo%20de%20personalidade%20de%20estudantes%20do%20ensino%20a%20dist%c3%a2ncia.pdf","A computational model for the automatic classification of personality type distance learning students","('Jorge Artur Peçanha de Miranda Coelho',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/1845","Campus A.C. Simões","Instituto de Computação","Dissertação","Modelo computacional baseado em conhecimento para avaliação postural tridimensional","(""Hugo Gustavo Franco Sant'Ana"",)","('Aydano Pamponet Machado',)","('Evandro de Barros Costa', 'Rodrigo Freitas Monte Bispo')","Está bem estabelecida na literatura a importância da caracterização da postura para um bom diagnóstico cineticofuncional, identificando e mensurando as alterações posturais e os desequilíbrios musculares permitindo a elaboração adequada de programas de reabilitação. Para facilitar a ação do especialista, programas computacionais foram desenvolvidos para análises tridimensionais das curvaturas da coluna vertebral a partir de imagens bidimensionais. Tais métodos apresentam limitações, mesmo com a evolução tecnológica, inclusive os métodos mais recentes com a utilização de captura tridimensional para avaliação dos desequilíbrios musculares. Sendo assim, urge a necessidade de aperfeiçoar os métodos utilizados para a avaliação das alterações posturais, corrigindo as limitações e aperfeiçoando as técnicas existentes para identificação das assimetrias, desvios na coluna e alterações nas articulações periféricas. Esse estudo trata-se de uma pesquisa metodológica de desenvolvimento com o objetivo geral de propor um modelo computacional baseado em conhecimento para avaliação postural tridimensional. E, objetivos específicos: desenvolver algoritmos novos ou aperfeiçoar os que já existem para uma análise postural baseada nas coordenadas cartesianas em três dimensões; propor um modelo computacional baseado no conhecimento que minimize as limitações dos métodos já existentes; testar a implementação do modelo através de um estudo piloto. Por fim, o estudo mostrou que, o modelo proposto pretende resolver parte das limitações que as atuais ferramentas computacionais para a avaliação biofotogramétrica.","It is well established in the literature the importance of the posture characterization for a good kinetic-functional diagnosis, identifying and measuring postural changes and muscle imbalances allowing the adequate elaboration of rehabilitation programs. To facilitate the action of the specialist, computer programs were developed for three-dimensional analyzes of the curvatures of the spine from two-dimensional images. Such methods have limitations, even with technological evolution, including the most recent methods with the use of three-dimensional capture for the evaluation of muscular imbalances. Thus, there is an urgent need to improve the methods used to evaluate postural changes, correcting the limitations and improving existing techniques for identifying asymmetries, spinal deviations and alterations in peripheral joints. This study is a methodological research of development With the general aim of proposing a knowledge-based computer model for three-dimensional postural evaluation. And, specific objectives: to develop new algorithms or to perfect those that already exist for a postural analysis based on Cartesian coordinates in three dimensions; Propose a knowledge-based computer model that minimizes the limitations of existing methods; Test the implementation of the model through a pilot study. Finally, the study showed that, the proposed model intends to solve part of the limitations that the current computer tools for the biophotogrammetric evaluation bear.","('Fotogrametria', 'Postura humana', 'Biofotogrametria computadorizada', 'Modelo computacional', 'Software', 'Photogrammetry', 'Human posture', 'Computerized biophotogrammetry', 'Computational model')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1845","2017-05-22","https://www.repositorio.ufal.br/bitstream/riufal/1845/1/Modelo%20computacional%20baseado%20em%20conhecimento%20para%20avalia%c3%a7%c3%a3o%20postural%20tridimensional.pdf","Computational knowledge-based model for three-dimensional postural assessment",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/123456789/14380","Campus A.C. Simões","Instituto de Computação","Dissertação","Um modelo de aferição de usabilidade dos diferentes personas em ambientes virtuais de aprendizagem no contexto da educação à distância a partir de um estudo de caso do sistema UAB/UFAL","('Ângela Lima Peres',)","('Fábio Paraguaçu Duarte da Costa',)","('Arturo Hernández-Domínguez', 'Cleide Jane de Sá Araujo Costa', 'Lynn Rosalina Gama Alves')","O presente trabalho apresenta um Modelo de Aferição de Usabilidade de Ambientes Virtuais de Aprendizagem no contexto da educação à distância a partir do estudo de caso do Moodle UAB/UFAL. Estes ambientes representam a sala de aula do estudante onde ele obtém os materiais, executa atividades de aprendizagem, interage com colegas, tutores e professores e é avaliado. Aferições e recomendações de melhoria em usabilidade têm como meta promover a motivação no processo de ensino-aprendizagem. O modelo propõe a aferição através de questionários e complementada por análise das interações provenientes da observação em laboratório. As dimensões propostas para análise são: eficácia, eficiência, facilidade de uso, facilidade de aprendizado, memorização, facilidade na recuperação de erros, disponibilidade e utilidade dos recursos, confiabilidade, satisfação e motivação em explorar os inúmeros recursos da plataforma. Personas foram criados com o objetivo de dar mais visibilidade aos perfis encontrados no estudo e a análise foi realizada para cada um destes perfis. O modelo sugere métricas quantitativas complementadas por análises qualitativas. O estudo de caso da avaliação da plataforma AVA Moodle UAB/UFAL envolveu 55 estudantes. O AVA obteve um bom nível de usabilidade no contexto analisado em quase todas as dimensões, com exceção da facilidade na correção de erros e disponibilidade dos recursos que podem ser aprimoradas. Nas análises qualitativas, foram identificadas questões que interferem na percepção da usabilidade da plataforma relacionadas a aspectos operacionais e de planejamento pedagógico e administrativos.","This research presents a Model to analyze the usability of learning management systems in distance learning through the case study of Moodle UAB/UFAL. This environment is the student virtual classroom where they obtain the materials, execute tasks, and interact with classroom mates, tutors, and teachers and also is evaluated. The usability assessment and improvement recommendations have the goal of promoting the motivation in teaching-learning process. The techniques proposed are questionnaires and laboratory usability test with video records and analysis. The dimensions are: efficacy, efficiency, ease of use, ease of learning, memorization, easy of recover from errors, usefulness and usable, reliability, motivation and satisfaction. Personas were used to promote visibility of the profiles identified in this study. The analysis have to involve each of identified persona. The recommended metrics are quantitative but also complemented by a qualitative analysis. The case study of Moodle UAB/UFAL was provided by 55 students. The AVA Moodle has a good level of usability in the research context. There are some questions related to operational and also pedagogical and administrative issues that interfere in the usability perception of LMS.","('Ambientes virtuais de aprendizagem – Usabilidade', 'Educação à distância', 'Métricas de usabilidade', 'Personas', 'Virtual learning environments – Usability', 'Distance education', 'Usability metrics')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/14380","2009-11-01","https://www.repositorio.ufal.br/bitstream/123456789/14380/1/Um%20modelo%20de%20aferi%c3%a7%c3%a3o%20de%20usabilidade%20dos%20diferentes%20personas%20em%20ambientes%20virtuais%20de%20aprendizagem%20no%20contexto%20da%20educa%c3%a7%c3%a3o%20%c3%a0%20dist%c3%a2ncia%20a%20partir%20de%20um%20estudo%20de%20caso%20do%20sistema%20UABU.pdf","",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/5473","Campus A.C. Simões","Instituto de Computação","Dissertação","Um modelo conceitual para apoiar o desenvolvimento de ferramentas computacionais para auxiliar no processo de aquisição da língua de sinais por criança surda","('Floripes Teixeira Santos',)","('Evandro de Barros Costa',)","('Fábio Paraguaçu Duarte da Costa', 'Roberta Vilhena Vieira Lopes', 'Jair Barbosa da Silva')","A linguagem é um recurso importante para o desenvolvimento social e cognitivo do ser humano. Em geral, é adquirida naturalmente, até os cinco anos de idade, a partir da interação da criança com o ambiente familiar e social. Todavia, as crianças surdas filhas de pais ouvintes (90% dos casos) não possuem a oportunidade de acesso a sua língua natural desde o nascimento, pois o canal de comunicação utilizado pelos pais ouvintes (auditivo) não é o mesmo da criança surda (visual). Sendo assim, essa diferença linguística, na maioria das vezes, impossibilita a criança de receber o input adequado para adquirir a língua de sinais no período apropriado. Tal situação implica na aquisição tardia da linguagem, acarretando sérios danos a sua aprendizagem, seu desenvolvimento social e cognitivo, bem como a relação familiar. Portanto, os pais ouvintes precisam buscar conhecer a língua de sinais e oportunizar o contato da criança surda com a língua o mais precocemente possível, possibilitando, assim, que a criança desenvolva sua linguagem de forma natural. Nessa perspectiva, a tecnologia se apresenta como um recurso importante para auxiliar o acesso da criança surda à língua de sinais. Todavia, as ferramentas computacionais destinadas às crianças surdas na faixa etária até os cinco anos ainda são escassas, principalmente, em Língua Brasileira de Sinais – Libras. Considerando tal lacuna, este trabalho desenvolveu um modelo conceitual para apoiar a concepção de ferramentas computacionais destinadas a auxiliar a criança surda filha de pais ouvintes na aquisição da língua de sinais. O modelo conceitual foi desenvolvido a partir de um estudo detalhado sobre o desenvolvimento da linguagem e das variáveis que envolvem o processo de aquisição da língua de sinais pela criança surda filha de pais ouvintes. Também foram consideradas as características do público-alvo e a tecnologia computacional disponível. O modelo proposto foi organizado a partir de três eixos norteadores: objetivo, público-alvo e tecnologia. Com base no modelo desenvolvido foi elaborado um conjunto de diretrizes para orientar, de forma mais detalhada, a concepção de ferramentas destinadas à aquisição da linguagem da criança surda entre 2 e 3 anos. O modelo conceitual e as diretrizes propostas nesta dissertação foram validados através da versão protótipo de um aplicativo disponibilizado para as plataformas Android e iOS. O protótipo, denominado Loodus, foi submetido a um processo de avaliação com surdos, educadores de surdos e intérpretes de Libras, utilizando um questionário semiestruturado. Os participantes da pesquisa avaliaram a proposta positivamente.","Language is an important resource for the social and cognitive development of the human being. Usually, it is acquired naturally, up to five years of age, from the interaction of the child with the family and social environment. However, deaf children of hearing parents (90% of cases) do not have the opportunity to interact with their natural language from birth, since the communication channel used by the hearing parents (auditory) is distinguished from the deaf child (visual). Therefore, this linguistic difference, in most cases, makes it impossible for the child to receive the adequate input to acquire sign language in the ideal period. This situation implies the late acquisition of language, causing serious damage to their learning, their social and cognitive development, as well as the family relationship. Therefore, the hearing parents need to know the sign language in order to approximate the deaf child with the language as early as possible, thus enabling the child to develop their language in a natural way. In this perspective, technology is an important resource to assist the deaf child access to sign language. However, computational tools for deaf children up to the age of five are still scarce, especially in the Brazilian Sign Language – Libras. This work has addressed this gap by developing a conceptual model to support the computational tool design in order to assist the deaf child of hearing parents in the acquisition of sign language. The model has been created from a detailed study on the development of the tongue and variables related to the sign language acquisition process by the deaf child of hearing parents. Other issues regarded are the target audience and the computational technology available. The proposed model was organized from three guiding axes: objective, target audience and technology. Based on this, a set of guidelines was developed in order to orientate the tools design for acquiring the language of the deaf child between 2 and 3 years. The conceptual model and the guidelines proposed in this dissertation were validated through an initial prototype of a móbile application made available for the Android and iOS platforms. The prototype, denoted Loodus, was evaluated by deaf, deaf educators and interpreters of Libras, using a semi-structured questionnaire and obtaining positive results.","('Tecnologia – Surdez', 'Crianças surdas -Família', 'Aquisição da linguagem', 'Língua de sinais', 'Língua Brasileira de Sinais', 'Technology – Deafness', 'Deaf children – Family', 'Acquisition of language', 'Sign language', 'Brazilian Language of Signals')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/5473","2018-08-28","https://www.repositorio.ufal.br/bitstream/riufal/5473/1/Um%20modelo%20conceitual%20para%20apoiar%20o%20desenvolvimento%20de%20ferramentas%20computacionais%20para%20auxiliar%20no%20processo%20de%20aquisi%c3%a7%c3%a3o%20da%20l%c3%adngua%20de%20sinais%20por%20crian%c3%a7a%20surda.pdf","A conceptual model to support the development of computational tools to auxiliate the process of acquisition of sign language by deaf child","('Fábio José Coutinho da Silva',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/2111","Campus A.C. Simões","Instituto de Computação","Dissertação","Modelo baseado em RBC usando algoritmos genéticos para auxiliar na educação ambiental utilizando casos no contexto do gerenciamento do lixo eletrônico","('Eraldo Alves da Silva Neto',)","('Fábio Paraguaçu Duarte da Costa',)","('Roberta Vilhena Vieira Lopes', 'André Ricardo Magalhães')","A questão ambiental é bastante discutida na nossa sociedade, na verdade o homem e a natureza sempre tiveram uma relação conflitante, é preciso pensar e agir de forma rápida, com eficiência e eficácia sobre como o ser humano se relaciona com o meio ambiente buscando o desenvolvimento auto-sustentável sem comprometer a qualidade de vida do planeta Terra. A sociedade atual, capitalista, industrial e extremamente apoiada pela indústria da propaganda implicitamente passou a imprimir um estilo de vida altamente consumista, em relação ao exacerbado avanço tecnológico e com isso, vive-se um momento de intensa aquisição e descarte de equipamentos cujo tempo de vida útil torna-se cada vez menor. O lixo eletrônico ou “e-lixo” gerado pela grande quantidade de produtos tecnológicos colocados à disposição da sociedade é um contrapeso que a evolução do acesso a informação e comunicação, traz no seu bojo um grande prejuízo ao meio ambiente e consequentemente ao homem. O descarte do e-lixo é altamente prejudicial à natureza, devido aos seus componentes, se não forem descartados e tratados adequadamente, eles também podem representar novas oportunidades de negócio e aprendizado, como já é feito em várias partes do mundo, inclusive no Brasil. Este trabalho tem como foco propor um modelo computacional de aprendizagem baseado em RBC usando algoritmos genéticos para auxiliar na educação ambiental utilizando a representação de casos do processo de gerenciamento do lixo eletrônico tendo como área de estudo a cidade de Maceió/AL – uma cidade com um potencial turístico enorme e com uma dimensão geográfica, relativamente pequena e como complemento, identificar o vocabulário de indexação do escopo do gerenciamento do “lixo” tecnológico e construir uma base de casos sobre a temática.","The environmental issue is widely debated in our society, in fact man and nature have always had a conflicted relationship, you need to think and act quickly, efficiently and effectively on how humans relate to the environment seeking self development -sustainable without compromising the quality of life on the planet Earth. Current society, capitalist, industrial and highly supported by the advertising industry has implicitly printing a highly consumerist lifestyle, exacerbated in relation to technological advancement and with that, we live a moment of intense acquisition and disposal of equipment which time life becomes increasingly smaller. Electronic waste or “e-waste” generated by the large amount of technological products made available to the company is a counterweight to the evolution of access to information and communication, brings in its wake a great damage to the environment and consequently to man. Disposal of e-waste is highly harmful to nature due to its components, if not properly treated and disposed of, they can also represent new business opportunities and learning, as is done in many parts of the world, including Brazil. This work focuses on proposing a computational model of learning based on RBC using genetic algorithms to assist in environmental education using the representation case management process of e-waste as a study area with the city of Maceió/AL -a city with a tourism potential and a huge geographical size, relatively small, and in addition, identify the vocabulary indexing the scope of management ""trash "" and build a technological base cases on the subject.","('Tecnologia da informação', 'Lixo eletrônico', 'Educação ambiental', 'Information technology', 'Junk mail', 'Environmental education')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/2111","2013-12-22","https://www.repositorio.ufal.br/bitstream/riufal/2111/1/Modelo%20baseado%20em%20RBC%20usando%20algoritmos%20gen%c3%a9ticos%20para%20auxiliar%20na%20educa%c3%a7%c3%a3o%20ambiental%20utilizando%20casos%20no%20contexto%20do%20gerenciamento%20do%20lixo%20eletr%c3%b4nico.pdf","RBC model based on using genetic algorithms to aid in cases in environmental education using context of management of e-waste electronic","('Arturo Hernández-Domínguez',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/1616","Campus A.C. Simões","Instituto de Computação","Dissertação","Um modelo computacional de combinação social aplicado ao processo de planejamento de orientadores em ambientes virtuais de aprendizagem","('Douglas de Lima Feitosa',)","('Fábio Paraguaçu Duarte da Costa',)","('Arturo Hernández-Domínguez', 'Guilherme Ataíde Dias')","A Educação a Distância (EAD) é uma modalidade de ensino capaz de viabilizar a formação de profissionais com dificuldades de acesso à formação universitária. Para tanto, esta modalidade necessita dispor de um conjunto de ferramentas computacionais que viabilizem o processo de ensino aprendizagem (PEREIRA et al., 2006a). A identificação de possíveis orientadores e a sobrecarga de trabalho são algumas das dificuldades existentes neste processo. Pesquisas nesta área investem na idéia de trabalhar os interesses de alunos, professores e gestores da educação. Para tanto, esta pesquisa utilizou uma abordagem quali-quantitativa, de maneira que os dados foram coletados em um Ambiente Virtual de Aprendizagem (AVA), bem como através da aplicação de um questionário estruturado aos orientadores em potencial. Desta forma, este trabalho tem o objetivo de propor um Modelo Computacional de Combinação Social que auxilia o Gestor de EAD no processo de planejamento de orientadores de trabalhos monográficos. São apresentadas três ferramentas computacionais, desenvolvidas por meio de algoritmos genéticos, que foram aplicadas no âmbito do Curso de Bacharelado em Sistemas de Informação a Distância, ofertado pela Universidade Federal de Alagoas e Universidade Aberta do Brasil. Os resultados obtidos apontam que o modelo computacional proposto pode ser utilizado para auxiliar os gestores de EAD na redução dos casos de incompatibilidades de perfis de alunos e orientadores, bem como na redução da sobrecarga de trabalho dos docentes.","Distance Education (DE) is a teaching modality capable of providing professional formation for people with limited access to university education. For this end, a set of computational tools is required in assisting the teaching and learning process (PEREIRA et al., 2006a). Moreover, some common obstacles for DE are the issues of identifying possible advisors for those students in the process of writing monographs and work overload. This has become an important issue for researches, placing their emphasis on the idea of working the interests of students, teachers and education managers. For such, this work used a quali-quantitative approach, in a way that data were collected in a Distance Learning Environment (DLE) and also by the application of a structured questionnaire to potential advisors. As such, this work has the objective of proposing a Computational Model of Social Combination that helps the DE Manager in the process of advisors planning for monograph works. This paper presents three computational tools developed by using genetic algorithms. These tools were applied according to the context of the DE undergraduate course of Information Systems offered by the Federal University of Alagoas and the Open University of Brazil. The results show that the proposed computational model can be used to help DE Managers to reduce the cases of studentsâ€™ and advisorsâ€™ profiles incompatibility, as well as to reduce docent work overload.","('Ambiente virtual de aprendizagem', 'Educação à distância', 'Trabalhos acadêmicos -Orientação', 'Orientadores -Formação', 'Combinação social', 'Algoritmos genéticos', 'Distance learning environment', 'Distance education', 'Planning advisor', 'Social combination', 'Genetic algorithms')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1616","2011-02-28","https://www.repositorio.ufal.br/bitstream/riufal/1616/1/Um%20modelo%20computacional%20de%20combina%c3%a7%c3%a3o%20social%20aplicado%20ao%20processo%20de%20planejamento%20de%20orientadores%20em%20ambientes%20virtuais%20de%20aprendizagem.pdf","A computational model of social combination applied to the advisor planning process in distance learning environments","('Roberta Vilhena Vieira Lopes',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/2375","Campus A.C. Simões","Instituto de Computação","Dissertação","Modelagem matemática para otimização de dietas de portadores de Diabetes Mellitus","('Juliana Cristina Pereira Lima Paulino',)","('João Inácio Soletti',)","('Evandro de Barros Costa', 'Sandra Mary Lima Vasconcelos')","O Diabetes Mellitus é uma enfermidade que afeta milhões de pessoas em todo o mundo e se apresenta de diversas formas, sendo as principais os tipos 1 e 2 da doença. O tipo 1 ocorre quando a produção do hormônio insulina pelo pâncreas é insuficiente, sendo frequentemente diagnosticado em crianças e adolescentes. O tipo 2 é responsável por mais de 90% dos casos de diabetes, caracterizando-se por mau funcionamento dos receptores de insulina, sendo mais comum em adultos e estando relacionada com excesso de peso, sedentarismo e alimentação inadequada. Em todas as formas da doença há um aumento da concentração dos níveis de glicose na corrente sanguínea, sendo importante a observação da quantidade e o tipo de carboidrato presente na alimentação, o índice glicêmico do alimento a ser ingerido pelo indivíduo entre outros fatores para diminuição de seus efeitos indesejados no organismo do portador de Diabetes Mellitus. A busca por métodos viáveis do controle do diabetes assim como a adesão pelos pacientes tem incentivado o desenvolvimento de pesquisas e a inovação das metodologias já existentes. Este trabalho tem como objetivo apresentar um modelo matemático que seja capaz de permitir auxílio ao planejamento de dieta de portadores de Diabetes Mellitus através da Programação Linear. Para isso foram desenvolvidas tabelas com base de dados suficientes para elaboração de planos alimentares genéricos no software GAMS® onde se contemplam os alimentos e seus respectivos valores nutricionais. Foram realizados três estudos de casos genéricos simulando escolhas hipotéticas de usuários/pacientes de diferentes sexos, alturas e níveis de intensidadede atividade física desempenhadas, a fim de verificar o emprego desta modelagem matemática quanto ao atendimento às recomendações nutricionais pertinentes. O modelo foi gerado a partir de parâmetros relativos à observância das recomendações nutricionais identificando as melhores combinações que possibilitem a minimização do consumo diário de carboidratos, resultando nas soluções ótimas das dietas obtidas.","Diabetes Mellitus is a disease that affects millions of people around the world and presents itself in several ways, the main types 1 and 2 of the disease. Type 1 occurs when the production of the hormone insulin by the pancreas is insufficient and is often diagnosed in children and adolescents. Type 2 is responsible for more than 90% of diabetes cases, characterized by malfunctioning of insulin receptors, being more common in adults and related to overweight, sedentary lifestyle and inadequate diet. In all forms of the disease there is an increased concentration of glucose levels in the bloodstream, being important the observation of the amount and type of carbohydrate present in the diet, the glycemic index of the food to be ingested by the individual among other factors to decrease its undesirable effects on the body of the Diabetes Mellitus carrier. The search for viable methods of diabetes control as well as patient adherence has encouraged the development of research and innovation of existing methodologies. This work aims to present a mathematical model that is able to allow assistance to the diet planning of Diabetes Mellitus carriers through Linear Programming. In order to do so, tables with sufficient data bases were developed for the elaboration of generic food plans in the GAMS® software where food and their respective nutritional values are considered. Three generic case studies were performed simulating hypothetical choices of users/patients of different sexes, heights and intensity levels of physical activity performed, in order to verify the use of this mathematical modeling in compliance with the pertinent nutritional recommendations. The model was generated from parameters related to the observance of nutritional recommendations, identifying the best combinations that make possible the minimization of daily carbohydrate consumption, resulting in optimal solutions of the diets obtained.","('Diabetes mellitus', 'Modelagem matemática', 'Programa linear', 'Dietas -Otimização', 'Mathematical modeling', 'Linear programming', 'Optimization of diets')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/2375","2017-11-29","https://www.repositorio.ufal.br/bitstream/riufal/2375/1/Modelagem%20matem%c3%a1tica%20para%20otimiza%c3%a7%c3%a3o%20de%20dietas%20de%20portadores%20de%20diabetes%20mellitus.pdf","Mathematical modeling for optimization of diets of Diabetes Mellitus carriers",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/1775","Campus A.C. Simões","Instituto de Computação","Dissertação","Uma modelagem diagnóstica multidimensional para o entendimento do perfil de alunos iniciantes em programação","('Maria Cristina Tenório Cavalcante Escarpini',)","('Evandro de Barros Costa',)","('Jorge Artur Peçanha de Miranda Coelho', 'Dalton Dario Serey Guerrero')","Estudos revelam dificuldades por parte de estudantes no aprendizado de programação para iniciantes. Trata-se de um problema reportado em várias instituições, tal como se observa na literatura sobre o assunto. Neste sentido, o presente trabalho buscou esclarecer possíveis fatores cognitivos relacionados ao desempenho insatisfatório apresentado por muitos estudantes de Ciência da Computação da Universidade Federal de Alagoas, relativamente à atividade de resolução de problemas de programação em um nível iniciante. Neste sentido, procurou-se conhecer quem é este estudante de programação inicial, observando-o em diferentes contextos. Particularmente, investiuse primeiramente na análise de grupos com vistas à compreensão dos estados cognitivos destes estudantes. Além disso, estudou-se a relação entre os dados de desempenho apresentados pelos estudantes na disciplina de programação com disciplinas assumidas como relacionadas tanto na graduação, quanto no ensino médio expresso no exame de ingresso na universidade. Para tanto, avaliou-se diferentes fontes de dados, que trazem informações quantitativas e qualitativas a respeito do estudante: (i) notas de todos os alunos que cursaram a disciplina entre 2006 e 2013, (ii) notas de disciplinas afins a disciplina de programação entre 2010 e 2013, e (iii) conjunto de dados correspondente ao código-fonte produzidos por uma amostra de alunos em exercícios e avaliações. A partir desses dados, foi possível elaborar um modelo para o diagnóstico de perfil dos iniciantes em programação, que identificou a existência de três grupos de alunos, que possuem características cognitivas que variam de estudantes sem sucesso para os que obtiveram sucesso no curso introdutório.","Studies reveal learning difficulties faced by students in taking introductory programming course. This problem has been reported in various institutions, according to the literature on the subject. In this sense, the present study aims to clarify possible cognitive factors related to poor performance shown, particularly, by many students of Computer Science from the Federal University of Alagoas, concerning to the activity of solving programming problems on a beginner level. In this perspective, we have tried to know, in some cognitive respect, the mentioned students of introductory programming, considering them in different academic contexts. Particularly, we invested primarily in the analysis of groups aiming at understanding the cognitive states of these students. Furthermore, we studied two main kinds of relatioships: (i) the relationship between the performance data presented by the students in the discipline of programming and other related disciplines, as well as, (ii) and in the discipline of programming and the score expressed in the exame to access from high school to the university. To this end, we evaluated different data sources, bringing quantitative and qualitative information about the student, such as: (i) scores of all students that took this course between 2006 and 2013, (ii) scores related to disciplines, including discipline programming between 2010 and 2013, and (iii) corresponding to the set of source code produced by a sample of students on home works and reviews data. From these data, it was possible to develop a model for diagnostic profile of beginners in programming, which identified the existence of three groups of students who have cognitive characteristics ranging from students without success for those who have obtained success in the introductory programming course.","('Mineração de dados (Computação)', 'Programação (Computadores) -Estudo e ensino', 'Data mining (computing)', 'Programming (Computers)-Study and teaching')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1775","2013-12-20","https://www.repositorio.ufal.br/bitstream/riufal/1775/1/Uma%20modelagem%20diagn%c3%b3stica%20multidimensional%20para%20o%20entendimento%20do%20perfil%20de%20alunos%20iniciantes%20em%20programa%c3%a7%c3%a3o.pdf","A diagnostic multidimensional modeling for understanding the profile of students beginners in programming","('Rodrigo de Barros Paes',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/2110","Campus A.C. Simões","Instituto de Computação","Dissertação","Modelagem de um ambiente para iniciantes em programação apoiado por um assistente inteligente","('Cledson Calaça Cavalcante Gomes',)","('Patrick Henrique da Silva Brito',)","('Evandro de Barros Costa', 'Jair Cavalcanti Leite')","Neste trabalho é apresentada uma proposta de ambiente computacional denominado AIIP -Ambiente Inteligente para Iniciantes em Programação, cujo objetivo é auxiliar alunos e professores no processo de ensino/aprendizagem de programação de computadores. O AIIP utiliza a abordagem de resolução de problemas, cujos problemas armazenados em sua base de dados são propostos para serem resolvidos pelos alunos durante o momento de interação com o ambiente. O AIIP possui ainda um assistente inteligente para auxiliar os alunos, acompanhando suas ações, fornecendo dicas e feedbacks apropriados durante o processo de resolução dos problemas, além de identificar os erros cometidos durante o processo de desenvolvimento de suas soluções algorítmicas. Com relação aos professores, o assistente inteligente também auxilia ao avaliar as soluções algorítmicas dos alunos de forma automática, de acordo com métricas pré-estabelecidas, passíveis de flexibilização. Após a realização de um experimento e aplicação de um questionário, ambos relacionados ao uso do AIIP, com alunos do curso de Sistemas de Informação à Distância da Universidade Federal de Alagoas, foram encontrados resultados que apontam para a viabilidade da proposta apresentada como ferramenta de auxilio a alunos e professores em turmas iniciais de programação de computadores.","This work presents a proposal for a computing environment called AIIP -Intelligent Environment for Beginners in Programming, whose objective is to help students and teachers in the teaching/learning process of computer programming. AIIP uses the problem solving approach, whose problems stored in their database are proposed to be solved by the students during their interactions with the environment. AIIP also has an intelligent assistant to help students, monitoring their actions, providing hints and appropriate feedbacks during the solving problems process, and identifying the mistakes while they are developing their algorithmic solutions. About teachers, the intelligent assistant also helps evaluating students’s algorithmic solutions automatically according to pre-established metrics, capable of flexibility. After conducting an experiment and application of a survey, both related to the use of AIIP, with Information Systems students of Federal University of Alagoas, the obtained results indicate the feasibility of the proposal as tool to help students and teachers in initial classes of computer programming.","('Programação (Computadores) -Ensino', 'Agentes inteligentes (Software)', 'Sistemas de informação -Educação', 'Programming (Computers)-Teaching', 'Intelligent agents (Software)', 'Information systems -Education')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/2110","2012-12-13","https://www.repositorio.ufal.br/bitstream/riufal/2110/1/Modelagem%20de%20um%20ambiente%20para%20iniciantes%20em%20programa%c3%a7%c3%a3o%20apoiado%20por%20um%20assistente%20inteligente.pdf","Modeling of an environment for beginners in programming supported by an intelligent assistant","('Eliana Silva de Almeida',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/1862","Campus A.C. Simões","Instituto de Computação","Dissertação","Modelagem formal de workflows a partir de uma metodologia para gestão de processos de negócio na saúde pública","('André Gustavo Teixeira Lins',)","('Eliana Silva de Almeida',)","('Alejandro César Frery Orgambide', 'Daniela Barreiro Claro')","A eficiência das políticas de saúde pública no Brasil depende, entre outros fatores, de uma gestão avançada de seus processo de negócio. Entretanto, esses processos muitas vezes se baseiam no conhecimento tácito de seus especialistas e em métodos de trabalho eventualmente mal definidos que podem resultar em dados redundantes, tarefas estagnadas e recursos mal utilizados pelas empresas. No intuito de contribuir para a melhoria desse quadro, sistemas de informação orientados a processo se mostram como grandes aliados na implantação de uma visão mais sistêmica de trabalho nas organizações, principalmente na gestão pública, onde essa cultura não é muito comum. Nesse contexto, destacamos os sistemas de gerenciamento de workflow como uma das melhores soluções para corrigir problemas dessa natureza, por conta de sua habilidade no tratamento de fluxos de trabalho, interligação de tarefas e compartilhamento de recursos nas organizações. Em complemento à modelagem de negócio, é fundamental que a especificação do workflow seja feita de maneira visual, flexível e muito precisa, promovendo a aplicação de técnicas de análise que garantam de maneira eficaz resultados previamente estabelecidos, principalmente em tarefas críticas como o tratamento de pacientes, investigação de epidemias e promoção da saúde coletiva de uma população. De acordo essas premissas, este trabalho tem como objetivo a utilização das workflow-Nets, uma das extensões do formalismo redes de Petri, para especificação formal de workflows e a execução de técnicas de análise como validação, verificação e simulação, norteados por uma metodologia interativa para gestão de processos de negócio fortemente baseada em fluxos de trabalho. Além da especificação do workflow e da nova metodologia apresentada, esse trabalho também promove o desenvolvimento de um sistema de workflow, com um módulo para extração de logs, a partir de sua base de dados, para aplicação da técnica de Workflow mining, usada para identificação do hiato entre modelos de negócio e especificações de workflow. Identificamos nosso escopo de atuação do projeto, a área da saúde pública dedicada à gestão dos processos de monitoramento da qualidade da água para consumo humano em Alagoas e sua ligação com um dos maiores problemas do estado: a mortalidade infantil.","The efficiency of Brazilian Public health policies relies on many variables such as advanced management of its business processes. However, the rules of these processes are often based on tacit specialist knowledge and eventually on erratic working methods which result in redundant data, static tasks and wasted company resources. In order to improve this scenario, process-aware information systems have shown their importance by implementing a more systemic vision of corporate work, especially for public administration where this is not very well known. In the light of this matter, we highlight the workflow management systems as one of the best solutions to correct such problems due to its skill in handling workflows, linking broken tasks and sharing resources. In addition to the process of business modeling, it is essential that this specification is visual, flexible and very accurate, promoting the application of analysis techniques which guarantee previous results, especially in critical activities such as patients treatment, investigation of epidemics, and health promotion for large groups of people. Based on these assumptions, this work aims to adopt the Workflow-nets, an extension of the Petri nets formalism, to the formal specification and implementation of analysis techniques such as validation, verification and simulation, guided by an iterative methodology for business process management heavily based on workflows. Besides the workflow specification and the new methodology presented, this work also develops a workflow system with a log extraction module for the application of Workflow Mining, a technique used to identify the gap between business models and workflow specifications. For the scope of this project, we identified the area of public health responsible for water quality management in Alagoas and its connection with one of the most worrying social problems of the state: the infantile mortality.","('Workflow', 'Saúde pública', 'Petri, Redes de', 'Public health', 'Ptri, Networks of')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1862","2010-04-30","https://www.repositorio.ufal.br/bitstream/riufal/1862/1/Modelagem%20formal%20de%20workflows%20a%20partir%20de%20uma%20metodologia%20para%20gest%c3%a3o%20de%20processos%20de%20neg%c3%b3cio%20na%20sa%c3%bade%20p%c3%bablica.pdf","Workflow formal modeling from a methodology for business process management",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/1767","Campus A.C. Simões","Instituto de Computação","Dissertação","Modelagem adaptativa de processos para instituição de ensino superior","('Arquiris Ferreira da Silva',)","('Alan Pedro da Silva',)","('Marcus de Melo Braga', 'Luciana Peixoto Santa Rita')","Este trabalho tem por objetivo desenvolver uma modelagem adaptativa de processos para Instituições de Ensino Superior, analisar e avaliar o uso da modelagem de processos em diversos tipos de organizações. Sabe-se que o business process é largamente utilizado ao redor do mundo em indústrias de todos os contextos e tamanhos. Porém, o assunto ainda é pouco discutido na gestão acadêmica. No contexto nacional, o Ministério da Educação – MEC, vem criando formas de controlar a qualidade do ensino superior e as IES tem sido obrigadas a se adequar e a manter os indicadores de qualidade propostos dentro de certos limites. Caso estes limites sejam desrespeitados, várias sanções podem ser aplicadas: visitas in loco, perda de vagas, suspensão dos processos seletivos e até mesmo o fechamento. Aliado a isso, sabe-se que na academia existem professores que foram designados para ocuparem cargos de gestão. Comprova-se neste trabalho através da aplicação de questionários que além deste aspecto, estes não receberam capacitação para ocupar tais cargos dentro do meio acadêmico, fazendo suas atividades de acordo com a experiência pessoal de cada um. Em outras palavras, o MEC criou formas de avaliar os cursos superiores mas não definiu os procedimentos para que os indicadores previstos sejam atingidos e forçou que as IES tivessem que fazer um exercício de criatividade. A padronização de processos chega para dar sua contribuição neste cenário. Contudo, ela por si só não é eficiente devido a uma grande diferença entre a indústria e a academia, o dinamismo do ensino superior. Desta forma, apresentamos uma metodologia adaptável que pode ser aplicada em IES de diversos tamanhos. Espera-se desta forma contribuir desta forma com a qualidade do ensino superior como um todo.","as well as to present a solution for using this approach in the academic field. It is known that business process is widely used around the world in industries of all contexts and sizes. However, the subject is still little discussed in academic management. In the national context, the Ministry of Education (MEC) has been creating ways to control the quality of higher education and HEIs have been obliged to adapt and maintain the proposed quality indicators within certain limits. If these limits are not respected, several sanctions can be applied: on-site visits, loss of vacancies, suspension of selective processes and even closure. Allied to this, it is known that in the academy there are professors who have been assigned to hold management positions. It is shown in this work that besides this aspect, they did not receive the qualification to occupy such positions within the academic environment, doing their activities according to the personal experience of each one. In other words, MEC created ways to control the quality of higher education courses but did not define the procedures for them to be achieved the HEIs have to struggle in creativity. The standardization of processes is enough to make a contribution in this scenario. However, it alone is not efficient due to a large difference between industry and academia, the dynamism of higher education. In this way, we present an adaptable methodology that can be applied in HEIs of different sizes. It is expected, in this way, to contribute to the quality of higher education as a whole.","('Computação -Modelagem de processos', 'Gestão acadêmica – Ensino superior -Administração', 'Business Process', 'Business Process and Notation', 'Business process model and notation', 'Academic management', 'Process modeling')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1767","2017-02-14","https://www.repositorio.ufal.br/bitstream/riufal/1767/1/Modelagem%20adaptativa%20de%20processos%20para%20institui%c3%a7%c3%a3o%20de%20ensino%20superior.pdf","Adaptive process modeling for higher education institution","('Ibsen Mateus Bittencourt Santana Pinto',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/2178","Campus A.C. Simões","Instituto de Computação","Dissertação","Modelagem de conceitos geométricos por meio de sistemas de micromundo","('Terence Coelho Lopes de Magalhães',)","('Fábio Paraguaçu Duarte da Costa',)","('Cleide Jane de Sá Araujo Costa', 'Carloney Alves de Oliveira')","Estudantes com dificuldade de aprendizagem em matemática, na área específica de geometria, contribuem para os resultados insatisfatórios nos índices educacionais. Estes resultados são observados e analisados nas avaliações externas, como o Programa Internacional de Avaliação de Alunos -PISA, Prova Brasil, no ensino fundamental e médio. Este trabalho tem como objetivo geral propor um modelo de aprendizagem de conceitos geométricos através da Aprendizagem Baseada em Problemas (ABP), utilizando suportes pedagógicos e o micromundo na área de geometria, o GeoGebra, como programa de aplicação no Ambiente Virtual de Aprendizagem, o Moodle. A pesquisa visa investigar se ocorre aprendizagem de conceitos geométricos com o uso da ABP como metodologia ativa, analisar o uso de suportes pedagógicos como auxílio na resolução de problemas de geometria e verificar se o micromundo GeoGebra auxilia na resolução de problemas de geometria por meio da compreensão das figuras geométricas planas e não planas. Foram utilizados como principais fundamentos teóricos as concepções sobre a APB (Barrows, 1980), as fases de resolução de problemas de George Polya (1975), a teoria da assimilação cognitiva de Ausubel (2001) e as concepções sobre a zona de desenvolvimento proximal de Vygotsky (Ivic, 2010). O estudo coloca em evidência a utilização de metodologias ativas no processo de aprendizagem. O traabalho busca responder a seguinte questão: Como o uso da Aprendizagem Baseada em Problemas (ABP), como metodologia ativa subsidiada por suportes pedagógicos e micromundos de geometria promove a aprendizagem de conceitos geométricos? O método de pesquisa seguido se inscreve numa abordagem qualitativa, o tipo de pesquisa foi a pesquisa ação, onde foram utilizados como instrumentos de coleta de dados o diário de bordo subsidiados pelas observações em sala de aula, no laboratório de informática e no Ambiente Virtual de Aprendizagem (AVA).Foi demonstrado na pesquisa que a implementação da ABP subsidiada com o uso de suportes pedagógicos e do micromundo promoveu ganhos cognitivos no processo de aprendizagem dos estudantes.","Students with learning difficulties in mathematics, in the specific area of geometry, contribute to the unsatisfactory results in the educational indexes. These results are observed and analyzed in external evaluations, such as the International Student Assessment Program -PISA, Prova Brasil, in primary and secondary education. The objective of this work is to propose a model of learning of geometric concepts through Problem Based Learning (PBL), using pedagogical supports and the microworld in the area of geometry, GeoGebra, as an application program in the Virtual Learning Environment, Moodle. The aim of this research is to investigate whether learning of geometric concepts occurs with the use of ABP as an active methodology, to analyze the use of pedagogical supports as an aid in the resolution of geometry problems and to verify if the GeoGebra micromundo helps in the resolution of geometry problems through the understanding of flat and non-planar geometrical figures. Concepts about PBL (Barrows, 1980), George Polya's problem-solving phases (Polya, 1975), Ausubel's theory of cognitive assimilation (Ausubel, 2001) and conceptions about the proximal developmental zone of Vygotsky (Ivic, 2010). The study highlights the use of active methodologies in the learning process. As the use of Problem-Based Learning (PBL), as an active methodology subsidized by pedagogical supports and micromundos of geometry, promotes the learning of geometric concepts? The research method followed is part of a qualitative approach. type of research was the action research, where they were used as instruments of data collection the logbook subsidized by observations in the classroom, in the computer lab and in the Virtual Learning Environment (VLE). It was demonstrated in the research that the implementation of ABP subsidized with the use of pedagogical supports and the microworld promoted cognitive gains in the learning process of the students.","('Geogebra (Software)', 'Conceitos geométricos -Modelagem', 'Aprendizagem baseada em problemas – ABP', 'Problem -based learning', 'Pedagogical supports', 'Geogebra', 'Geometric concepts')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/2178","2017-08-25","https://www.repositorio.ufal.br/bitstream/riufal/2178/1/Modelagem%20de%20conceitos%20geom%c3%a9tricos%20por%20meio%20de%20sistemas%20de%20micromundo.pdf","Modeling geometric concepts through micromundo systems",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/845","Campus A.C. Simões","Instituto de Computação","Dissertação","Um Middleware adaptável para descoberta, composição e invocação automâtica de serviços web semânticos","('Heitor José dos Santos Barros',)","('Evandro de Barros Costa',)","('Patrick Henrique da Silva Brito', 'Daniela Barreiro Claro', 'Hyggo Oliveira de Almeida')","Os Serviços Web Semânticos têm ganhado uma atenção especial pela academia e indústria. Eles têm sido utilizados como uma promessa para possibilitar a automação de todos os aspectos da provisão e uso de Serviços Web, tais como criação, seleção, descoberta, composição e invocação de serviços. Para isso, a comunidade tem se dedicado a criação de ferramentas e técnicas para explorar as informações semânticas destes serviços. Entretanto, como apontado pela comunidade especializada no tema, aplicações baseadas em Serviços Semânticos possuem suas próprias características, interesses e prioridades. Esta diversidade influencia diretamente na escolha das técnicas e tecnologias utilizadas para manipulação de serviços, ou seja, uma mesma ferramenta pode ter resultados satisfatórios em uma determinada aplicação e não ser adequada para outras. Além disso, essas aplicações podem evoluir, o que implica na necessidade de mudança nestas ferramentas. Com o objetivo de contribuir na solução deste problema, propõe-se na pesquisa em pauta um Middleware adaptável para gerenciamento de descoberta e invocação de serviços capaz de integrar diferentes técnicas e ferramentas de acordo com as necessidades da aplicação. Como forma de avaliar o trabalho, realizou-se um estudo de caso envolvendo o uso de Serviços Web Semânticos no domínio de educação, com isso, verificou-se que o Middleware proposto se mostrou eficiente na realização dos processos de descoberta, composição e invocação de serviços de maneira adaptável.","Semantic Web Services domain has gained special attention in academia and industry. It has been adopted as a promise to enable automation of all aspects of Web services provision and use, such as service creation, selection, discovery, composition, invocation. For that, the Semantic Web Services community has been devoted to creating tools and techniques that explore the semantic information of these services. However, the state of the art shows that the aplications based on Semantic Services have their own characteristics, interests and priorities. This diversity directly influences the choice of techniques and technologies for handling services, ie, a single tool can have satisfactory results in a particular application and is not appropriate for others. Moreover, these applications can evolve, which implies the need of changing these tools. Aiming to solve this problem, this work proposes an adaptive middleware for managing discovery and invocation of services capable of integrating different tools and techniques according to application needs. In order to validate the work, a case study with Semantic Web Services of education domain is presented, with this, it was noted that the proposed Middleware is efficient for performing the processes of discovery, composition and invocation of services in an adaptable manner.","('Semantic web services', 'Semantic web', 'Service Discovery and composition', 'Serviços web semânticos', 'Web semântica', 'Descoberta e composição de serviços')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/845","2011-03-25","https://www.repositorio.ufal.br/bitstream/riufal/845/1/Um%20Middleware%20adapt%c3%a1vel%20para%20descoberta%2c%20composi%c3%a7%c3%a3o%20e%20invoca%c3%a7%c3%a3o%20autom%c3%a2tica%20de%20servi%c3%a7os%20web%20sem%c3%a2nticos.pdf","An adaptable Middleware for automatic Discovery, composition and invocation of semantic web services","('Ig Ibert Bittencourt Santana Pinto',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/123456789/12724","Campus A.C. Simões","Instituto de Computação","Dissertação","Modelagem de zonas de ancoragem para disseminação de conteúdo flutuante em redes veiculares utilizando métricas de centralidade temporais","('Marcelo de Oliveira Souza',)","('André Luiz Lins de Aquino',)","('Rian Gabriel Santos Pinheiro', 'Maurício José da Silva')","Redes veiculares são grandes redes compostas por veículos com tecnologias que possibilitam a troca de informações. Estas redes possuem grande capacidade para produção e disseminação de conteúdo, porém, as mudanças topológicas constantes dificultam a troca de informações entre os nós e podem invalidar as informações, gerando perdas de informações, atrasos de pacotes, desconexões indevidas, entre outros problemas. Nas redes veiculares há locais onde os conteúdos gerados pelos nós sensores alcançam um público maior, estes locais, aos quais chamamos de Zonas de Ancoragem, são utilizados para troca de informações relevantes com uma maior conectividade. As informações disseminadas em uma Zona Âncora são conhecidas como Conteúdo Flutuante pois possuem validade local, temporal e espacial. Desenvolvemos um estudo utilizando métricas de redes complexas como, Betweenness e Degree em conjunto com medidas de fluxo, e, incorporamos à estas métricas o aspecto temporal da rede para determinar as melhores zonas para troca de informações em uma rede veicular. Em nossas avaliações utilizamos bases de dados reais para avaliar estaticamente o desempenho de nossa abordagem, e simulamos o comportamento de uma rede veicular ao considerar nossa abordagem. Os resultados mostram que métricas de centralidade temporais são eficazes para caracterização de Zonas Âncoras em redes veiculares, pois, a informação extraída com o tempo discretizado é melhor aproximada da realidade, eliminando arestas que deixaram de existir entre os nós da rede, diferente do tempo agregado que guarda informações de arestas não mais existentes.","Vehicle networks are large networks composed of vehicles with technologies that enable the exchange of information. These networks have great capacity for the production and dissemination of content, however, the constant topological changes make it difficult to exchange information between nodes and can invalidate the information, generating information losses, packet delays, improper disconnections, among other problems. In vehicular networks there are places where the content generated by the sensor nodes reaches a larger audience, these places which we call Anchorage Zones are used for exchanging relevant information with greater connectivity. The information disseminated in an anchor zone is known as Floating Content because it has local, temporal and spatial validity. We developed a study using complex network metrics such as, Betweenness and Degree together with flow measures, and, we incorporated the network’s temporal aspect to these metrics to determine the best zones for exchanging information on a vehicular network. In our evaluations we use real databases to statically evaluate the performance of our approach, and simulate the behavior of a vehicular network when considering our approach. The results show that the methodology used is effective for characterizing anchor zones in vehicular networks, because the information extracted with the discretized time is better approximated to reality, eliminating edges that no longer exist between the nodes of the network, differently from the aggregate time that stores information for edges that no longer exist.","('Redes veiculares', 'Sistemas de comunicação móvel', 'Zonas de ancoragem', 'Conteúdo flutuante', 'Métricas temporais', 'Vehicular nets', 'Mobile communication systems', 'Anchor Zones', 'Floating content', 'Temporal metrics')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/12724","2021-01-29","https://www.repositorio.ufal.br/bitstream/123456789/12724/1/Modelagem%20de%20zonas%20de%20ancoragem%20para%20dissemina%c3%a7%c3%a3o%20de%20conte%c3%bado%20flutuante%20em%20redes%20veiculares%20utilizando%20m%c3%a9tricas%20de%20centralidade%20temporais.pdf","Modeling of anchorage zones for dissemination of floating content in vehicular networks using time centrality metrics","('Raquel da Silva Cabral',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/123456789/9818","Campus A.C. Simões","Instituto de Computação","Dissertação","Microbiota fecal de pacientes com Diabetes Mellitus Tipo 2 após uso de probióticos: uma revisão sistemática e metanálise","('Victor Lemos Tenório',)","('Jorge Artur Peçanha de Miranda Coelho',)","('Eliana Silva de Almeida', 'Francisca Rosaline Leite Mota')","Contexto: A incidência de diabetes mellitus aumentou acentuadamente e sua prevalência representa uma grande ameaça à saúde global. A microbiota intestinal humana se refere aos micróbios que colonizam o intestino e participam de várias funções que beneficiam o hospedeiro. Estudos sugerem que probióticos podem ser administrados em alterações do microbioma diabético para restaurar a composição da microbiota intestinal. Esta revisão sistemática tem como objetivo identificar e avaliar as evidências científicas dos efeitos da suplementação com probióticos na composição da microbiota gastrointestinal de adultos com diabetes mellitus do tipo 2. Métodos: A revisão sistemática foi conduzida com o objetivo de avaliar os resultados de Ensaios Clínicos Randomizados (ECR’s) sobre alterações microbianas intestinais em pessoas com diabetes mellitus do tipo 2 após a administração de probióticos. Considerou-se cinco bancos de dados da literatura (EMBASE, MEDLINE, ISI -Web of Science, Scopus e CENTRAL). O protocolo que delimita este trabalho foi registrado em PROSPERO (International Prospective Register of Systematic Reviews). Resultados: 973 registros foram identificados durante a pesquisa bibliográfica. Após a revisão dos títulos e resumos, 58 publicações foram selecionadas para a leitura completa dos textos, dos quais apenas 4 atenderam aos critérios de seleção e foram incluídas para metanálise. A análise de qualidade metodológica classificou 2 estudos como ""alto risco de viés"", 1 como ""algumas preocupações""e 1 ""baixo risco de viés"". Os 4 estudos mostraram mudanças de alguns gêneros de bactérias após a intervenção com probióticos. Conclusões: Os resultados obtidos a partir dessa revisão sistemática e metanálise sugerem que o efeito de suplementos probióticos na microbiota intestinal de pacientes diabéticos tem resultado inconclusivo e que se faz necessário um quantitativo maior de Ensaios Clínicos Randomizados que amplie o número de participantes, com intervalo temporal mais longo e que forneça informações detalhadas quanto a diversidade da microbiota intestinal para avaliar, completamente, o tamanho do efeito desta terapia no tratamento da diabetes mellitus do tipo 2.","Background: The incidence of diabetes mellitus has risen sharply and its prevalence poses a major threat to global health. The human gut microbiota refers to microbes that colonize the gut and participate in various functions that benefit the host. Studies suggest that probiotics can be administered in alterations of the diabetic microbiome to restore the composition of the intestinal microflora. This systematic review aims to identify and evaluate the scientific evidence of the effects of supplementation with probiotics on the composition of the gastrointestinal microbiota of adults with type 2 diabetes mellitus. Methods: Systematic review was conducted with the aim of evaluating the results of Randomized Clinical Trials (RCTs) on intestinal microbial changes in people with type 2 diabetes mellitus after administration of probiotics. Five literature databases were considered (EMBASE, MEDLINE, ISI -Web of Science, Scopus and CENTRAL). The protocol that delimits this work was registered in PROSPERO (International Prospective Register of Systematic Reviews). Results: 973 records were identified during the literature search. After reviewing the titles and abstracts, 58 publications were selected for the complete reading of the texts, of which only 4 met the selection criteria and were included for meta-analysis. The methodological quality analysis classified 2 studies as ""high risk of bias"", 1 as ""some concerns"" and 1 as ""low risk of bias"". The 4 studies showed changes in some genera of bacteria after intervention with probiotics. Conclusions: The results obtained from this systematic review and meta-analysis suggest that the effect of probiotic supplements on the intestinal microbiota of diabetic patients has been inconclusive and that a larger quantity of Randomized Clinical Trials is needed to expand the number of participants, with a longer time interval and to provide detailed information on the diversity of the gut microbiota to fully assess the size of the effect of this therapy in the treatment of type 2 diabetes mellitus.","('Diabetes Mellitus Tipo 2', 'Microbiota Gastrointestinal -Diabetes', 'Probióticos', 'Microbiota Intestinal', 'Revisão Sistemática – Estudo', 'Metanálise', 'Diabetes mellitus', 'Gastrointestinal Microbiota -Diabetes', 'Probiotics', 'Gut Microbiota', 'Systematic Review -Study', 'Metanalysis')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/9818","2021-06-25","https://www.repositorio.ufal.br/bitstream/123456789/9818/1/Microbiota%20fecal%20de%20pacientes%20com%20Diabetes%20Mellitus%20Tipo%202%20ap%c3%b3s%20uso%20de%20probi%c3%b3ticos%3a%20uma%20revis%c3%a3o%20sistem%c3%a1tica%20e%20metan%c3%a1lise.pdf","Fecal Microbiota of Patients with Type 2 Diabetes Mellitus after Use of Probiotics: A Systematic Review and Meta-Analysis",""
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/15655","Campus A.C. Simões","Instituto de Computação","Dissertação","Water potability classification: an approach using machine learning in an embedded system","('Emanuel Adler Medeiros Pereira',)","('Erick de Andrade Barboza',)","('Ícaro Bezerra Queiroz de Araújo', 'Allan de Medeiros Martins')","O acesso à água potável é um recurso vital e um direito humano reconhecido. Contudo, ainda hoje, bilhões de pessoas sofrem com a falta de acesso à água adequada para consumo, o que pode levar a diversos problemas de saúde. Um dos principais desafios no monitoramento da qualidade da água é a coleta e análise de grandes volumes de dados. Modelos de Aprendizado de Máquina têm sido amplamente aplicados no monitoramento da qualidade da água para facilitar a tomada de decisão por gestores e prevenir a contaminação. Um sistema embarcado que integre sensores a um modelo de Aprendizado de Máquina poderia oferecer respostas em tempo real e seria viável para ser aplicado em qualquer local, independentemente da conexão com a internet. Esse sistema, no contexto da classificação da potabilidade da água, permitiria respostas mais rápidas diante de potenciais ameaças. Este estudopropõeummodelodeTinyMLeficienteemtermosenergéticosparaaclassificaçãoda potabilidade da água, utilizando apenas parâmetros que podem ser obtidos por meio de sensoriamento eletrônico. O estudo avaliou o desempenho utilizando métricas como Acurácia, Precisão, Recall, F1-Score, espaço ocupado em memória pelo modelo, tempo de execução e consumo de energia, e comparou modelos desenvolvidos com os algoritmos Random Forest e Redes Neurais. Também foi analisada a melhor combinação entre modelo e biblioteca de adaptação para o sistema embarcado. O modelo de Aprendizado de Máquina inicial, utilizando Random Forest, demonstrou um bom desempenho alcançando uma Precisão de 0.70 e pode funcionar por anos com uma bateria comum como fonte de energia. Comparando todos os modelos e bibliotecas do estudo, o modelo de perceptron multicamadas com a biblioteca EmbML usou a menor memória, com 283.113bytes, e o modelo Random Forest com Micromlgen teve o menor consumo de energia, usando apenas 104.534 milijoules. Este trabalho pode ajudar pesquisadores e profissionais a implementar sistemas de classificação de potabilidade da água e a usar TinyML em outros problemas de classificação também.","Access to clean drinking water is a vital resource and a recognized human right. However,billionsofpeoplestillsufferfromthelackofaccesstosafedrinkingwater,leading to various health issues. One major challenge in water quality monitoring is the collection and analysis of large a mounts of data. Machine learning models have been widely appliedin water quality monitoring to aid decision making by managers and prevent contamination. An embedded system that integrates sensors with a Machine Learning mode lcould providere al time responses and be feasible for deployment anywhere, regardless of internet connectivity requirements. Such a system, in the context of water potability classification, would allow faster responses to potential threats. This study proposes an energy-efficient TinyML model for classifying water potability, using only parameters available through electronic sensing. The study evaluated performance using metrics such as Accuracy, Precision, Recall, F1Score,memoryoccupiedbythemodel,executiontime,andenergyconsumption,comparing models developed with Random Forest and Neural Networks algorithms. It also assessed the best combination of model and adaptation library for the embedded system. The initial Machine Learning model, using Random Forest, demonstrated good performance, reaching a Precision of 0.70, and compared to its cloud-based counterpart, it can operate for years on a standard battery power source. When comparing all models and libraries in the study, the multilayer perceptron model with the EmbML library used the least memory, with 283,113 bytes, and the Random Forest model with Micromlgen had the lowest energy consumption, usingonly104.534millijoules. This work can help researchers and professionals implement water potability classification systems and use TinyML in other classification problems as well.","('TinyML', 'Água potável', 'Sistemas embarcados (Computadores)', 'Aprendizagem de máquina', 'Inteligência artificial', 'Random Forest', 'Random Forest', 'Redes neurais')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/15655","2024-07-26","https://www.repositorio.ufal.br/bitstream/123456789/15655/1/Water%20potability%20classification%20%20an%20approach%20using%20machine%20learning%20in%20an%20embedded%20system.pdf","",""
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/15032","Campus A.C. Simões","Instituto de Computação","Dissertação","A multi-start simulated annealing strategy for data lake organization problem","('Danilo Fernandes Costa',)","('André Luiz Lins de Aquino',)","('Fabiane da Silva Queiroz', 'Fábio José Coutinho da Silva', 'Igor Machado Coelho')","Data Lake é a solução para Big Data que mais tem recebido atenção na atualidade. Sua principal característica é a capacidade de administrar imensos volumes de dados heterogêneos em seu formato bruto. Contudo, isto torna o acesso, a gestão e a exploração de dados mais complexos. Esse desafio define um problema organizacional. O Problema de Organização de Data Lake consiste na geração de uma estrutura navegacional otimizada para reduzir o esforço do usuário na exploração de todos os dados disponíveis. O objetivo é encontrar uma organização de dados que maximize a probabilidade esperada de descoberta de tabelas durante a navegação do utilizador. Para este problema, propomos uma metaheurística de recozimento simulado e comparamo-la com a solução Organize da literatura em instâncias de referência. Propomos também uma variação mais eficiente que elimina os cálculos excessivos. As instâncias são amostras do Socrata Open Data Lake com tópicos variados e dados abertos de entidades governamentais de todo o mundo. Para validar as nossas propostas, realizamos uma análise estatística utilizando um teste não paramétrico, que confirmou o domínio da nossa proposta sobre o estado-da-arte. Nossa melhor proposta foi mais eficiente e aumentou a probabilidade esperada de descoberta de tabelas em até 44%. Assim, nossa estratégia pode encontrar melhores soluções nos benchmarks avaliados mesmo sem analisá-los exaustivamente e explorar mais efetivamente o espaço de soluções.","Data Lake is the solution for Big Data that has received the most attention recently. Its main feature is handling vast volumes of heterogeneous data in its raw format. However, this makes data access, management, and exploration more complex. Such a challenge defines the organizational problem. The Data Lake Organization Problem comprises optimized data navigation structures generation to reduce the user’s time exploring all available data. The goal is to find a data organization that maximizes the expected probability of table discovery during user navigation. For this problem, we propose a simulated annealing metaheuristic and compare it with the Organize literature solution on benchmark instances. We also propose a more efficient variation that prunes excessive computations. The instances are Socrata Open Data Lake samples with varying topics and open data from government entities worldwide. To validate our proposals, we performed statistical analysis using a non-parametric test, which confirmed the dominance of our proposition over the state-of-the-art. Our best proposal was more efficient and increased the expected probability of table discovery up to 44%. Thus, our strategy can find better solutions in the benchmarks evaluated even without exhaustively analyzing all of them and more effectively exploring the space of solutions.","('Data lake', 'Organização', 'Meta-heurística', 'Descoberta de datasets', 'Taxonomia', 'Otimização', 'Dataset discovery', 'Taxonomy', 'Optimization')","Ciência da Computação","eng","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/15032","2024-04-19","https://www.repositorio.ufal.br/bitstream/123456789/15032/1/A%20multi-start%20simulated%20annealing%20strategy%20for%20data%20lake%20organization%20problem.pdf","Uma estratégia de recozimento simulado com multi-início para o problema de organização de data lake","('Rian Gabriel Santos Pinheiro',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/15977","Campus A.C. Simões","Instituto de Computação","Dissertação","Uma nova metodologia baseada em grafos de ruas para investigar a relação entre crimes e pontos de interesse usando dados georreferenciados: um estudo de caso em Maceió, AL","('Débora Barbosa Leite Silva',)","('Thales Miranda de Almeida Vieira',)","('Evandro de Barros Costa', 'Afonso Paiva Neto')","Assim como as cidades, os crimes também evoluíram com o tempo: estão exponen cialmente mais intensos, mais violentos e mais modernos, levando à exaustão dos modelos de segurança. Consequentemente, a sociedade, e principalmente os gestores, necessitam de ferra mentas sofisticadas para ajudá-los na tomada de decisão. A crescente digitalização de dados da última década tem possibilitado a coleta de dados urbanos em larga escala e com muita agilidade. Isso abre oportunidades de se desenvolverem novas técnicas e ferramentas para análise de dados urbanos massivos, inclusive no escopo da criminalidade urbana. Porém, a análise de dados urbanos georreferenciados em larga escala requer o uso de discretizações espaciais adequadas e o emprego de algoritmos de Aprendizado de Máquina robustos capazes de identificar padrões urbanos complexos. Neste trabalho, apresentamos uma metodologia computacional baseada em grafos de rua para realizar a análise de dados urbanos massivos georreferenciados com o objetivo de investigar a relação entre a ocorrência de crimes e a proximidade de pontos de interesse da cidade (POIs). Em particular, também propomos realizar análises segmentadas de acordo com padrões socioeconômicos das diferentes regiões da cidade, através do uso de algoritmos de agrupamento. Por meio de um estudo de caso realizado na cidade de Maceió, concluímos que que existe, globalmente, correlação entre pontos de interesse e eventos criminais. Além disso, esta correlação é significativamente alterada quando analisados grupos de esquinas segmentadas de acordo com os diferentes padrões socioeconômicos.","Just like cities, crimes have also evolved over time: they are exponentially more intense, more violent, and more modern, leading to the exhaustion of security models. Consequently, society, and especially managers, need sophisticated tools to assist them in decision-making. The increasing digitization of data in the last decade has enabled the large-scale and agile collection of urban data. This opens up opportunities to develop new techniques and tools for analyzing massive urban data, including within the scope of urban crime. However, the analysis of large-scale georeferenced urban data requires the use of appropriate spatial discretizations and the employment of robust Machine Learning algorithms capable of identifying complex urban patterns. In this work, we present a computational methodology based on street graphs to perform the analysis of massive georeferenced urban data with the aim of investigating the relationship between the occurrence of crimes and the proximity of points of interest (POIs) in the city. In particular, we also propose to carry out segmented analyses according to the socioeconomic patterns of different city regions using clustering algorithms. Through a case study conducted in the city of Maceió, we conclude that there is, globally, a correlation between points of interest and criminal events. Moreover, this correlation is significantly altered when analyzing groups of corners segmented according to different socioeconomic patterns.","('Predição de Crimes', 'Dados Urbanoss', 'Probabilidade Condicional', 'Grafo de Rua', 'Public Security', 'Data Science', 'Spatiotemporal data analysis', 'Urban data', 'Big Data')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/15977","2024-08-23","https://www.repositorio.ufal.br/bitstream/123456789/15977/1/Uma%20nova%20metodologia%20baseada%20em%20grafos%20de%20ruas%20para%20investigar%20a%20rela%c3%a7%c3%a3o%20entre%20crimes%20e%20pontos%20de%20interesse%20usando%20dados%20georreferenciados%20%20um%20estudo%20de%20caso%20em%20Macei%c3%b3%2c%20AL.pdf","",""
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/9015","Campus A.C. Simões","Instituto de Computação","Dissertação","A variable gain physiological controller for rotary ventricular assistent devices.","('Luís Felipe Vieira Silva',)","('Thiago Damasceno Cordeiro',)","('Ícaro Bezerra Queiroz de Araújo', 'Antônio Marcus Nogueira de Lima')","Este trabalho envolve o projeto de uma lei de controle fisiológico adaptativo para um dispositivo de assistência ventricular turbodinâmico (TVAD) usando um modelo variante no tempo de parâmetros concentrados que descreve o sistema cardiovascular. O TVAD é uma bomba de sangue rotativa acionada por um motor elétrico. A simulação do sistema também inclui o controlador de realimentação adaptativo, que fornece uma saída cardíaca fisiologicamente correta sob diferentes condições de pré-carga e pós-carga. A saída cardíaca é estimada a cada batimento cardíaco e o objetivo de controle é alcançado alterando dinamicamente a referência do controlador de velocidade do motor com base no erro da pressão sistólica. TVADs fornecem suporte para a circulação sanguínea em pacientes com insuficiência cardíaca. Diversas estratégias de controle foram desenvolvidas ao longo dos anos, com destaque para as fisiológicas, que adaptam seus parâmetros para melhorar a condição do paciente. Neste trabalho, uma nova estratégia é proposta utilizando um controlador fisiológico de ganho variável para manter a saída cardíaca em um valor de referência sob alterações tanto na pré-carga quanto na pós-carga. Um modelo computacional é usado para avaliar o desempenho desta técnica de controle, que tem apresentado melhores resultados de adaptabilidade do que controladores de velocidade constante e controladores de ganho constante.","This work involves designing a physiological adaptive control law for a turbodynamic ventricular assist device (TVAD) using a lumped parameter time-varying model that describes the cardiovascular system. The TVAD is a rotary blood pump driven by an electrical motor. The system simulation also includes the adaptive feedback controller, which provides a physiologically correct cardiac output under different preload and afterload conditions. The cardiac output is estimated at each heartbeat, and the control objective is achieved by dynamically changing the motor speed controller’s reference based on the systolic pressure error. TVADs provide support for blood circulation in patients with heart failure. Several control strategies have been developed over the years, emphasizing the physiological ones, which adapt their parameters to improve the patient’s condition. In this work, a new strategy is proposed using a variable gain physiological controller to keep the cardiac output in a reference value under changes in both preload and afterload. Computational models are used to evaluate the performance of this control technique, which has shown better adaptability results than constant speed controllers and constant gain controllers.","('Coração auxiliar', 'Controladores fisiológicos', 'Sistema cardiovascular', 'Dispositivo de assistência ventricular', 'Auxiliary heart', 'Physiological Controller', 'Cardiovascular System', 'Ventricular Assist Devices')","Ciência da Computação","eng","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/9015","2022-02-11","https://www.repositorio.ufal.br/bitstream/123456789/9015/1/A%20variable%20gain%20physiological%20controller%20for%20rotary%20ventricular.pdf","",""
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/8765","Campus A.C. Simões","Instituto de Computação","Dissertação","Multimodality CT/MRI Radiomics for Lung Nodule Malignancy Suspiciousness Classification","('Anthony Emanoel de Albuquerque Jatobá',)","('Marcelo Costa Oliveira',)","('Thales Miranda de Almeida Vieira', 'Paulo Mazzoncini de Azevedo Marques')","O câncer de pulmão é o tipo mais frequente e letal de câncer e o seu diagnóstico precoce é crucial para a sobrevivência do paciente. A tomografia computadorizada (TC) é o padrão-ouro para o rastreio da doença, mas estudos recentes têm demonstrado o potencial da ressonância magnética (RM) no diagnóstico de nódulos pulmonares, bem como da combinação de imagens médicas multimodalidade. Neste estudo, foi avaliado se a combinação de características radiômicas de imagens de TC e RM de pacientes de câncer pulmonar contribui para classificações mais precisas da suspeita de malignidade de nódulos. Para atingir tal objetivo, foi realizado o registro de exames de TC e RM de 47 pacientes, segmentação dos nódulos em cada modalidade, extração de características radiômicas dos nódulos, e classificação usando XGBoost, avaliando métricas de desempenho dos modelos em 30 iterações. O mesmo experimento foi realizado para quatro conjuntos de características: 1) somente de TC; 2) somente de RM; 3) concatenação de TC e RM; 4) fusão de TC e RM. Nossos resultados indicam que a estratégia de fusão de imagens pode levar a ganhos de desempenho significativos, em um teste dos postos sinalizados de Wilcoxon, sobre os modelos de modalidades individuais, com AUC média de 0.794, mas a concatenação de características não se provou uma abordagem adequada para lidar com imagens multimodalidade, uma vez que a AUC média de 0.770 não indicou ganhos de desempenho. Além disso, foi observado que RM, com AUC média de 0.770, apresentou desempenho significativamente superior à TC, com 0.755, encorajando estudos em RM como modalidade para o acompanhamento do câncer de pulmão. Por fim, a análise das características reforçou a relevância da morfologia de um nódulo, como seu tamanho e esfericidade, além de características de textura que quantificam a complexidade e homogeneidade do ambiente intratumoral.","Lung cancer is the most common and deadly form of cancer, and its early diagnosis is decisive to the patient’s survival. Computed Tomography (CT) is the gold-standard imaging modality for lung cancer management, but recent studies have shown the potential of Magnetic Resonance Imaging (MRI) in lung cancer diagnosis and how combining multimodality medical images can yield better outcomes. In this study, we evaluated whether the combination of CT and MRI scans from lung cancer patients can leverage a more precise malignancy suspiciousness classification. For such, we registered paired CT and MRI scans from 47 patients, segmented the nodules in each modality, extracted radiomics features, and performed an experiment with an XGBoost classifier, evaluating models’ performance metrics across 30 trials. The same experiment was performed with four sets of features: 1) CT-only; 2) MRI-only; 3) CT and MRI features; 4) CT/MRI fused images. Our results indicate that the image fusion approach can yield significant AUC performance gains over the single modalities models, with an average AUC of 0.794, but feature concatenation is not an adequate strategy for dealing with multimodality data, as its average AUC of 0.770 didn’t indicate any improvement over the single modalities. Additionally, we observed that MRI, with na average AUC of 0.770, has shown significantly better performance than CT, with 0.754, encouraging further studies in MRI as a lung cancer management image modality. Finally, the analysis on the importance of radiomics features reinforced the relevance of features that reflects on morphological characteristics of a nodule, such as its dimension and roundness, as well as texture features that relate to the intratumoral environment, measuring its complexity and homogeneity.","('Processamento de imagem assistida por computador', 'Neoplasias', 'Características Radiômicas', 'Multimodality medical imaging', 'Lung câncer', 'Radiomics')","Ciência da Computação","eng","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/8765","2021-10-29","https://www.repositorio.ufal.br/bitstream/123456789/8765/1/Multimodality%20CT%20MRI%20radiomics%20for%20Lung%20Nodule%20Malignancy%20Suspiciousnes%20Classification.pdf","Características Radiômicas de TC/RM para Classificação de Suspeição de Malignância de Nódulos Pulmonares",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/1540","Campus A.C. Simões","Instituto de Computação","Dissertação","Um método para verificação formal e dinâmica de sistemas de software concorrentes","('Bruno Roberto Santos',)","('Leandro Dias da Silva',)","('Patrick Henrique da Silva Brito', 'Angelo Perkusich')","Neste trabalho é apresentado um método para verificação formal e dinâmica de software concorrentes. O objetivo é oferecer um método capaz de identificar problemas inerentes a programas cuja execução baseia-se em múltiplas threads, além de analisar propriedades comportamentais descritas com base nos preceitos da lógica temporal. Propõe-se um método capaz de detectar problemas e verificar formalmente a adequação da execução de sistemas de software concorrentes com relação ao comportamento desejável a tais sistemas, baseando-se em informações coletadas dinamicamente, ou seja, em tempo de execução. As informações coletadas correspondem às sequências de execução de sistemas de software, bem como dados sobre a maneira como se comunicam seus componentes durante sua execução. Os dados colhidos refletem a execução do sistema de software propriamente dito, o que garante maior confiança às informações coletadas. Tais informações são analisadas de modo a identificar impasses e condições de corrida em um processo denominado Análise Dinâmica. Ademais, estas informações também são utilizadas para geração automática de um modelo que descreve o comportamento do sistema de software, o qual é utilizado para verificação de propriedades comportamentais. A este processo de verificação dá-se o nome de Verificação Formal. A geração automática do modelo elimina a necessidade de construção manual do mesmo, que requer muito esforço e conhecimento acerca de métodos formais, isso pode aumentar custos e tempo de desenvolvimento do sistema de software. Entretanto, a análise dinâmica é conhecida por apenas realizar cobertura sobre o comportamento atual de sistemas de software concorrentes, sem considerar a análise de todas as outras possíveis sequências de execuções devido ao não determinismo. Em razão do comportamento não determinístico, sistemas de software concorrentes são capazes de produzir resultados diferentes para a mesma entrada a cada nova execução. Deste modo, reproduzir o comportamento que leva sistemas de software concorrente à falha é uma tarefa complexa. O presente trabalho propõe um método para realizar verificação formal e dinâmica de sistemas de software concorrente capaz de capturar o comportamento não determinístico desses sistemas, além de proporcionar a redução de custos de desenvolvimento através da eliminação da necessidade de construção manual de modelos de sistemas de software concorrente. O método é validado através de um estudo de caso composto por testes em três sistemas de software.","This work presents a method to perform formal and dynamic verification of concurrent software. The objective is to provide a method capable of identifying problems in programs whose execution is based on multiple threads, and analyze behavioral properties. The method is able to detect problems in concurrent software, as well as check conformity of the concurrent software with desirable behavior, based on information collected dynamically, i.e. at runtime. The information collected consists of the software execution flow as well as data about the way communicate the software components during this run. The data collected reflect the software's execution, which ensures greater confidence to the information collected. This information is analyzed to identify deadlocks and race conditions in a process called Dynamic Analysis. In addition, this information is also used to automatically generate a model that describes the behavior of a software, which is used for verification of behavioral properties. This process is called Formal Verification. The automatic model generation eliminates the need for manual construction of the model, which requires much effort and knowledge of formal methods, this can increase costs and development time software. However, the dynamic analysis is known to only perform coverage of the current behavior of competing software systems. Current behavior is one that occurs only during an execution of concurrent software systems, without considering all other possible behaviors from the non-determinism. Due to the non-determinism, concurrent software can produce different results for the same input to each execution of software. Therefore reproduce the behavior that leads to competitive software failure is a complex task. This paper proposes a method to perform formal verification and dynamic concurrent software capable of capturing the non-deterministic behavior of these systems and provide reduced development costs by eliminating the need for manual construction of concurrent software system models. The method is validated by a case study consists of three test software systems.","('Verificação formal', 'Sistemas concorrentes', 'Análise dinâmica', 'Formal verification', 'Concurrent systems', 'Dynamic analysis')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1540","2016-05-20","https://www.repositorio.ufal.br/bitstream/riufal/1540/1/Um%20m%c3%a9todo%20para%20verifica%c3%a7%c3%a3o%20formal%20e%20din%c3%a2mica%20de%20sistemas%20.pdf","A method for formal and dynamic verification of concurrent software systems","('Márcio de Medeiros Ribeiro',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/2131","Campus A.C. Simões","Instituto de Computação","Dissertação","Visualização de dados de monitoramento de requisitos de qualidade contextualizados coma arquitetura de software","('Marcos José Ferreira Neto',)","('Patrick Henrique da Silva Brito',)","('Baldoíno Fonseca dos Santos Neto', 'Regina Lúcia de Oliveira Moraes')","O problema do grande volume de dados está presente na indústria de software, em especial nos dados de log de monitoramento de software, que são gerados em tempo real, à medida que o software é utilizado. Alguns fatores dificultam consideravelmente a análise manual dos dados de log. Um deles é o grande volume de dados gerado; outro fator que dificulta a análise manual dos logs é o fato de estarem, normalmente, espalhados em um ou vários arquivos de registro, apresentando-se de forma desordenada. Por essa razão, a análise manual dos logs tem se mostrado uma atividade propensa a erros. Sendo assim, se faz necessário utilizar alguma ferramenta computacional para apoiar a análise dos logs. Além disso, para se ter uma boa interpretação dos dados analisados é necessário contextualizá-los com modelos abstratos do software, tais como por exemplo a arquitetura de software. Esse trabalho tem como objetivo desenvolver uma abordagem de visualização para facilitar o processo de análise de dados de monitoramento dos requisitos de qualidade (eficiência e confiabilidade), proporcionando uma maior contextualização com abstrações da arquitetura do software e uma ferramenta, chamada VisRQ, com suporte a essa abordagem. Tal ferramenta foi avaliada por um experimento semi-estruturado, em que os usuários analisaram os logs de monitoramento e responderam questionários visando aferir o atendimento dos requisitos desejados. Também foram avaliados o tempo de aprendizado da ferramenta e se ela torna o processo de análise dos logs mais preciso e rápido. Os participantes do experimento foram discentes do curso técnico de Informática do Instituto Federal de Alagoas -Campus Arapiraca e do curso de Ciência da Computação daUniversidade Federal de Alagoas -Campus Arapiraca, além de alguns profissionais formados que trabalham com Tecnologia da Informação. A aceitação da ferramenta foi positiva, conforme as respostas do experimento avaliativo, 100% dos participantes afirmaramque preferem utilizar a ferramenta VisRQ em vez do processo anterior que é menos automatizado e 97,6% consideraram que ela facilita o processo de análise. O experimento mostra que o processo de análise dos logs envolvendo a ferramenta VisRQ émais eficiente, além de permitir a visualização das informações sobre os requisitos não-funcionais de forma contextualizada com diagramas da arquitetura de software.","The problem of the large volume of data is present in the software industry, especially in the software monitoring log data, which is generated in real time, as the software is used. Some factors make it difficult to manually analyze log data. One is the large volume of data generated; another factor that makes it difficult to manually analyze the logs and the fact that they are usually scattered in one or several log files, presenting itself in a disorderly way. For this reason, a manual log analysis has been shown as an error-prone activity. Therefore, it is necessary to use some computational tool to support log analysis. In addition, in order to have a good interpretation of the analyzed data, it is necessary to contextualize them with abstract software models, such as software architecture. This work aims to develop a visualization approach to facilitate the data analysis process of monitoring the requirements of quality, efficiency and reliability, providing a greater contextualization with abstractions of the software architecture and a tool, called VisRQ, supporting this approach. This tool was evaluated by a semi-structured experiment, in which the users analyzed the monitoring logs and answered questionnaires in order to verify the fulfillment of the desired requirements. We also evaluated the tool learning time and whether it makes the log analysis process more accurate and faster. The experiments participants were students of the Informatics technical course of the Federal Institute of Alagoas -Campus Arapiraca and of the course of Computer Science of the Federal University of Alagoas -Campus Arapiraca, besides some professionals that work with Information Technology. The tool acceptance was positive, according to the responses of the evaluative experiment, 100% of the participants stated that they prefer to use the VisRQ tool instead of the previous process that is less automated and 97.6% considered that it facilitates the analysis process. The experiment shows that the log analysis process using VisRQ tool is more efficient, besides allowing the visualization of information about the nonfunctional requirements in a contextualized way with diagrams of the software architecture.","('Arquitetura de software', 'Monitoração de requisitos', 'Requisitos não-funcionais', 'Requisitos de qualidade', 'Software – Visualização', 'Software architecture', 'Quality requirements', 'Data visualization', 'Non-Functional requirements', 'Software visualization tool')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/2131","2017-10-05","https://www.repositorio.ufal.br/bitstream/riufal/2131/1/Visualiza%c3%a7%c3%a3o%20de%20dados%20de%20monitoramento%20de%20requisitos%20de%20qualidade%20contextualizados%20coma%20arquitetura%20de%20software.pdf","Visualization of monitoring data of quality requirements contextualized with the software architecture",""
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/2687","Campus A.C. Simões","Instituto de Computação","Dissertação","Validação empírica de uma abordagem para alfabetização de autistas utilizando aplicativos para dispositivos móveis","('Ezequiel Batista Farias',)","('Patrick Henrique da Silva Brito',)","('Leandro Melo de Sales', 'Luis Paulo Leopoldo Mercado')","É crescente o uso de tecnologias em todos os setores da sociedade, visto a praticidade e dinamismo que fornecem aos mais variados processos. Um campo bastante promissor que tem aumentado substancialmente, foca no estudo e desenvolvimento de tecnologias para apoio e suporte ao tratamento multidisciplinar de pessoas com transtorno do espectro do autismo (TEA). No entanto, tem-se notado que boa parte destas tecnologias não consideram como base pedagógica, metodologias que já são consolidadas e efetivas na conduta autista o que pode impactar diretamente nos efeitos causados por tais tecnologias ao público alvo. Sendo assim, este trabalho teve o intuito de realizar um experimento para validar uma abordagem, em sua versão tecnológica, já utilizada dentro do processo interventivo de pessoas com autismo de forma convencional com o intuito de desenvolver habilidades dentro do processo alfabetizador, chamada TEACCH. A avaliação teve como foco investigativo, a redução nos índices de erros, ajuda profissional e tempo total entre sessões para uma sequência de atividades executada pela amostra em ambas as abordagens do TEACCH: a convencional e a tecnológica, que incorpora aspectos e recomendações da abordagem tradicional. Como resultados, levantamos que parte considerável da amostra apresentou redução nos índices em todas as variáveis investigadas, inclusive para alguns participantes esta redução foi mais evidente com o uso da tecnologia. Sabendo-se que o modelo convencional da abordagem TEACCH encontra-se validado em literatura os resultados indicaram alinhamento das estratégias pedagógicas inseridas nas atividades da tecnologia em comparação com as atividades convencionais visto que a melhoria no desempenho apresentado pelo autista foi evidente em ambas as abordagens.","The use of technologies in all sectors of society is increasing, given the practicality and dynamism they provide to the most varied processes. A very promising field that has increased substantially, it focuses on the study and development of technologies to support and support the multidisciplinary treatment of people with autism spectrum disorder (ASD). However, it has been noticed that many of these technologies do not consider as pedagogical basis, methodologies that are already consolidated and effective in autistic behavior, which can directly impact the effects caused by such technologies to the target audience. Thus, this work had the intention to perform an experiment to validate an approach, in its technological version, already used within the intervention process of people with autism in a conventional way with the purpose of developing skills within the literacy process, called TEACCH. The evaluation focused on the reduction of error rates, professional help and total time between sessions for a sequence of activities performed by the sample in both the TEACCH approaches: conventional and technological, incorporating aspects and recommendations of the traditional approach . As results, we found that a considerable part of the sample presented a reduction in the indices in all variables investigated, including for some participants this reduction was more evident with the use of the technology. Knowing that the conventional model of the TEACCH approach is validated in the literature the results indicated the alignment of the pedagogical strategies inserted in the activities of the technology in comparison to the conventional activities since the improvement in the performance presented by the autista was evident in both approaches.","('Tecnologia da Informação', 'Tecnologia Educacional', 'Alfabetização', 'Estratégias Pedagógicas', 'Desenvolvimento de Potencialidades', 'Skills development', 'Information technology', 'Educational technology', 'Autism', 'Literacy', 'Ensino -Meios auxiliares')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/2687","2017-05-23","https://www.repositorio.ufal.br/bitstream/riufal/2687/1/Valida%c3%a7%c3%a3o%20emp%c3%adrica%20de%20uma%20abordagem%20para%20alfabetiza%c3%a7%c3%a3o%20de%20autistas%20utilizando%20aplicativos%20para%20dispositivos%20m%c3%b3veis.pdf","",""
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/6966","Campus A.C. Simões","Instituto de Computação","Dissertação","Understanding and classifying code harmfulness","('Rodrigo dos Santos Lima',)","('Baldoíno Fonseca dos Santos Neto',)","('Márcio de Medeiros Ribeiro', 'Leopoldo Motta Teixeira')","Code Smells geralmente indicam más opções de implementação que podem prejudicar a qualidade do software. Portanto, eles precisam ser detectados com cuidado para evitar degradação do software. Nesse contexto, alguns estudos tentam entender o impacto dos Code Smells na qualidade do software, enquanto outros propõem regras ou técnicas baseadas em aprendizado de máquina para detectar Code Smells. No entanto, nenhum desses estudos / técnicas se concentram na análise de trechos de código que são realmente prejudiciais à qualidade do software. Nosso estudo tem como objetivo entender e classificar a nocividade do código. Analisamos a nocividade em termos de código CLEAN, SMELLY, BUGGY e HARMFUL. Por código nocivo, queremos dizer código que já prejudicou a qualidade do software e ainda está sujeito a danos. Realizamos nosso estudo com 22 tipos de Smells, 803 versões de 12 projetos de código aberto, 40.340 bugs e 132.219 Code Smells. Os resultados mostram que, embora tenhamos um número alto de Code Smells, apenas 0,07% desses Smells são prejudiciais. O Abstract Call From Constructor é o tipo de Smell mais relacionado ao código nocivo. Para validar empiricamente nossos resultados, também realizamos uma pesquisa com 77 desenvolvedores. A maioria deles (90,4%) considera Code Smells prejudiciais ao software e 84,6% desses desenvolvedores acreditam que as ferramentas de detecção de Code Smells são importantes. Mas, esses desenvolvedores não estão preocupados em selecionar ferramentas capazes de detectar Code Smells. Também avaliamos técnicas de aprendizado de máquina para classificar a nocividade do código: elas atingem a eficácia de pelo menos 97% para classificar o código nocivo. Enquanto Random Forest é eficaz na classificação de Code Smells e nocivos, o Gaussian Naïve Bayes é a técnica menos eficaz. Nossos resultados também sugerem que as métricas de software e desenvolvedores são importantes para classificar códigos nocivos.","Code smells typically indicate poor implementation choices that may degrade software quality. Hence, they need to be carefully detected to avoid such degradation. In this context, some studies try to understand the impact of code smells on the software quality, while others propose rules or machine learning-based techniques to detect code smells. However, none of those studies/techniques focus on analyzing code snippets that are really harmful to software quality. Our study aims to understand and classify code harmfulness. We analyze harmfulness in terms of CLEAN, SMELLY, BUGGY, and HARMFUL code. By harmful code, we mean code that has already harmed software quality and is still prone to harm. We perform our study with 22 smell types, 803 versions of 12 open-source projects, 40,340 bugs and 132,219 code smells. The results show that even though we have a high number of code smells, only 0.07% of those smells are harmful. The Abstract Function Call From Constructor is the smell type more related to harmful code. To cross-validate our results, we also perform a survey with 77 developers. Most of them (90.4%) consider code smells harmful to the software, and 84.6% of those developers believe that code smells detection tools are important. But, those developers are not concerned about selecting tools that are able to detect harmful code. We also evaluate machine learning techniques to classify code harmfulness: they reach the effectiveness of at least 97% to classify harmful code. While the Random Forest is effective in classifying both smelly and harmful code, the Gaussian Naive Bayes is the less effective technique. Our results also suggest that both software and developers’ metrics are important to classify harmful code.","('Code smells', 'Software – Qualidade', 'Aprendizagem de máquina', 'Code Smells', 'Software Quality', 'Machine Learning')","Ciência da Computação","eng","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/6966","2020-02-28","https://www.repositorio.ufal.br/bitstream/riufal/6966/3/Understanding%20and%20Classifying%20Code%20Harmfulness.pdf","Entendendo e reconhecendo códigos prejudiciais",""
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/14927","Campus A.C. Simões","Instituto de Computação","Dissertação","Use of information theory measures extracted from OBD-II interface data for driver identification","('Gean da Silva Santos',)","('André Luiz Lins de Aquino',)","('Osvaldo Aníbal Rosso', 'Denis Lima do Rosário', 'Raquel da Silva Cabral')","Investigamos o uso de ferramentas de Aprendizado de Máquina aplicadas à identificação de motoristas. Propomos o uso de medidas de Teoria da Informação como recursos em modelos de Aprendizado de Máquina. As medidas utilizadas são Complexidade Estatística, Entropia de Permutação e Informação de Fisher. Calculamos essas medidas sobre os dados brutos dos valores dos sensores do Sistema de Diagnóstico Embarcado versão 2 (OBD-II) e as utilizamos como novas características aplicadas aos seguintes modelos de classificação: k-Nearest Neighbors, Support Vector Machine, Decision Tree, Random Forest, Multi-Layer Perceptron e Naive Bayes. Avaliamos o cenário de identificação de motorista considerando janelas deslizantes de 120 amostras e uma sobreposição de 60 amostras. Em cada janela, os modelos bem estabelecidos são treinados e avaliados. Os modelos são analisados pela acurácia, pela Área Sob a Curva da Curva Característica de Operação do Receptor (que determina quão relevante o classificador é em termos de sua sensibilidade e specificidade), pela precisão e pela cobertura. Observamos ganhos significativos para todos os modelos considerados no cenário. Seguindo o procedimento tradicional, obtivemos os valores: de 78,5 a 91,1% de acurácia, de 74,5 a 87,8% de ROC AUC, de 62,5 a 84,2% de precisão e de 60,6 a 85,3% de revocação. Enquanto usando nossa proposta, obtivemos os valores: de 94,3 a 99,9% de acurácia, de 91,7 a 99,9% de ROC AUC, de 89,8 a 99,9% de precisão e de 86,4 a 99,9% de cobertura.","We investigate the use of Machine Learning tools applied to driver identification. We propose us ing Information Theory measures as features in Machine Learning models. The measures used are Statistical Complexity, Permutation Entropy, and Fisher Information. We calculate these mea sures over the raw data of On Board Diagnostics version 2 (OBD-II) sensor values and use them as new features applying to the following classification models: k-Nearest Neighbors, Support Vector Machine, Decision Tree, Random Forest, Multi-Layer Perceptron, and Naive Bayes. We evaluate the driver identification scenario considering sliding windows of 120 samples and an overlap of 60 samples. In each window, the well-established models are trained and evaluated. The models are analyzed by accuracy, by the Area Under the Curve of the Receiver Operating Characteristic Curve (which determines how relevant the classifier is in terms of its sensitivity and specificity), by precision and by recall. We observed significant gains for all models consid ered in the scenario. Following the traditional procedure, we obtained the values: 78.5 to 91.1 % of accuracy, 74.5 to 87.8 % of ROC AUC, 62.5 to 84.2 % of precision, and 60.6 to 85.3 % of recall. While using our proposal, we obtained the values: 94.3 to 99.9 % of accuracy, 91.7 to 99.9 % of ROC AUC, 89.8 to 99.9 % of precision, and 86.4 to 99.9 % of recall.","('Identificação de motorista (Aprendizado do computador)', 'Teoria da informação', 'Complexidade estatística', 'Shannon, Entropia de', 'Fisher, informação de', 'Aprendizado do computador', 'Dados de veículo', 'Sistema de Diagnóstico Embarcado')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/14927","2024-03-25","https://www.repositorio.ufal.br/bitstream/123456789/14927/1/Use%20of%20information%20theory%20measures%20extracted%20from%20OBD-II%20interface%20data%20for%20driver%20identification.pdf","",""
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/17511","Campus A.C. Simões","Instituto de Computação","Dissertação","Towards automating lung-rads classification in clinical routine insights from portuguese radiology reports","('Tarcísio Lima Ferreira',)","('Marcelo Costa Oliveira',)","('Thales Miranda de Almeida Vieira', 'Álvaro Alvares de Carvalho César Sobrinho', 'Paulo Mazzoncini de Azevedo Marques')","O câncer de pulmão tem a maior taxa de mortalidade entre todos os tipos de câncer, tanto para homens quanto para mulheres. Estima-se que o câncer de pulmão seja responsável por 21% das mortes por câncer em cada gênero no mundo. Essa estatística alarmante destaca o impacto significativo do câncer de pulmão na mortalidade geral por câncer, sublinhando a necessidade urgente de estratégias eficazes de prevenção, detecção precoce e tratamento para combater essa doença. O rastreamento do câncer de pulmão é um processo projetado para detectar o câncer de pulmão em indivíduos em risco, particularmente aqueles com histórico de tabagismo. Envolve tomografias computadorizadas de baixa dose anuais, interpretação cuidadosa dos resultados e acompanhamento opor tuno para garantir a detecção e o tratamento precoces. Várias sociedades profissionais, incluindo a American College of Radiology e a Sociedade Fleischner, publicaram diretrizes para o manejo de pacientes com nódulos pulmonares detectados durante o rastreamento de câncer de pulmão. As diretrizes são uma ferramenta importante em programas de rastreamento que visam reduzir a incidência de exames de acompanhamento desnecessários e orientar o manejo ideal do paciente. Lung Computed Tomography Screening Reporting & Data System (Lung-RADS) ´e um sistema de classificação padronizado para nódulos pulmonares detectados em exames de imagem, como tomografias computadorizadas. O Lung-RADS avalia o risco de malignidade (câncer) nesses nódulos e orienta as decisões de manejo subsequentes. Neste contexto, este trabalho visa analisar a eficácia de modelos de aprendizado profundo e Large Language Model na extração de características de nódulos pulmonares de laudos de Tomografia Computadorizada em português para permitir a classificação automatizada do Lung-RADS. Este trabalho avaliou a eficácia de BiLSTM CRF, BioBERTpt, Gemini 1.5 Flash, GPT-4o e Llama 370B. Os resultados sugerem que o Gemini 1.5 Flash se destaca como o modelo com maior eficácia, superando os demais em quatro das cinco classificações Lung-RADS no conjunto de teste, com um F1-score ponderado de 0,95, destacando sua eficácia na avaliação precisa de nódulos pulmonares em vários cenários de classificação.","Lung cancer has the highest mortality rate among all cancer types, affecting both men and women. It is estimated that lung cancer accounts for 21% of cancer deaths in each gender worldwide. This alarming statistic highlights the significant impact of lung can cer on overall cancer mortality, underscoring the urgent need for effective prevention, early detection, and treatment strategies to combat this disease. Lung cancer screening is a process designed to detect lung cancer in at-risk individuals, particularly those with a history of smoking. It involves annual low-dose computed tomography (CT) scans, careful interpretation of results, and timely follow-up to ensure early detection and treat ment. Several professional societies, including the American College of Radiology and the Fleischner Society, have published guidelines for the management of patients with pulmonary nodules detected during lung cancer screening. The guidelines are an important tool in screening programs aimed at reducing the incidence of unnecessary follow-up examinations and guiding optimal patient management. The Lung Computed Tomography Screening Reporting & Data System (Lung-RADS) is a standardized classification system for pulmonary nodules detected on imaging examinations, such as CT scans. Lung-RADS assesses the risk of malignancy (cancer) in these nodules and guides subsequent management decisions. In this context, this work aims to analyze the effectiveness of deep learning and large language models in extracting features of pulmonary nodules from Portuguese CT reports to enable automated classification of Lung-RADS. This work evaluated the effectiveness of BiLSTM-CRF, BioBERTpt, Gemini 1.5 Flash, GPT-4o, and Llama 3 70B. The results suggest that the Gemini 1.5 Flash stands out as the most effective model, outperforming the others in four of the five Lung-RADS classifications in the test set, with a weighted F1-score of 0.95, highlighting its effectiveness in accurately assessing lung nodules in various classification scenario.","('Neoplasias pulmonares', 'Lung-RADS', 'Processamento de linguagem natural (Computação).', 'Armazenamento e recuperação da informação', 'Large language models', 'Lung Cancer', 'Lung-RADS', 'NLP', 'Information Extraction', 'LLM')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/17511","2025-02-13","https://www.repositorio.ufal.br/bitstream/123456789/17511/1/Towards%20automating%20lung-rads%20classification%20in%20clinical%20routine%20%20insights%20from%20portuguese%20radiology%20reports.pdf","","('Thales Miranda de Almeida Vieira',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/13325","Campus A.C. Simões","Instituto de Computação","Dissertação","O uso da aprendizagem de máquina para a criação de fórmula biométrica para o cálculo da lente intraocular","('Mariana Silva Gois de Almeida',)","('Aydano Pamponet Machado',)","('Evandro de Barros Costa', 'Edileuza Virginio Leão', 'Rafael Ferreira Leite de Mello')","Objetivo: Elaborar uma nova fórmula biométrica com base em um banco de dados da população brasileira e comparar o seu desempenho com o de outras 6 fórmulas existentes tanto na prática clínica quanto no meio científico. Local: Os participantes foram avaliados e submetidos à cirurgia em um hospital oftalmológico de Brasília, DF, Brasil. Desenho: Um estudo clínico retrospectivo para comparar o desempenho de fórmulas biométricas. Metodologia: A fórmula biométrica foi construída seguindo o processo de descoberta de conhecimento em base de dados (KDD) e os desempenhos de modelos de aprendizagem de máquina e das fórmulas de Barrett Universal II, Haigis, Hoffer Q, Holladay 1, Kane e SRK/T foram analisados comparando-se o erro absoluto mediano e a porcentagem de olhos com menos de 0,5 e 1,0D de erro absoluto. Resultados: Foram analisados 1526 olhos únicos, onde as fórmulas de Barrett Universal II, Haigis, Hoffer Q, Holladay 1, Kane e SRK/T e os modelos MLP e SVR obtiveram, respectivamente, os seguintes valores de erro absoluto mediano: 0.393, 0.426, 0.427, 0.387, 0.409, 0.410, 0.405 e 0.370 D. Os desempenhos do modelo SVR e das fórmulas Holladay 1 e Barrett Universal II também foram superiores em todos os subgrupos estudados. Conclusão: A fórmula baseada em modelo computacional proposta obteve resultados superiores em comparação com outras fórmulas para cálculo do poder da lente intraocular nesta população e em todos os subgrupos biométricos estudados.","Objective: To develop a new biometric formula based on a database of the Brazilian population and compare its performance with that of 6 other formulas existing both in clinical practice and in the scientific world. Location: Participants were evaluated and underwent surgery at an ophthalmological hospital in Brasília, DF, Brazil. Design: A retrospective clinical study to compare the performance of biometric formulas. Methodology: The biometric formula was constructed following the knowledge discovery in database (KDD) and the performances of machine learning models and the formulas of Barrett Universal II, Haigis, Hoffer Q, Holladay 1, Kane and SRK/ T were analyzed by comparing the median absolute error and the percentage of eyes with less than 0.5 and 1.0D of absolute error. Results: 1526 single eyes were analyzed, where the Barrett Universal II, Haigis, Hoffer Q, Holladay 1, Kane and SRK/T formulas and the MLP and SVR models obtained, respectively, the following median absolute error values: 0.393, 0.426, 0.427, 0.387, 0.409, 0.410, 0.405 and 0.370 D. The performances of the SVR model and the Holladay 1 and Barrett Universal II formulas were also superior in all subgroups studied. Conclusion: The proposed computational model-based formula obtained superior results compared to other formulas for calculating intraocular lens power in this population and in all biometric subgroups studied.","('Biometria ocular', 'Fórmulas biométricas', 'Cálculo do poder da lente intraocular', 'Aprendizagem de máquina', 'Inteligência artificial', 'Ocular biometrics', 'Biometric formulas', 'Calculation of IOL power', 'Machine learning', 'Artificial intelligence')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/13325","2023-08-31","https://www.repositorio.ufal.br/bitstream/123456789/13325/1/O%20uso%20da%20aprendizagem%20de%20m%c3%a1quina%20para%20a%20cria%c3%a7%c3%a3o%20de%20f%c3%b3rmula%20biom%c3%a9trica%20para%20o%20c%c3%a1lculo%20da%20lente%20intraocular.pdf","The use of machine learning to create a biometric formula for intraocular lens calculation","('João Marcelo de Almeida Gusmão Lyra',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/1614","Campus A.C. Simões","Instituto de Computação","Dissertação","Uma solução para apoiar processos de desenvolvimento de software centrado na arquitetura","('Ítalo Carlo Lopes Silva',)","('Patrick Henrique da Silva Brito',)","('Evandro de Barros Costa', 'Hyggo Oliveira de Almeida')","O sucesso de um projeto de software está fortemente relacionado com o projeto arquitetural. No entanto, projetar a arquitetura de software correta é uma tarefa muito subjetiva e leva muito tempo, sendo muito influenciada pela experiência do arquiteto e a qualidade da engenharia de requisitos. Este conhecimento arquitetural, geralmente, não está documentado, uma vez que é considerado o conhecimento tácito dos arquitetos ou dos interessados, e, eventualmente, se dissipa. Também é essencialmente importante assegurar a consistência entre a arquitetura de software e a implementação. No entanto, esse mapeamento é feito manualmente na maioria das vezes, baseado apenas no entendimento do desenvolvedor sobre a arquitetura, exigindo disciplina por parte dele. Assim, erros podem surgir durante esta fase, comprometendo a consistência entre as decisões arquiteturais e o código fonte. Em face destas dificuldades, foi desenvolvido este trabalho, cujo o objetivo é apresentar uma ferramenta que apoie jovens arquitetos com a recomendação de um estilo arquitetural adequado, baseado nos requisitos do sistema, particularmente os atributos de qualidade do sistema. A ferramenta compreende tanto resolução trade-off sobre os atributos de qualidade e recomendação de estilos arquiteturais com base em atributos de qualidade. Por fim, com base na arquitetura recomendada, a ferramenta irá gerar o código estrutural do sistema, utilizando um modelo de implementação de componente chamado COSMOS*, proporcionando rastreabilidade entre projeto arquitetural e a implementação. A solução proposta foi avaliada no contexto de um domínio específico dos Ambientes Virtuais e Aprendizagem (AVA), a fim de ilustrar o suporte da ferramenta na execução de um processo de projeto arquitetural.","The success of a software project is strongly related with architectural design. However, designing the right Software Architecture is a very subjective task and takes a long time, being much influenced by architect's experience and the quality of requirements engineering. This architectural knowledge, usually, is not documented, since it is considered tacit knowledge of architects or other stakeholders, and eventually dissipates. It is also essentially important to ensure the consistency between software architecture and implementation. However, this mapping is usually made manually, based only on the developer's understanding over the software architecture, which requires high discipline. Thus, errors can arise during this phase, compromising the consistency amongst architectural decisions and source code. The objective of this work is to present a tool-based solution that supports young architects by recommending a suitable architectural style, based on the system's requirements, particularly the quality attributes of the system. The tool encompasses both trade-o resolution over quality attributes and recommendation of architectural styles based on quality attributes. Finally, based on the recommended architecture, the tool will generate the system structural source-code, using a component implementation model called COSMOS*, providing traceability between architectural design and implementation. The proposed solution has been evaluated in the context of a specific domain of Learning Management System (LMS), in order to illustrate the tool support in the execution of an architectural design process.","('Arquitetura de software', 'Engenharia de requisitos', 'Resolução de Tred-off', 'Assistente baseado em regras', 'Rastreabilidade', 'Software -Desenvolvimento', 'Software architecture', 'Architectural decisions', 'Requirements engineering', 'Trade-off resolution', 'Traceability between software architecture and source-code', 'Rule-based assistant')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1614","2014-12-30","https://www.repositorio.ufal.br/bitstream/riufal/1614/1/Uma%20solu%c3%a7%c3%a3o%20para%20apoiar%20processos%20de%20desenvolvimento%20de%20software%20centrado%20na%20arquitetura.pdf","A solution to support development process centered in the architecture","('Baldoíno Fonseca dos Santos Neto',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/3009","Campus A.C. Simões","Instituto de Computação","Dissertação","Tailoring gamified virtual learning environments based on gamer types","('Wilk Oliveira dos Santos',)","('Ig Ibert Bittencourt Santana Pinto',)","('Patrick Henrique da Silva Brito', 'Maiga Chang')","Nos últimos anos, é notório o crescente uso das diferentes tecnologias digitais em diferentes campos de pesquisa, com destaque para redes sociais, marketing, ciências da saúde e educação. No domínio da educação, especialmente, recentes estudos têm destacado o uso de diferentes tecnologias digitais para fornecer diferentes recursos educacionais, como jogos educacionais, sistemas tutores inteligentes, ambientes virtuais de aprendizagem e outros. Para criar melhores ambientes virtuais de aprendizagem, uma grande quantidade de estudos tem usado elementos de design de jogos para projetar esses sistemas, com o objetivo de aumentar a concentração, motivação, experiência de fluxo e outros, criando os ambientes de virtuais de aprendizagem gamificados. No entanto, pesquisas recentes mostram que, em alguns casos, o uso da gamificação pode causar efeitos opostos do proposto, isso porque os estudantes são motivados ou desmotivados por diferentes elementos de gamificação de acordo com seu perfil, por exemplo, alguns estudantes podem ser melhores motivados por elementos específicos de gamificação e desmotivados por outros elementos de gamificação. Assim, um dos principais desafios contemporâneos neste domínio de pesquisa é fornecer ambientes de virtuais de aprendizagem gamificados adaptados de acordo com os tipos de perfil dos estudantes. Esta dissertação de mestrado tem como objetivo propor um processo e uma arquitetura para adaptar ambientes virtuais de aprendizagem gamificados com base no tipo de jogador do estudante. O processo e a arquitetura propostos foram criados com base nas diretrizes de Orji, que associam as melhores estratégias persuasivas para cada tipo de jogador identificados pelo BrainHex e foram criadas através da metodologia de Transferência de Tecnologia com base em um estudo empírico. Um ambiente virtual de aprendizagem gamificado foi adaptado com base em nossa proposta e foi avaliado através de um experimento empírico com 125 estudantes de ensino básico, a fim de analisar comparativamente as versões personalizadas e não personalizads do sistema em termos de concentração e experiência de fluxo. Os principais resultados indicam que não houve diferença significativa entre alguns dos tipos de jogadores em termos de concentração e experiência de fluxo, e, para alguns tipos de jogadores, o sistema personalizado foi mais efetivo, no entanto, em alguns casos específicos, a experiência de fluxo e a concentração foram maiores na versão não personalizada do sistema, surpreendendo e contradizendo a expectativa de recentes estudos teóricos importantes deste domínio. Assim, após o nosso experimento principal, também realizamos um segundo experimento empírico, para identificar os melhores elementos de gamificação para motivar cada tipo de jogador. Este experimento foi conduzido com 111 estudantes brasileiros e os resultados confirmam que os alunos têm diferentes preferências sobre cada elemento de jogo e classificaram os melhores elementos de gamificação para cada tipo de jogador. Finalmente, fornecemos um guideline para adaptar ambientes virtuaus de aprendizagem gamificados com base em nosso processo e arquitetura e um segundo guideline destacando quais os melhores elemenos de gamfiicação para motivar cada tipo de jogador.","In the last years, is notorious the growing use of different digital technologies in many different fields, with highlight for, social networks, marketing, health, and education. In the field of education, specially, studies have highlighted the use of different digital technologies in order to provide different educational resources, such as educational games, intelligent tutoring systems, virtual learning environments, and others. In order to create better virtual learning environments, a plethora of studies have been using game design elements to design these systems, aiming to increase students’ concentration, motivation, flow experience, and others, creating the named gamified virtual learning environments. However, besides these plenty of studies, recent researches are showing that in some case, the use of gamification can cause the opposite effects, because the students are motivated or demotivated for different gamification elements according to their gamer type, for instance, some students can be more motivated for specific gamification elements and demotivated for others gamification elements. Thus, one of the main contemporary challenges in this field is to provide gamified virtual learning environments tailored according to students’ gamer types. This master thesis aims to propose a process and architecture to tailor gamified virtual learning environments based on the students’ gamer type. The process and architecture proposed were created based on the Orji’ guideline that associate the best persuasive strategies for each BrainHex gamer types and were designed through the Empirically-Based Technology Transfer methodology. A real gamified virtual learning environment was tailored based on our proposal and was evaluated through an empirical experiment with 125 elementary students in order to comparatively evaluate the tailored and the counter-tailored versions of the system in terms of students’ concentration and flow experience. The main results indicate that are not significant difference of gamer types in terms of concentration and flow experience in some of gamer types, and, for some gamer types the tailored system was more effective, however, in some specific cases, the flow experience and concentration was larger in the counter-tailored version of the system, surprising and contradicting the expectation of recent important theoretical studies of this field. So, after our main experiment, we also conducted a second empirical experiment, in order to identify the better gamification element to motivate each gamer type. This experiment was conducted with 111 Brazilians students and the results confirm that students have different preferences about each gamification element and classified the better gamification elements to each gamer type. Finally, we provided a guideline to tailor gamified virtual learning environments based on our process and architecture and a second guideline with the better, neuter and worse gamification elements to motivate each gamer type.","('Gamificação', 'Tipos de jogadores', 'Estratégias de tecnologia persuasivas', 'Ambientes virtuais de aprendizagem', 'Adaptação de sistemas educacionais', 'Gamification', 'Gamer types', 'Persuasive technology strategies', 'Virtual learning environments', 'Tailoring educational systems')","Ciência da Computação","eng","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/3009","2017-10-20","https://www.repositorio.ufal.br/bitstream/riufal/3009/1/Tailoring%20gamified%20virtual%20learning%20environments%20based%20on%20gamer%20types.pdf","Adaptação de Ambientes Virtuais de Aprendizagem Gamificados com Base em Tipos de Jogador","('Julita Vassileva',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/8814","Campus A.C. Simões","Instituto de Computação","Dissertação","Systematic review and meta-analysis: processes towards selection automation","('Randy Ambrósio Quindai João',)","('André Luiz Lins de Aquino',)","('Rian Gabriel Santos Pinheiro', 'Jorge Artur Peçanha de Miranda Coelho')","Evidências científicas na área médica e outras disciplinas estão sendo produzidas e publicadas em uma escala e taxa sem precedentes. Essas evidências podem assumir muitas formas, os tipos e fontes mais comuns e, convencionais de evidência publicada incluem artigos de periódicos, resumos / artigos de conferências, relatórios técnicos e registros de ensaios clínicos. Para acompanhar o cenário da medicina em rápida evolução e para responder às necessidades críticas das crises de saúde pública de hoje em tempo hábil, há uma necessidade crescente de explorar, alavancar e integrar os resultados das novas evidências. Uma linha comum em todas essas evidências é que tais dados são, em geral, armazenados em um formato ruidoso e não estruturado, o que torna incrivelmente desafiador conduzir atividades de pesquisa, síntese e geração de relatórios de dados. Métodos secundários de pesquisa, como a síntese de evidências e revisão sistemática, estão se espalhando por todos os campos de pesquisa. O objetivo deste projeto de pesquisa foi estabelecer uma estrutura baseada em evidências para uma solução ótima de Processamento de Linguagem Natural (PLN) (incluindo um protótipo funcional) para apoiar a extração de informação de artigos científicos na forma de texto de forma automática. As mais recentes inovações em inteligência artificial (IA), aprendizado de máquina, ferramentas e técnicas de PLN oferecem a capacidade de extrair, analisar, sintetizar e compreender rapidamente dados textuais não estruturados em escala. Avanços recentes nessas tecnologias levaram a modelos de PLN amplamente aprimorados, que são capazes de capturar e modelar relacionamentos linguísticos mais complexos do que nunca. Ao fornecer a capacidade de avaliar e analisar grandes quantidades desses dados, o PLN abriu vastas oportunidades. Sendo assim, nossa maior meta foi estabelecer uma estrutura baseada em evidências para uma solução de PLN ideal, com a estrutura da revisão sistemática tradicional, onde todas as etapas são previstas e padronizadas. Procuramos desse modo, reduzir a carga do especialista de revisão, mantendo os altos padrões de qualidade e abrangência disponíveis numa revisão sistemática, desenvolvemos uma abordagem de triagem semiautomatizada usando os critérios definidos pelo revisor escritos em linguagem comum. Também oferecemos uma extração de tópicos simplificada e comparamos com a Alocação de Dirichlet Latente tradicional (LDA). Para o agrupamento dos estudos, transformamos o título, o resumo e as palavras-chaves em uma nuvem de palavras para cada estudo e agrupamos usando uma técnica de PLN chamada Sentence Boundary Detection (Detecção de limite de sentença) para encontrar e segmentar sentenças individuais significativas, assim, estudos com as mesmas sentenças são colocados juntos, organizados e agrupados por frequência de sentenças. Alcançamos a geração de resumo para estudos agrupados usando geração de linguagem natural. Realizamos uma comparação da Geração de Cadeia de Markov com a geração de Rede Neural Recorrente para avaliação da qualidade do texto gerado. Disponibilizamos gráficos de dados explorando os dados BibTeX e minerando relações de mudanças semânticas ou grupos de colaboração do autor. A metodologia de resultados segue as melhores práticas para a realização e relato de revisões, resolvendo um problema prático de forma eficaz e com resultados reproduzíveis e repetíveis. Esses resultados mostram que a ferramenta desejada é viável com o atual estado da arte da tecnologia. Esse trabalho resultou em uma startup que entrega produtos para explorar e analisar documentos científicos em larga escala, e foi validado pelo usuário final.","Public health evidence and other disciplines are being produced and published at an unprecedented rate and scale. This evidence can take many forms, the more common and conventional types and sources of published evidence include journal articles, conference abstracts/proceedings, technical reports, and clinical trial records/registries. To keep pace with the rapidly evolving public health landscape, and to respond to the critical needs, issues, and public health crises of today in a timely manner, there is a growing need to explore, leverage and integrate insights from more novel sources of evidence. A common thread across all this evidence is that such data is, at large, stored in a noisy, unstructured format, which makes secondary research-led activities in data extraction, synthesis, and reporting incredibly challenging. Secondary public health research methods, such as evidence synthesis and systematic reviewing, are spreading across all research fields. The aim of this research project was to establish an evidence-based framework for an optimal Natural Language Processing (NLP) solution (including a working prototype) to support public health evidence extraction and synthesis research activity. The latest innovations in artificial intelligence (AI), machine learning, and NLP tools and techniques offer the ability to rapidly extract, analyze, synthesize, and understand unstructured textual data, at scale. Recent breakthroughs in these technologies have led to vastly improved NLP models, which are able to capture and model more complex linguistic relationships than ever before. By providing the ability to assess and analyze large quantities of this data, NLP has opened up vast opportunities The aim of this research project was to establish an evidence-based framework for an optimal NLP solution (including a working prototype) to support public health evidence extraction and synthesis research activity. The traditional systematic review framework is a feasible starting point, where all steps are predicted and standardized. In order to reduce systematic reviewer burden while maintaining the high standards of systematic review validity and comprehensiveness we, developed a semi-automation screening approach using the reviewer’s criteria written in natural language. We offer a simplified topic’s extraction too and compare it to the traditional Latent Dirichlet Allocation (LDA). For clustering of studies, we transformed the title, abstract and keywords, into a wordcloud for each study, and grouped using a NLP technique called Sentence Boundary Detection for finding and segmenting meaningful individual sentences, studies with same sentences are put together, organized, and clustered by sentences frequency. We achieve the generation of summary for clustered studies using natural language generation. We perform a comparison of Markov Chain Generation with Recurrent Neural Network Generation for quality assessment of the generated text. We obtain data graphics by exploring BIBTEXdata already available, and mining relations of semantic changes or author’s groups of collaboration. The results methodology follows the best practices for conducting and reporting reviews, thus solving a practical problem effectively with reproducible and repeatable results. These results show that the desired tool is feasible with the current state of the art technology. This work resulted in a startup that delivers products to explore and analyze scientific documents in large scale, and it has been validated by the end user.","('Processamento de Linguagem Natural (PLN)', 'Alocação de Dirichlet Latente tradicional (LDA)', 'Revisão Sistemática da Literatura', 'Sistemas de Informação', 'Automação', 'SLR', 'NLG', 'Bibliometrics', 'Information Systems', 'Quantitative methods', 'NLP')","Ciência da Computação","eng","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/8814","2021-08-28","https://www.repositorio.ufal.br/bitstream/123456789/8814/1/Systematic%20review%20and%20meta-analysis%20-%20processes%20towars%20selection%20automation.pdf","Revisão Sistemática e Metanálise – Processos para automação da Seleção","('Fabiane da Silva Queiroz',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/1717","Campus A.C. Simões","Instituto de Computação","Dissertação","Uma tecnologia assistiva baseada na semiótica peirciana para a educação inclusiva de crianças surdas e ouvintes","('Denys Fellipe Souza Rocha',)","('Ig Ibert Bittencourt Santana Pinto',)","('Alan Pedro da Silva', 'Patrick Henrique da Silva Brito', 'Maria Cecilia Calani Baranauskas')","No cenário atual das escolas brasileiras, têm-se salas de aula heterogêneas com estudantes tendo diferentes necessidades. Todavia, o sistema educacional atual não atende de forma satisfatória tais estudantes. Como exemplo, inclui-se o caso de uma criança surda, possuindo necessidades diferentes de comunicação e precisando de algum tipo de acessibilidade, sendo a mesma ignorada por não se encaixar no padrão dos demais alunos. É nesse contexto que surge a educação inclusiva, sendo uma prática pouco realizada nas escolas atuais e carecendo de pesquisas científicas relevantes. Esta dissertação propõe um modelo para educação inclusiva baseado na semiótica peirceana e incluído em uma tecnologia, tendo como objetivo melhorar o processo de comunicação entre crianças surdas e ouvintes em salas de aula através de uma alfabetização bilíngue. A tecnologia incorpora um modelo que consiste em utilizar o signo e suas significações como forma de aprendizado. A partir de um signo que a criança conhece, faz-se referência a um objeto ainda desconhecido, causando na mente da criança um outro signo ou um signo mais evoluído. Seguindo uma cadeia de significações, a criança adquire signos como grafemas, datilologia (alfabeto manual) e alguns sinais da língua de sinais. Para validação da ferramenta proposta, foi realizado um experimento com crianças em uma sala de aula, por um período aproximado de uma semana, onde foi observado o nível de comunicação durante as brincadeiras. Posteriormente foram feitas análises dos resultados encontrados, afim de observar a qualidade dessa comunicação, através da presença da Língua Portuguesa e da Língua Brasileira de Sinais (Libras). Para tal análise, foi utilizado o teste Anderson-Darling, afim de verificar se os dados eram provenientes de uma população normal, o que rejeitou tal hipótese. A partir de então, descobriu-se a natureza dos dados através do teste Wilcoxon e utilizou-se os grupos ""Sem Tecnologia"" e ""Com Tecnologia e Professor"", afim de perceber se havia diferença na quantidade de sinais executados pelas crianças após a execução do experimento. Tais análises mostraram que havia uma diferença positiva considerável na concentração de sinais após a intervenção da tecnologia, o que valida a proposta desta dissertação. Os mesmos resultados podem ser observados através do modelo de regressão gerado para validar as hipóteses já lançadas. Portanto, podemos concluir que o modelo semiótico e a tecnologia que o incorpora produziu um ambiente de sala de aula mais inclusivo, no contexto de crianças surdas e ouvintes.","In the current scenario of Brazilian schools, there are heterogeneous room classes with students presenting different needs. However, the current educational system does not fulfill the satisfaction of such students. As an example, the case of a deaf child is included, having different communication needs and in need of some kind of accessibility, being ignored by the same does not fit the pattern of other students. It is in this context that inclusive education, being a little practice held in the current schools and lacking relevant scientific research. This dissertation proposes a model for inclusive education based on Peirce's semiotics, included a technology, and aims to improve the process of communication between deaf children and listeners in classrooms through a bilingual literacy. The technology incorporates a model that is to use the sign and its meaning as a way of learning. From a sign that the child knows, reference is made to an unknown object, causing the child's mind another sign or a more evolved sign. Following a chain of meanings, the child acquires signs as grapheme, dactylology (manual alphabet) and some signs of sign language. To validate the proposed tool, an experiment was conducted with children in a room, in a period of approximately one week, where we observed the level of communication during play. Later analyzes were made of the findings in order to observe the quality of that communication, through the presence of the Portuguese language and Brazilian Sign Language (Libras). For this analysis we used the Anderson-Darling test in order to verify that the data came from a normal population, which rejected the hypothesis. From then on, it was discovered the nature of the data by Wilcoxon test, and used the ""Without technology"" groups and ""With Technology and Teacher"" in order to understand if there was a difference in the number of signals carried by the children after execution of the experiment. These analyzes showed that there was a significant positive difference in the concentration of signs after the intervention of technology, which validates the purpose of this dissertation. The same results can be seen through the generated regression model to test hypotheses already launched. Therefore, we conclude that the semiotic model and the technology that incorporates produced a more inclusive classroom environment in the context of deaf and hearing children.","('Educação de crianças -Inclusão', 'Surdos -Educação', 'Ensino -Metodologia', 'Semiótica', 'Education of children -Inclusion', 'Deaf -Education', 'Teaching Methodology', 'Semiotics')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1717","2016-04-29","https://www.repositorio.ufal.br/bitstream/riufal/1717/1/Uma%20tecnologia%20assistiva%20baseada%20na%20semiotica%20peirciana%20para%20a%20educa%c3%a7%c3%a3o%20inclusiva%20de%20crian%c3%a7as%20surdas%20e%20ouvientes.pdf","An assistive technology based on peircean semiotics for inclusive for education of deaf and listener children","('Rafael de Amorim Silva',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/10887","Campus A.C. Simões","Instituto de Computação","Dissertação","Um sistema inteligente para a avaliação de risco da DRC e encaminhamento de pacientes em emergência para unidades de saúde","('Andressa Carvalho Melo da Silveira Queiroz',)","('Leandro Dias da Silva',)","('Evandro de Barros Costa', 'Ivo Augusto Andrade Rocha Calado', 'Angelo Perkusich')","A alta incidência e prevalência de Doença Renal Crônica (DRC), frequentemente causada por diagnósticos tardios, é um problema crítico de saúde pública, principalmente em países em desenvolvimento como o Brasil. As terapias de tratamento da DRC, como diálise e transplante renal, aumentam as taxas de morbimortalidade, além dos custos com saúde pública. Inicialmente, neste estudo, foi analisado o uso de técnicas de aprendizado de máquina para auxiliar no monitoramento da DRC em países em desenvolvimento. Análises comparativas qualitativas e quantitativas foram, respectivamente, realizadas executando uma revisão sistemática da literatura e um experimento com técnicas de aprendizado de máquina, com o método de validação cruzada k-fold, baseado no software Weka(c) e um conjunto de dados da DRC. A partir das análises, foi possível discutir a adequação das técnicas de aprendizado de máquina para a avaliação de risco de DRC, concentrando-se em ambientes de baixa renda e de difícil acesso em países em desenvolvimento, devido aos problemas específicos enfrentados, como, por exemplo, atendimento primário inadequado. Com base nos resultados do estudo, foi possível observar que a árvore de decisão J48 é uma técnica de aprendizado de máquina adequada para a avaliação de risco em países em desenvolvimento, devido à fácil nterpretação de resultados de classificação, com 95,00% de precisão, alcançando concordância quase perfeita com a opinião de um nefrologista experiente. Por outro lado, as técnicas de floresta aleatória, naive Bayes, máquina de vetores de suporte, perceptron multicamada e k vizinho mais próximo, respectivamente, apresentaram 93,33%, 88,33%, 76,66%, 75,00% e 71,67% de precisão, com pelo menos concordância moderada com o nefrologista, à custa de uma interpretação mais difícil dos resultados da classificação. Com esta conclusão, a árvore de decisão J48 foi usada para desenvolver um sistema inteligente para avaliar o risco de DRC em países em desenvolvimento. Além disso, quando o paciente com DRC está fora de seu município e ocorre uma emergência, o sistema recomenda que o paciente compareça a uma unidade de saúde apropriada, dependendo da situação clínica, para evitar cuidados de saúde tardios ou inadequados.","The high incidence and prevalence of chronic kidney disease (CKD), often caused by late diagnoses, is a critical public health problem, especially in developing countries such as Brazil. CKD treatment therapies, such as dialysis and kidney transplantation, increase the morbidity and mortality rates, besides the public health costs. Firstly, this study analyses the usage of machine learning techniques to assist in the early diagnosis of CKD im developing countries. Qualitative and quantitative comparative analyses are, respectively, conducted using a systematic literature review and an experiment with machine learning techniques, with the k-fold cross-validation method based on the Weka? software and a CKD dataset. These analyses enable a discussion on the suitability of machine learning techniques for screening for CKD risk, focusing on low-income and hard-to-reach settings of developing countries, due to the specific problems, e.g., inadequate primary health care. The study results show that the J48 decision tree is a suitable machine learning technique for such screening in developing countries, due to the straightforward interpretation of its classification results, with 95.00% accuracy, reaching a nearly perfect agreement with an experienced nephrologist's opinion. Conversely, random forest, naive Bayes, support vector machine, multilayer perceptron, and k-nearest neighbor techniques, respectively, yield 93.33%, 88.33%, 76.66%, 75.00%, and 71.67% accuracy, presenting at least moderate agreement with the nephrologist, at the cost of a more difficult interpretation of the classification results. With this conclusion, J48 decision tree was used to develop an intelligent system to evaluate the CKD risk in developing countries. In besides, when the CKD patient is outside his/her county and an emergency occurs, it is proposed that the system recommends the patient to attend an appropriate health unit depending on the clinical situation to prevent late or inadequate health care.","('Aprendizado do computador', 'Insuficiência renal crônica', 'Países em desenvolvimento', 'Machine Learning', 'Chronic Kidney Disease', 'Web Application', 'Developing Countries')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/10887","2020-08-28","https://www.repositorio.ufal.br/bitstream/123456789/10887/1/Um%20sistema%20inteligente%20para%20a%20avalia%c3%a7%c3%a3o%20de%20risco%20da%20DRC%20e%20encaminhamento%20de%20pacientes%20em%20emerg%c3%aancia%20para%20unidades%20de%20sa%c3%bade.pdf","","('Álvaro Alvares de Carvalho César Sobrinho',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/1610","Campus A.C. Simões","Instituto de Computação","Dissertação","Um sistema oportunista para detecção de vagas de estacionamento utilizando placas inteligentes acopladas em câmeras de segurança","('David Henrique de Souza Lima',)","('André Luiz Lins de Aquino',)","('Leandro Dias da Silva', 'Heitor Soares Ramos Filho', 'Antônio Alfredo Ferreira Loureiro')","Este trabalho apresenta um sistema para detecção de vagas de estacionamento utilizando câmeras de forma oportunista. A ideia central é a utilização de imagens provenientes de câmeras já instaladas para verificar a existência de vagas de estacionamento. É importante ressaltar que questões legais, de segurança e privacidade no uso de câmeras para detecção de vagas de estacionamento estão fora do escopo desta dissertação. Neste trabalho é abordado o problema de como utilizar câmeras de forma oportunista para detecção de vagas de estacionamento. A ideia para a solução é que por intermédio de sistemas embarcados, adaptado-os às câmeras já instaladas na cidade, podemos conceber satisfatoriamente a detecção de vagas. O objetivo principal deste trabalho é apresentar a viabilidade da utilização de sistemas embarcados para detecção de vagas de estacionamento. Para tal são propostas três técnicas de processamento de imagens para resolução do problema e como principal contribuição temos a apresentação de uma arquitetura distribuída para utilização de câmeras de forma oportunista para obtenção das imagens. As principais contribuições deste trabalho são a avaliação de três técnicas de processamento de imagens para detecção de veículos; proposta de uma arquitetura distribuída e oportunista utilizando câmeras para detecção de vagas de estacionamento; uma avaliação comparativa entre a arquitetura proposta e outras duas arquiteturas existentes; e um algoritmo de roteamento para encaminhamento das requisições na arquitetura Embutida. Inicialmente foram avaliadas três técnicas propostas de processamento de imagens para detecção de vagas de estacionamento, sendo a melhor delas a Dilatação após Detecção de Borda com uma eficiência de aproximadamente 100%. Essa avaliação serviu para escolhermos a técnica usada no restante do trabalho. Após a escolha da técnica, realizamos um experimento utilizando a arquitetura proposta e outras duas que serviram para comparação. O resultado do experimento demonstrou a viabilidade da utilização da arquitetura Embutida. Como realizar experimentos de grande porte Ã© uma tarefa complexa, foi desenvolvida uma simulação utilizando o simulador de redes Sinalgo para analisar quatro variáveis no sistema (raio de comunicação, quantidade de câmeras auxiliares, quantidade de requisições simultâneas e percentual de falhas nas câmeras). Com o resultado da simulação pode-se concluir que os fatores com maior influência na variação dos tempos médios das requisições são o tamanho do raio de comunicação e a quantidade de câmeras auxiliares.","This work aims to present a system for parking spaces detection using opportunistic cameras. The central idea is to use images from cameras that are already installed to identify possible parking spaces. It is important to highlight that legal, privacy and security issues in using cameras for parking detection is out of scope. This work addressed the problem of how to use cameras opportunistically to detect free parking spaces. The idea for the solution is that by means of embedded systems, adapted them to the cameras already installed in the city, we can successfully design the detection of vacancies. The main objective of this work is to present the feasibility of using embedded systems to detect parking spaces, for such, it is proposed three image processing techniques to solve the problem and as main contribution it is presented a distributed architecture for use of cameras opportunistically to obtain the images. The major contributions of this work were the development of three image processing techniques for vehicle detection; a distributed and opportunistic architecture proposal using cameras to detect parking spaces; comparative evaluation of the proposed architecture and two other existing architectures; a routing algorithm for routing requests in the Embedded architecture Initially, it was evaluated three proposed image processing techniques to detect parking spaces, the best technique was the Dilation after Border Detection with a success rate close to 100%, this evaluation was performed to choose the technique used in the rest of this work. After choose the best technique, it was performed an experiment using the proposed architecture and two others that are used for comparison, the result of the experiment demonstrated the feasibility of use the Embedded architecture. To conduct large experiments is a complex task, because of this a simulation was developed using the network simulator Sinalgo to analyze four variables in the system (communication radius, number of auxiliary cameras, amount of simultaneous requests and percentage of failed cameras). The simulation result shows that the factors with the greatest inï¬‚uence on the variation of the average times of the requests are the size of the communication radius and the amount of auxiliary cameras.","('Sistemas embarcados -Computadores', 'Processamento de imagens', 'Placas inteligentes', 'Câmeras de vídeos', 'Cidades inteligentes', 'Smart cities', 'Intelligent boards', 'Oportunistic cameras', 'Embedded systems', 'Image processing')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1610","2014-06-10","https://www.repositorio.ufal.br/bitstream/riufal/1610/1/Um%20sistema%20oportunista%20para%20detec%c3%a7%c3%a3o%20de%20vagas%20de%20estacionamento%20utilizando%20placas%20inteligentes%20acopladas%20em%20c%c3%a2meras%20de%20seguran%c3%a7a.pdf","An oportunistic system to detect free parking using inteligente boards embedded in surveillance cameras","('Eliana Silva de Almeida',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/1726","Campus A.C. Simões","Instituto de Computação","Dissertação","Soft skills do programador de software: abordagem conceitual e definição de métricas para identificação automática no contexto de um sistema de juiz online","('Maria Helynne Lima Silva',)","('Rodrigo de Barros Rodrigo de Barros Paes',)","('Márcio de Medeiros Ribeiro', 'Rohit Gheyi')","Soft skills são características associadas a personalidade de um indivíduo. Consideradas relevantes para compor o perfil de um profissional qualificado, elas melhoram o desempenho no trabalho. Diante de sua importância, empresas de Tecnologia da Informação precisam entender quais soft skills são necessárias para cada papel no processo de desenvolvimento de software. Além disso, durante o processo de contratação, essas empresas precisam identificar soft skills em candidatos a fim de descobrir quais deles possuem as características exigidas para os cargos disponíveis. No entanto, a identificação de soft skills é uma tarefa difícil, pois exige conhecer um indivíduo e seu comportamento por um tempo. Normalmente também requer esforços como entrevistas e recomendações, tendo sido observada a falta de abordagens automáticas nesse contexto. Esta dissertação propõe uma estratégia para minimizar o problema da identificação de soft skills. Tal estratégia foca no papel do programador de software e tem como objetivo encontrar formas para identificar automaticamente soft skills de indivíduos nesse papel. Para isso, propomos um conjunto de métricas que pontuam soft skills. Coletamos essas métricas a partir de um juiz online, de acordo com o desempenho e atividades de usuários no sistema. Para avaliar as métricas propostas, conduzimos um estudo empírico envolvendo 56 estudantes de cursos de programação. Nossos resultados indicam que as métricas para identificar as soft skills Análise e resolução de problemas, Atenção a detalhes, Aprendizagem rápida e Persistência são satisfatórias. Por outro lado, as métricas relativas às soft skills de Comunicação e Trabalho independente não alcançaram resultados significativos.","Soft skills are characteristics associated with an individual’s personality. They are relevant to professional qualification because they improve the performance at work. Since they are important, Information Technology companies need to understand the soft skills to each role in software development process. Additionally, during the hiring process these companies need to identify soft skills in candidates to find out which one of them have the required characteristics to fit the available jobs. However, soft skills identification is a hard task because it takes time to know an individual’s behavior and normally uses interviews or recommendations. Therefore, we notice a lack of automatic approaches in this context. This dissertation proposes a strategy to minimize the problem of soft skills identification. The strategy focus on the role of software programmers and it aims to find ways to automatically identify soft skills of individuals in this role. To do so, we propose a set of metrics that evaluate soft skills. We collect the metrics from an online judge system, according to its users’ performance and activities. To evaluate the metrics, we conduct an empirical study regarding 56 students of programming courses. Our results indicate that the metrics to identify Analytical and solving problems skills, Attention to details, Fast learning and Persistence are satisfactory. On the other hand, Communication and Work independently skills did not reach significant results.","('Soft skills', 'Programador -Software', 'Métricas', 'Programmer-Software', 'Metrics')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1726","2015-03-27","https://www.repositorio.ufal.br/bitstream/riufal/1726/1/Soft%20skills%20do%20programador%20de%20software%3a%20abordagem%20conceitual%20e%20defini%c3%a7%c3%a3o%20de%20m%c3%a9tricas%20para%20identifica%c3%a7%c3%a3o%20autom%c3%a1tica%20no%20contexto%20de%20um%20sistema%20de%20juiz%20online.pdf","Soft skills of software programmer: conceptual approach and definition of metrics for automatic identification in the context of an online judge system",""
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/12315","Campus A.C. Simões","Instituto de Computação","Dissertação","Skelibras: Uma extensa base de dados de Libras construída com esqueletos 2D","('Lucas Antônio Ferro do Amaral',)","('Thales Miranda de Almeida Vieira',)","('Marcelo Costa Oliveira', 'Fabiano Petronetto do Carmo')","O reconhecimento de sinais dinâmicos de línguas de sinais é uma tarefa difícil que começa a se tornar praticável com o uso de redes neurais profundas. Porém, a ausência de grandes bases de dados anotados inviabiliza o treinamento destes classificadores. Neste trabalho, foi construída uma base de dados, intitulada Skelibras, contendo 57760 amostras de esqueletos (poses) divididas em 6572 classes de sinais dinâmicos da Língua Brasileira de Sinais (Libras). Cada sinal na Skelibras é constituído de sequências de poses do corpo e das mãos. As poses são extraídas e indexadas automaticamente a partir de vídeos da base Corpus de Libras. Para extrair e organizar esses dados anotados de forma consistente, apresenta-se uma metodologia capaz de identificar e rastrear as poses de cada falante, indexar as legendas com os falantes presentes nas conversas e indexando a informação entre os vídeos adquiridos em distintos pontos de vista para uma única conversa com suas respectivas legendas. Realizamos experimentos em variações de redes neurais profundas baseadas em camadas convolucionais, densas, e unidades LSTMs para validar e fornecer resultados preliminares na base gerada neste trabalho, possibilitando assim a comparação futura com novos métodos de reconhecimento de sinais dinâmicos, alcançando 88.40 % de acurácia no melhor experimento, e cerca de 7.5% no pior dos experimentos. A Skelibras é uma base de dados pública e pode ser acessada pelo URL: https://github.com/luqsthunder/Skelibras.","The recognition of dynamic signs of sign languages is a difficult task that is starting to become feasible with the use of deep neural networks. However, the absence of large annotated databases makes the training of these classifiers unfeasible. In this work, a database called Skelibras was built, containing 57760 skeleton samples (poses) divided into 6572 classes of dynamic signs of Brazilian Sign Language (Libras). Each sign in Skelibras is made up of sequences of poses of the body and hands. The poses are automatically extracted and indexed from videos from the Corpus de Libras database. To extract and organize these annotated data consistently, a methodology capable of identifying and tracking the poses of each speaker, indexing the subtitles and speakers present in the conversations, and indexing the information between the videos acquired from different points of view for a single conversation with their respective subtitles. We performed experiments on variations of deep neural networks based on convolutional layers, dense layers, and LSTMs units to validate and provide preliminary results in the base generated in this work, thus enabling future comparison with new dynamic signal recognition methods, reaching 88.40 % of accuracy in the best experiment, and about 7.5% in the worst of the experiments. Skelibras is a public database and can be accessed at the URL: https://github.com/luqsthunder/Skelibras.","('Aprendizado do computador', 'Aprendizado profundo', 'Língua de sinais -Reconhecimento automático', 'Língua brasileira de sinais', 'Visão computacional', 'Computer Learning', 'Deep Learning', 'Sign Language -Automatic Recognition', 'Computer vision')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/12315","2021-10-29","https://www.repositorio.ufal.br/bitstream/123456789/12315/1/Skelibras_Uma%20extensa%20base%20de%20dados%20de%20Libras%20constru%c3%adda%20com%20esqueletos%202D.pdf","Skelibras: an extensive Libras database built with 2D skeletons","('Tiago Figueiredo Vieira',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/11919","Campus A.C. Simões","Instituto de Computação","Dissertação","Uma solução baseada em simulação para a validação de sistemas de aquisição de sinais biomédicos","('José Irineu Ferreira Júnior',)","('Álvaro Alvares de Carvalho César Sobrinho',)","('Thiago Damasceno Cordeiro', 'Angelo Perkusich', 'Antônio Marcus Nogueira de Lima')","Sistemas de aquisição de sinais biomédicos são indispensáveis para o monitoramento e diagnóstico de pacientes. Por isso, devem estar em conformidade com normas reguladoras vigentes e passar por manutenção periódica, conforme as exigências presentes em resoluções normativas do Ministério da Saúde e da Agência Nacional de Vigilância Sanitária. Neste sentido, o objetivo com este trabalho é definir uma solução confiável, baseada em simulação, para auxiliar fabricantes, órgãos validadores e unidades de saúde (em um contexto de manutenção) na validação de múltiplos equipamentos/sistemas de aquisição de sinais biomédicos. A solução proposta é constituída de duas partes que se complementam: o software em um dispositivo de computação, representada por uma interface gráfica de usuário, lógica de aplicação e modelo formal baseado em Redes de Petri Colorida (Colored Petri Nets -CPN) dotado de um método de filtragem baseado em frequência; e o hardware configurável por software, representada por um dispositivo Transceptor de Sinais Biomédicos (TSB), especialmente projetado para trabalhar com sinais de ECG, EEG, EMG e EGG. O sistema foi validado usando o banco de dados da Physionet e testes de comparação para verificar o sinal esperado e as saídas de sinal com base nos filtros MATLAB e no aparelho de ECG comercial ENGC901448 da Instramed. O sistema provou ser confiável, de baixo custo, portátil e relevante para fornecer evidências para certificação e auxiliar os estabelecimentos de saúde na realização de calibrações e manutenções.","Biomedical signal acquisition systems are relevant for patient monitoring and diagnosis. Therefore, such systems must comply with current regulatory standards and undergo periodic maintenance, in accordance with the requirements defined in normative resolutions of the Ministry of Health and the National Health Surveillance Agency. Thus, the objective of this work is to define a reliable simulation-based approach to assist manufacturers, validation agencies, and healthcare facilities (in a maintenance context) in the validation of multiple equipment or biomedical signal acquisition systems. The proposed approach consists of two parts that complement each other: the software embedded in a computing device, represented by a graphical user interface, formal application logic model based on Colored Petri Nets (CPN) with a frequency-based filtering method; and the hardware, represented by a Biomedical Signals Transceiver (TSB) device, configurable by software, specially designed to work with ECG, EEG, EMG and EGG signals. The system was validated using Physionet’s database and comparison tests to verify expected signal and signal outputs based on MATLAB filters and Instramed’s commercial ECG instrument ENGC901448. The system has proven to be reliable, cost-effective, portable and relevant to provide evidence for certification and assist healthcare facilities in performing calibrations and maintenance.","('Equipamentos biomédicos', 'Sinais biomédicos', 'Redes de Petri Coloridas', 'Arquitetura Hardware/Software', 'Biomedical equipment', 'Biomedical signals', 'Colored Petri Nets', 'Hardware/Software Architecture')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/11919","2022-06-29","https://www.repositorio.ufal.br/bitstream/123456789/11919/1/Uma%20solu%c3%a7%c3%a3o%20baseada%20em%20simula%c3%a7%c3%a3o%20para%20a%20valida%c3%a7%c3%a3o%20de%20sistemas%20de%20aquisi%c3%a7%c3%a3o%20de%20sinais%20biom%c3%a9dicos.pdf","A simulation-based solution for validating biomedical signal acquisition systems","('Leandro Dias da Silva',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/14424","Campus A.C. Simões","Instituto de Computação","Dissertação","Representação, visualização e análise de grandes volumes de dados urbanos espaço-temporais de segurança pública","('Tiago Paulino Santos',)","('Thales Miranda de Almeida Vieira',)","('Rian Gabriel Santos Pinheiro', 'Luis Gustavo Nonato')","As transformações tecnológicas advindas da transformação digital de órgãos públicos e da internet das coisas têm possibilitado a geração e coleta de grandes volumes de dados, que podem ser posteriormente utilizados em análises precisas. Para a segurança pública, a aplicação de novas tecnologias nas atividades de análise criminal, patrulhamento e repressão ao crime trazem inúmeras possibilidades também, como conseguir visualizar de maneira profunda o desempenho das ações da corporação, monitorar a atividade criminosa, compreender padrões e buscar alternativas para implementar melhores políticas de segurança. Big Data também já não é uma realidade distante das corporações de segurança pública. Dispositivos de rastreamento, câmeras de vigilância, sistemas de monitoramento, sistemas de atendimento e muitas outras fontes de informação já provêm um grande volume de dados que precisam ser devidamente tratados para que seja possível obtenção de conhecimento relevante. Nos últimos anos, muitos trabalhos científicos têm proposto o uso de algoritmos de Aprendizado de Máquina para reconhecer padrões espaciais e temporais de crimes. Nesse contexto, propomos neste trabalho uma ferramenta de análise visual de dados urbanos espaço-temporais, e um novo algoritmo para detecção de manchas criminais. Estas soluções foram validadas usando bases de dados da Polícia Militar do Estado de Alagoas (PMAL) em estudos de caso onde o objetivo era analisar dados espaço-temporais de crimes e de patrulhamento. Os resultados desta pesquisa terão importância não só do ponto de visto científico, mas também poderão ser aproveitados pela PMAL para otimizar seus processos de tomada de decisão. Um diferencial deste trabalho é a abordagem de fontes de dados de crimes e de patrulhamento na mesma ferramenta de visualização.","Technological transformations arising from the digital transformation of public bodies and the internet of things have enabled the generation and collection of large volumes of data, which can later be used in precise analyses. For public security, the application of new technologies in criminal analysis, patrolling and crime repression activities also bring countless possibilities, such as being able to visualize in depth the performance of the corporation’s actions, monitor criminal activity, understand patterns and seek alternatives to implement better security policies. Big Data is also no longer a distant reality for public security corporations. Tracking devices, surveillance cameras, monitoring systems, customer service systems and many other sources of information already provide a large volume of data that needs to be properly processed in order to obtain relevant knowledge. In recent years, many scientific works have proposed the use of Machine Learning algorithms to recognize spatial and temporal patterns of crimes. In this context, we propose in this work a visual analysis tool for spatio-temporal urban data, and a new algorithm for detecting crime spots. These solutions were validated using databases from the Military Police of the State of Alagoas (PMAL) in case studies where the objective was to analyze spatio-temporal data on crimes and patrolling. The results of this research will be important not only from a scientific point of view, but can also be used by PMAL to optimize its decision-making processes. A difference of this work is the approach of crime and patrol data sources in the same visualization tool.","('Segurança pública', 'Ciência de dados', 'Análise de dados espaço-temporais', 'Dados Urbanos', 'Big Data', 'Public Security', 'Data Science', 'Spatiotemporal data analysis', 'Urban data', 'Big Data')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/14424","2024-01-25","https://www.repositorio.ufal.br/bitstream/123456789/14424/1/Representa%c3%a7%c3%a3o%2c%20visualiza%c3%a7%c3%a3o%20e%20an%c3%a1lise%20de%20grandes%20volumes%20de%20dados%20urbanos%20espa%c3%a7o-temporais%20de%20seguran%c3%a7a%20p%c3%bablica.pdf","Representation, visualization and analysis of large volumes of spatio-temporal urban public safety data",""
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/1723","Campus A.C. Simões","Instituto de Computação","Dissertação","Sistema de monitoramento móvel de sinais cardíacos para uso em assistência domiciliar","('Gilton José Ferreira da Silva',)","('Leandro Dias da Silva',)","('Evandro de Barros Costa', 'Antônio Marcus Nogueira de Lima')","O trabalho apresenta o projeto e o desenvolvimento de um sistema que visa auxiliar os profissionais de saúde em suas tarefas de tratamento de pacientes em um sistema homecare que necessitem de monitoramento de modo contínuo, em especial os pacientes que estejam em quadros clínicos pós-cirúrgico de problemas cardiovasculares. Com isso, facilitando e apresentando ferramentas para a coleta constante de sinais vitais de eletrocardiograma (ECG) e emitindo alertas de acordo mudanças críticas na frequência cardíaca do paciente. O sistema é dividido em três módulos distintos: O Módulo Local que é responsáveis pela aquisição dos sinais vitais do paciente, se comunicando com equipamentos portáteis de monitoramento, como um eletrocardiógrafo portátil; O Módulo Web que se destina a realizar a centralização da coleta e persistência dos dados em um banco de dados em nuvem e o Módulo Mobile que é um aplicativo voltado para dispositivos móveis, com sistema operacional Android, que visa auxiliar o pro ssional de saúde na tomada de decisão sobre o tratamento do paciente em caso de mudanças no estado clínico, através da visualização em tempo real dos sinais vitais e do recebimento de alertas. Foi feita a veri cação do sistema em ambiente de desenvolvimento através de testes unitários, testes de integração e testes de interface. Já a validação foi realizada com a integração de um eletrocardiógrafo portátil acoplado a um simulador de sinais de ECG, no Módulo Local, e para o Módulo Web, testes de desempenho foram submetidos através da ferramenta Apache Jmeter, onde foram feitos envios de alertas simultâneos. Os testes realizados, junto aos profissionais, revelam a viabilidade de utilização do sistema com os cuidados de pacientes em homecare.","This work presents the design and development of a system designed to assist healthcare professionals in their treatment of patients in a homecare system tasks that require continuously monitoring, especially patients who are in post-surgical clinical cases of cardiovascular problems. Thus, facilitating and presenting tools for continuous monitoring of vital signs electrocardiogram (ECG) and issuing alerts according critical changes in heart rate of the patient. The system is divided into three distinct modules: Local module that is responsible for acquiring the patient's vital signs, communicating with portable monitoring equipment such as a portable electrocardiograph; The Web module that is designed to perform centralized collection and storage of data in a cloud database and the Mobile Module which is a focused application for mobile devices with Android operating system, which aims to assist health professionals in decision decisions on the patient's treatment in the event of changes in clinical status through real-time display of vital signs and receiving alerts. Checking the system development environment it was taken through unit testing, testing and integration testing interface. Already the validation was performed with the integration of a portable electrocardiograph coupled to a simulator of ECG signals, the Local Module, and the Web module, performance tests were submitted by Apache Jmeter tool, where they were made submissions simultaneous alerts. The tests carried out with professionals, show the feasibility of using the system with the care of patients in home care. Keywords: Homecare Systems. mHealt","('Eletrocardiografia', 'Android (Recurso eletrônico)', 'Electrocardiography', 'Android (Electronic Resource)')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1723","2015-05-15","https://www.repositorio.ufal.br/bitstream/riufal/1723/1/Sistema%20de%20monitoramento%20m%c3%b3vel%20de%20sinais%20card%c3%adacos%20para%20uso%20em%20assist%c3%aancia%20domiciliar.pdf","Mobile monitoring system of hearth signs for use in homecare","('Cleumar da Silva Moreira',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/10547","Campus A.C. Simões","Instituto de Computação","Dissertação","Sistema de validação de aspectos técnicos e pedagógicos de videoaulas : construindo recomendações e visualizações para apoiar o professor","('Júlio César Ferreira Silva de Holanda',)","('Alan Pedro da Silva',)","('Diego Dermeval de Medeiros da Cunha Matos', 'Rafael Ferreira Leite de Mello')","Com o avanço da tecnologia de educação e a tendência de aceitação de ambientes virtuais de aprendizagem como MOOCs e plataformas de vídeo como o YouTube por parte de alunos e professores, a migração para estes tipos de plataformas é cada vez maior, e os professores que decidem aceitar a mudança devem se adequara produção de material didático específico para tais ambientes online. As videoaulas são o principal material didático disponível em boa parte dos cursos e aulas online, mas sua produção desafia o conhecimento técnico prévio que boa parte dos professores possuem. Como forma de apoiar o professor na produção de videoaulas melhores, este trabalho propõe um Sistema de Validação de Videoaulas (SVV), caracterizado por processar os vídeos dos professores e retornar uma série de informações e dados apresentáveis e de fácil leitura e entendimento. Um primeiro estudo foi realizado para detectar os aspectos das videoaulas mais relevantes para a aceitação de alunos sobre o material, os quais se destacaram a duração do vídeo, tipo de apresentação do vídeo (talking head), frequência de mudança de cenas, presença de ruído, resolução da imagem e boa resolução de problemas e questões no vídeo. Os aspectos foram utilizados para construir um dashboard com informações sobre a videoaula baseadas nestes aspectos. Um segundo estudo mostrou que o dashboard elaborado foi bem aceito por uma amostra de participantes que envolvia estudantes e professores de computação, reforçando a utilidade da ferramenta proposta para a melhoria de videoaulas.","With the advancement of education technology and the trend of acceptance of virtual learning environments such as MOOCs and video platforms such as YouTube by students and teachers, the migration to these types of platforms is increasing, and the teachers who decide accepting the change must adapt the production of specific teaching material for such online environments. Video classes are the main teaching material available in most courses and online classes, but their production challenges the prior technical knowledge that most teachers have. As a way to support the teacher in the production of better video lessons, this work proposes a Video Lesson Validation System (SVV), characterized by processing the teachers videos and returning a series of presentable, easy-to-read and understandable information and data. A first study was carried out to detect the most relevant aspects of video classes for the acceptance of students about the material, which highlighted the duration of the video, type of video presentation (talking head), frequency of scene changes, presence of noise , image resolution and good resolution of problems and issues in the video. Aspects were used to build a dashboard with information about the video class based on these aspects. A second study showed that the dashboard was well accepted by a sample of participants that involved computer students and teachers, reinforcing the usefulness of the proposed tool for improving video classes.","('Videoaula', 'Montagem de sistemas', 'Learning analytics', 'Dashboards (Sistema de informação gerencial)', 'Aceitação de tecnologia', 'Video Lessons', 'System Modeling', 'Learning Analytics', 'Dashboard', 'Technology Acceptance Study')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/10547","2021-10-29","https://www.repositorio.ufal.br/bitstream/123456789/10547/1/Sistema%20de%20valida%c3%a7%c3%a3o%20de%20aspectos%20t%c3%a9cnicos%20e%20pedag%c3%b3gicos%20de.pdf","","('Ranilson Oscar Araújo Paiva',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/7053","Campus A.C. Simões","Instituto de Computação","Dissertação","Reconhecimento facial RGBD para análise de parentesco","('Felipe Carmo Crispim',)","('Tiago Figueiredo Vieira',)","('Thales Miranda de Almeida Vieira', 'Douglas Cedrim Oliveira')","Este trabalho apresenta uma abordagem inédita de reconhecimento de parentesco baseada em Aprendizado Profundo aplicado a dados faciais de imagens coloridas e com informação de profundidade, i. e., RGBD. Para contornar a falta de uma base de dados 3D adequada com informações de parentesco, foi fornecida uma plataforma online onde os participantes podem submeter vídeos capturados com câmeras de smartphones comuns contendo a sua face e as de seus parentes. Em seguida, os vídeos são processados para a reconstrução 3D das faces gravadas, gerando um banco de dados normalizado batizado Kin3D. Nele, combinam-se informações de profundidade de reconstruções 3D normalizadas com imagens 2D, compondo o banco de dados RGBD de parentesco inédito na literatura. Seguindo as abordagens de trabalhos relacionados, imagens são organizadas em quatro categorias de acordo com suas respectivas relações de parentesco. Para a classificação foram utilizadas Redes Neurais Convolucionais (CNN) bem como Máquina de Vetores de Suporte para a obtenção de um baseline. A CNN foi testada em um banco de dados de parentesco 2D previamente consolidado na literatura científica, conhecido como KinFaceW-I e II, e em nosso Kin3D para comparação com trabalhos relacionados. Uma outra abordagem foi usada ao reunir todos os parentes de primeiro grau de uma vez e classificá-los de maneira binária. Resultados indicam que a adição de informação de profundidade aprimora a performance do modelo, aumentando a acurácia de classificação. Até o momento da escrita desse trabalho, este é o primeiro banco de dados contendo informação de profundidade para verificação de parentesco bem como a análise de técnicas do estado da arte para a obtenção do benchmark, fornecendo uma performance como ponto de partida para estimular ainda mais avaliações da comunidade de pesquisa.","This work presents a new approach to kinship recognition based on Deep Learning applied to facial data of color images with depth information, i. e., RGBD. To work around the lack of an adequate 3D database containing kinship information, an online platform was provided where participants can submit videos captured by common smartphones cameras containing their face and those of their relatives. Then, the videos are processed to generate the 3D reconstruction of recorded faces, resulting in a standardized database coined Kin3D. It combines depth information from normalized 3D reconstructions with 2D images comprising RGBD data with unprecedent kinship information. Following previous works, image files are segmented into four categories according to their respective kinship relationship. For the classification, Convolutional Neural Networks (CNN) were used, as well as a Support Vector Machines (SVM) to obtain a baseline. The CNN was tested in a 2D kinship database previously consolidated in the scientific literature, known as KinFaceW-I and II, and in our Kin3D for comparison with related works. Another approach was used by bringing all first-degree relatives together at once and classifying them in a binary way. Results have shown that the addition of depth information improves the performance of the model, increasing the classification accuracy. As of the writing of this work, this is the first database containing depth information for kinship verification as well as the analysis of state-of-the-art techniques for obtaining the benchmark, providing performance as a starting point to further stimulate evaluations from the research community.","('Parentesco -Percepção facial', 'Biometria -Percepção facial', 'Movimento de câmara', 'Reconhecimento facial', 'Kinship verification', 'Face Biometrics', 'Structure from Motion', '3D Reconstruction')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/7053","2020-03-13","https://www.repositorio.ufal.br/bitstream/riufal/7053/3/Reconhecimento%20facial%20RGBD%20para%20an%c3%a1lise%20de%20parentesco.pdf","Verifying kinship from RGB-D face data",""
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/1963","Campus A.C. Simões","Instituto de Computação","Dissertação","Uma proposta para aprimorar o anonimato em transações bitcoin com suporte à auditoria","('Daniel de Melo Pimentel',)","('Leandro Melo de Sales',)","('Rafael de Amorim Silva', 'Aydano Pamponet Machado')","Neste trabalho, apresenta-se uma avaliação de desempenho da aplicação da técnica de Assinatura de Grupo no sistema Bitcoin e um estudo sobre anonimato e auditoria. O Bitcoin tem como objetivo prover uma moeda virtual e um sistema de transação online anônima. Todavia, pesquisas recentes relatam que é possível quebrar o anonimato das transações Bitcoin, por meio de técnicas de rastreabilidade cronológica nas transações Bitcoin e da análise dos endereços de rede. Como consequência da quebra de anonimato das transações Bitcoin, a privacidade dos usuários e todo ecossistema Bitcoin são afetados negativamente. Por este motivo, neste trabalho, propõe-se a inclusão de técnicas de Assinaturas de Grupos no sistema Bitcoin para aumentar o anonimato nesse sistema, porém em tempo hábil, cerca de 10 minutos. A técnica de Assinatura de Grupo gera diversos grupos distintos para diversas transações Bitcoin, dificultando assim a rastreabilidade dessas transações. Após a implementação dessa técnica em uma versão modificada do sistema Bitcoin, avaliou-se tal proposta por meio de experimentos executados em simulações. Através dos resultados dos experimentos e análises estatísticas, constatou-se que a abordagem com a inclusão da Assinatura de Grupo é viável para implantação no sistema Bitcoin desde que os grupos sejam pequenos, cerca de 500 clientes. Para todos os casos avaliados, verificou-se que com o uso da Assinatura de Grupo as transações Bitcoin se tornam anônimas. Porém, avaliou-se que o desempenho das transações Bitcoin com a técnica de Assinatura de Grupo nesse sistema tem lentidão aproximada de 50% em comparação com as transações Bitcoin sem essa técnica. Além disso, em grupos pequenos com Assinatura de Grupo, obtêm-se um elevado nível de anonimato e permite-se auditoria, porém em grupos grandes com aproximadamente mais de 500 clientes essa técnica não se mostra tão eficiente, pois as transações começam a exceder o tempo hábil.","This work show an avaliation about the performance of the application of Group Signature technique in Bitcoin system and a study about the anonymity and auditory. The Bitcoin’ goal is provide a virtual currency and an anonymous online transaction system. However, recent researches show that can be to break the anonymity of transactions through the chronological traceability technique in the Bitcoin transactions and analysis of network addresses. As a result of breaking anonymity of Bitcoin transactions, users’ privacy and all Bitcoin ecosystem are affected negatively. For this reason, in this work, it was proposed to include Group Signatures techniques in the Bitcoin system to increasing of anonymity in Bitcoin transactions but with audity possibility in accept time, more or less 10 minutes. The Group Signature generate a lot of dinstinct groups to dinstinct Bitcoin transactions. After to include the Group Signature technique in a modified version of Bitcoin system, we evaluated this technique in Bitcoin system through experiment in simulations. Through the experiments and statistic analysis, it was found that the approach of including the Group Signature is feasible for implementation in Bitcoin system with small groups, 500 clients. For the all cases analyzed, it was verified that the use of Group Signature in Bitcoin transactions increase the anonymity. Therefore, it was verified that the performance of Bitcoin transactions with Group Signature technique show a delay in nearly 50% less than current Bitcoin system whitout this technique. Nevertheless, in small groups with Group Signature get a better anonymity level and audity, but in big groups with more than 500 clients this technique not is good because the transactions time is over.","('Bitcoin', 'Moeda virtual', 'Auditoria', 'Assinatura de grupo -Anonimato', 'Serviços online -Transações', 'Virtual currency', 'Audit', 'Signature of group -Anonymity', 'Online services -Transactions')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1963","2017-05-19","https://www.repositorio.ufal.br/bitstream/riufal/1963/1/Uma%20proposta%20para%20aprimorar%20o%20anonimato%20em%20transa%c3%a7%c3%b5es%20bitcoin%20com%20suporte%20%c3%a0%20auditoria.pdf","A proposal for increase the anonymity in bitcoin transactions with audity support",""
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/13028","Campus A.C. Simões","Instituto de Computação","Dissertação","Recomendação de um modelo de aprendizado de máquina parapredição de risco cardiovascular com biomarcadores da síndrome metabólica e Escore de Framingham","('Wellignton Batista da Silva',)","('Rafael de Amorim Silva',)","('Ranilson Oscar Araújo Paiva', 'Almir Pereira Guimarães', 'Rafael Ferreira Leite de Mello')","A previsão de eventos cardiovasculares em pacientes diagnosticados com Síndrome Metabólica (SM) é um tema de grande relevância para a área da Saúde, em geral, e fundamental para a da Endocrinologia. Esta dissertação objetiva recomendar um modelo de Machine Learning (ML) para estimar os riscos de eventos cardiovasculares em pacientes com SM, explorando os marcadores do escore de Framingham (FRS) e da SM. Metodologicamente, utilizamos um modelo de regressão logística e análises com árvore de decisão, floresta aleatória, impulsionamento de gradiente, máquina de vetores de suporte e k-vizinhos mais próximos para testar nossa hipótese central de que os bioindicadores (variáveis relacionadas à SM) exercem um impacto positivo, forte e significativo nos eventos cardiovasculares em pacientes com SM. Tecnicamente a pesquisa foi conduzida por meio de experimentos realizados em diferentes cenários. No primeiro cenário, um algoritmo foi desenvolvido para avaliar o risco cardiovascular em pacientes com e sem SM. Nos cenários 2, 3 e 4, foram analisados pacientes com e sem SM, considerando os marcadores de SM e FRS como variáveis dependentes, enquanto a condição de Síndrome Metabólica foi adotada como variável independente. No quinto cenário, uma análise foi realizada para selecionar o modelo de regressão e classificação mais adequado para a predição do risco cardiovascular em um conjunto de dados combinado de doenças cardíacas. No sexto cenário, o modelo desenvolvido foi fundamentado no Escore de Risco Global (ERG) de Framingham, incorporando os marcadores da SM nos experimentos. Os dados foram obtidos a partir do repositório do National Center for Health Statistics (NHANES), um conjunto de dados combinados de doenças cardíacas do Repositório de aprendizado de máquina UCI. e da plataforma Kaggle. Em resumo, os principais achados desta dissertação são os seguintes: (1) No primeiro cenário, uma diferença percentual de 81,74% foi observada nas médias de Risco ECV entre as populações com e sem Síndrome Metabólica, evidenciando um aumento significativo do risco cardiovascular na população com SM; (2) nos cenários dois, três e quatro, o modelo Random Forest (RF) se destacou, alcançando alta acurácia em todas as combinações de variáveis, especialmente na combinação dos marcadores da Sm como marcador de sexo; (3)no quinto cenário, o modelo RF foi identificado como o mais indicado, destacando a importância das variáveis relacionadas à SM na predição do risco cardiovascular e ressaltando a necessidade de aprimoramentos nos modelos para melhor identificação dos casos positivos; (4) tanto o modelo com quatro marcadores da SM quanto o modelo com cinco marcadores da SM combinados ao escore de Framingham (SM + FRS) apresentaram desempenho considerável, com correlações e acurácias significativas (0.80 e 0.84, respectivamente). Essas combinações mais simples de variáveis podem ser uma abordagem interessante, uma vez que fornecem informações relevantes para a predição do risco cardiovascular de forma menos invasiva, evitando a necessidade de exames mais complexos.","The prediction of cardiovascular events in patients diagnosed with Metabolic Syndrome (MS) is a topic of great importance in the field of Health in general and crucial for Endocrinology. This dissertation aims to recommend a Machine Learning (ML) model to estimate the risks of cardiovascular events in patients with MS, exploring the markers of the Framingham Risk Score (FRS) and MS. Methodologically, we used a logistic regression model and conducted analyses with decision trees, random forest, gradient boosting, support vector machine, and k-nearest neighbors to test our central hypothesis that bioindicators (variables related to MS) exert a positive, strong, and significant impact on cardiovascular events in MS patients. Technically, the research was carried out through experiments conducted in different scenarios. In the first scenario, an algorithm was developed to assess cardiovascular risk in patients with and without MS. In scenarios 2, 3, and 4, patients with and without MS were analyzed, considering MS and FRSmarkersasdependentvariables,whiletheMetabolicSyndromeconditionwasadoptedasan independent variable. In the fifth scenario, an analysis was performed to select the most suitable regression and classification model for predicting cardiovascular risk in a combined dataset of heart diseases. In the sixth scenario, the developed model was based on the Framingham Global Risk Score (FRS), incorporating MS markers into the experiments. Data were obtained from the National Center for Health Statistics (NHANES) repository, a combined dataset of heart diseases from the UCI Machine Learning Repository, and the Kaggle platform. In summary, the main findings of this dissertation are as follows: In the first scenario, a percentage difference of 81.74% was observed in mean CVD Risk between populations with and without Metabolic Syndrome, demonstrating a significant increase in cardiovascular risk in the population with MS. In scenarios two, three, and four, the Random Forest (RF) model excelled, achieving high accuracy in all variable combinations, especially in the combination of MS markers with gender. In the fifth scenario, the RF model was identified as the most suitable, emphasizing the importance of variables related to MS in predicting cardiovascular risk and highlighting the need for model improvements to better identify positive cases. Both the model with four MS markers and the model with five MS markers combined with the Framingham Risk Score (SM + FRS) demonstrated considerable performance, with significant correlations and accuracies (0.80 and 0.84, respectively). These simpler variable combinations can be an interesting approach as they provide relevant information for predicting cardiovascular risk in a less invasive manner, avoiding the need for more complex tests.","('Aprendizado de máquina', 'Modelo de predição', 'Síndrome metabólica', 'Escore de risco global (ERG) de Framingham', 'Machine Learning', 'Prediction model', 'Metabolic Syndrome', 'Framingham Global Risk Score (GRS)')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/13028","2023-08-30","https://www.repositorio.ufal.br/bitstream/123456789/13028/1/Recomenda%c3%a7%c3%a3o%20de%20um%20modelo%20de%20aprendizado%20de%20m%c3%a1quina%20parapredi%c3%a7%c3%a3o%20de%20risco%20cardiovascular%20com%20biomarcadores%20da%20s%c3%adndrome....pdf","","('Bruno Almeida Pimentel',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/14070","Campus A.C. Simões","Instituto de Computação","Dissertação","A recomendação pedagógica em tempo real baseada na atenção dos estudantes utilizando computação afetiva","('Daniel Borges Ferreira da Silva',)","('Ig Ibert Bittencourt Santana Pinto',)","('Alan Pedro da Silva', 'Jorge Artur Peçanha de Miranda Coelho')","Dispositivos móveis estão sendo utilizados cada vez mais pela população. O público jovem tem utilizado tais dispositivos a qualquer momento, principalmente com a finalidade de troca de mensagens e isso tem afetado, negativamente, a sua concentração em sala de aula. Por um lado, pode-se utilizar métodos que restringem o uso de tais dispositivos em sala de aula com a finalidade de reduzir o nível de distração, mas estes métodos causam problemas que podem afetar os estudantes que utilizam os dispositivos para fins de estudos. Por outro lado, pode-se utilizar métodos alternativos que envolvem desde aplicações de filtro, até a conscientização da sociedade a respeito do mal que a distração pode causar. Esses últimos métodos devem ser aplicados com cautela, pois sua eficácia é variável e difícil de mensurar. A distração em sala de aula usando dispositivos móveis se torna um problema no qual a educação presencial lida ultimamente. Diante disto, este trabalho tem como objetivo apresentar uma abordagem alternativa para resolver o problema da distração em sala de aula por meio de um processo de recomendação. Tal processo está fundamentado no uso de recomendações pedagógicas baseadas no nível de engajamento dos estudantes, detectado por intermédio de sistemas computacionais. Para tal, utilizou-se teorias e técnicas de computação afetiva, para a detecção do engajamento, e dispositivos móveis, para o envio das recomendações. Consideramos a falta de engajamento dos estudantes, caracterizada pela falta de atenção na aula, como o principal foco do problema de pesquisa. A proposta deste trabalho foi testada em sala de aula, por meio de um experimento controlado onde recomendações pedagógicas eram enviadas para os celulares dos estudantes, após a medição do nível de atenção dos estudantes. Essas recomendações tinham o objetivo de fazer com que o estudante voltasse sua atenção para a aula, combatendo a distração. Tal experimento foi realizado em um cenário real onde, de fato, o problema em questão esteve presente durante a aula. Participaram do experimento três turmas do ensino superior da Universidade Federal de Alagoas (UFAL), contemplando as três áreas de atuação existentes: Ciências Exatas (Matemática), Ciências Biológicas (Enfermagem) e Ciências Humanas (Administração). No total, participaram do experimento 38 alunos. Através da análise quantitativa e qualitativa dos dados, concluímos que o uso de recomendação pedagógica baseada nos estados afetivos dos alunos enviada através de dispositivos móveis para combater a distração causada pelo mesmo não é uma boa alternativa de solução para o problema, pois é gerada nos alunos a ansiedade para verificar as recomendações enviadas, e continuam se distraindo. Por fim, levantamos outras questões e hipóteses para trabalhos futuros.","Mobile devices are actually used more and more by the population. Young people have used this kind of devices at any time, especially for the purpose of exchanging messages and this has adversely affected their concentration in the classroom. On the one hand, methods that restrict the use of such devices in the classroom can be used to reduce the level of distraction, but these methods cause problems that may affect students who use the devices for study purposes. On the other hand, it is possible to use alternative methods that involve the use of filter applications to the education of society about the negative effects that distraction can cause. The restrictive methods should be applied with caution since their effectiveness is variable and difficult to measure. Classroom distraction using mobile devices becomes a problem in which classroom education deals lately. In view of this, this work aims to present an alternative approach to solving the problem of distraction in the classroom by means of a recommendation process. This process is based on the use of pedagogical recommendations based on the engagement level of student, detected through computational systems. For that, theories and techniques of affective computing, for the detection of the engagement, and mobile devices, were used to send the recommendations. We consider students’ lack of engagement, characterized by lack of attention in class, as the main focus of the research problem. The proposal of this work was tested in the classroom, through a controlled experiment where pedagogical recommendations were sent to students’ cell phones, after measuring students’ level of attention. These recommendations were meant to get the student to turn his attention to class, fighting distraction. This experiment was carried out in a real scenario where, in fact, the problem in question was present during the lesson. Three higher education groups from the Universidade Federal de Alagoas (UFAL) participated in the experiment, covering three existing areas: Exact Sciences (Mathematics), Biological Sciences (Nursing) and Human Sciences (Administration). In total, 38 students participated in the experiment. Through the quantitative and qualitative analysis of the data, we conclude that the use of pedagogical recommendation based on the affective states of the students sent throughmobile devices to combat the distraction caused by the same is not a good alternative solution to the problem, since it is generated in the students the anxiety to check the recommendations sent, and continue to distract. Finally, we raise other questions and hypotheses for future work.","('Computação afetiva', 'Estudantes – Engajamento', 'Dispositivos móveis', 'Affective computing', 'Students – Engagement', 'Mobile devices')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/14070","2017-10-20","https://www.repositorio.ufal.br/bitstream/123456789/14070/1/A%20recomenda%c3%a7%c3%a3o%20pedag%c3%b3gica%20em%20tempo%20real%20baseada%20na%20aten%c3%a7%c3%a3o%20dos%20estudantes%20utilizando%20computa%c3%a7%c3%a3o%20afetiva.pdf","Pedagogical recommendation in real time based on students’ attention using affective computing","('Ranilson Oscar Araújo Paiva',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/7280","Campus A.C. Simões","Instituto de Computação","Dissertação","Reconhecimento e análise de rachaduras a partir de imagens para monitoramento em regiões com atividade sísmica frequente","('João Miguel Correia Lima',)","('Thales Miranda de Almeida Vieira',)","('Tiago Figueiredo Vieira', 'Douglas Cedrim Oliveira')","Em áreas de risco, principalmente naquelas ocasionadas por movimentações sísmicas frequentes, faz-se necessário o monitoramento de eventos como alterações nas dimensões de rachaduras em imóveis e demais estruturas urbanas. Esse processo, principalmente em regiões sem infraestrutura adequada, é realizado por meio de observações empíricas realizadas pelos próprios ocupantes dessas áreas. Essa atividade, pela sua própria natureza, resulta na coleta imprecisa e desatualizada de dados, haja vista o lapso temporal entre a coleta e a mensuração das alterações, que deve ser feita por um especialista. Neste trabalho, propomos algoritmos, baseados em visão computacional, para automatizar esse processo por meio do emprego de técnicas de Aprendizagem Profunda. Assim, é possível ao computador fazer a detecção de rachaduras e a devida mensuração destas nas imagens enviadas aos órgãos responsáveis pelos residentes, dando agilidade na detecção de potenciais riscos à integridade física das pessoas, e, ao mesmo tempo, fornecendo aos especialistas dados precisos para uma ação preventiva eficaz. Usaremos como corpus a situação vivenciada pelos moradores de alguns bairros na cidade de Maceió, estado de Alagoas, no Brasil, onde são empregadas atualmente réguas para identificar o avanço ou recuo de rachaduras nos imóveis, fotografadas diariamente e cujas imagens são enviadas aos órgãos de segurança. No presente trabalho, apresentamos um processo dividido em três etapas. A primeira é a identificação de pontos de interesse na régua, como dígitos, usando a arquitetura da rede neural profunda YOLO. Em seguida, apresentamos um algoritmo para filtrar os dígitos corretos e, finalmente, identificamos a rachadura e sua largura, aplicando um algoritmo de processamento de imagens e calibração de câmera. Assim, após os experimentos, conseguimos obter uma precisão de 75,65% quando usamos a implementação Darknet com 31 camadas convolucionais. Portanto, este trabalho, além de poder salvar vidas, é também uma ferramenta de baixo custo para inspeção de estruturas.","In riskareas,especiallythosecausedbyfrequentseismicmovements,itisnecessarytomonitor eventssuchaschangesinthesizeofcracksinbuildingsandotherurbanstructures.This process, especiallyinregionswithoutadequateinfrastructure,iscarriedoutthroughempirical observationsmadebytheoccupantsoftheseareasthemselves.Thisactivity,byitsverynature, results ininaccurateandoutdateddatacollection,giventhetimelapsebetweencollectionand measurement ofchanges,whichshouldbedonebyaspecialist.Inthispaper,wepropose algorithms basedoncomputervision,toautomatethisprocessbyemployingDeepLearning techniques. Thus,itispossibleforthecomputertodetectcracksandproperlymeasurecracksin images senttoresponsibleagenciesbyresidents,providingagilityindetectingpotentialrisks to people’sphysicalintegrity,whileprovidingexpertswithaccuratedataforactioneffective preventive.Wewilluseasthesituationexperiencedbyresidentsofsomeneighborhoodsinthe city ofMaceió,stateofAlagoas,Brazil,whererulersarecurrentlyemployedtoidentifythe advanceorindentationsofcracksinrealestate,whicharephotographeddailyandtheimages sent tosecurityagencies.Inthepresentworkwepresentaprocessdividedintothreesteps:The first istheidentificationofpointsofinterestintheruler,suchasdigits,usingtheYOLO,adeep neural networkarchitecture,thenwepresentanalgorithmtofilterthecorrectdigitsandfinallyto identify thecrackanditswidthbyapplyingimageprocessingalgorithmandcameracalibration. Thus, aftertheexperiments,wewereabletoachieve75,65%accuracywhenusingthedarktext implementation with31convolutionallayers.Therefore,thiswork,besidesbeinglifesaving,is also alowcosttoolforstructuralinspection. Keywords:","('Visão por computador', 'Aprendizagem de máquina', 'Aprendizagem profunda', 'Sistemas de reconhecimento de padrões', 'Computer Vision', 'Machine Learning', 'Deep Learning', 'Pattern recognition systems')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/7280","2019-12-17","https://www.repositorio.ufal.br/bitstream/riufal/7280/3/Reconhecimento%20e%20an%c3%a1lise%20de%20rachaduras%20a%20partir%20de%20imagens%20para%20monitoramento%20em%20regi%c3%b5es%20com%20atividade%20s%c3%adsmica%20frequente.pdf","Recognition and analysis of cracks in images for monitoring of regions with frequent seismic activity",""
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/12317","Campus A.C. Simões","Instituto de Computação","Dissertação","Proposta e avaliação de um modelo de prognóstico para pacientes com septicemia","('Marcos Vinícius Silva Bento',)","('Rafael de Amorim Silva',)","('Diego Dermeval de Medeiros da Cunha Matos', 'Almir Pereira Guimarães')","A tecnologia utilizada na medicina evolui a cada momento, e com isso novas soluções surgem. Com a inteligência artificial e aprendizagem de máquina aplicada em problemas da área médica, a capacidade de antecipação à diagnósticos e prognósticos aumentaram consideravelmente, devido a capacidade de processamento de dados que um computador pode realizar. Foi aplicado no presente trabalho algoritmos de aprendizagem de máquina, a fim de obter prognóstico de uma doença conhecida na medicina, a SEPSES, que causa uma infecção generalizada. Septicemia é uma infecção que se não identificada corretamente, compromete significativamente a saúde dos órgão próximos, e pode causar falência múltipla dos órgãos, desse modo é necessário adotar medidas preditivas para poder conter o avanço da doença. Portanto, a metodologia deste trabalho consistiu em apresentar um modelo supervisionado para o prognóstico de pacientes que possuem sintomas de Sepses. Por fim, a proposta integrou a elaboração de modelos de aprendizagem de máquina no intuito de obter uma predição no prognóstico de SEPSE a partir de dados coletados no monitoramento dos pacientes internados em UTI por meio de dados disponilizados no programa PhysioNet -eICU Collaborative Research Database. Com isso, de acordo com os modelos implementados, regressão logística, K-vizinhos mais próximos (KNN) e Máquina de Vetores de Suporte. O melhor resultado de cada modelo entre os cenários explorados para prognóstico de mortalidade, de acordo com AUC do método estatístico, característica de operação do receptor (ROC), foi de 0.82, 0.74 e 0.85, respectivamente. E para a predição do tempo de internação do paciente, de acordo com o melhor cenário, os modelos obtiveram AUC 0.85, 0.64 e 0.32, respectivamente.","The technology used in medicine evolves all the time, and with that new solutions emerge. With artificial intelligence and machine learning applied to medical problems, the ability to anticipate diagnoses and prognoses can be considered, due to the data processing capacity that a computer can perform. No machine learning problem was applied, a prognostic end of a disease known in medicine, SEPSIS, which causes a generalized infection. Sepsis is an effective prevention of measures not correctly identified, significantly compromising the destruction of Organs following organs, and can cause the destruction of multiple organs, so it is necessary to adopt measures to be able to contain the advance of pre-health. Therefore, the methodology of this work is to present a model of supervision for the prognosis of patients who present symptoms of sepsis. Finally, a proposal integrated the elaboration of learning models in order to obtain a prediction from an ICU prediction data program in the monitoring of inpatients from PhysioNet S in the monitoring of inpatients from ICU research data -eICU Collaborative Database through data used in the research database. With that, with the models vector models according to the solution, K-nearest neighbors (KNN) and Support machines. The best result of receiver operation (ROC) was according to the method of each model (ROC), respectively. And for the prediction of patient time, according to the best scenario, the models obtained AUC 0.85, 0.64 and 0.32, respectively.","('Prognóstico', 'Diagnóstico', 'Sepse', 'Unidades de terapia intensiva', 'Aprendizagem de máquina', 'Prognosis', 'Diagnosis', 'Sepsis', 'Intensive care units', 'Machine learning')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/12317","2022-08-26","https://www.repositorio.ufal.br/bitstream/123456789/12317/1/Proposta%20e%20avalia%c3%a7%c3%a3o%20de%20um%20modelo%20de%20progn%c3%b3stico%20para%20pacientes%20com%20septicemia.pdf","Proposal and evaluation of a prognosis model for patients with sepsis","('Bruno Almeida Pimentel',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/12287","Campus A.C. Simões","Instituto de Computação","Dissertação","Proposta e avaliação de um modelo para predição da morbidade e mortalidade em pacientes diagnosticados com taquicardia ventricular","('Victor Gabriel Lima Holanda',)","('Rafael de Amorim Silva',)","('Diego Dermeval de Medeiros da Cunha Matos', 'Almir Pereira Guimarães')","Segundo a Organização Mundial da Saúde, as doenças cardiovasculares são a maior causa de morte no mundo. Milhares de pessoas vêm a óbito todos os anos em decorrência das complicações ocasionadas por este tipo de doença. Neste sentido, médicos cardiologistas buscam o diagnóstico precoce, evitando que a doença alcance a fase patológica (i.e. os estágios onde as limitações surgem e se tornam cada vez maiores para os seus portadores). No contexto das arritmias do tipo taquicardia, os pacientes precisam adotar o uso contínuo de medicamentos e a mudança de hábitos para reduzir o impacto causado por este tipo de doença, provendo assim uma vida mais saudável. Sendo assim, este trabalho propõe e avalia um modelo de prognóstico de morbidade e mortalidade para pacientes diagnósticados com taquicardia ventricular. O modelo proposto considera o cenário onde o paciente diagnósticado com taquicardia ventricular irá desenvolver o quadro de insuficiéncia cardíaca (IC) e fibrilaçao ventricular (FV). Neste cenário, utilizamos o score CHA2DS2-VASc para predição do risco de AVC, AIT e Embolia Sistêmica para o cenário de FV. Além de uma combinação do CHA2DS2-VASc com o score gerado a partir dos hábitos do paciente, para ser capaz de categorizar o paciente dentro das classes de NYHA, que por sua vez gera um nível de morbidade e mortalidade para cada categoria. Foram utilizadas técnicas computacionais como o uso de Máquinas de Vetores Suporte (SVM),K vizinhos mais próximos (KNN), Redes Neurais, Árvores Aleatórias e Naïve Bayes para validar o sistema. O modelo alcançou seus melhores resultados pela validação com Máquinas de Vetores Suporte (SVM), com acurácia de 0.997, F1, precision e recall de 0.976. A partir destas classificações e predições, é possível prover ao cardiologista um maior nível de informações, otimizando as tomadas de decisão, impactando no tratamento adotado, intervenções, e acompanhamento do paciente.","According to the World Health Organization, cardiovascular diseases are the leading cause of death in the world. Thousands of people die every year due to complications caused by this type of disease. In this sense, cardiologists seek early diagnosis, preventing the disease from reaching the pathological phase (i.e. the stages where limitations arise and become increasingly greater for its bearers). In the context of tachycardia-type arrhythmias, patients need to adopt the continuous use of medication and change habits to reduce the impact caused by this type of disease, thus providing a healthier life. Therefore, this study proposes and evaluates a morbidity and mortality prognostic model for patients diagnosed with ventricular tachycardia. The proposed model considers the scenario where the patient diagnosed with ventricular tachycardia will develop heart failure (HF) and ventricular fibrillation (VF). In this scenario, we used the CHA2DS2-VASc score to predict the risk of stroke, TIA and Systemic Embolism for the VF scenario. In addition to a combination of the CHA2DS2-VASc with the score generated from the patient’s habits, to be able to categorize the patient within NYHA classes, which in turn generates a morbidity and mortality level for each category. Computational techniques such as the use of SVM,KNN, Neural Networks, Random Trees and Naïve Bayes were used to validate the system. The model achieved its best results by validation with Support Vector Machines (SVM), with an accuracy of 0.997, F1, precision and recall of 0.976. From these classifications and predictions, it is possible to provide the cardiologist with a higher level of information, optimizing decision making, impacting on the adopted treatment, interventions, and patient follow-up.","('Morbidade e mortalidade – Prognóstico', 'Taquicardia ventricular', 'Informática em saúde', 'Morbidity and Mortality -Prognosis', 'Tachycardia, Ventricular', 'Health informatics')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/12287","2022-08-29","https://www.repositorio.ufal.br/bitstream/123456789/12287/1/Proposta%20e%20avalia%c3%a7%c3%a3o%20de%20um%20modelo%20para%20predi%c3%a7%c3%a3o%20da%20morbidade%20e%20mortalidade%20em%20pacientes%20diagnosticados%20com%20taquicardia%20ventricular.pdf","Proposal and evaluation of a model for prediction of morbidity and mortality in patients diagnosed with ventricular tachycardia","('Bruno Almeida Pimentel',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/12318","Campus A.C. Simões","Instituto de Computação","Dissertação","Proposta e avaliação de um modelo híbrido de seleção de características para o prognóstico do câncer de mama","('Maxwell Esdra Acioli Silva',)","('Rafael de Amorim Silva',)","('Diego Dermeval de Medeiros da Cunha Matos', 'Almir Pereira Guimarães')","A tecnologia de Inteligência Artificial tem sido fundamental no papel do cuidado à saúde da sociedade. Ela vem sendo amplamente utilizada nos diversos ramos da medicina. Uma de suas principais aplicações é no contexto do prognóstico da doença de câncer de mama. O câncer é considerado como a segunda maior causa de mortes decorrentes de doenças no mundo. Neste contexto, destaca-se o câncer de mama, que é considerado a maior ocorrência de câncer entre as mulheres no mundo. Um dos principais desafios neste cenário é identificar quais são as características mais relevantes no desenvolvimento deste tipo de neoplasia por um paciente. Este tipo de filtro é realizado pelos métodos de seleção de características. Este trabalho apresenta um modelo híbrido de seleção de características que deve ser utilizado por clínicos de um paciente, a fim de realizar uma predição de mortalidade do câncer de mama. O modelo híbrido é composto de dois algoritmos já existentes na literatura: Gain Ratio e ReliefF. Em comparação com os modelos já existentes na literatura, o algoritmo proposto apresentou melhores resultados para as métricas de avaliação utilizadas para tal finalidade.","Artificial Intelligence technology has been instrumental in the role of health care for society. It has been widely used in various branches of medicine. One of its main applications is in the context of breast cancer disease prognosis. Cancer is considered the second leading cause of death from disease in the world. In this context, breast cancer stands out, which is considered the largest occurrence of cancer among women in the world. One of the main challenges in this scenario is to identify which are the most relevant characteristics in the development of this type of neoplasm by a patient. This type of filtering is performed by feature selection methods. This paper presents a hybrid feature selection model that should be used by clinicians of a patient in order to perform a breast cancer mortality prediction. The hybrid model is composed of two algorithms already existing in the literature: Gain Ratio and ReliefF. In comparison with the models already existing in the literature, the proposed algorithm presented better results for the evaluation metrics used for this purpose.","('Inteligência artificial', 'Prognóstico', 'Câncer de mama', 'Aprendizagem de máquina', 'Artificial intelligence', 'Prognosis', 'Breast cancer', 'Machine learning')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/12318","2022-08-26","https://www.repositorio.ufal.br/bitstream/123456789/12318/1/Proposta%20e%20avalia%c3%a7%c3%a3o%20de%20um%20modelo%20h%c3%adbrido%20de%20sele%c3%a7%c3%a3o%20de%20caracter%c3%adsticas%20para%20o%20progn%c3%b3stico%20do%20c%c3%a2ncer%20de%20mama.pdf","Proposal and evaluation of a hybrid feature selection model for breast cancer prognosis","('Bruno Almeida Pimentel',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/7852","Campus A.C. Simões","Instituto de Computação","Dissertação","PREDCGAN: uma abordagem para geração de nódulos pulmonares sintéticos GAN usando pré-treinamento","('Bruno Henrique Lira dos Anjos',)","('Marcelo Costa Oliveira',)","('Thales Miranda de Almeida Vieira', 'Paulo Mazzoncini de Azevedo Marques')","O diagnóstico de câncer de pulmão usando imagens de tomografia computadorizada (CT) é um trabalho complexo e desafiador, mesmo para radiologistas experientes. Para mitigar essa dificuldade, Sistemas de Diagnóstico Auxiliado por Computador (CAD) são desenvolvidos para auxiliar a performance dos especialistas. Uma das principais áreas utilizadas no CAD é a Aprendizagem Profunda (DL). Entretanto, por ser um processo de difícil validação e depender de um profissional bem treinado, a construção de grandes bancos de dados de imagens médicas estruturadas, bem validadas e abrangentes é um dos principais desafios das aplicações de DL no CAD em imagens médicas. s rede adversária generativa (GAN) consiste em um modelo para gerar dados probabilísticos heterogêneos que se apresenta como uma solução adequada para suprir o pequeno número de exames patológicos que compõem os mais diversos bancos de imagens médicas. Entretanto, os treinamentos das GAN para nódulos pulmonares não utilizam de informações condicionais para geração das imagens sintéticas. Assim, neste trabalho propomos a utilização da transferência de conhecimento utilizando um pré-treinamento da GAN para resultar em nódulos pulmonares sintéticos mais eficientes para aumento de base. Para isso, foi realizado o treinamento de uma Deep Convolutional GAN (DCGAN) em dois momentos, o primeiro para geração de nódulos segmentados e em um segundo momento foi feito um ajuste fino para gerar nódulos com as estruturas adjacentes. Através do uso das imagens geradas pela nossa proposta como aumento de base e de uma comparação com outras técnicas de aumento de base, obtivemos um aumento na AUC de 0.77% em relação ao aumento de base clássico e quando utilizada nossa proposta em conjunto com aumento de base clássico temos um aumento na AUC de 2.06% em relação ao individual do aumento de base clássico.","The diagnosis of lung cancer using computed tomography (CT) images is a complex and challenging job, even for experienced radiologists. To mitigate this difficulty, Computer Aided Diagnostic (CAD) systems are developed to assist the performance of specialists. One of the main areas used in CAD is Deep Learning (DL). However, because it is a difficult process to validate and depends on a well-trained professional, the construction of large databases of structured, well-validated and comprehensive medical images is one of the main challenges of DL applications in CAD in medical images. The generative adversarial networks (GAN) consist of a model to generate heterogeneous probabilistic data that presents itself as an adequate solution to supply the small number of pathological exams that make up the most diverse medical image banks. However, GAN training for pulmonary nodules does not use conditional information to generate synthetic images. Thus, in this work it is proposed to use knowledge transfer applied through GAN pre-training to result in more efficient synthetic pulmonary nodules for base increase. For this, the training of a textit Deep Convolutional GAN (DCGAN) was carried out in two moments, the first to generate segmented nodules and in a second moment a fine adjustment was made to generate nodules with the adjacent structures. Through the use of the images generated by our proposal as a base increase and a comparison with other techniques of base increase, we obtained an increase in AUC of 0.77 % in relation to the increase of classic base and when used our proposal in conjunction with increase of classic base we have an increase in AUC of 2.06 % in relation to the individual of the increase of classic base.","('Generative Adversarial Network', 'PREDCGAN', 'Pré-treinamento', 'Neoplasias pulmonares', 'Pre-training', 'Lung cancer')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/7852","2020-11-27","https://www.repositorio.ufal.br/bitstream/123456789/7852/1/PREDCGAN%20-%20uma%20abordagem%20para%20gera%c3%a7%c3%a3o%20de%20n%c3%b3dulos%20pulmonares%20sint%c3%a9ticos%20GAN%20usando%20pr%c3%a9-treinamento.pdf","PREDCGAN: na approach to synthetic lung nodule generation with the use of pre-training",""
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/1594","Campus A.C. Simões","Instituto de Computação","Dissertação","Um processo para monitoração de requisitos de qualidade de software utilizando informações arquiteturais","('Suzy Kamylla de Oliveira Menezes',)","('Patrick Henrique da Silva Brito',)","('Evandro de Barros Costa', 'Cecília Mary Fischer Rubira')","Os avanços na construção de sistemas computacionais possibilitaram que sistemas cada vez mais sofisticados surgissem. Nesse contexto, os desenvolvedores de software deparam-se com problemas complexos que podem ser difíceis de solucionar. Um dos passos fundamentais ao construir um software é definir as principais características dele, isto é, definir os requisitos. Contudo, nem sempre é trivial definir quais são esses requisitos. Normalmente, os requisitos são classificados como funcionais e não-funcionais. Os requisitos não-funcionais definem propriedades do sistema ou como esse deve operar. Eles também são chamados de requisitos de qualidade, pois são importantes para garantir que o sistema seja viável para uso e atenda às necessidades dos usuários. Apesar da sua importância, eles são difíceis de serem avaliados e mensurados de forma a gerar evidências do seu pleno atendimento. Uma das razões para essa dificuldade é a necessidade de se avaliar o software em tempo de execução, o que é uma tarefa complexa que envolve grandes volumes de dados a serem analisados. O objetivo dessa dissertação é sistematizar e viabilizar a monitoração de requisitos de qualidade a partir de características dos estilos arquiteturais utilizados no projeto da arquitetura de software. Nesse sentido, a questão de pesquisa que direcionou esse estudo foi “como monitorar e analisar requisitos de qualidade em um sistema de software”. Com base nisso, foi proposto um processo de monitoração de requisitos de qualidade utilizando informações arquiteturais, tais como estilos arquiteturais, denominado ArMoni. Para avaliar a utilização prática do referido processo foi realizado um experimento avaliativo com alunos do curso de Ciência da Computação. Os alunos realizaram a monitoração de uma aplicação real denominada Falibras. Esse sistema realiza tradução online de textos em língua portuguesa para a Língua Brasileira de Sinais (LIBRAS). Através do experimento, foi possível perceber que os alunos consideraram o processo proposto viável para direcionar as decisões de monitoração. Por outro lado, os alunos que não tiveram acesso ao processo proposto e não conheciam a arquitetura do Projeto Falibras sentiram mais dificuldades para analisar o sistema. Desse modo, é importante para o(a) desenvolvedor(a) de software ter recursos que o(a) auxiliem na compreensão dos requisitos de qualidade relevantes para o software que está sendo monitorado, bem como processos que direcionem a monitoração desses requisitos. Os resultados preliminares apontam que o processo ArMoni contribui para guiar a monitoração e analisar os requisitos de qualidade a partir de informações arquiteturais, tais como os estilos arquiteturais que compõem o sistema e nota-se que ele beneficia principalmente desenvolvedores menos experientes. Assim, essa dissertação apresenta relevância acadêmica na área de engenharia de software e poderá auxiliar desenvolvedores(as) e engenheiros(as) de software a monitorar requisitos de qualidade, tais como confiabilidade e eficiência, além de identificar possíveis gargalos estruturais que podem comprometer a satisfação desses requisitos.","Advances in building computer systems allowed the development of increasingly sophisticated software. In this context, software developers are faced with complex problems that can be difficult to resolve. One of the fundamental steps to build a software is to define its main features, that is, define the requirements that can be satisfied, which is not an easy task. Typically, requirements are classified as functional and non-functional. The non-functional requirements define system’s properties or how it should operate. They are also called quality requirements, since they are important to ensure that the system is feasible to use and meets the needs of users. Despite their importance, they are difficult to assess and be measured in order to generate evidence of its full service. One reason for this difficulty is the need to evaluate the software at run-time, which is a complex task that involves large volumes of data to be analyzed. This work aims to systematize and facilitate the monitoring of quality requirements from characteristics of architectural styles used in the software architecture design. In this sense, the research question that guided this study was “how to monitor and analyse quality requirements for a software system”. On that basis, it was proposed a process, called ArMoni, for monitoring quality requirements using architectural information, such as architectural styles. To assess the practical use of the proposed process, an evaluation experiment with students from the Computer Science course was performed. Students performed the monitoring of a real application called Falibras. This target system performs online text translation from Portuguese to the Brazilian Sign Language (Libras). Through the experiment, it was observed that the students considered the proposed process feasible to direct monitoring decisions. On the other hand, students who did not have access to the proposed process and do not know the architecture of Falibras have related more difficult to analyze the system. Thus, we have realized that it is important for the software developer to have guidelines that assist him/her in understanding the relevant quality requirements for the software that is being monitored, such as a processes that address the monitoring of these requirements. Preliminary results indicate that the ArMoni process contributes to guide the monitoring and analysis of the system based on architectural information, such as the architectural styles and we have noticed that it benefits mainly less experienced developers. Thus, this work presents academic relevance in software engineering and can assist developers and software engineers to monitor quality requirements, such as reliability and efficiency, as well as to identify possible structural bottlenecks that could compromise the satisfaction of these requirements.","('Arquitetura de software', 'Estilos arquiteturais', 'Monitoração de requisitos', 'Requisitos de qualidade', 'Requisites não-funcionais', 'Software Architecture', 'Architectural Styles', 'Requirements Monitoring', 'Quality Requirements', 'Non-Functional Requirements')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1594","2016-12-16","https://www.repositorio.ufal.br/bitstream/riufal/1594/1/Um%20processo%20para%20monitora%c3%a7%c3%a3o%20de%20requisitos%20de%20qualidade%20de%20software%20utilizando%20informa%c3%a7%c3%b5es%20arquiteturais.pdf","A process for monitoring software quality requirements using architectural information",""
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/15870","Campus A.C. Simões","Instituto de Computação","Dissertação","Proposta de modelo de previsão de estadiamento em pacientes diagnosticados com PDAC","('Fabiano Santos Conrado',)","('Rafael de Amorim Silva',)","('Almir Pereira Guimarães', 'Bruno Almeida Pimentel')","O câncer de pâncreas (CP) é de difícil diagnóstico precoce, uma vez que evolui de forma silenciosa, sem apresentar sinais específicos, e responde mal à maioria dos tratamentos. Noventa por cento dos casos de CP são do tipo adenocarcinoma ductal pancreático (PDAC), e a sobrevida global em cinco anos após o diagnóstico é de apenas 12,8%. Esse baixo índice leva os pacientes diagnosticados a questionarem quanto tempo lhes resta de vida. O sistema de classificação TNM para tumores malignos tem sido o método mais comum para avaliar a sobrevida e apoiar a tomada de decisão médica em relação a intervenções curativas ou paliativas. Entretanto, essa classificação só pode ser realizada após exames de imagem avançados, exigindo que os pacientes se submetam a novos testes para monitorar alterações no estadiamento. Nem todos os pacientes dispõem de recursos, disponibilidade física e/ou emocional para reavaliações constantes. Dada a alta taxa de mortalidade e a dificuldade na detecção dessa neoplasia, diversas pesquisas têm surgido em busca de biomarcadores para um diagnóstico precoce. No entanto, poucos desses trabalhos focam no desenvolvimento de métodos para prognósticos prévios. Esta pesquisa propõe e avalia um modelo de prognóstico prévio de estadiamento para PDAC com base em biomarcadores urinários utilizados no diagnóstico de PDAC, combinados com idade e sexo. Para isso, foram coletados dados de vários centros de saúde e analisados utilizando técnicas de Aprendizado de Máquina (Machine Learning, ML). As técnicas adotadas para a classificação prévia dos estadiamentos foram K-Nearest Neighbors (KNN), Support Vector Machines (SVM) e Random Forest. Resultados encontrados: O classificador KNN alcançou uma acurácia máxima de 0,62, o SVM atingiu uma acurácia de 0,58 e o Random Forest apresentou os melhores resultados, com acurácia de 0,81. Isso indica que o uso de biomarcadores para a classificação prévia de estadiamento pode auxiliar na tomada de decisão médica e no monitoramento da progressão da neoplasia.","Pancreatic cancer (PC) is difficult to diagnose early because it progresses silently, without specific symptoms, and responds poorly to most treatments. Ninety percent of pancreatic cancer cases are pancreatic ductal adenocarcinoma (PDAC), and the overall five-year survival rate after diagnosis is only 12.8%. This low survival rate leads diagnosed patients to question how much time they have left. The TNM classification system for malignant tumors has been the most common method for assessing survival and supporting medical decision-making regarding curative or palliative interventions. However, this classification can only be performed after advanced imaging exams, requiring patients to undergo new imaging tests to monitor changes in staging. Not all patients have the resources, physical availability, or emotional capacity for constant re-evaluation. Given the high mortality rate and difficulty in detecting this neoplasm, several research studies have emerged in search of biomarkers for early diagnosis. However, few of these studies focus on developing methods for early prognosis. This research proposes and evaluates a prior staging prognosis model for PDAC based on urinary biomarkers used for PDAC diagnosis, combined with age and gender. To this end, data from various health centers were collected and analyzed using Machine Learning (ML) techniques. The adopted techniques for prior staging classification were K-Nearest Neighbors (KNN), Support Vector Machines (SVM), and Random Forest. Results: The KNN classifier achieved a maximum accuracy of 0.62, SVM reached an accuracy of 0.58, and Random Forest produced the best results with an accuracy of 0.81. This indicates that the use of biomarkers for prior staging classification can assist in medical decision-making and monitoring the progression of the neoplasm.","('Neoplasias pandreáticas -Diagnóstico', 'Carcinoma ductal pancreático', 'Estadiamento de neoplasias', 'Biomarcadores', 'Aprendizado de máquina', 'KNN (Algoritmo)', 'Máquinas de vetor de suporte (Algoritmo)', 'Floresta aleatória (Algoritmo)', 'Neoplasias', 'Urina', 'LYVE1 (Biomarcadores)', 'Litostatina', 'Fator trefoil-1', 'Creatinina', 'Antígeno CA-19-9', 'Pancreatic Cancer', 'Diagnosis', 'Pancreatic Ductal Adenocarcinoma', 'Staging', 'Malignant Tumor Classification', 'Biomarkers', 'Machine Learning', 'KNN', 'SVM', 'Random Forest', 'PDAC', 'TNM', 'Neoplasm', 'Urine', 'LYVE1', 'REG1B', 'TFF1', 'Creatinine', 'Plasma CA199', 'REG1A')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/15870","2022-08-29","https://www.repositorio.ufal.br/bitstream/123456789/15870/1/Proposta%20de%20modelo%20de%20previs%c3%a3o%20de%20estadiamento%20em%20pacientes%20diagnosticados%20com%20PDAC.pdf","Proposal of a staging prediction model for patients diagnosed with pancreatic ductal adenocarcinoma (PDAC)",""
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/15955","Campus A.C. Simões","Instituto de Computação","Dissertação","PageRank das normas brasileiras no Diário Oficial da União de 2002 a 2022","('Felipe Salomão Cardoso',)","('Ranilson Oscar Araújo Paiva',)","('Alan Pedro da Silva', 'Juliana Roberta Theodoro de Lima', 'André Câmara Alves do Nascimento', 'Dalgoberto Miquilino Pinho Júnior')","Introdução: No Brasil, de 1988 até 2023, foram criadas aproximadamente 7,5 milhões de normas. Desse modo, encontrar as normas mais relevantes relacionadas a um tema, entre diferentes Poderes e entes federados, é um desafio a pesquisadores, operadores do Direito e cidadãos em geral. Por outro lado, o algoritmo do PageRank, que originou o buscador do Google, resolveu problema semelhante para as páginas web. Pois o Google ranqueia as páginas mais relevantes relacionadas a um tema. Desse modo, a presente pesquisa aplicou o PageRank a normas brasileiras. E, com base na Hierarquia das Normas e na Teoria Pura do Direito, de Hans Kelsen, o problema desta pesquisa buscou determinar se a Constituição tem o maior PageRank. Objetivos: Como objetivo geral, pretendeu-se proporcionar a programadores e juristas uma base racional para operar o Direito. Para tanto, foram objetivos específicos: definir abstratamente norma e importância da norma; determinar a norma mais importante do Ordenamento Jurídico Brasileiro; e explorar consequências jurídicas e computacionais. Metodologia: Para alcançar esses objetivos, a base de dados contou com 20 anos de publicações no Diário Oficial da União (DOU), de janeiro de 2002 a dezembro de 2022. A linguagem computacional utilizada foi Python, para coleta, tratamento, estruturação e análise dos dados. E, para operar computacionalmente as normas brasileiras, foi desenvolvida a biblioteca Têmis, também em Python. Resultados: Com a metodologia adotada, verificou-se que o PageRank das normas analisadas correspondeu à Pirâmide de Kelsen. Desse modo, a Constituição obteve o maior PageRank. Enfim, refletiu-se, por quatro maneiras distintas, o Direito como Ciência Exata: por dedução, indução, analogia e abdução. Discussão: A pesquisa aplicou a Álgebra especialmente ao Direito e à Computação. Assim, o estudo mostrou-se relevante a projetos relacionados, como o LexML, do Senado, e a plataforma Normativas, do Ministério da Educação (MEC). Discutiu-se também a possível criação do Google Law. Contribuições: Para modelar completamente as normas, foram necessários doze conceitos novos em Álgebra: nove noções gerais (princípio, finalidade, conjuntura, estrutura, subestrutura, infraestrutura, superestrutura, objeto e principalidade); e três funções (intraobjetiva, extraobjetiva e transobjetiva). Fundada nessas três funções, a biblioteca Têmis também é contribuição deste trabalho. Os novos conceitos contribuíram também com o próprio entendimento do que seriam as Ciências, e que o Direito poderia ser também abordado como uma Ciência Exata. E discutimos uma nova modalidade de ensino, correspondente à Ciência Prática de Aristóteles.","Introduction: From 1988 to 2023, approximately 7.5 million norms were created in Brazil. Thus, finding the most relevant norms related to a topic among different branches of government and federated entities is a challenge for researchers, legal practitioners, and citizens in general. On the other hand, Google's PageRank algorithm solved a similarproblem for web pages by ranking the most relevant pages related to a topic. Therefore, this research applied PageRank to Brazilian norms. Based on Hans Kelsen's Hierarchy of Norms and Pure Theory of Law, the research problem sought to determine if the Constitution would have the highest PageRank. Objectives: The general objective was to provide programmers and jurists with a rational basis for legal operations. Specific objectives included defining abstractly the concept of norm and the importance of norms, determining the most important norm in the Brazilian Legal System, and exploring legal and computational consequences. Methodology: To achieve these objectives, the database comprised 20 years of publications in the Official Gazette of the Union (DOU), from January 2002 to December 2022. Python was used as the computational language for data collection, processing, structuring, and analysis. The Têmis library, also developed in Python, was used to computationally operate Brazilian norms. Results: With the adopted methodology, it was found that the PageRank of the analyzed norms corresponded to Kelsen's Pyramid. Thus, the Constitution obtained the highest PageRank. Finally, Law was reflected upon in four different ways as an Exact Science: through deduction, induction, analogy, and abduction. Discussion: The research applied Algebra specifically to Law and Computer Science. Therefore, the study proved relevant to related projects such as LexML by the Senate and the Normativas platform by the Ministry of Education (MEC). The possible creation of Google Law was also discussed. Contributions: To fully model the norms, twelve new concepts in Algebra were required, including nine general notions (principle, purpose, conjuncture, structure, substructure, infrastructure, superstructure, object, and principality) and three functions (intraobjective, extraobjective, and transobjective). Based on these three functions, the Têmis library is also a contribution of this work. The new concepts also contributed to the understanding of what Sciences would be, and that Law could also be approached as an Exact Science. Thus, we discussed a new teaching modality, corresponding to Aristotle's Practical Science.","('Normas – Hierarquia', 'PageRank', 'Teoria pura do direito', 'Legislative Technique', 'Hierarchy of Norms', 'Pure Theory of Law', 'PageRank', 'Official Gazette of the Union', 'National Press')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/15955","2024-04-03","https://www.repositorio.ufal.br/bitstream/123456789/15955/1/PageRank%20das%20normas%20brasileiras%20no%20Di%c3%a1rio%20Oficial%20da%20Uni%c3%a3o%20de%202002%20a%202022.pdf","","('Diego Dermeval de Medeiros da Cunha Matos',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/1611","Campus A.C. Simões","Instituto de Computação","Dissertação","Pride: uma ferramenta de detecção de similaridade em código-fonte","('Diogo Cabral de Almeida',)","('Rodrigo de Barros Paes',)","('Leandro Dias da Silva', 'Leopoldo Motta Teixeira')","O plágio entre alunos de disciplinas introdutórias de programação vem aumentando ao longo do tempo. A facilidade na troca de informações trazida pela Internet pode ser um dos fatores responsáveis por esse aumento. Em muitos casos, os alunos tentam disfarçar o plágio fazendo algumas modïficações no código-fonte. Porém, algumas técnicas de disfarce são extremamente complexas e podem não ser detectadas a olho nu. Neste trabalho, foram analisadas as técnicas de detecção e, com base nelas, foi desenvolvido um sistema capaz de detectar plágio em código-fonte. Este sistema é baseado na representação do código como uma árvore sintática abstrata e no algoritmo Karp-Rabin Greedy String Tiling. O sistema foi avaliado utilizando uma base de códigos-fonte de alunos de disciplinas programação. Foi realizada uma comparação baseada em oráculo para comparar o sistema com os demais. O oráculo foi criado a partir da análise do docente da disciplina, onde foi marcado se havia plágio ou não em cada par de código-fonte. Para representar os resultados, foram utilizadas curvas ROC e matrizes de confusão. O mesmo procedimento foi aplicado aos sistemas já existentes, o que permitiu a comparação direta entre os resultados. Mais específicamente, utilizamos o valor da área sob a curva e a distância mínima para o ponto (0, 1) do espaço ROC, uma vez que esses valores representam o desempenho de classificação. A análise dos resultados indica que, para a amostra utilizada, o sistema desenvolvido obteve o maior valor da Ã¡rea sob a curva e também a menor distância para o ponto (0, 1) do espaço ROC. No entanto, concluímos que a escolha de uma ferramenta de detecção de similaridade em código-fonte dependerá bastante do período conservador ou liberal do docente.","Plagiarism among students of introductory programming courses has been increasing over time. The ease of exchange of information brought by the Internet can be the factor responsible for this increase. In many cases, students try to disguise the plagiarism making some modifications to the source code. However, some masking techniques are extremely complex to be detected and may not be seen with the naked eye. In this dissertation, detection techniques were analyzed and, on this basis, was developed a system able to detect plagiarism in source code. This system is based on the representation code as an abstract syntax tree and Karp-Rabin Greedy String Tiling algorithm. The system was evaluated using a source-code base of students of programming disciplines. Oracle based comparison was performed to compare the system with others. The oracle was created from the manual analysis of the teacher of the subject, which was marked if there was plagiarism or not in each pair of source code. To represent the results, ROC curves and confusion matrices were used. The same procedure was applied to existing systems, allowing direct comparison of results. More specifically, we use the value of the area under the curve and the minimum distance to point (0, 1) of the ROC space, since these figures represent the classification performance. The analysis of results shows that, for the sample used, the developed system obtained higher area under the curve and also the shortest distance to the point (0, 1) of the space ROC. However, we find that the choice of similarity detection tool in source code will depend on conservative or liberal profile of teaching.","('Código-fonte', 'Linguagem de programação -Computadores', 'PRIDE (Linguagem de programação de computador)', 'Similaridade', 'Plágio', 'Computer programming language', 'source code', 'Plagiarism')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1611","2015-03-31","https://www.repositorio.ufal.br/bitstream/riufal/1611/1/Pride%3a%20uma%20ferramenta%20de%20detec%c3%a7%c3%a3o%20de%20similaridade%20em%20c%c3%b3digo-fonte.pdf","Pride: a tool for detecting similarity in source code","('Márcio de Medeiros Ribeiro',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/13997","Campus A.C. Simões","Instituto de Computação","Dissertação","Percepção de Carga de Trabalho no Envio de Feedback para Dashboards e Learning Analytics -Um Experimento Controlado com Professores","('Ítalo Rodrigo da Silva Arruda',)","('Diego Dermeval de Medeiros da Cunha Matos',)","('Rafael de Amorim Silva', 'Helena Macedo Reis')","O e-learning tem utilizado tecnologias de informação para potencializar a educação via internet. Com um aumento de 87% nas matrículas em Educação a Distância desde 2014, a modalidade ultrapassou o ensino presencial em oferta de vagas desde 2020, refletindo a adaptabilidade das instituições ao mundo digital. Assim, os professores têm enfrentado desafios referente ao aumento da carga de trabalho devido à gestão das interações nos ambientes virtuais. Nesse contexto, essa dissertação investiga qual a percepção dos docentes em relação ao seu esforço cognitivo e tempo de dedicação na criação e envio de feedbacks em uma plataforma educacional simulada por meio da Inteligência Artificial e Learning Analytics. Este estudo irá comparar três grupos de professores, utilizando um dos ambientes (manual -AM, automatizado -AA e semi-automatizado -AS) de acompanhamento de uma plata forma educacional simulada. O intuito é otimizar o processo educacional, tornando a gestão de feedbacks mais eficiente, sem sobrecarregar os profissionais da educação. Neste estudo, 98 docentes participantes avaliaram aleatoriamente através de um questionário qual é a sua percepção de esforço cognitivo e tempo dedicado para a criação e envio de feedback para alunos na plataforma. Foi aplicado diversos testes estatísticos, como Kolmogorov-Smirnov e Levene, visando compreender a distribuição dos dados, bem como o NASA TLX foi utilizado para avaliar a carga de trabalho percebida pelos docentes. Os resultados revelaram que o teste de ANOVA destacou discrepâncias em certos ambientes e fatores. Na avaliação geral, verificou-se uma diferença estatística significativa entre os AM e AA, tendo o p-valor= 0,060 e entre os mesmos ambientes, sob o p-valor= 0,065 para as dimensões de demanda física e temporal, respectivamente, abaixo do limiar de p-valor=0,1. Ao avaliar os professores por gênero, para as mulheres verificou-se uma diferença estatística significativa entre os AS e AM, tendo o p-valor de 0,053 e entre os ambos os gêneros para o AS, sob o p-valor de 0,046 para a dimensão de demanda física. O AS na maioria dos testes ficava entre o AA e o AM. Notavelmente, o AA influenciou certos aspectos em comparação ao AM. A pesquisa sugere que o tipo de ambiente de feedback pode afetar a carga de trabalho dos docentes, variando de acordo com fatores específicos e independente do gênero.","E-learning has used information technologies to enhance education via the internet. With an 87% increase in enrollments in Distance Education since 2014, the modality has surpassed face-to-face teaching in terms of vacancies since 2020, reflecting the adaptability of institu tions to the digital world. Thus, teachers have faced challenges regarding increased workload due to managing interactions in virtual environments. In this context, this dissertation inves tigates the perception of teachers in relation to their cognitive effort and time dedicated to creating and sending feedback on an educational platform simulated through Artificial Intel ligence and Learning Analytics. This study will compare three groups of teachers, using one of the environments (manual -AM, automated -AA and semi-automated -AS) to monitor a simulated educational platform. The aim is to optimize the educational process, making feedback management more efficient, without overloading education professionals. In this study, 98 participating teachers randomly assessed their perception of cognitive effort and time dedicated to creating and sending feedback to students on the platform through a questionnaire. Several statistical tests were applied, such as Kolmogorov-Sm irnov and Levene, aiming to understand the distribution of data, and NASA TLX was used to evaluate the workload perceived by teachers. The results revealed that the ANOVA test highlighted discrepancies in certain environments and factors. In the general assessment, there was a significant statistical difference between AM and AA, with p-value = 0.060 and between the same environments, with p-value = 0.065 for the dimensions of physical and temporal de mand, respectively, below the p-value threshold=0.1. When evaluating teachers by gender, for women there was a significant statistical difference between AS and AM, with a p-value of 0.053 and between both genders for AS, with a p-value of 0.046 for the dimension of physical demand. The AS in most tests was between AA and AM. Notably, AA influenced certain aspects compared to AM. Research suggests that the type of feedback environment can affect teachers’ workload, varying according to specific factors and regardless of gender.","('Teoria da carga de cognitiva', 'NASA TLX', 'Ambiente educacional', 'Learning Analytics', 'Cognitive Load Theory', 'NASA TLX', 'Educational Environments', 'Learning Analytics')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/13997","2023-11-22","https://www.repositorio.ufal.br/bitstream/123456789/13997/1/Percep%c3%a7%c3%a3o%20de%20Carga%20de%20Trabalho%20no%20Envio%20de%20Feedback%20para%20Dashboards%20e%20Learning%20Analytics%20-%20Um%20Experimento%20Controlado%20com%20Professores.pdf","","('Ranilson Oscar Araújo Paiva',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/5889","Campus A.C. Simões","Instituto de Computação","Dissertação","Predição do absenteísmo em agentes de segurança pública usando aprendizagem profunda","('Edival Lima da Silva Júnior',)","('Thales Miranda de Almeida Vieira',)","('Tiago Figueiredo Vieira', 'Nivan Roberto Ferreira Júnior')","O absenteísmo é um fenômeno complexo que se expressa pela ausência física do indivíduo, geralmente ao seu posto de trabalho. Nas instituições de segurança pública, essas ausências trazem inúmeros prejuízos de ordem pessoal, social e econômica, além de acontecerem em percentuais superiores aos das demais categorias profissionais. Assim, determinar seus fatores preponderantes e permitir que ações preventivas sejam realizadas de forma efetiva traria inúmeros benefícios a essas instituições e aos seus agentes. Neste trabalho, propomos e avaliamos preditores capazes de identificar os agentes mais propensos ao absenteísmo de longa duração. Esses preditores devem tomar decisões baseando-se no histórico profissional de cada agente extraído de bases de dados das instituições de segurança pública. Realizamos experimentos usando uma base de dados referente a 6 anos de afastamentos de agentes da Polícia Militar de Alagoas do Brasil, dos quais foram selecionados atributos que estariam correlacionados ao fenômeno do absenteísmo. Avaliamos arquiteturas de aprendizagem profunda do tipo Multilayer Perceptron, Long Short-term Memory e Recurrent Neural Network. Aplicamos técnicas de seleção de atributos e fizemos a comparação dos resultados obtidos com a técnica de Máquina de Vetores de Suporte. Apresentamos as melhores arquiteturas para predição do absenteísmo prolongado de agentes, o que comprova que é possível realizar a predição desse tipo de afastamento, atingindo 78% de acurácia, o que subsidiaria a implantação de medidas efetivas de prevenção nessas instituições. Finalmente, concluímos que o uso de dados referentes a uma quantidade maior de anos resulta em melhores resultados na predição do absenteísmo.","Absenteeism is a complex phenomenon that is expressed by the physical absence of the individual, usually at his job. In public security institutions, these absences bring many personal, social and economic losses, in addition to occurring in percentages superior to those of the other professional categories. Thus, determining its preponderant factors and allowing preventive actions to be carried out effectively would bring numerous benefits to these institutions and their agents. In this work, we propose and evaluate predictors capable of identifying the most prone agents to long-term absenteeism. These predictors should make decisions based on the professional history of each agent extracted from databases of public security institutions. We carried out experiments using a database comprised of 6 years of absences from agents of the Military Police of Alagoas in Brasil, from which we selected attributes that would be correlated to the phenomenon of absenteeism.We evaluated Deep Learning architectures such as Multilayer Perceptron, Long Short-term Memory and Recurrent Neural Network. We applied attributes selection techniques and compared the results obtained by the Machine Learning Support-Vector Machine technique.We present the best architectures for predicting the prolonged absenteeism of agents, which proves that it is possible to predict this type of absence, reaching 78% of accuracy, which would support the implementation of effective prevention measures in these institutions. Finally, we conclude that the use of data referring to a more significant number of years results in better results in the prediction of absenteeism.","('Absenteísmo (Trabalho)', 'Aprendizagem profunda', 'Aprendizado do computador', 'Teoria da predição', 'Redes neurais (Computação)', 'Absenteism (Work)', 'Deep learning', 'Computer learning', 'Prediction theory', 'Neural Networks (Computation)')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/5889","2019-06-19","https://www.repositorio.ufal.br/bitstream/riufal/5889/1/Predi%c3%a7%c3%a3o%20do%20absente%c3%adsmo%20em%20agentes%20de%20seguran%c3%a7a%20p%c3%bablica%20usando%20aprendizagem%20profunda.pdf","Predicting Absenteeism in Public Security Officers Using Deep Learning","('Evandro de Barros Costa',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/16366","Campus A.C. Simões","Instituto de Computação","Dissertação","Prevenção de acidentes em zonas rurais utilizando redes 5G e computação de borda","('Felipe Tiago Lima de Oliveira',)","('Leandro Dias da Silva',)","('Álvaro Alvares de Carvalho César Sobrinho', 'Ivo Augusto Andrade Rocha Calado', 'Baldoíno Fonseca dos Santos Neto', 'Abel Cavalcante Lima Filho')","As estradas e rodovias do Brasil estão entre as mais perigosas do mundo, principalmente porque a aioria delas não são duplicadas, além disso, não possuem uma boa pavimentação, e há ainda uma enorme incidência de buracos. Caminhões estão envolvidos em quase metade dos acidentes, e isso resulta num grande número de vítimas fatais, sobretudo por conta da estrutura e diferença de massa existente entre esses veículos e veículos de passeio. São vários os fatores de risco de acidentes letais quando se tem uma grande quantidade de caminhões nas rodovias, e dentro dessa perspectiva, é importante enfatizar os caminhões canavieiros, por possuírem uma estrutura reforçada em relação a outros caminhões, o que acaba tornando maiores as chances de letalidade nos casos de acidentes entre eles e veículos menores. A partir de um sistema de envio de mensagens de alerta, utilizando a rede 5G e a computação de borda, este trabalho teve como proposta, a prevenção de acidentes, principalmente em estradas e rodovias que não são duplicadas, por oferecerem um risco maior, mas não se limitou a elas. A escolha por essas duas tecnologias como base para este trabalho, se deu a partir da observação de problemas comuns existentes em áreas rurais e remotas, como é o caso das rodovias, a saber, alta latência, baixa vazão, conectividade limitada e até ausência de conexão à internet. A utilização da rede 5G associada à computação de borda, pode surgir como uma potencial solução para dirimir ou ao menos atenuar os problemas citados anteriormente e isso deverá possibilitar o desenvolvimento de sistemas que possam enviar e receber dados em tempo real, entre veículos, infraestruturas e demais dispositivos na rede. O trabalho indicou que é de extrema importância, o desenvolvimento de sistemas para a prevenção de acidentes nas rodovias do Brasil, e a partir de uma Revisão Sistemática da Literatura, foram observadas as principais tecnologias capazes de dar suporte a criação de tais sistemas. Como prova de conceito, um simulador foi utilizado para demonstrar a comunicação entre veículos, nas mais variadas circunstâncias, tendo em vista que ele dispõe de um ecossistema com uma infraestrutura de rede preexistente, permitindo a interação entre seus elementos, além de um ambiente virtual realístico composto por diferentes veículos, cidades e mapas. O simulador ainda possibilita a configuração de sensores, controle e personalização do ambiente, simulação de diversas situações de tráfego, dentre outros.","Brazil's roads and highways are among the most dangerous in the world, mainly because most of them are not dual carriageways, and they are not well paved, and there is also a high incidence of potholes. Trucks are involved in almost half of the accidents, and this results in a large number of fatalities, mainly due to the structure and difference in mass between these vehicles and passenger vehicles. There are several risk factors for fatal accidents when there are a large number of trucks on the highways, and from this perspective, it is important to emphasize sugarcane trucks, as they have a reinforced structure in relation to other trucks, which ends up increasing the chances of fatalities in cases of accidents between them and smaller vehicles. Based on a system for sending alert messages, using the 5G network and edge computing, this work aimed to prevent accidents, mainly on roads and highways that are not dual carriageways, as they present a greater risk, but it was not limited to them. These two technologies were chosen as the basis for this work based on the observation of common problems that exist in rural and remote areas, such as highways, namely, high latency, low throughput, limited connectivity and even lack of internet connection. The use of the 5G network associated with edge computing may emerge as a potential solution to resolve or at least mitigate the problems mentioned above and this should enable the development of systems that can send and receive data in real time between vehicles, infrastructure and other devices on the network. The work indicated that it is extremely important to develop systems to prevent accidents on Brazilian highways, and based on a Systematic Review of the Literature, the main technologies capable of supporting the creation of such systems were observed. As a proof of concept, a simulator was used to demonstrate communication between vehicles in the most varied circumstances, given that it has an ecosystem with a preexisting network infrastructure, allowing interaction between its elements, in addition to a realistic virtual environment composed of different vehicles, cities and maps. The simulator also allows for the configuration of sensors, control and customization of the environment, simulation of different traffic situations, among others.","('Redes de Computadores', 'Rede 5G', 'Computação de Borda', 'Internet de veículos', 'Simulador CARLA', 'Acidentes -Prevenção -Zona rural', 'Computer Networks', '5G Network', 'Edge Computing', 'Internet of vehicles', 'CARLA Simulator', 'Accidents -Prevention -Rural area')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/16366","2024-09-13","https://www.repositorio.ufal.br/bitstream/123456789/16366/1/Preven%c3%a7%c3%a3o%20de%20acidentes%20em%20zonas%20rurais%20utilizando%20redes%205G%20e%20computa%c3%a7%c3%a3o%20de%20borda.pdf","",""
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/2971","Campus A.C. Simões","Instituto de Computação","Dissertação","Otimização incremental de percurso de transporte público","('Marcos Paulo José de Melo Silva',)","('Baldoíno Fonseca dos Santos Neto',)","('Patrick Henrique da Silva Brito', 'Aydano Pamponet Machado')","Nos últimos anos, muitos pesquisadores investigaram os problemas da otimização de percursos de transporte público. Os principais objetivos das suas abordagens foram: construir rotas com tempo de viagem curto; reduzir o tempo de espera dos passageiros; minimizar a demanda de viagens não atendidas; reduzir o tamanho das frotas; entre outros. Porém, apesar da grande quantidade de contribuições, eles não consideram os padrões de viagens conhecidos pelos usuários durante a construção das novas rotas. Entretanto, construí-las sem os considerar dificulta a adoção e implantação delas no ambiente urbano real. Sendo assim, o presente trabalho construiu um novo algoritmo capaz de reduzir o custo dos usuários e dos operadores através de poucas mudanças nos percursos existentes com o objetivo de manter os padrões de viagens. Para avaliá-lo, foram utilizados dois benchmark. Um é amplamente referenciado em pesquisas anteriores e o outro foi proposto a pouco tempo. Além deles, o algoritmo também foi aplicado na cidade de Maceió/AL. O experimento consistiu em três passos. O primeiro objetiva avaliar a eficácia do novo método. O segundo compara os resultados do algoritmo com os da literatura. O último passo analisa a quantidade de mudanças necessárias para gerar os novos percursos. Por fim, os resultados dos experimentos indicam que a abordagem é capaz de gerar rotas eficazes aplicando poucas mudanças.","In recent years, many researchers have investigated the problems of route optimization in public transportation. The main goals in their approaches were: construct routes with short time travelling; reduce the wait time; minimize the travel demands not met; reduce the size of the fleets; among others. Though, despite the large amount of contributions, these approaches do not consider the travel patterns already known by the users when constructing new routes. However, constructing them without considering such patterns makes their adoption and implementation difficult in a real urban environment. Therefore, the present study developed an algorithm capable of reducing the users’ and operators’ costs with few changes in the existent routes, with the objective of keeping the travel patterns. Two benchmark was used to evaluate this algorithm. One is widely referenced in previous studies and the other was proposed recently. Besides those, the algorithm was also applied in the city of Maceió/AL. The experiment consists in three steps. The first aims to evaluate the new method’s efficiency. The second compares the results of the new algorithm to the ones in the literature. The last step analyzes the number of changes required to generate the new routes. Lastly, the results of the experiments indicate that this approach is capable of generating effective routes applying few changes.","('Transporte público', 'Otimização matemática', 'Transporte urbano – Maceió (AL) – Rotas', 'Linhas de transporte urbano – Maceió (AL)', 'Mathematical optimization', 'Public transportation', 'Transport lines -Maceió (AL)', 'Transportation routes')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/2971","2018-03-14","https://www.repositorio.ufal.br/bitstream/riufal/2971/1/Otimiza%c3%a7%c3%a3o%20incremental%20de%20percurso%20de%20transporte%20p%c3%bablico.pdf","Incremental optimization of public transportation route",""
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/8241","Campus A.C. Simões","Instituto de Computação","Dissertação","Otimização de processos de alocação e handover em redes móveis","('Geymerson dos Santos Ramos',)","('André Luiz Lins de Aquino',)","('Alexandre Mendes', 'Erick de Andrade Barboza', 'Marília Curado')","O número crescente de dispositivos conectados à Internet tem exigido avanços em tecnologias de comunicação sem fio. A rede 4G e suas antecessoras estão sendo gradativamente substituídas pela 5G, que promete maior velocidade, heterogeneidade e escalabilidade. A 5a geração oferece suporte amplo para aplicações de redes definidas por software, aumentando a flexibilidade para modelagem de processos e protocolos que antes eram embarcados e de difícil atualização. Este trabalho tem como objetivo melhorar processos em redes móveis através de modelos matemáticos, que podem impactar mobilidade, balanceamento de carga na rede e redução de custos operacionais. Nossa proposta visa a alocação de usuários em torres ou estações bases de redes de telecomunicação, minimizando handovers e melhorando a qualidade de comunicação. O trabalho oferece as seguintes contribuições: i) Um modelo matemático para alocação de usuários em estações bases de redes de telefonia móvel, com a redução de transferências; ii) Uma solução meta-heurística como alternativa a modelos exatos, visto que estes podem se tornar inviáveis em condições de restrição de recursos de tempo e computacionais; iii) A avaliação dos modelos em cenários simulados de mobilidade, avaliando o processo de handover e a distribuição de usuários na rede em função de largura de banda disponível. A modelagem, que considera a frequência média de handover de cada estação base e o sinal indicador de qualidade de comunicação, foi avaliada com soluções exatas e heurísticas, sendo estas o algoritmo de branch and bound, busca local iterativa, e solução gulosa. Através dos métodos heurísticos o algoritmo de busca local iterativa obteve uma redução de aproximadamente 82% do tempo de execução em comparação ao algoritmo exato branch and bound. Com relação ao indicador de qualidade de conexão, a solução obteve um ganho médio de 1.45 em comparação à solução da literatura, mantendo o número handovers. Apesar do ganho reduzido, o que torna nossa proposta estatisticamente equivalente, oferecemos a vantagem de não computar todas possíveis e futuras rotas dos usuários, sendo suficiente a posição atual. Adicionalmente, nossa solução considera a capacidade de largura de banda de cada estação base, respeitando a capacidade de rede e mantendo o controle de alocação.","The growing number of devices connected to the Internet has required advances in wireless communication technologies. As a result, 5G networks gradually replace 4G and its predecessors, offering more speed, heterogeneity, and scalability. The fifth-generation provides broad support for software-defined networking (SDN) applications, increasing the programming flexibility of processes and protocols previously embedded and difficult to update. This work aims to improve processes in mobile networks through mathematical models. Our work focuses on optimizing the allocation of users in base stations of telecommunication networks, minimizing the handover of users between base stations, and improving network communication quality. The contributions of this work are: i) A mathematical model for allocating users of mobile networks at base stations, also aiming handover reduction; ii) A metaheuristic solution as an alternative to exact models since exact models can prove to be non-scalable and present unfeasible solving times under computationally restricted conditions; iii) A model evaluation in simulated mobility scenarios considering the handover process and the network user distribution according to available bandwidth. Our allocation model considers the average handover frequency of each base station and the Reference Signal Received Quality (RSRQ) indicator between users and base stations. The model evaluation used exact and heuristic methods: the branch and bound algorithm, iterated local search, and a greedy solution. On average, the iterated local search algorithm obtained an execution time reduction of approximately 82% compared to the branch and bound exact algorithm. Regarding the RSRQ indicator, the solution reached a 1.45% average gain, and the number of performed handovers was maintained, compared to a similar literature model. Despite the modest improvement, which makes our proposal statistically equivalent to the literature model, we offer the advantage of not predicting the users’ possible and future routes. Only the current position is required. Furthermore, our solution also considers base stations’ bandwidth capacity, controlling the allocation and network occupation limits.","('Redes móveis', 'Alocação de usuários', 'Otimização de processos', 'Handover', 'Redes locais sem fio', 'Mobile Networks', 'Allocation', 'Optimization', 'Handover')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/8241","2021-10-27","https://www.repositorio.ufal.br/bitstream/123456789/8241/1/Optimizing%20allocation%20and%20handover%20processes%20in%20mobile%20networks.pdf","Optimizing allocation and handover processes in mobile networks","('Rian Gabriel Santos Pinheiro',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/15089","Campus A.C. Simões","Instituto de Computação","Dissertação","Omnino: plataforma aberta de robô omnidirecional para enxame","('José Henrick Viana Ramalho',)","('Heitor Judiss Savino',)","('Ícaro Bezerra Queiroz de Araújo', 'Armando Alves Neto')","Este trabalho apresenta uma plataforma aberta de um robô para atividades de pesquisa e educacionais. A plataforma é definida como um robô omnidirecional, que é um dos primeiros passos no currículo de robótica quando se deseja projetar um controlador, dado que este não impõe restrições ao movimento num plano. Os robôs são projetados para serem de baixo custo e com acesso aberto ao software e hardware. A maior parte do projeto mecânico também é fácil de imprimir em impressoras 3D comumente usadas. O robô é integrado com a plataforma ROS -Robot Operating Systems, amplamente utilizada na comunidade de robótica, e o modelo de simulação em ROS-Gazebo é fornecido para permitir uma passagem fácil do ambiente de simulação ao ambiente experimental. Experimentos reais com os robôs propostos são mostrados, assim como a plataforma de simulação com múltiplos robôs.","This work presents an open robotic platform for research and educational activities. The platform is defined as an omnidirectional robot, which is one of the first steps in the robotics curriculum when a controller is to be designed, as it does not impose restrictions for moving on a plane. These robots are designed to be low cost and have open access to software and hardware. Most of the mechanical design is also easy to print on commonly used 3D printers. The robot is integrated with ROS -Robot Operating Systems platform, widely used in the robotics community, and the ROS-Gazebo simulation model is provided to allow an easy transition from the simulation environment to the experimental environment. Real experiments with the proposed robots are shown, as well as the simulation platform with multiple robots.","('Educação em robótica', 'Robôs -Baixo custo', 'Simulação (Computadores)', 'Robotics education', 'Robots -Low cost', 'Simulation (Computers)')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/15089","2020-08-31","https://www.repositorio.ufal.br/bitstream/123456789/15089/1/Omnino%20plataforma%20aberta%20de%20rob%c3%b4%20omnidirecional%20para%20enxame.pdf","","('Erick de Andrade Barboza',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/2414","Campus A.C. Simões","Instituto de Computação","Dissertação","Objeto de aprendizagem baseado em redes sociais para ensino de Libras a alunos ouvintes","('Bruno Rafael Ferreira Souza Barbosa da Silva',)","('Patrick Henrique da Silva Brito',)","('Fábio José Coutinho da Silva', 'Ivani Rodrigues Silva')","Se considerarmos os 9,6 milhões de brasileiros com alguma deficiência auditiva e sabendo que a média de pessoas por família no Brasil é de 3,3, poderia-se inferir um número de mais de 30 milhões de pessoas que têm interesse direto em resolver os problemas relacionados à surdez; isso considerando apenas o parentesco direto. No Brasil, de acordo com o decreto 5.636 de 2005, a Língua Brasileira de Sinais (Libras) é a língua oficial para a comunicação da pessoa surda. Porém, estatísticas internacionais mostram que 95% das crianças surdas são filhas de pais ouvintes que, infelizmente, desconhecem, ou, se conhecem, rejeitam a língua de sinais. A falta de conhecimento sobre a Libras e o preconceito com a “deficiência”, faz com que os pais busquem a “cura” e métodos de oralização no lugar de educar seus filhos através da língua de sinais. A surdez acaba sendo tratada como doença e não como um problema social que necessita de um atendimento diferenciado. Sem a Libras o indivíduo surdo tem dificuldades de desenvolver um padrão de raciocínio lógico necessário para o seu crescimento social e intelectual, interferindo diretamente na aprendizagem do português. Apesar da Libras ser a língua oficial do surdo brasileiro, o mesmo decreto ressalta também a importância da pessoa surda se comunicar com pessoas ouvintes. Nesse sentido, o decreto define a obrigatoriedade da oferta da disciplina de Libras em cursos de licenciatura, fonoaudiologia e formação de professores. Dada a escassez de intérpretes, pesquisas relatam dificuldade no atendimento às exigências da lei, o que leva muitas vezes à oferta de cursos de baixa qualidade, visando apenas o cumprimento da carga horária mínima exigida. Partindo do pressuposto que as dificuldades apresentadas, em relação a comunicação, estão ligadas ao aprendizado de uma segunda língua, o objetivo deste trabalho é facilitar o aprendizado da Libras por parte de alunos ouvintes, visando a diminuição da exclusão social existente entre as duas comunidades. O presente trabalho propõe que esse objetivo possa ser conquistado através de um objeto de aprendizagem dotado de um tradutor português-Libras integrado a um comunicador de mensagens instantâneas de uma rede social. Dessa forma, o objeto de aprendizagem proposto pode ser utilizado por surdos e ouvintes, permitindo a interação das duas comunidades de forma acessível e a tradução em tempo real do português para Libras. Foi realizado um experimento avaliativo com 30 voluntários, cujos resultados ressaltam a importância da ferramenta para estimular o contato frequente com a língua de sinais e consequentemente benefícios da assimilação de novos sinais. Os resultados preliminares também apresentam indícios do potencial da ferramenta proposta para facilitar o aprendizado do português por parte de alunos surdos. Porém, uma avaliação mais criteriosa nesse sentido é um dos trabalhos futuros identificados.","If we consider the 9.6 million Brazilians with some hearing impairment and knowing that the average number of people per family in Brazil is 3.3, it could be inferred by a number of more than 30 million people who are highly involved in solving deafness communication problems. In Brazil, according to Decree 5,636 of 2005, the Brazilian Sign Language (Libras) is an official language for the deaf person’s communication. However, international statistics show that 95% of deaf children are daughters of parents who are unfortunately unaware or deny sign language. Lack of knowledge about the sign language and deafness makes parents seek a “cure” and oralization methods with no place to educate their children through sign language. Deafness ends up being treated as a disease and not as a social problem that needs a differentiated care. Without a sign language the deaf person has difficulties in developing a logical reasoning pattern necessary for their social and intellectual growth, which directly interferes in the learning of a written language, such as Portuguese. Although the Libras is an official language for the Brazilian deafs, the same decree also emphasizes the importance of the deaf person to communicate with hearing people. In this sense, the decree defines an obligation of providing the course of Libras in undergraduate courses for teachers and phonoaudiology. Given the shortage of interpreters, researchs report that it is difficult to meet the requirements of the law, which often leads to the supply of low quality courses, aiming only at achieving the minimum hours required. Based on the assumption that the difficulties presented in relation to communication are linked to the learning of a second language, the goal of this work is to facilitate the learning of Libras by hearing students, aiming to reduce the social exclusion existing between the two communities. The present work believes that this objective can be achieved through a learning object equipped with a Portuguese translator-Libras integrated to an instant messaging communicator of a social network. In this way, the proposed learning object can be used by both deaf and hearing people, allowing the two communities to interact each other in an accessible and real-time way, involving automatic translation from Portuguese to Libras. An evaluation experiment was carried out with 30 volunteers, whose results highlight the importance of the tool to stimulate contact with sign language. The preliminary results also show evidence of the potential of the proposed tool to facilitate the learning of Portuguese by deaf students. However, a more careful evaluation in this sense is one of the future work identified.","('Língua brasileira de sinais', 'Ensino auxiliado por computador', 'Redes sociais', 'Educação inclusiva', 'Surdos', 'Online education', 'Sign language', 'Libras', 'Learning object', 'Social networks')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/2414","2016-12-14","https://www.repositorio.ufal.br/bitstream/riufal/2414/1/Objeto%20de%20aprendizagem%20baseado%20em%20redes%20sociais%20para%20ensino%20de%20Libras%20a%20alunos%20ouvintes.pdf","Social Net Based Learning Object to Support the Teaching of Pounds to Hearers",""
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/9851","Campus A.C. Simões","Instituto de Computação","Dissertação","Otimização de hiperparâmetros do XGBoost utilizando meta-aprendizagem","('Tiago Lima Marinho',)","('Bruno Almeida Pimentel',)","('Evandro de Barros Costa', 'Roberta Vilhena Vieira Lopes', 'Diego Carvalho do Nascimento')","Com a evolução computacional, houve um crescimento no número de algoritmos de aprendizagem de máquina e em paralelo, foram se tornando cada vez mais robustos. Este crescimento nos algoritmos de aprendizagem de máquina, ocasionou uma complexidade maior na configuração dos algoritmos, com o intuito de aumentar a precisão. Com isso, a escolha dos hiperparâmetros mais adequados para um determinado conjunto de dados, pode ser uma tarefa custosa tanto em questão de tempo, quanto em questão de dinheiro. Sendo assim, é necessário que hajam maneiras mais rápidas e práticas para achar hiperparâmetros que vão configurar cada algoritmo individualmente. Este trabalho visa utilizar da Meta-Aprendizagem como uma solução viável para a recomendação de hiperparâmetros para o recente algoritmo de aprendizagem de máquina XGBoost, a fim de que haja uma redução de custos computacionais, visando também a redução de custo para as empresas. Este trabalho utilizou de 198 conjuntos de dados, seguindo a ideia de validação cruzada leave-one-out para os experimentos, fazendo assim, com que cada um dos conjuntos de dados fossem testados em comparação a todos os outros disponíveis. Além disso, foram utilizados 3 conjuntos de Meta-Características disponíveis na literatura: general, statistical e info-theory para a fase de caracterização de cada um dos conjuntos de dados fazendo assim, com que houvesse uma comparação de similaridade entre os conjuntos de dados para que dessa forma, pudesse ser aplicado a Meta-Aprendizagem e ter por fim, a recomendação de cada um dos hiperparâmetros. Os resultados obtidos foram promissores, fazendo com que em alguns casos, 86.36% dos testes tivessem resultados positivos, ou seja, a acurácia do XGBoost utilizando a Meta-Aprendizagem, tivesse um resultado melhor do que os hiperparâmetros padrões utilizados pelo XGBoost em 86.36% dos casos. Outro ponto que é importante concluir em torno dos resultados, é que a Meta-Aprendizagem visa utilizar a similaridade entre os conjuntos de dados para a recomendação dos hiperparâmetros; com isso, a similaridade dos conjuntos de dados tendiam a dar hiperparâmetros mais efetivos.","With computional evolution, there was a growth in the number of machine learning algorithms and in parallel, they became more complex and robust. With the growth of this complexity, it was increasingly necessary to focus on the configuration of algorithms, in accordance with their hyperparameters, with the aim of increasing the precision in the result of each one of them: which is not a trivial task. Thus, choosing the most suitable hyperparameters for a given data set can be a costly task both in terms of time and money. Thus, it is necessary that there are faster and more practical ways to find hyperparameters that will set up each algorithm individually. This work aims to use Meta-Learning as a viable solution for the recommendation of hyperparameters for the recent XGBoost machine learning algorithm, in order to reduce computional costs, also aiming at reducing costs for companies. This work used 198 datasets, following the idea of leave-one-out cross-validation for the experiments, thus making each of the datasets tested in the experiment against all others. In addition, were used 3 sets of Meta-Features available in the literature: general, statistical and info-theory for the characterization phase of each one of the datasets to compare the similarity among them. The experimental results attested the success of the application of the heuristics using Meta-Learning for their recommendation, Thus, initially a characterization of the data sets was made using three sets of Meta-Features, so that there was a way to compare the similarity between them and thus apply Meta-Learning to recommend the hyperparameters between the data sets used in the experiments. The results obtained were promising, making that in some cases, 86.36% of the tests had positive results, that is, the accuracy of XGBoost using Meta-Learning, had a better result than the standard hyperparemeters used by XGBoost in 86.36% of cases.","('Meta-aprendizagem', 'Aprendizagem de máquina', 'Custo', 'Ciência de dados', 'XGBoost', 'Meta-learning', 'Recommendation systems')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/9851","2021-12-16","https://www.repositorio.ufal.br/bitstream/123456789/9851/1/Otimiza%c3%a7%c3%a3o%20de%20hiperpar%c3%a2metros%20do%20XGBoost%20utilizando%20meta-aprendizagem.pdf","Optimization of XGBoost hyperparameters using meta-learning",""
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/7022","Campus A.C. Simões","Instituto de Computação","Dissertação","On the agreement among developers when detecting code smells aided by decision tree","('Christiano Rossini Martins Costa',)","('Baldoíno Fonseca dos Santos Neto',)","('Márcio de Medeiros Ribeiro', 'Rafael Maiani de Mello')","O code smell é um sintoma de um mau design de código em desenvolvimento de software.Geralmente ocorre quando os desenvolvedores conceberam mal o design de um componente de código ou porque não projetaram a solução adequadamente devido a prazos rígidos. Na literatura, o code smell é descrito informalmente, isto é, não é possível identificá-lo objetivamente. Essa informalidade pode levar dois ou mais desenvolvedores a raciocinar sobre cada ocorrência de smell a sua maneira. Como conseqüência de diferentes pontos de vista, percepções conflitantes nas mesmas bases de código podem ser notáveis, afetando a consistência entre as revisões de código. Trabalhos anteriores que abordam a subjetividade do code smell carecem de elementos informativos que possam descrever por que certos códigos-fonte foram anteriormente classifi-cados como code smell, a fim de ajudar os desenvolvedores a raciocinar sobre a ocorrência de um code smell com mais eficácia. Em nossa pesquisa, propomos mostrar ao desenvolvedor uma visualização de um classificador de árvore de decisão, composto por regras baseadas em métricas de software, com o objetivo de informar as razões pelas quais algum código-fonte foi classificado anteriormente como um host de um code smell. O fornecimento de novos insights pode levar o desenvolvedor a raciocinar de forma mais ampla sobre a ocorrência de um code smell, não se restringindo a fatores relacionados apenas a experiências e vida profissional. Nosso objetivo é, após várias avaliações de code smells, investigar como a concordância entre desenvolvedores pode ser influenciada pela visualização fornecida por um modelo de classificação compreensí-vel, o classificador de árvore de decisão. Realizamos um experimento on-line onde reunimos colaborações de 30 desenvolvedores da indústria e da academia. Os resultados indicam que: (i) a detecção de code smells auxiliada por uma árvore de decisão leva a uma melhora relativa da concordância em relação às detecções com base apenas na análise de código; (ii) a detecção de code smell auxiliada pela árvore de decisão não diminui o esforço para detectar smells (iii) nosso experimento sugere que as árvores de decisão usadas para dar suporte à detecção de code smells são úteis para o desenvolvedor em termos de insights para tomada de decisão.","Code smell is a symptom of poor code design on software development. It often occurs when developers poorly conceived the design of the code component or because they did not properly designed the solution due to strict deadlines. In literature, code smell is described informally, i. e., it isn’t possible to identify a smelly code objectively. Such informality may lead two or more developers to reason about each smell occurrence in their own way. As a consequence of different viewpoints, conflicting perceptions on the same code bases may be notable, impacting the consistency across code reviews. Previous works that addresses code smell subjectivity lacks of some informative element that may describe why certain suspicions source code was previously classified as code smell in order to aid developers to reasoning about the occurrence of a code smell with more effectivity. In our research, we propose to show to the developer a visualization of a decision tree classifier, composed by some metric-based rules, aimed to inform the developer the reasons why some source code was previously classified as a host of a certain code smell. Providing new insights may tease the developer to reasoning the occurrence of a code smell widely, not restricting to factors concerned only to past experiences and backgrounds. Our objective is, after several code smell evaluations, investigate how the agreements among developers may be influenced by the visualization provided by a comprehensible classification model, the decision tree classifier. We performed an on line experiment where we gather collab-orations from 30 developers from industry and academy. The results indicate: (i) code smells detection aided by a decision tree leads to a relative improvement of agreement in relation to detections based solely on code analysis; (ii) the detection of code smell aided by decision tree do not decrease the effort to detect smells (iii) our experiment suggests that the decision trees used to support code smell detection are useful to the developer in terms of insights for decision making.","('Code smells', 'Concordâncias', 'Sistemas de suporte de decisão', 'Code Smells', 'Agreements', 'Code Review', 'Decision Tree Classifier', 'Detection', 'Identification', 'Empirical study')","Ciência da Computação","eng","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/7022","2020-04-06","https://www.repositorio.ufal.br/bitstream/riufal/7022/3/On%20the%20agreement%20among%20developers%20when%20detecting%20code%20smells%20aided%20by%20decision%20tree%20.pdf","Sobre a concordância entre desenvolvedores ao detectarem code smells auxiliados por árvores de decisão",""
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/16887","Campus A.C. Simões","Instituto de Computação","Dissertação","On-device machine learning for forecasting reference evapotranspiration","('Maria Júlia de Oliveira Vieira',)","('Erick de Andrade Barboza',)","('Tiago Figueiredo Vieira', 'Fernando França da Cunha')","O cenário climático-mundial atual demanda o uso dos recursos naturais de forma equilibrada, especialmente a água. A predição da evapotranspiração de referência (ETo) pode auxiliar no gerenciamento dos recursos hídricos, sendo um parâmetro determinante na avaliação inicial da água para aplicações como programação de irrigação e estudos hidrológicos. A literatura mostra que modelos de Machine Learning (ML) têm sido amplamente aplicados na predição de ETo e têm mostrado resultados promissores, mesmo com o uso de parâmetros reduzidos. Trabalhos anteriores também apresentaram sistemas de irrigação automatizados que se conectam a serviços Web para prever os parâmetros necessários para fazer a programação de irrigação. No entanto, um sistema baseado em nuvem depende de uma infraestrutura de conexão à internet; tal infraestrutura nem sempre está disponível em áreas rurais. Além disso, um dispositivo que depende de uma conexão à internet geralmente consumirá mais energia. Portanto, esta pesquisa tem como objetivo principal desenvolver e avaliar um modelo TinyML projetado para prever ETo, com o objetivo de estabelecer um modelo de machine learning energeticamente eficiente adequado para integração em um sistema embarcado. Avaliamos três modelos considerando temperatura do ar, umidade relativa e velocidade do vento como entradas. Os modelos foram incorporados em um microcontrolador ESP32 e comparados com suas versões em nuvem. Os resultados mostram que o modelo que estima ETo considerando apenas a temperatura do ar e a umidade é a melhor opção considerando o trade-off entre custo e precisão. Comparado com sua versão baseada em nuvem, este modelo incorporado consome 37,97% menos espaço de memória, usa aproximadamente 99,98% menos energia e roda 99,97% mais rápido.","The current climate-world scenario demands the use of natural resources in a balanced way, especially water. The prediction of reference evapotranspiration (ETo) can assist in the management of water resources, being a determining parameter in the early assessment of water for applications such as irrigation scheduling and hydrological studies. The literature shows that Machine Learning (ML) models have been widely applied in the prediction of ETo and have shown promising results, even with the use of reduced parameters. Previous works also presented automated irrigation systems that connect to Web services to predict the parameters needed to make irrigation scheduling. However, a cloud-based system depends on an internet connection infrastructure; such infrastructure is not always available in rural areas. In addition, a device that relies on an internet connection will generally consume more power. Therefore, this research primarily aims to develop and assess a TinyML model designed to forecast ETo, with the goal of establishing an energy-efficient machine learning model suitable for integration into an embedded system. We evaluated three models considering air temperature, relative humidity, and wind speed as inputs. The models were embedded in an ESP32 microcontroller and compared to its cloud versions. The results show that the model that estimates ETo considering only air temperature and humidity is the best option considering the trade-off between cost and precision. Compared to its cloud-based version, this embedded model consumes 37.97% less memory space, uses approximately 99.98% less energy and runs 99.97% faster.","('Engenharia de sistemas de computação', 'Sistemas embarcados (Computadores)', 'Aprendizado de máquina', 'Eficiência energética', 'Eletrônica de baixa potência', 'TinyML', 'Power efficiency', 'Embedded systems', 'Low power eletronics', 'Machine learning')","Ciência da Computação","eng","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/16887","2024-10-29","https://www.repositorio.ufal.br/bitstream/123456789/16887/1/On-device%20machine%20learning%20for%20forecasting%20reference%20evapotranspiration.pdf","Predição de evapotranspiração de referência para planejamento de irrigação utilizando aprendizagem de máquina em sistemas embarcados","('Davi Bibiano Brito',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/11931","Campus A.C. Simões","Instituto de Computação","Dissertação","Otimização do sistema de transporte público utilizando algoritmo genético enviesado de chaves aleatórias","('João Luiz Alves Oliveira',)","('Bruno Costa e Silva Nogueira',)","('André Luiz Lins de Aquino', 'Gustavo Rau de Almeida Callou')","A economia de uma cidade ou região é diretamente proporcional à eficiência do seu sistema de transporte público. O planejamento de um sistema de transporte público depende de diversos fatores como modais de transporte, demandas de origem-destino, qualidade e confiabilidade desse serviço, custos operacionais, entre outros. Essas características levam a problemas muito complexos, como o projeto de rede e configuração de frequência de veículos. O presente trabalho propõe uma metodologia, baseada em Algoritmos Genéticos Enviesados de Chaves-Aleatórias (BRKGA), para otimização da frequência de veículos do sistema de transporte público de ônibus considerando duas métricas: (i) tempo de espera dos passageiros; (ii) custo operacional para a empresa concessionária. A metodologia proposta foi aplicada em um estudo de caso real com dados de transporte de ônibus da cidade de Maceió/AL. Neste estudo de caso, foram considerados dois cenários diferentes: no primeiro cenário buscou-se minimizar o tempo de espera dos passageiros, e no segundo o objetivo foi minimizar o custo operacional da empresa concessionária. Os resultados demonstram que em ambos os casos a metodologia proposta foi capaz de melhorar em mais que 10% o desempenho da configuração em relação a que está atualmente em uso no transporte público da cidade.","The economy of a city or region is directly proportional to its public transport system efficiency. Planning of a public transport system depends on several factors such as transport modals, origin-destination demands, quality and reliability of this service, operational costs, among others. These features leads to very complex problems like the network design and vehicles frequency setting. The present work focus to propose a methodology, based on biased random-key genetic algorithms (BRKGA), for optmizing the vehicle frequency of the bus public transport system considering two metrics: (i) passengers waiting time; (ii) operational cost for the concessionaire company. The proposed methodology was applied in a real case study with bus transport data from the city of Maceió/AL. In this case, two different scenarios were considered: In the first scenario, it sought to minimize the passengers waiting time, and in the second, the objective was to minimize the operating cost of the concessionaire company. The results show that in both cases the proposed methodology was able to improve the performance of the configuration currently in use in the city’s public transport by over than 10%.","('Chaves aleatórias enviesadas (Algoritmos genéticos)', 'Transporte público – Planejamento', 'Transporte público – Otimização', 'Eurística', 'Biased random-key genetic algorithms', 'Frequency setting', 'Planning of public traffic system', 'Heuristics', 'Optimization')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/11931","2022-09-14","https://www.repositorio.ufal.br/bitstream/123456789/11931/3/Otimiza%c3%a7%c3%a3o%20do%20sistema%20de%20transporte%20p%c3%bablico%20utilizando%20algoritmo%20gen%c3%a9tico%20enviesado%20de%20chaves%20aleat%c3%b3rias.pdf","Optimizing public transport system using biased random-key genetic algorithm","('Rian Gabriel Santos Pinheiro',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/1721","Campus A.C. Simões","Instituto de Computação","Dissertação","Monitoração de requisitos de qualidade baseada na arquitetura de software","('André Almeida Silva',)","('Patrick Henrique da Silva Brito',)","('Marcelo Costa Oliveira', 'Hyggo Oliveira de Almeida')","Os sistemas computacionais ganham dia a dia mais espaço na vida dos indivíduos, fazendo com que a demanda por soluções computadorizadas, cada vez mais sofisticadas e precisas, seja crescente. Assim, há a exigência de efetivas garantias de qualidade aos softwares produzidos, conferidas pela monitoração dos atributos de qualidade. Contudo, as principais técnicas de monitoração atuais voltam-se, sobretudo, aos sistemas baseados em serviços, deixando de lado uma grande parcela de softwares. Neste contexto, o presente trabalho possui como objetivo discutir acerca da monitoração dos atributos de qualidade referenciados pela norma ISO/IEC 9126. Serão definidas árvores de decisão, que relacionarão os elementos arquiteturais às questões de monitoração, e ainda uma ferramenta que utilizará conceitos da Programação Orientada a Aspectos para automatizar o processo de monitoração dos requisitos confiabilidade e eficiência, através da geração de aspectos-monitores destinados ao logging e registro de exceções de determinado sistema-alvo. Ainda será observada a disposição de estudo de caso estruturado pelo paradigma Goal/Question/Metric (GQM), realizado com a finalidade de analisar a viabilidade da solução desenvolvida que representa uma maneira simplificada para que arquitetos e desenvolvedores de softwares definam monitores para aferir atributos de qualidade em seus sistemas.","Computer systems gain more space day by day in the lives of individuals, causing the demand for computerized solutions more and more sophisticated and accurate, become increasing. Thus, there is a requirement of effective quality assurance for software produced, checked by monitoring of quality attributes. However, the main current monitoring techniques are turning mainly to service-based systems, setting aside a large number of software. In this context, this work aims to discuss about the monitoring of quality attributes referenced by ISO/IEC 9126 standard. Decision trees will be set relating to the architectural elements monitoring issues, and also a tool that uses the concepts of Aspect-Oriented Programming to automate the process of monitoring the reliability and efficiency requirements by generating aspects-monitors intended for logging and recording exceptions given target system. Still be observed the case study disposal structured by the Goal/Question/Metric (GQM) paradigm, conducted with the purpose of analyze the feasibility of the developed solution which is a simplified way for architects and software developers to define monitors to measure quality attributes in their systems.","('Software -Manutenção', 'Arquitetura de Software', 'Software -Controle de qualidade', 'Software -Maintenance', 'Software architecture', 'Software -Quality control')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1721","2015-02-19","https://www.repositorio.ufal.br/bitstream/riufal/1721/1/Monitora%c3%a7%c3%a3o%20de%20requisitos%20de%20qualidade%20baseada%20na%20arquitetura%20de%20software.pdf","Quality requirements monitoring based on software architecture","('Baldoíno Fonseca dos Santos Neto',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/3627","Campus A.C. Simões","Instituto de Computação","Dissertação","Modelos de personalização de visualização de dados para o professor","('Maria das Graças Cavalcante da Silva',)","('Alan Pedro da Silva',)","('Rafael de Amorim Silva', 'Patrícia Leone Espinheira Ospina')","A presente dissertação trata da criação de modelos de personalização de Visualizações de dados para os professores, no intuito de viabilizar auxílio na tomada de decisão pedagógica, em que, fundamentado neste auxílio, os professores poderão analisar corpus com base em visualizações apropriadas, a partir de características pessoais. Para tanto, realizamos pesquisas na área de visualização de dados, em que optamos por dividir as técnicas de visualização de dados em dois grandes grupos, técnicas tradicionais e técnicas não tradicionais. Durante a pesquisa, necessitamos adaptar um processo de recomendação pedagógica, de forma que o mesmo pudesse dá suporte exclusivamente ao professor por meio de visualização de dados, apartir disto, foi elaborado e aplicado um survey, com trezentas e trinta e três participantes, dos quais duzentas e trinta e cinco eram professores. Realizaram-se diversas ﬁltragens de dados e análises estatísticas baseadas em modelos de regressão beta. Nestas análises foram identiﬁcadas variáveis pertinentes às características dos professores, tais que ﬁzeram com eles escolhessem entre visualizações tradicionais e não tradicionais. Depois desta fase, realizou-se uma modelagem de classiﬁcação, do tipo árvore de decisão, a ﬁm de descobrirmos quais os conjuntos de características podem estar relacionados à preferência do professor por uma determinada visualização. Com isso criamos quatro classes, a classe (i) preferência, (ii) a classe percepção, (iii) a classe tempo e (iv) a classe ajuda. As quais modelam as características relacionadas ao professor, quando ele busca analisar um dado em uma visualização de acordo com suas preferências,uma visualização que dentro de suas características o faça perceber melhor os dados, uma visualização que o ajude a ver as informações e uma visualização que reduz ao seu tempo de decisão. Com os resultados, fomos capazes de identiﬁcar quais características pertinentes aos professores tem inﬂuência na preferência de uma visualização e quais conjuntos de características levam a possíveis escolhas de visualizações possibilitando-nos, assim, criarmos modelos de personalização de visualizações de dados, como forma de melhorar a tomada de decisão pedagógica.","This thesis studies the creation of personalization models of data visualization for instructors in order to assist pedagogical decision making.Thus, instructors Will be able to analyze data based on appropriate data visualizations from personal characteristics. For this purpose, we researched on the literature for data visualization and decided to divide its techniques into two major groups, traditional techniques, and non-traditional techniques.Duringthe research, we adapted a pedagogical recommendation process to provide exclusive support to instructors through the use of data visualization. We also designed and placed a survey involving 333 participants, of which 235 are instructors. After that, we used beta regression model stoper form statistical analysis and data ﬁltering. The study identiﬁed variables related to instructors characteristics that led them to choose between traditional visualizations and non-traditionalones. After that phase, we performe dadecision tree classiﬁcation modeling to identifyaset of characteristics related to instructors preferences in certain visualizations. There fore, we created four classes: (i) preference, (ii) perception, (iii) time, and (iv) help. These classes mold speciﬁc characteristics related to the instructor when he is analyzing data according to his preferences, avisualization that makes him better understandt He data, other to help him perceive the data, and avisualization to reduce his decision-making time. The results allowe didentifying which characteristics relevant to the instructors have some in ﬂuence on a visualization preference. Further, which characteristic set led us to identify certain visualization alternatives that enable us to create personalization models of data visualization to improve pedagogical decision making.","('Modelos computacionais', 'Ambiente virtual de aprendizagem', 'Banco de dados – Visualização de dado', 'Educação', 'Computational models', 'Virtual learning environment', 'Database -Data view', 'Education')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/3627","2018-06-28","https://www.repositorio.ufal.br/bitstream/riufal/3627/1/Modelos%20de%20personaliza%c3%a7%c3%a3o%20de%20visualiza%c3%a7%c3%a3o%20de%20dados%20para%20o%20professor.pdf","Model of customization data visualization for the teacher","('Ig Ibert Bittencourt Santana Pinto',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/7473","Campus A.C. Simões","Instituto de Computação","Dissertação","Um motor de inferência para relações de identidade em grafos de conhecimento","('Williams Lourenço de Alcantara',)","('Evandro de Barros Costa',)","('Patrick Henrique da Silva Brito', 'Frederico Luiz Gonçalves de Freitas', 'Mirko Barbosa Perkusich')","A crescente demanda por acesso a informações em tempo real tem demandado um alto custo – financeiro e computacional – para a integração de dados devido à ausência de padronização, o que normalmente resulta em problemas durante a modelagem e representação de dados. Grafos de Conhecimento (GC) tem sido um dos mecanismos utilizados para abordar tais problemas. Apesar de fornecerem um modelo estruturado, escalável e compreensível por máquina, a sua criação e manutenção são vulneráveis a erros em razão da dificuldade de raciocínio automático em um grande volume de dados de diferentes domínios – que pode gerar resultados imprecisos, errados ou incompletos – principalmente relacionados à ambiguidade. Normalmente, os problemas causados pela ocorrência de relações ambíguas são derivados da imprecisão ao determinar uma Relação de Identidade (IR) em um domínio, pois os trabalhos existentes na literatura realizam comparação de todos os atributos sem considerar que alguns podem ser mais relevantes. Assim, este trabalho propõe um mecanismo automático para detecção de IR capaz de realizar seleção automática de atributos relevantes de um domínio a partir de análises de entropia e correlação estatística entre os atributos. A solução proposta foi aplicada em 12 conjuntos de dados reais que contém atividades de desenvolvimento de software, sendo que os atributos selecionados automaticamente obtiveram melhor acurácia na detecção de IR do que os atributos relevantes definidos por um especialista do domínio.","The growing demand for realtime information access requires high cost – financial and computational – for data integration due to lack of standardization, resulting in problems during modeling and display data. The Knowledge Graphs were used to deal these problems. By providing a structured, scalable and understandable machine model, the creation and maintenance are vulnerable to errors due to automatic reasoning difficulties in large data from different domains – which can produce inaccurate, erroneous or incomplete results – mainly related with ambiguity. The problems are normally caused by ambiguous relationships and by inaccuracy in determining Identity Relations (IR) in a domain. Recent studies compare all attributes without considering that some of them can be more relevant. This work applied an automatic IR detection mechanism which execute an automatic selection of relevant attributes for a domain from entropy analysis and statistical correlation between the attributes. The proposed solution was applied in 12 real datasets that include software development activities. The characters which were automatically selected obtained better IR detection accuracy than the criteria recommended by a domain expert.","('Grafos de ligação', 'Inferência estatística', 'Web semântica', 'Identity relationship', 'Knowledge graph', 'Inference', 'Attribute selection')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/7473","2019-12-12","https://www.repositorio.ufal.br/bitstream/riufal/7473/1/Um%20motor%20de%20infer%c3%aancia%20para%20rela%c3%a7%c3%b5es%20de%20identidade%20em%20grafos%20de%20conhecimento.pdf","An inference engine for identity relations in knowledge graphs",""
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/10777","Campus A.C. Simões","Instituto de Computação","Dissertação","Monitoramento da qualidade da pavimentação de vias utilizando computação em nuvem veicular","('Jefferson David dos Anjos Silva',)","('Leandro Dias da Silva',)","('Rafael de Amorim Silva', 'Ivanovitch Medeiros Dantas da Silva')","Defeitos nas superfícies das ruas, como buracos e imperfeições, podem ocorrer a qualquer momento, de acordo com as condições e a vida útil da estrada. Essas imperfeições nas superfícies das ruas podem comprometer a segurança no trânsito e também ocasionando desgastes prematuros nas peças dos veículos. Neste trabalho, propomos um modelo arquitetural para o ambiente de Vehicular Cloud Computing, capaz de monitorar e avaliar a qualidade da rugosidade da rua, utilizando a métrica do International Roughness Index (IRI). O objetivo deste trabalho, é desenvolver um modelo arquitetural automatizado de monitoramento da rugosidade da estrada para medir a rugosidade do pavimento com base na resposta vibracional utilizando os sensores do smartphone. Com a intenção de informar aos motoristas sobre a qualidade de pavimentação das vias de determinado percursso, para que o motorista possa escolher um caminho mais confortável e mais seguro. Para os experimentos, desenvolvemos um aplicativo android, para fazer os registros da qualidade de rugosidade das vias, junto a um web service que também desenvolvemos, a fim, de armazenar os dados gerados pelo aplicativo. Os experimentos foram realizados na cidade de Garanhuns-PE, percorrendo trechos a uma velocidade de 50 km/h, utilizando três celulares android posicionados encima do painel do automóvel. O modelo do automóvel utilizado foi um Volkswagen Fox 1.0. Os resultados afirmam que o nosso modelo arquitetural consegue monitorar, medir e exibir no mapa a qualidade da rugosidade das vias. No aplicativo são plotados no mapa os lugares onde foram feitos os registros do IRI.","Defects in street surfaces, such as potholes and imperfections, can occur at any time, depending on the conditions and life of the road. These imperfections on street surfaces can compromise traffic safety and also cause premature wear of vehicle parts. In this work, we propose an architectural model for the Vehicular Cloud Computing environment, capable of monitoring and evaluating the quality of street roughness, using the International Roughness Index (IRI) metric. The objective of this work is to develop an automated architectural model of road roughness monitoring to measure pavement roughness based on the vibrational response using smartphone sensors. To inform drivers about the quality of paving of the lanes on a given route, so that the driver can choose a more comfortable and safer route. For the experiments, we developed an application android, to record the roughness quality of the roads, together with a web service that we also developed, to store the data generated by the application. The experiments were carried out in the city of Garanhuns-PE, covering stretches at a speed of 50 km/h, using three android cell phones positioned on top of the car’s dashboard. The car model used was a Volkswagen Fox 1.0. The results affirm that our architectural model can monitor, measure and display on the map the quality of road roughness. In the application, the places where the IRI records were made are plotted on the map.","('Rugosidade – vias', 'Vehicular cloud computing', 'Pavimentação -Qualidade', 'Índice internacional de rugosidade (IRI)', 'International roughness index (IRI)', 'Paving quality')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/10777","2021-04-30","https://www.repositorio.ufal.br/bitstream/123456789/10777/1/Monitoramento%20da%20qualidade%20da%20pavimenta%c3%a7%c3%a3o%20de%20vias%20utilizando%20computa%c3%a7%c3%a3o%20em%20nuvem%20veicular.pdf","","('Ivo Augusto Andrade Rocha Calado',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/7536","Campus A.C. Simões","Instituto de Computação","Dissertação","Modelos de previsão de ativos utilizando aprendizagem profunda e linguagem natural","('João Victor de Lima Moura',)","('Xu Yang',)","('Evandro de Barros Costa', 'Yuri Fahham Saporito')","Predizer o futuro é algo que a humanidade anseia, de modo a poder se preparar para possíveis eventualidades. Hoje, aliando a facilidade de acesso a informações através de notícias com o uso de programas que “leem” os sentimentos dos usuários na internet, é possível usar a linguagem computacional para predizer, inclusive, o comportamento do mercado financeiro. No âmbito da economia, essa predição possibilita novas formas de intervir no mercado, propiciando o vislumbre de diversos cenários, facilitando desse modo a tomada de decisão sobre investimentos e sobre o futuro econômico de empresários, empresas e governos. Neste sentido, as ferramentas de inteligência artificial vêm se tornando uma boa ponte entre as técnicas de previsão e as técnicas de engenharia, úteis na referida abordagem, apresentando tratamentos quantitativos e análises de limitações de mercado. O presente trabalho visa desenvolver um modelo de predição da bolsa de valores Brasileira, elaborado na linguagem de programação Python, e verificar a sua capacidade preditiva através da submissão dos dados das séries históricas em redes neurais Long Short Term Memory (LSTM) e Deep Neural Network (DNN). Para isto, foi utilizado mineração de notícias no Twitter de jornais confiáveis, sendo que os dados oriundos dos classificadores baseados em Naive Bayes e Suport Vector Machine (SVM) foram incorporado as séries histórias das empresas Banco do Brasil e Petrobras para serem utilizados nas redes neurais supracitadas. Os resultados mostraram que os classificadores tiveram bons resultados, principalmente o classificados SVM, apresentando uma precisão de 82% de notícias classificadas corretamente para a Petrobras. Já as redes neurais apresentaram uma razoável capacidade preditiva, apresentando RSME de 26,4% utilizando a rede DNN, e 35,1% na rede LSTM para a Petrobras e RMSE de 32,70% utilizando a rede LSTM e 24,25% na rede DNN para o Banco do Brasil. Apesar do banco de dados utilizado ter sido relativamente pequeno, o que pode ter influenciado nos resultados deste trabalho, pesquisas apontam que, em geral, é possível relacionar notícias a alta e a baixa de ações. Quanto a isto, ainda há muitas questões a serem elucidadas a fim de serem encontradas previsões mais realísticas.","Predicting the future is something that humanity craves for, in order to be able to prepare for possible eventualities. Today, combining facility of access to information through news with the use of programs that “read” the feelings of users on the Internet, it is possible to use computer language to even predict market behavior. In the scope of economy, this prediction enables new ways of intervening in the economic market, providing a glimpse of different scenarios, therefore facilitating the decision-making about investments and also about the economic future of entrepreneurs, companies and governments. In this sense, artificial intelligence tools have become a great bridge between forecasting techniques and engineering techniques, useful in that approach, presenting quantitative treatments and limitations analysis. The present work aims to develop a prediction model for the Brazilian Stock Exchange, developed in the Python programming language, and to verify its predictive capacity through the submission of historical series data in Long Short Term Memory (LSTM) and Deep Neural Network (DNN). For this, news were researched on Twitter from trusted newspapers, and data from classifiers based on Naïve Bayes and Support Vector Machine (SVM) were incorporated into the historical series of the companies Banco do Brasil and Petrobras to be used in the aforementioned neural networks. The results showed that the classifiers had good results, mainly the SVM classifier, presenting an accuracy of 82% of correctly classified news for Petrobras. The neural networks had a reasonable predictive capacity, with RSME of 26.4% using the DNN network, and 35.1% in the LSTM network for the Banco do Brasil. Although the database used was relatively small, which may have influenced the results of this study, papers show that, in general, it is possible to relate news with the rising or falling of the stock market. In this regard, there are still many questions to be clarified in order to find realistic predictions.","('Modelo de sentimento (Inteligência artificial)', 'Bolsa de valores', 'Redes neurais (Computação)', 'Aprendizado profundo', 'Análise de séries temporais', 'Sentiment analysis', 'Stock exchange', 'Neural networks', 'Deep learning', 'Time series')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/7536","2020-08-27","https://www.repositorio.ufal.br/bitstream/riufal/7536/1/Modelos%20de%20previs%c3%a3o%20de%20ativos%20utilizando%20aprendizagem%20profunda%20e%20linguagem%20natural.pdf","Stock exchange prediction model based on deep learning and data mining",""
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/2537","Campus A.C. Simões","Instituto de Computação","Dissertação","Modelos e técnicas para melhorar a qualidade da avaliação automática para atividades escritas em língua portuguesa brasileira","('Jário José dos Santos Júnior',)","('Ig Ibert Bittencourt Santana Pinto',)","('Patrick Henrique da Silva Brito', 'Jorge Artur Peçanha de Miranda Coelho')","Diante da sobrecarga gerada pela avaliação de atividades escritas em ambientes EAD, diferentes sistemas, como Coursera e edX, vêm adaptando suas abordagens para a avaliação das devidas atividades. Contudo, utilizando abordagens distintas, ambos os sistemas fazem uso dos mais populares métodos de avaliação dessas atividades, avaliação por pares e avaliação automática. Entretanto, cada técnica apresenta suas vantagens e desvantagens, principalmente sob o olhar na aprendizagem do aluno, uma vez que além de propiciar um aumento na aprendizagem, avaliação por pares se destaca por possuir qualidade na avaliação semelhante ao de um especialista. Mas, avaliação automática ganha olhares por se tratar de um método que provê rápido feedback, e que, quanto maior a base de treino, a técnica apresenta melhor eficácia, além de ser utilizado com o próprio sistema EAD em diferentes aspectos, como por exemplo, acompanhamento das limitações existentes nos alunos, entre outras palavras, quais são as dúvidas que determinado aluno possui, que são extraídas através de características oriundas da avaliação de atividades subjetivas. Com isso, o presente trabalho propõe um modelo de avaliação com qualidade de atividades subjetivas, com o intuito de diminuir a sobrecarga gerada pela avaliação de atividades subjetivas no professor e auxiliar no processo da aprendizagem dos alunos. O sistema foi calibrado com aproximadamente 5407 avaliações e redações, onde passou por um experimento contendo 60 redações que indicou que as avaliações realizada pela abordagem são semelhantes às avaliações realizadas pelo especialista com 95% de nível de confiança. Além de mostrar um precisão mais elevada em relação à avaliação provida pela abordagem.","Against the workload generated by the evaluation of activities written in online learning, different systems, like Coursera and edX, have adapted their approaches to the evaluation of the appropriate activities. However, using differents approaches, both systems do use of the most popular methods of evaluating such activities, peer review, and automatic evaluation. However, each technique presents its advantages and disadvantages, especially under the student learning perspective, since in addition to providing an increase in learning, peer evaluation stands out for having quality in the assessment similar to that of a specialist. But, automatic essay evaluation is a method that provides fast feedback, and how larger the training base is, the technique has better efficacy, in addition to being used with the online learning system in different aspects, such as monitoring the existing limitations in students, among other words, what are the doubts that a student has, which are extracted from patterns derived from the evaluation of subjective activities. Thus, the present work proposes a model to evaluate efficiently subjective activities, reducing the workload generated by the evaluation of subjective activities by the teacher. The automatic essay score system was calibrated with approximately 5407 evaluations and essays, where it underwent an experiment containing 60 essays which indicated that the evaluations carried out by the approach are similar to the expert’s evaluations with 95% level of trust. In addition to showing a higher accuracy in relation to the evaluation provided by the approach.","('Tecnologias educacional', 'Processamento de linguagem natural (PLN)', 'Atividade escrita – Avaliação automática', 'Atividade subjetiva – Avaliação automática', 'Written activity -Automatic evaluation', 'Natural Language Processing', 'Teacher workload', 'Educational Technologies', 'Subjective activity -Automatic evaluation')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/2537","2017-10-20","https://www.repositorio.ufal.br/bitstream/riufal/2537/1/Modelos%20e%20t%c3%a9cnicas%20para%20melhorar%20a%20qualidade%20da%20avalia%c3%a7%c3%a3o%20autom%c3%a1tica%20para%20atividades%20%20escritas%20em%20l%c3%adngua%20portuguesa%20brasileira.pdf","Models and techniques to improve the quality of automatic assessment of written activities in brazilian portuguese","('Ranilson Oscar Araújo Paiva',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/11923","Campus A.C. Simões","Instituto de Computação","Dissertação","Monitoramento do desequilíbrio de tensão e da corrente reversa na rede de distribuição de baixa tensão: uma proposta de sistema computacional que utiliza a infraestrutura de iluminação pública","('Luciano Júlio dos Santos',)","('Erick de Andrade Barboza',)","('André Luiz Lins de Aquino', 'Ronaldo Ribeiro Barbosa de Aquino')","As matrizes energéticas do Brasil e do mundo estão num processo de descentralização da produção de energia devido à expansão da Geração Distribuída (DG) resultado da energia gerada por meio dos Painéis Fotovoltaicos (PV) instalados nos telhados das residências em áreas urbanas. Esta descentralização fez do monitoramento da qualidade da energia das Redes de Distribuição de Baixa Tensão (RDBT) um dos maiores desafios para os Operadores de Sistemas de Distribuição (OSDs) que só estão conscientes dos níveis de qualidade energética por intermédio das queixas dos clientes às distribuidoras. Existem poucos projetos de implementação de sistemas para este fim, possivelmente devido ao elevado investimento necessário para esta tecnologia. Por conseguinte, este trabalho propõe um sistema de monitoramento do sentido do fluxo da corrente elétrica e do Desequilíbrio de Tensão (DT) em uma RDBT, utilizando a Infraestrutura da Iluminação Pública (IIPu). O sistema proposto fornecerá aos OSDs informações em tempo real da qualidade da energia na RDBT por meio de um modelo de aquisição de dados de baixo custo, utilizando a IIPu por meio dos Relés de Telegestão (RT). O sistema foi validado empiricamente por meio do monitoramento de uma rua onde os sistemas de geração fotovoltaica ligados a RDBT injetam energia. Os resultados mostram que o sistema proposto pode identificar a direção da corrente na RDBT e estimar o DT com um erro médio absoluto de 0,096% em comparação com o analisador de energia profissional. Os resultados deste projeto podem trazer contribuições relevantes para o desafio no monitoramento da qualidade da energia; por exemplo, os OSDs podem utilizar o sistema proposto para acessar a informação em tempo real relativa à RDBT por meio de um modelo de aquisição de dados de baixo custo. Espera-se que os resultados deste projeto tragam contribuições relevantes para o desafio no monitoramento dos níveis da qualidade da energia, colaborando assim para uma expansão mais ordenada da distribuição da produção de energia no Brasil.","Brazil’s and the world’s energy matrices are in an energy generation decentralization process due to the Distributed Generation (DG) expansion resulting in the energy generated through Photovoltaic Panels (PP) installed on the roofs of residences in urban areas. This change has made the energy quality monitoring for the Low Voltage Distribution Networks (LVDN) one of the Distribution System Operators (DSO) biggest challenges, who are only aware of the energy quality levels through the customers’ complaints to the distributors. There are few projects implementing systems for this purpose, possibly due to the high investment required for this technology. Therefore, this research proposes a cyber-physical system for monitoring the direction of electric current flow and voltage imbalances in an RDBT using the street lighting infrastructure. The proposed system will provide the DSO’s with real-time information on the power quality in the RDBT through a low-cost data acquisition model using the street lighting infrastructure through Telemanagement Relays (TR). The system was empirically validated by monitoring a street where photovoltaic generation systems stochastically connected to RDBT inject power. The results show that the proposed system can identify the direction of the current in the RDBT and estimate the voltage unbalance with an average absolute error of 0.096% compared to the professional power analyzer. The results of this project can make relevant contributions to the challenge in power quality monitoring; for example, DSO’s can use the proposed system to access real-time information relative to the RDBT through a low-cost data acquisition model. It is expected that the results of this project would bring relevant contributions to the challenge of monitoring the levels of power quality, thus collaborating for a more orderly expansion of the distribution of energy production in Brazil.","('Engenharia de sistemas de computação', 'Sistema de monitoramento', 'Iluminação pública', 'Distribuição de baixa tensão', 'Energia elétrica – Distribuição', 'Direção das Correntes elétricas – Distribuição', 'Sistemas fotovoltaicos integrados em edifícios', 'Computer systems engineering', 'Monitoring system', 'Public Lighting', 'Low voltage distribution', 'Electricity -Distribution', 'Direction of Electric Currents -Distribution', 'Building-integrated photovoltaic systems')","Sistemas de Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/11923","2023-05-23","https://www.repositorio.ufal.br/bitstream/123456789/11923/1/Monitoramento%20do%20desequil%c3%adbrio%20de%20tens%c3%a3o%20e%20da%20corrente%20reversa%20na%20rede%20de%20distribui%c3%a7%c3%a3o%20de%20baixa%20tens%c3%a3o%3a%20uma%20proposta%20de%20sistema%20computacional%20que%20utiliza%20a%20infraestrutura%20de%20ilumina%c3%a7%c3%a3o%20p%c3%bablica.pdf","Monitoring voltage unbalance and reverse current in a low voltage distribution network: a proposal using public lighting infrastructure","('Igor Cavalcante Torres',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/8422","Campus A.C. Simões","Instituto de Computação","Dissertação","Novo modelo de rede neural para detecção de objetos aplicado à inspeção industrial","('Bruno Georgevich Ferreira',)","('Tiago Figueiredo Vieira',)","('Thales Miranda de Almeida Vieira', 'Douglas Cedrim Oliveira')","Em muitas indústrias, a montagem de componentes específicos para serem inseridos em um recipiente de plástico é um procedimento manual. Cada kit deve ser composto por peças específicas seguindo uma receita pré-definida, que pode ser atualizada ao longo do tempo. Kits montados de forma inadequada causam retrabalho, reduzindo a qualidade e o tempo de produção. Aqui propomos melhorias em um modelo de detecção de objetos, capaz de realizar uma inspeção de qualidade, incrementando as funcionalidades do Few-Shot Object Detection (FSOD) baseado no modelo OS2D, previamente proposto na literatura. O modelo OS2D apresenta limitações ao tentar detectar objetos de aspect ratio que não se encaixam nas âncoras predeterminadas. Além disso, ele também tem um mecanismo de inferência que o restringe a apenas uma imagem de referência para cada classe, dificultando a detecção de objetos mais complexo, que se apresentam diferentes para cada ângulo. Dessa forma, foi proposto o modelo OS2D aprimorado (OS2D+) incorporando camadas de distorção e correção e modificando sua estratégia de inferência para facilitar a utilização de múltiplas imagens referências por componente. Para que seja possível avaliar os resultados da solução OS2D+, desenvolveu-se também uma outra solução baseada em processamento de imagens (PIMG), para que os resultados das duas sejam comparados. Foram propostas as camadas de distorção e correção, que compõem à solução OS2D+, permitindo que a mesma possa detectar objetos cujo aspect ratio não se enquadre em nenhuma âncora de detecção do modelo OS2D. O mecanismo de inferência do modelo OS2D também foi modificado, buscando viabilizar a inferência de múltiplas imagens de referência, para cada componente de um kit. Por fim, realizou-se uma comparação entre os desempenhos dos dois modelos, na tentativa de analisar se as modificações realizadas no OS2D+ incrementaram a performance do modelo OS2D em detectar objetos. Após a análise, a solução OS2D+ proposta se mostrou mais robusta que a PIMG, detectando menos falsos positivos e negativos, além de apresentar um tempo de inferência menor. Entretanto, a solução PIMG foi capaz de fornecer melhores estimações de bounding boxes (BB), devido ao seu processo de proposição de localizações. Ainda assim, a solução OS2D+ apresenta potencial para ter estimações equivalentes à PIMG, sendo necessário um ajuste fino em seus parâmetros. Também foi construída uma base de dados composta de 111 fotos, que descrevem cinco kits diferentes e seus respectivos componentes. Essa base de dados foi anotada e utilizada para mensurar os resultados das duas soluções propostas.","In many industries, assembling specific components to be inserted into a plastic container is a manual procedure. Each kit must be comprised of specific parts following a pre-defined recipe, which can be updated throughout time. Kits assembled inadequately cause rework, reducing production quality and time. Here we propose improvements in an object detection model, capable of performing a quality inspection, increasing the features of Few-Shot Object Detection (FSOD) based on the OS2D model, previously proposed in the literature. The OS2D model has limitations when trying to detect objects of aspect ratio that do not fit the predetermined anchors. In addition, it also has an inference mechanism that restricts it to only one reference image for each class, making it difficult to detect more complex objects, which are different for each angle. Bearing in mind this, the improved OS2D model (OS2D+) was proposed, incorporating layers of distortion and correction and modifying its inference strategy to facilitate the use of multiple reference images per component. In order to be able to evaluate the results of the OS2D+ solution, a image processing based solution (PIMG) was also developed, so the results of both solutions can be compared. The distortion and correction layers of the OS2D+ solution allowing it to detect objects whose aspect ratio does not fit into any OS2D detection anchor. The inference mechanism of the OS2D model has also been modified, seeking to enable the inference of multiple reference images to a kit component. Finally, the performances of both models were compared, in an attempt to evaluate whether the modifications proposed in the OS2D+ model improved the ability of the OS2D model of detecting objects. Finally, the proposed OS2D+solution proved to be more robust than PIMG, detecting fewer false positives and negatives, in addition to presenting a shorter inference time. However, the PIMG solution was able to provide better bounding boxes (BB) estimations due to its process of proposing locations. Despite this, the OS2D+ solution has the potential to have equivalent estimations, requiring a fine adjustment in its parameters. A database composed of 111 photos was also built, describing five different kits and their respective components. This database was annotated and used to measure the results of the two proposed solutions.","('Rede neural', 'Monitoração industrial', 'Processamento de imagens', 'Software – monitoramento', 'Components kits inspection', 'Image processing', 'Few-shot learning', 'Few-shot object detection')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/8422","2021-04-23","https://www.repositorio.ufal.br/bitstream/123456789/8422/1/Novo%20modelo%20de%20rede%20neural%20para%20detec%c3%a7%c3%a3o%20de%20objetos%20aplicado%20%c3%a0%20inspe%c3%a7%c3%a3o%20industrial.pdf","New neural network model for object detection applied to industrial inspection",""
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/2000","Campus A.C. Simões","Instituto de Computação","Dissertação","Modelo para a classificação de nódulos pulmonares pequenos usando descritores radiomics","('Ailton Felix de Lima Filho',)","('Marcelo Costa Oliveira',)","('Tiago Figueiredo Vieira', 'Paulo Mazzoncini de Azevedo Marques')","O câncer de pulmão é uma doença caracterizada como crescimento anormal de células que invadem e destroem tecidos vizinhos, sendo responsável por muitas mortes ao redor do mundo. Um diagnóstico precoce da doença, geralmente realizado com base em informações qualitativas e semi-quantitativas extraídas de imagens de Tomografia Computadorizada (TC), traz maiores chances de cura e opções de tratamento para o paciente, porém, devido aos desafios no processo de interpretação de imagens médicas, principalmente no tocante a nódulos pulmonares pequenos (<10mm), o diagnóstico se torna clinicamente difícil, tornando a decisão clínica complexa. Devido à variabilidade e complexidade do diagnóstico de nódulos pulmonares pequenos, ferramentas de Auxílio ao Diagnóstico por Computador (CAD) baseadas em atributos de imagem, providenciam ajuda ao radiologista visando alcançar uma melhor acurácia da classificação de nódulo (provável maligno ou benigno), por agir como uma segunda opinião ao especialista. O uso de atributos radiomics permite um diagnóstico quantitativo mais objetivo se comparado às abordagens qualitativas ou semi-quantitativas mais comumente utilizadas na avaliação do câncer, diminuindo significativamente o problema da variabilidade no diagnóstico. Porém, ainda existe uma necessidade de descobrir conteúdos/atributos relevantes a fim de melhorar o desempenho de sistemas CAD. O objetivo deste trabalho foi desenvolver um modelo para classificação de nódulos pulmonares pequenos usando atributos radiomics extraídos da região de microambiente do nódulo. Foi avaliado também o teste de hipótese de que considerar a região de parênquima no entorno do nódulo, permite uma melhora de desempenho na classificação de nódulos pulmonares pequenos. O modelo para classificação desenvolvido obteve como melhor resultado uma área sob a curva ROC (AUC) média de 0.875 ± 0.048 com o algoritmo Perceptron de Múltiplas Camadas (MLP) com uma validação cruzada 10-fold na classificação de 214 nódulos pulmonares com diâmetros entre 5 e 10mm. Os resultados mostraram a relevância da utilização de atributos radiomics para classificação de nódulos pulmonares pequenos. A utilização da região do parênquima pulmonar melhorou o desempenho do modelo, comprovando o teste de hipótese. A classificação de nódulos pulmonares é uma área desafiadora mesmo para os médicos especialistas, devido à natureza complexa desse tipo de achado radiológico, porém, crítica para sobrevida dos pacientes diagnosticados com câncer. Logo, avanços nessa área são de extrema importância.","Lung cancer is a disease characterized as abnormal cells growth that invade and destroy neighboring tissues, accounting for many deaths around the world. An early diagnosis, usually performed based on qualitative information extracted from CT images, brings greater chances of cure and treatment options for the patient, however, due to the challenges in the medical image interpretation process, mainly for small pulmonary nodules (<10mm), the diagnosis becomes clinically difficult, making the clinical decision complex. Due to the variability and complexity of the diagnosis of small pulmonary nodules, Computer-Aided Diagnosis (CAD) tools based on image features, provides assistance to the radiologist in order to achieve a better accuracy of nodule classification (probable malignant or benign), by acting as a second opinion to the specialist. The use of radiomics features allows a quantitative diagnosis when compared to the recent qualitative strategies of cancer evaluation, significantly reducing the problem of variability in diagnosis. However, discovering the relevant content/features is still a necessity in order to improve the CAD systems performances. The aim of this study was to develop a classification model for small pulmonary nodules using radiomics features extracted from the nodule microenvironment. It was also evaluated the hypotheses test that considering the parenchyma region around the nodule allows an improvement in the small pulmonary nodules classification. The developed classification model obtained the best Area Under the ROC curve (AUC) of 0.875 ± 0.048 with the Multilayer Perceptron (MLP) algorithm with a 10-fold cross-validation in the classification of 214 pulmonary nodules with diameters between 5 and 10mm. The results showed the relevance of radiomics features for the classification of small pulmonary nodules. The use of the pulmonary parenchyma region improved the model performance, proving the hypothesis test. The nodules classification is a challenging area for specialists due to the natural complexity of diagnosis lesions, however, critical for patient survival diagnosed with cancer. Therefore, advances in this area are extremely important.","('Tecnologia da informação', 'Informática médica', 'Diagnóstico auxiliado por computador', 'Nódulo pulmonar', 'Câncer de pulmão', 'Diagnóstico por imagem', 'Radiomics', 'Information technology', 'Medical informatics', 'Diagnostics aided computer', 'Lung node', 'Lung cancer', 'Diagnosis by image')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/2000","2017-07-31","https://www.repositorio.ufal.br/bitstream/riufal/2000/3/Modelo%20para%20a%20classifica%c3%a7%c3%a3o%20de%20n%c3%b3dulos%20pulmonares%20pequenos%20usando%20descritores%20radiomics.pdf","Classification model of small pulmonary nodules using radiomics descriptors","('Aydano Pamponet Machado',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/14077","Campus A.C. Simões","Instituto de Computação","Dissertação","Um modelo computacional de recomendação de tratamento terapêutico personalizado para paciente com quadro séptico","('Flávio Yuri Aquino de Oliveira',)","('Rafael de Amorim Silva',)","('Diego Dermeval de Medeiros da Cunha Matos', 'Almir Pereira Guimarães', 'Filipe Montez Coelho Madeira')","A Informática na Saúde provê recursos para a geração, manutenção, e armazenamento dos dados vitais dos pacientes através de prontuários construídos a partir de sistemas. Este estudo aborda a lacuna identificada na literatura quanto ao suporte técnico aos médicos, especificamente para o fornecimento de sugestões medicamentosas para pacientes com quadro séptico de maneira automática e assistida pelo Machine Learning. Dentro da área da Saúde, a SEPSE se apresenta como um quadro clínico em que o tempo de resposta para esta condição é vital para o paciente. Se não tratada de maneira eficiente e eficaz, o paciente pode evoluir a óbito em menos de 24h. Neste contexto, o presente trabalho tem como ideia principal proporcionar um modelo de Machine Learning para predizer prescrição terapêutica de maneira automática para auxiliar o médico em sua tomada de decisão e personalizada para o paciente. Foram encontrados resultados satisfatórios nos modelos testados para a sugestão, tornando-se um caminho promissor para a mitigação de óbitos decorrentes de SEPSE.","Health Informatics provides resources for the generation, maintenance, and storage of necessary patient data through medical records built from systems. This study addresses the identified gap in the literature regarding technical support for physicians, specifically for the automatic and Machine Learning-assisted provision of medication suggestions for patients with septic conditions. Within the Health area, SEPSIS presents itself as a clinical condition in which the response time for this condition is vital for the patient. If not treated efficiently and effectively, the patient may die in less than 24 hours. In this context, the main idea of this work is to provide a Machine Learning model to automatically predict therapeutics to assist the doctor in their decision-making and personalized for the patient. Satisfactory results were found in the tested models for the suggestion, becoming a promising path for mitigating deaths resulting from SEPSIS.","('SEPSE', 'Aprendizado do computador', 'Prescrição Terapêutica', 'SEPSIS', 'Machine Learning', 'Therapeutic Prescription')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/14077","2023-12-21","https://www.repositorio.ufal.br/bitstream/123456789/14077/1/Um%20modelo%20computacional%20de%20recomenda%c3%a7%c3%a3o%20de%20tratamento%20terap%c3%aautico%20personalizado%20para%20paciente%20com%20quadro%20s%c3%a9ptico.pdf","A computational model for recommending personalized therapeutic treatment for patients with septic","('Bruno Almeida Pimentel',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/1715","Campus A.C. Simões","Instituto de Computação","Dissertação","Um modelo de avaliação por pares gamificado para ambientes educacionais online : um experimento com o meu tutor","('Thyago Tenório Martins de Oliveira',)","('Ig Ibert Bittencourt Santana Pinto',)","('Seiji Isotani', 'Baldoíno Fonseca dos Santos Neto', 'Alan Pedro da Silva')","Nos últimos anos, o uso de tecnologias de informação e comunicação (TIC) aplicado no contexto educacional tem se tornado cada vez mais frequente. Diversos países adaptaram suas abordagens educacionais para promover e suportar a utilização dessas tecnologias tanto em cursos presenciais quanto em cursos a distância. No contexto de Educação à distância, o número de usuários tem crescido consideravelmente, o que torna os ambientes mais complexos, tendo em vista que esses irão gerar uma grande quantidade de atividades para serem avaliadas, tornando o processo de avaliação manual uma tarefa árdua ao professor. Esse problema cresce exponencialmente se quisermos incluir avaliações abertas (escritas), uma vez que às suas correções aumentaria ainda mais o trabalho do professor, devido ao fato de que o processamento por máquina deste tipo de avaliação é uma opção trabalhosa e pouco efetiva, o que implica que as correções sejam feitas por eles individualmente, acarretando na sobrecarga de trabalho e consequentemente um alto custo para correção da produção textual. Com o crescimento do número de estudantes, um maior número de atividades serão feitas a cada momento e a correção pelos professores manualmente se tornaria rapidamente inviável. Existe uma técnica muito usada na literatura chamada avaliação por pares que possibilita a inclusão de avaliações escritas de tal maneira que não seja necessário aumentar os custos vinculados às correções destas, uma vez que os próprios alunos atuam no processo de correção, o que ganha uma independência e liberdade ao professor. No entanto, a aplicação dessa técnica geralmente gera uma insatisfação no aluno, o que pode levar a um fornecimento de um resultado incorreto e enganoso, o que indica que o aspecto motivacional gera comportamentos inadequados por parte dos alunos, comprometendo a aprendizagem e o sistema de avaliação. Dessa forma, é preciso um mecanismo para engajar os participantes do modelo de avaliação por pares, através da utilização de técnicas que tenham a capacidade de ""inflenciar positivamente o estado emocional/cognitivo do aluno. Nesse sentido, esse trabalho propõe um modelo de avaliação por pares juntamente com técnicas de gami cação. Com o modelo proposto é possível unir as vantagens de ambas as técnicas, diminuindo a sobrecarga do professor, economizando seu tempo e esforço para o que realmente é necessário, e consequentemente, diminuindo o custo associado as correções, sem o viés da desmotivação dos alunos no processo, o que possibilita a expansão de cursos para centenas ou até mesmo milhares de usuários. Através de experimentos realizados, foi possível concluir que as notas obtidas com o modelo proposto se equipararam às dos professores, utilizando menos tempo para obtê-las e a um custo aproximadamente 72% menor. Além disso, a gamificação influenciou de forma positiva, aumentando em 11.76% o número de cadastros e em 64.28% o número de acessos. Além disso, a quantidade de redações realizadas aumentou 10.53% e a quantidade de redações corrigidas cresceu em 20%.","In recent years, the use of information and communication technologies (ICT) applied in educational environments has become increasingly usual. Several countries have adapted their educational approaches to promote and support the use of these technologies in both classroom courses as in distance learning courses. In the context of Distance learning, the number of users has grown considerably, making the environments more complex, given that these will generate a lot of activities to be evaluated, making the manual evaluation process a chore to teacher. This problem grows exponentially if we want include open assessments (written), since their corrections would further increase the teacher's work, due to the fact that processing by machine of this type of evaluation is a laborious and less e ective option, which implies that corrections are made by them individually, resulting in overwork and consequently high costs for correction of text production. With the increasing number of students, more activities will be made every now and the correction by the teachers manually would quickly become infeasible. There is a technique widely used in the literature called peer assessment that enables the inclusion of the written evaluations in such a way that it is not necessary to increase the costs linked to these corrections, once the students themselves would act in the correction process, gaining independence and free to the teacher. However, the application of this technique usually generates a student dissatisfaction, which can lead to incorrect and misleading results, which indicates that the motivational aspect generates inappropriate behaviour by students, compromising learning and assessment system. Thus, we need a mechanism to engage the participants in the peer assessment model, using techniques that have the ability to ""influence"" a positive emotional/cognitive state on the student. In this sense, this work proposes an peer assessment model with gami cation techniques. With the proposed model, it is possible to unite the advantages of both techniques, reducing the overwork of the teacher, saving their time and effort to what is really necessary, and consequently reducing the cost associated with the corrections without the bias of demotivation of students in process, which allows the expansion of the courses for hundreds or even thousands of users. Through experiments, we concluded that the grades obtained with the proposed model were equivalent to those of teachers, using less time to to obtain them and at a cost approximately 72% less. Furthermore, gami cation had a positive impact by increasing the register number in 11.76% and 64.28% in the number of logins. Moreover, the amount of realized activities increased 10.53% and the amount of corrected activities increased by 20%.","('Ambiente escolar', 'Tecnologias de informação e comunicação', 'Ensino a distância', 'School environment', 'Information and communication technologies', 'Distance education')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1715","2015-06-15","https://www.repositorio.ufal.br/bitstream/riufal/1715/1/Um%20modelo%20de%20avalia%c3%a7%c3%a3o%20por%20pares%20gamificado%20para%20ambientes%20educacionais%20online.pdf","A model of peer evaluation gamification for online educational environments : an experiment with my tutor",""
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/9174","Campus A.C. Simões","Instituto de Computação","Dissertação","Um modelo de crowdsourcing para gestão de atos normativos dos conselhos de educação do Brasil","('Emerson Martins da Silva',)","('Alan Pedro da Silva',)","('Ranilson Oscar Araújo Paiva', 'Seiji Isotani')","A participação da sociedade tornou-se primordial nos processos de construção de políticas públicas educacionais. A Constituição Federal de 1988 (CF/88) preconizou a criação dos espaços públicos para a participação popular instituindo os conselhos gestores que exercem um canal de ligação entre os anseios da população e os entes públicos. O modelo de gestão participativa tem como premissa a participação do cidadão no processo de tomada de decisão, trazendo assim o cidadão para mais perto dos processos decisórios. Nesse contexto, crowdsourcing surge como um meio de viabilizar o potencial da gestão colaborativa e a participação popular, utilizando-se de uma grande quantidade de pessoas conectadas à uma plataforma através da internet para resolver problemas colaborativamente. No entanto a maioria dos modelos de crowdsourcing existentes, geralmente estão voltados para o conceito de entidades hierarquicas, e não atendem totalmente ao cenário de elaboração e manutenção de atos normativos pelos Conselhos de Educação no Brasil, entidades autônomas com processos de trabalhos heterogêneos e responsáveis por um grande arcabouço de atos normativos. Diante deste cenário, a proposta nesta dissertação é um ""Modelo de Crowdsourcing para a Gestão de Atos Normativos dos Conselhos de Educação"", com objetivo de aumentar a participação popular nas políticas públicas da educação e a gestão de atos normativos dos Conselhos de Educação, durante o processo de tomada de decisão. O modelo possui uma arquitetura de software para suportar o modelo crowdsourcing proposto com base nos requisitos de software coletados nas reuniões utilizando o Método Speed Dating e sessões de storyboards e posteriormente efetuada a validação com engenheiros e arquitetos de software. Visando validar a participação foi realizado um estudo de caso com conselheiros de educação e especialistas em educação. Os resultados preliminares das avaliações e do estudo de caso mostraram que o modelo crowdsourcing poderá contribuir significantemente com o aumento da participação pública e na gestão de atos normativos trazendo oportunidades que outrora não eram exploradas pelos conselhos de educação.","The participation of society has become essential in the construction of public education policies. The Federal Constitution of 1988 (CF/88) advocated the creation of public spaces for popular participation, instituting management councils that act as a link between the population’s concerns and public entities. The participatory management model is premised on citizen participation in the process of taking the decision, thus bringing the citizen closer to decision-making processes. In this context, crowdsourcing emerges as a means to enable the potential of collaborative management and popular participation, using a large number of people connected to a platform through the internet to solve problems collaboratively. However, most of the existing crowdsourcing models are generally focused on the concept of hierarchical entities and do not fully meet the scenario of elaboration and maintenance of normative acts by the Education Councils in Brazil, autonomous entities with heterogeneous work processes, and responsible for a great framework of normative acts. Given this scenario, the proposal in this dissertation is a ""Crowdsourcing Model for the Management of Normative Acts of Education Councils"", intending to increase popular participation in public education policies and the management of normative acts of Education Councils, during the decision-making process. The model has a software architecture to support the proposed crowdsourcing model based on the software requirements collected in the meetings using the Speed Dating Method and storyboard sessions and later validated with software engineers and architects. The participation of society in the design and construction of public educational policies has become increasingly essential. In Brazil, often well-defined programs and projects get lost along the way and do not achieve the expected results, as they do not actually represent the population’s needs and desires. Crowdsourcing, which relies on collective collaboration from a large group of people connected through the web, has often been used by private companies as a way of successfully solving problems of various modalities. In this dissertation, we propose the ""Crowdsourcing Model for the Management of Normative Acts in Education"", aiming to increase the participation of citizens and support decision-making by education councils (autonomous entities) during the elaboration of public educational policies in Brazil. To validate the model, we apply the Speed Dating method using storyboard sessions as participants. The Speed Dating method revealed opportunities and needs of two users during the work of meeting requirements and business meetings. We value a software architecture that is intended to support the complex, heterogeneous and autonomous environment of the Brazilian Education Councils. The preliminary results of the appraisals and the case study will show that the suggested crowdsourcing model will be able to contribute significantly to the implementation of public education policies, providing opportunities that were not previously explored by education.","('Crowdsourcing', 'Atos normativos', 'Políticas públicas -Brasil', 'Conselhos de educação -Brasil', 'Cidadão', 'Crowdsourcing', 'Normative Acts', 'Public Policies -Brazil', 'Education Councils -Brazil', 'Citizen')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/9174","2021-10-28","https://www.repositorio.ufal.br/bitstream/123456789/9174/1/Um%20modelo%20de%20crowdsourcing%20para%20gest%c3%a3o%20de%20atos%20normativos%20dos%20conselhos%20de%20educa%c3%a7%c3%a3o%20do%20Brasil.pdf","The crowdsourcing model for the management of normative acts in education","('Ivo Augusto Andrade Rocha Calado',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/7782","Campus A.C. Simões","Instituto de Computação","Dissertação","Modelo de análise e predição para identificação dos fatores que influenciam o desempenho escolar na rede de ensino básico: estudo de caso em escolas municipais de Alagoas","('Glevson da Silva Pinto',)","('Evandro de Barros Costa',)","('Thales Miranda de Almeida Vieira', 'Rodrigo Lins Rodrigues')","As transformações ocorridas na gestão e organização dos sistemas educacionais vêm demandando a tomada de decisões no sentido de melhorar o processo de ensino e aprendizagem nas instituições educacionais públicas do Brasil. Nesse sentido, o Ministério da Educação criou o Índice de Desenvolvimento da Educação Básica (IDEB), para avaliar e monitorar o processo educativo das escolas brasileiras. Neste contexto, particularmente, a Mineração de Dados Educacionais tem provido técnicas e, deste modo vem auxiliando educadores e gestores no apoio a tomada de decisões, permitindo extração de informações relevantes de bases de dados. Situado na mencionada área este trabalho objetiva explorar técnicas de seleção de atributos e algoritmos preditivos, visando identificar quais fatores impacta no IDEB das escolas municipais de Alagoas. Assim, visa-se auxiliar no processo decisório dos gestores educacionais, para posteriores estudos e reflexões na área da educação. Para tanto, utilizou-se dados do teste Saeb das escolas públicas de Maceió e de Teotônio Vilela, conduzindo um estudo experimental, produzindo relevantes resultados na tarefa de identificação de atributos relevantes para apoiar os gestores educacionais. Os resultados indicam que diversos fatores influenciam o desempenho dos alunos, tais como: a escolaridade dos pais do aluno, o incentivo aos estudos, o compromisso do docente e o estilo de gestão.","The transformations that have occurred in the management and organization of educational systems have been demanding decisions to improve the teaching and learning process in public educational institutions in Brazil. In this sense, the Ministry of Education created the Basic Education Development Index (IDEB), to evaluate and monitor the educational process of Brazilian schools. In this context, in particular, Educational Data Mining has provided techniques and, thus, has been helping educators and managers to support decision making, enabling the extraction of relevant information from databases. Situated in the aforementioned area, this work aims to explore attribute selection techniques and predictive algorithms, aiming to identify which factors impact on the IDEB of Alagoas municipal schools. Thus, it aims to assist in the decision-making process of educational managers, for further studies and reflections in the area. of education. Therefore, data from the Saeb test of the public schools of Maceió and Teotônio Vilela were used, conducting an experimental study, producing relevant results in the task of identifying relevant attributes to support educational managers. The results indicate that several factors influence student performance, such as the student's parents' education, the incentive to study, the teacher's commitment and the management style.","('Índice de Desenvolvimento da Educação Básica (Brasil. Ministério da Educação) -Alagoas', 'Mineração de dados (Computação)', 'Educação', 'Aprendizagem de máquina', 'Educational data mining', 'Attribute selection', 'Machine learning', 'IDEB')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/7782","2019-11-18","https://www.repositorio.ufal.br/bitstream/riufal/7782/1/Modelo%20de%20an%c3%a1lise%20e%20predi%c3%a7%c3%a3o%20para%20identifica%c3%a7%c3%a3o%20dos%20fatores%20que%20influenciam%20o%20desempenho%20escolar%20na%20rede%20de%20ensino%20b%c3%a1sico%3a%20estudo%20de%20caso%20em%20escolas%20municipais%20de%20Alagoas.pdf","Analysis and prediction model to identify factors that influence school performance in the basic education network: case study in municipal schools in Alagoas","('Olival de Gusmão Freitas Júnior',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/13273","Campus A.C. Simões","Instituto de Computação","Dissertação","Um modelo de gestão da qualidade para projetos crowdsourcing no setor público","('Bruno Ferreira Barbosa Rocha',)","('Alan Pedro da Silva',)","('Ranilson Oscar Araújo Paiva', 'Fernando Silvio Cavalcante Pimentel', 'Rafael Ferreira Leite de Mello')","No processo de gestão democrática, os governos tem se preocupado em se aproximar cada vez mais dos seus governados. A participação do cidadão na gestão pública é algo que faz parte dos governos (Liu, 2021). Decisões do governo com a participação pública tem se mostrado eficientes para resolver os problemas existentes nas comunidades e na sociedade como um todo. Crowdsourcing tem se mostrado um modelo de terceirização coletiva eficiente e eficaz para ajudar os governos a tomar decisões com a participação popular, estreitando o relacionamento com o cidadão e usando a chamada democracia digital. Plataformas e outras ferramenas que são usadas em projetos públicos com Crowdsourcing tem sido cada vez mais úteis para que o cidadão possa participar da gestão pública e fazer valer o exercício da cidadania. Porém, falta para as equipes que trabalham com projetos públicos usando Crowdsourcing, um modelo que possibilite padronizar os trabalhos, e tragam diretrizes que apontem para um nível de qualidade para estes projetos, para que os resultados possam retornar o que e fato foi alinhado no início do projeto. Este trabalho propõe um modelo de gestão da Qualidade construído baseado nos gargalos identificados na revisão da literatura, nos relatos colhidos através de entrevistas com especialistas em projetos públicos e na disciplina de gestão da qualidade do PMBOK (o guia para melhores práticas para gestão de projetos mais usado no mundo). O modelo proposto nesta pesquisa trará um padrão de qualidade aos projetos públicos usando Crowdsourcing, e consequentemente melhorará a participação do cidadão na gestão pública.","In the process of democratic management, governments have been concerned with getting closer and closer to their governed. Citizen participation in public management is something that is part of modern government. Government decisions with public participation have proven to be efficient to solve existing problems in the communities and in society as a whole. Crowdsourcing has proven to be an efficient and effective collective outsourcing model to help governments make decisions with popular participation, strengthening the relationship with the citizen and using the so-called digital democracy. Platforms and other tools that are used in public projects with Crowdsourcing have been increasingly useful for citizens to participate in public management and enforce the exercise of citizenship. However, the teams that work with public projects using Crowdsourcing lack a model that makes it possible to standardize the work, and bring guidelines that point to a level of quality for these projects, so that the results can return what was in fact aligned at the beginning of the project. This work proposes a quality management model based on the bottlenecks identified in the literature review, on the reports collected through interviews with experts in public projects, and on the quality management discipline of the PMBOK (the world’s most widely used project management best practices guide). The model proposed in this research will bring a quality standard to public projects using Crowdsourcing, and consequently improve citizen participation in public management.","('Crowdsourcing', 'Projetos públicos', 'Tecnologia da informação – Gestão pública', 'Participação pública – Projetos', 'Gestão da qualidade total', 'Public projects', 'Information technology – Public management', 'Public participation – Projects', 'Total quality management')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/13273","2023-07-10","https://www.repositorio.ufal.br/bitstream/123456789/13273/1/Um%20modelo%20de%20gest%c3%a3o%20da%20qualidade%20para%20projetos%20crowdsourcing%20no%20setor%20p%c3%bablico.pdf","A quality management model for crowdsourcing in the public sector","('Ivo Augusto Andrade Rocha Calado',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/5402","Campus A.C. Simões","Instituto de Computação","Dissertação","Modelo computacional para classificação de nódulos pulmonares utilizando redes neurais convolucionais","('Lucas Lins de Lima',)","('Marcelo Costa Oliveira',)","('Thales Miranda de Almeida Vieira', 'Paulo Mazzoncini de Azevedo Marques')","O câncer é uma doença em que as células do organismo de repente começam a ter um crescimento desordenado e que com o tempo passam a invadir os tecidos e órgãos, espalhando-se (metástase) para outras regiões do organismo. Dentre os mais de 100 tipos de câncer, o câncer de pulmão já é o que mais mata em todo o mundo, onde em cada 5 mortes, 1 é causada por este câncer. Contudo, se o diagnóstico for realizado no início da doença as taxas de sobrevivência de 1 ano são de aproximadamente de 15-19%. A principal manifestação do câncer de pulmão se inicia através do nódulo pulmonar, que apresentam diâmetros maiores entre 3mm e 30mm. O diagnóstico do nódulo pulmonar é realizado principalmente através de imagens de Tomografia Computadorizada (TC), porém, realizar este diagnóstico ainda representa uma tarefa complexa e desafiadora para os especialistas, pois os nódulos podem estar localizados em estruturas complexas do pulmão e a quantidade de exames ou imagens que chegam para serem examinados é cada vez maior. Assim, é essencial a integração de uma ferramenta de Auxílio ao Diagnóstico por Computador (CADx) à interpretação de imagens médicas, que tem como objetivo agir como uma segunda opinião aos especialistas através de uma sugestão fornecida por um modelo computacional. Há vários trabalhos propostos na literatura para auxiliar melhor os especialistas no diagnóstico do nódulo pulmonar, seja utilizando atributos radiomics aliado a uma técnica de aprendizagem de máquina, seja utilizando técnicas de aprendizagem profunda, que têm chamado a atenção tanto na comunidade científica como também na indústria. Mais especificamente, Redes Neurais Convolucionais (RNCs) têm se tornado uma tendência para classificar imagens. Porém, ainda existe uma busca por um modelo computacional que melhore o desempenho de sistemas CADx. Nesse contexto, o objetivo deste trabalho foi pesquisar e desenvolver um modelo computacional para classificar nódulos pulmonares em benignos ou malignos utilizando uma RNC junto com uma técnica de otimização hiperparamétrica. O modelo conseguiu os seguintes resultados: sensibilidade de 95%, especificidade de 100%, acurácia de 85% e área sob a curva ROC (AUC) de 0,93, em um conjunto de imagens médicas composta de nódulos pulmonares sólidos de TC com diâmetro entre 3mm e 30mm. Os resultados mostraram a importância de se analisar a região do parênquima em uma proporção bem próxima dos nódulos para alcançar uma performance maior na classificação dos nódulos pulmonares, e também, que a análise do parênquima isolado leva a resultados melhores do que analisar apenas o nódulo ou o nódulo com o parênquima.","Cancer is a disease that occurs when the organism’s cells suddenly begin to grow disorderly and over time invading tissues and organs, spreading (metastasizing) to other regions of the body. Among the more than 100 cancers, lung cancer is just the one that causes more deaths in the world, wherein every 5 deaths, 1 is caused by this cancer. However, if the diagnosis is made at the beginning of the disease, the 1-year survival rates are approximately of 15-19%. The main manifestation of lung cancer is the initiation of the pulmonary nodule, which hás larger diameters between 3mm and 30mm. The diagnosis of the pulmonary nodule is performed mainly through Computed Tomography (CT) images, however, performing this diagnosis still represents a complex and challenging task for the specialists, since the nodules can be located in complex structures of the lung and the number of exams or images that come to be examined is increasing. Thus, it is essential to integrate a tool of Computer Diagnostic Assistance (CADx) in the interpretation of medical images, which aims to act as a second opinion to specialists through a suggestion provided by a computational model. There are a number of papers proposed in the literature to better assist specialists in pulmonary nodule diagnosis, whether using radiomics attributes associated with a machine learning technique or using deep learning techniques, which have called the attention both in the scientific community as well as in industry. More specifically, Convolutional Neural Networks (CNNs) has become a trend for images. However, there is still a search for a computational model that improves the performance of CADx systems. In this context, the objective of this work was to research and develop a computational model to classify lung nodules in benign or malignant using a CNN together with a hyperparametric optimization technique. The model obtained the following results: sensitivity of 95%, specificity of 100%, an accuracy of 85% and under the ROC curve (AUC) of 0.93 in a set of medical images composed of solid pulmonary nodules of CT with a diameter between 3mm and 30mm. The results showed the importance of analyzing the parenchyma region in a very close proportion of the nodules to achieve a higher performance in the classification of the pulmonary nodules, and also that the analysis of the isolated parenchyma leads to better results than analyzing only the nodule or the nodule with the parenchyma.","('Neoplasias pulmonares', 'Diagnóstico por computador', 'Redes neurais (Computação)', 'Nódulos pulmonares', 'Lung Cancer', 'Computer-Aided Diagnosis', 'Deep Learning', 'Neural Networks (Computation)', 'Hyperparameter Optimization')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/5402","2019-01-31","https://www.repositorio.ufal.br/bitstream/riufal/5402/1/Modelo%20computacional%20para%20classifica%c3%a7%c3%a3o%20de%20n%c3%b3dulos%20pulmonares%20utilizando%20redes%20neurais%20convolucionais.pdf","Computational model for classification of pulmonary nodules using convolutional neural networks",""
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/13504","Campus A.C. Simões","Instituto de Computação","Dissertação","Modelo de minimização de entropia da informação aplicado à compressão de dados digitais","('Marcos Antonio Barbosa Lima',)","('Leandro Melo de Sales',)","('Evandro de Barros Costa', 'Joseana Macêdo Fechine Régis de Araújo')","Neste trabalho são apresentados os resultados da avaliação experimental de um modelo proposto de minimização de entropia da informação em processos de compressão de dados digitais. Durante a pesquisa foram analisados modelos matemáticos e alfabetos utilizados em codificação de dados digitais. A abordagem adotada foi a codificação de dados digitais em estrutura geométrica totalmente simétrica no espaço. Na execução dos experimentos, foram monitorados diversos aspectos relacionados ao processo de codificação de dados, como esforço computacional, taxa de compressão, entropia inicial e final. Como resultado deste trabalho, constatou-se a eficácia do modelo de redução de entropia de dados, o qual reduz a zero a incerteza de informações em aglomerados de dados digitais. Desta forma, os processos de codificação resultantes deste modelo terão como saída uma quantidade constante de dados, independentemente do tamanho dos conjuntos de origem e permitem a decodificação sem perdas de dados, reduzindo assim a entropia da informação a níveis próximos a zero.","In this work, the results of the experimental evaluation of a proposed model of information entropy minimization in digital data compression processes are presented. During the research, mathematical models and alphabets used in encoding digital data were analyzed. The approach adopted was the encoding of digital data in a geometric structure totally symmetric in space. During the execution of the experiments, several aspects related to the data encoding process were monitored, such as computational effort, compression rate, initial and final entropy. As a result of this work, the effectiveness of the data entropy reduction model was verified, which reduces the uncertainty of information in digital data clusters to zero. In this way, the encoding processes resulting from this model will output a constant amount of data, regardless of the size of the source sets and allow lossless decoding of data, thus reducing the entropy of information to levels close to zero.","('Entropia', 'Informação', 'Compressão de dados (Computação)', 'Algoritmos', 'Entropy', 'Information', 'Data compression (Computation)', 'Algorithm')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/13504","2022-08-31","https://www.repositorio.ufal.br/bitstream/123456789/13504/1/Modelo%20de%20minimiza%c3%a7%c3%a3o%20de%20entropia%20da%20informa%c3%a7%c3%a3o%20aplicado%20%c3%a0%20compress%c3%a3o%20de%20dados%20digitais.pdf","Information entropy minimization model applied to digital data compression",""
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/7471","Campus A.C. Simões","Instituto de Computação","Dissertação","MMI-GAN: multi medical imaging translation using generative adversarial network","('Eduardo Felipe de Souza',)","('Marcelo Costa Oliveira',)","('Tiago Figueiredo Vieira', 'Paulo Mazzoncini de Azevedo Marques')","A tradução de imagens médicas é considerada uma nova fronteira no campo da análise de imagens médicas, com grande potencial de aplicação. No entanto, as abordagens existentes têm escalabilidade e robustez limitadas no manuseio de mais de dois domínios de imagens, uma vez que diferentes modelos devem ser criados independentemente para cada par de domínios. Para resolver essas limitações, desenvolvemos a MMI-GAN, uma nova abordagem para tradução entre múltiplos domínios de imagem, capaz de traduzir imagens intermodais (TC e RM) e intramodais (PD, T1 e T2) usando apenas um único gerador e um discriminador, treinados com dados de imagens de todos os domínios. Propomos uma arquitetura GAN que pode ser facilmente estendida a outras tarefas de tradução para o benefício da comunidade de imagens médicas. A MMI-GAN baseia-se nos avanços recentes na área das GANs (Generative Adversarial Network), utilizando uma estrutura adversária com uma nova combinação de perdas não adversárias, que permite o treino simultâneo de vários conjuntos de dados com diferentes domínios numa mesma rede, bem como a capacidade inovadora de traduzir com flexibilidade entre e intra/inter modalidades. As imagens traduzidas pelo MMI-GAN conseguiram obter MAE de 5.792, PSNR de 27.398, MI de 1.430 e SSIM de 0.900. Os seus resultados se mostraram, por muitas vezes estaticamente equiparáveis ou superiores a Pix2pix e em quase todas as traduções foi superior a Cyclegan.","Medical image translation is considered a new frontier in the field of medical image analysis, with great potential for application. However, existing approaches have limited scalability and robustness in handling more than two image domains, since different models must be created independently for each pair of domains. To address these limitations, we developed MMI-GAN, a new approach for translation between multiple image domains, capable of translating intermodal (CT and RM) and intramodal (PD, T1 and T2) images using only a single generator and a discriminator, trained with image data from all domains. We propose a GAN architecture that can be easily extended to other translation tasks for the benefit of the medical imaging community. MMI-GAN is based on recent advances in the area of GANs (Generative Adversarial Network), using an adversary structure with a new combination of non-adversarial losses, which allows the simultaneous training of several data sets with different domains in the same network, as well as the innovative capacity to translate with flexibility between and inter/intra modalities. The images translated by MMI-GAN managed to obtain MAE of 5.792, PSNR of 27.398, MI of 1.430 and SSIM of 0.900. Its results were shown, often statically comparable or superior to Pix2pix and in almost all translations it was superior to Cyclegan.","('Generative adversarial network', 'Tradução de imagens', 'Imagem por ressonância magnética', 'Tomografia computadorizada', 'Generative adversarial networks', 'Image translation', 'Multi-domain', 'Magnetic resonance', 'Computed tomography')","Ciência da Computação","eng","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/7471","2020-11-27","https://www.repositorio.ufal.br/bitstream/riufal/7471/1/MMI-GAN%20-%20Multi%20medical%20imaging%20translation%20using%20Generative%20Adversarial%20Network.pdf","MMI-GAN: tradução multi-imagem médica usando rede adversarial generativa",""
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/2043","Campus A.C. Simões","Instituto de Computação","Dissertação","Um método para a poiar decisões de projeto em aplicações web com streaming de mídia visando desempenho e escalabilidade","('Anderson Mendes dos Santos',)","('Patrick Henrique da Silva Brito',)","('Baldoíno Fonseca dos Santos Neto', 'Aydano Pamponet Machado')","O avanço da arquitetura em que as aplicações são oferecidas aos clientes atuais, baseada em computação em nuvem, contribuiu para que as aplicações com streaming de mídia passassem a ser uma das formas mais utilizadas de entrega de conteúdo. O presente trabalho tem como finalidade a investigação de tecnologias de desenvolvimento Web que possam auxiliar projetos de aplicações baseadas em streaming de mídia. Para tal, foi proposto um método que é aplicado no contexto desse trabalho como um caso teste. Entre as diversas etapas, é feito um estudo comparativo das principais tecnologias (linguagem de programação e framework) utilizadas atualmente, destacando as duas mais promissoras pra uma comparação mais detalhada: uma tecnologia baseada em Java e outra baseada em Python. A seleção de uma arquitetura de referência a ser utilizada como base para o projeto e implementação das aplicações de teste. Também é utilizado um método de avaliação de desempenho e escalabilidade através benchmarking, onde foram definidos cenários com 10, 100 e 1000 usuários executando pelo período de 20 minutos em um ambiente controlado. As tecnologias foram avaliadas em termos de uso de CPU, uso de memória RAM, tempo de resposta e taxa de transferência com uso de pseudo streaming. Como resultado da aplicação do método, temos que Java tende a ter melhor desempenho em algumas métricas, à medida que a quantidade de usuários cresce; enquanto Python se mostra constante e uma boa solução em cenários com menos usuários.","The advancement of architecture in which applications are offered to current customers, based on cloud computing, contributed to applications with streamingmedia have become one of themost used forms of delivery content. This research has purpose to research web development technologies that can assist projects of web applications for streaming media. For this, a method was proposed that is applied in the context of thiswork as a test case. Among the several steps, a comparative study was done on several sources of which technologies (programming language and framework) are more promising and selected two: a technology based on Java and another based on Python. It selected a reference architecture to serve as the basis for the design and implementation of experiments. Through a performance evaluation method, benchmarking, the scenarios were defined with 10, 100 and 1000 users running the 20 minute period in a controlled environment. The technologies were evaluated in terms of CPU, RAM, response time and throughput with the use of pseudo streaming. As a result of the application of the method, we have that Java tends to performbetter in some metrics, as the number of users grows; While Python is steady and a good solution in scenarios with fewer users.","('Streaming de Mídia', 'Apoio ao desenvolvedor', 'Throughput', 'Tecnologias de desenvolvimento Web', 'Linguagem de programação – Avaliação', 'Choice of technology', 'Developer Support', 'Performance', 'Through-put', 'Evaluation', 'Streaming media')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/2043","2016-12-16","https://www.repositorio.ufal.br/bitstream/riufal/2043/1/Um%20m%c3%a9todo%20para%20apoiar%20decis%c3%b5es%20de%20projeto%20em%20aplica%c3%a7%c3%b5es%20web%20com%20streaming%20de%20m%c3%addia%20visando%20desempenho%20e%20escalabilidade.pdf","A method to support design decisions in web applications with streaming media aimig performance and scalability",""
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/14877","Campus A.C. Simões","Instituto de Computação","Dissertação","Uma meta-heurística para o problema da mochila com penalidades","('Matheus Machado Vieira',)","('Rian Gabriel Santos Pinheiro',)","('Dimas Cassimiro do Nascimento Filho', 'Erick de Andrade Barboza')","O problema da mochila está entre um dos problemas combinatórios mais conhecidos. Seu potencial de aplicação e as inúmeras variações que existem fazem dele um bom modelo para diversos problemas práticos da vida real. Mais especificamente, este trabalho aborda uma variante do problema, o Problema da Mochila com Penalidades (PMP, ou, em inglês, KPF). Nesta variante, é fornecido um conjunto de itens e um grafo de conflitos, e o objetivo é identificar uma coleção de itens que respeite a capacidade da mochila enquanto maximiza o valor total dos itens menos as penalidades pelos itens conflitantes. O PMP tem tido algum engajamento tanto por sua proximidade com outros problemas famosos, como o do conjunto independente de peso máximo, e suas aplicações. Alguns exemplos compreendem desde a organização da força de trabalho em chão de fábrica até problemas de decisão em investimentos. Este trabalho apresenta um novo método para o problema utilizando-se de ferramentas já bem estabelecidas, baseado na hibridização de Iterated Local Search (ILS), Variable Neighborhood Descent (VND), e elementos de Tabu Search. Nosso método leva em consideração quatro estruturas de vizinhança, introduzidas com estruturas de dados eficientes para explorá-las. Resultados experimentais demonstram que a abordagem proposta supera os algoritmos de ponta na literatura. Em particular, o método proposto fornece soluções superiores em tempos de computação significativamente mais curtos em todas as instâncias de referência. Também foi incluída uma análise de como as estruturas de dados propostas influenciaram tanto a qualidade das soluções quanto o tempo de execução do método.","The knapsack problem is among one of the most well-known combinatorial problems. Its potential for application and the numerous variations that exist make it a good model for various practical real-life problems. More specifically, this work addresses a variant of the problem, the Knapsack Problem with Forfeits (KPF). In this variant, a set of items and a conflict graph are provided, and the goal is to identify a collection of items that respects the knapsack’s capacity while maximizing the total value of the items minus the penalties for conflicting items. The KPF has garnered some attention both due to its proximity to other famous problems, such as the maximum weight independent set, and its applications. Some examples range from workforce organization on the factory floor to decision problems in investments. This work presents a new method for the problem using well-established tools, based on the hybridization of Iterated Local Search (ILS), Variable Neighborhood Descent (VND), and elements of Tabu Search. Our method takes into account four neighborhood structures, introduced with efficient data structures to explore them. Experimental results demonstrate that the proposed approach outperforms state-of-the-art algorithms in the literature. In particular, the proposed method provides superior solutions in significantly shorter computation times on all reference instances. An analysis of how the proposed data structures influenced both the quality of the solutions and the method’s execution time is also included.","('Otimização combinatória', 'Problema da mochila', 'Meta-heurísticas', 'Busca local iterada', 'Descida em vizinhança variável', 'Combinatorial optimization', 'Knapsack problem', 'Metaheuristics', 'Iterated Local Search', 'Variable Neighborhood Descent')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/14877","2024-01-31","https://www.repositorio.ufal.br/bitstream/123456789/14877/1/Uma%20meta-heur%c3%adstica%20para%20o%20problema%20da%20mochila%20com%20penalidades.pdf","","('Bruno Costa e Silva Nogueira',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/13304","Campus A.C. Simões","Instituto de Computação","Dissertação","Modelagem computacional para recomendação de parâmetros de dispositivos de assistência ventricular pulsáteis por meio da análise da resposta cardiovascular","('Cleberson dos Santos Machado',)","('Thiago Damasceno Cordeiro',)","('Álvaro Alvares de Carvalho César Sobrinho', 'Lenardo Chaves e Silva')","Doenças cardiovasculares representam grande parte das causas de morte no Brasil. Em casos graves, o uso de bombas mecânicas chamadas dispositivos de assistência ventricular (DAVs), projetadas para estender a perspectiva de vida do paciente, podem salvar vidas. Neste trabalho é proposto o uso de um modelo de parâmetro agregado acoplado (modelo 0D) do sistema cardiovascular humano (SCH) com um modelo 0D de um DAV pulsátil (PDAV). O objetivo principal desta pesquisa a recomendação de parâmetros do PDAV para melhorar as respostas fisiológicas dos pacientes. Embora a literatura acadêmica existente se refira apenas a metodologias aplicadas a DAVs rotacionais, existe uma lacuna substancial na aplicação dessas metodologias a dispositivos pulsáteis. A recomendação visa determinar a combinação ideal de dois parâmetros do dispositivo: a pressão de ejeção (Pe) e o instante de ejeção (δP DAV ) entre dois batimentos cardíacos consecutivos. Os intervalos de confiança para um conjunto específico de variáveis hemodinâmicas foram obtidos na literatura. Uma função objetivo avaliou se todas as variáveis hemodinâmicas permanecem dentro dos intervalos de confiança especificados para uma determinada combinação de Pe e δPDAV. Os resultados demonstraram a viabilidade de determinar uma combinação ideal de Pe e δPVAD do modo de operação do PDAV em relação a um conjunto específico de variáveis hemodinâmicas.","Cardiovascular diseases significantly impact global mortality rates. In cases of heightened severity, using ventricular assist devices (VADs) provides a vital conduit for patients, thereby extending life expectancy. This article employs a coupled lumped parameter model (0D-model) of the human cardiovascular system (HCS) with a 0d-model of a pulsatile VAD (PVAD). The primary objective of this research is to recommend PVAD parameters to enhance patients’ physiological responses. While the existing academic literature pertains solely to methodologies applied to rotational VADs, a substantial gap exists in applying these methodologies to pulsatile devices. The recommendation aims to determine the ideal combination of two device parameters: the ejection pressure (Pe) and the ejection instant (δP V AD) between two consecutive heartbeats. Confidence intervals for a specific set of hemodynamic variables were obtained from the literature. An objective function assessed whether all hemodynamic variables remain within the specified confidence intervals for a given combination of Pe and δPVAD. Results demonstrate the feasibility of determining an ideal combination of Pe and δPVAD for the operating mode of the PVAD concerning a specific set of hemodynamic variables.","('Sistema cardiovascular humano', 'Coração auxiliar -Modos de operação', 'Recomendação de parâmetros', 'Dispositivo de Assistência Ventricular', 'Modos de Operação', 'Parameter Recommendation', 'Human Cardiovascular System', 'Ventricular Assist Device', 'Operation Modes')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/13304","2023-09-05","https://www.repositorio.ufal.br/bitstream/123456789/13304/1/Modelagem%20computacional%20para%20recomenda%c3%a7%c3%a3o%20de%20par%c3%a2metros%20de%20dispositivos%20de%20assist%c3%aancia%20ventricular%20puls%c3%a1teis%20por%20meio%20da%20an%c3%a1lise%20da%20resposta%20cardiovascular.pdf","",""
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/9178","Campus A.C. Simões","Instituto de Computação","Dissertação","Metodologias ágeis na aprendizagem colaborativa baseada em projetos","('Carla Fabiana Gomes de Souza',)","('Alan Pedro da Silva',)","('Ranilson Oscar Araújo Paiva', 'Rachel Carlos Duque Reis')","A aquisição de competências, tais quais a comunicação e o comprometimento é desafiante. Neste sentido, recentes estudos da literatura, mostram que ao serem aplicadas Metodologias Ágeis (MA) há benefícios. Estudos também mostram que ao formar grupos pode-se maximizar os ganhos de aprendizagem e satisfação dos participantes. Neste trabalho, conceitualizamos e avaliamos a Formação de Grupos de Alto Desempenho (FGAD) para aplicar MA em cenários de Aprendizagem Colaborativa Baseada em Projetos (CPBL), no qual com base nos fatores e características individuais dos participantes, procuram maximizar o desempenho dos grupos. Através de uma revisão bibliográfica e mapas conceituais, a conceitualização de FGAD para aplicação de MA em cenários CPBL. Mediante uma revisão sistemática da literatura, identificou-se como os fatores e características individuais dos estudantes são empregados em estudos empíricos, tanto na formação de grupo, como na aplicação de MA em cenários CPBL. Tendo como resultados: a formação de grupos heterogêneos mais utilizada, sendo o nível de conhecimento dos participantes a característica individual frequentemente considerada, assim como o método scrum é a MA mais aplicada. Com base nesses resultados, conduziu-se um estudo quase-experimental realizado em uma escola particular de Maceió -Alagoas, com 44 participantes da escola de São José, na disciplina de Ciências Naturais, com faixa etária de 11 (onze) a 14 (anos), elaborando um projeto de Biodiversidade com o seminário sendo o artefato desenvolvido pelos estudantes, durante 2 (dois) meses. Os resultados do estudo empírico apontaram que, em cenários CPBL, a FGAD foi mais efetiva com referência aos ganhos da aprendizagem que a FGO (Formação de Grupos Otimizados) e a FGA (Formação de Grupos Aleatórios). A satisfação dos membros de equipes em cenários CPBL também foi melhor do que na FGO e na FGA. Também observou-se que houve benefício nas competências de comunicação e comprometimento dos estudantes. Embora esses resultados foram todos positivos, não houve diferença significativa estatística, pelo qual os benefícios da FGAD não podem ser generalizados para a população e o contexto empregado no estudo empírico.","Acquiring skills like communication and commitment is challenging. Recent studies from the literature show that when Agile Methodologies (AMs) are applied, there are benefits for these skills. Studies show that participants’ learning gains and satisfaction can be maximized by forming groups. In this dissertation, we conceptualize and assess the Formation of High-Performance Groups (FHPG) to apply AMs in Project-Based Collaborative Learning (CPBL) scenarios, which, based on the factors and individual characteristics of the participants, seek to maximize the group performance. We conceptualized the FHPG for applying AMs in CPBL scenarios through a literature review and concept maps. A systematic literature review was conducted to identify how the factors and individual characteristics of students are used in group formation and the application of AMs in CPBL scenarios. The results were: the formation of heterogeneous groups as the method most used; the level of knowledge of the participants being the individual characteristics more often considered; and the scrum method, being the most applied AMs. Based on these results, a quasi-experimental study was carried out in a private school in Maceió -Alagoas, with 44 participants from a public school, named São José, in the discipline of Natural Sciences, with students aged from 11 (eleven) to 14 (years old). The learning contente was Biodiversity, and the project was the elaboration of a seminar as the artifact developed by the students for 2 (two) months. The results of the empirical study pointed out that, in CPBL scenarios, FHPG was more effective in terms of learning gains than FGO (Formation of Optimized Groups) and FGA (Formation of Random Groups). Team member satisfaction in CPBL scenarios was also better than in FGO and FGA. It was also observed that there was a benefit in the students’ communication skills and commitment. Although these results were all positive, there was no statistically significant difference, whereby the benefits of FHPG cannot be generalized to the population and context employed in the empirical study.","('Metodologias ágeis', 'Aprendizagem colaborativa baseada em projetos (CPBL)', 'Formação de grupos de alto desempenho', 'Agile Methodologies', 'Project-Based Collaborative Learning', 'Formation of High Performance Groups')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/9178","2021-10-29","https://www.repositorio.ufal.br/bitstream/123456789/9178/1/Metodologias%20%c3%a1geis%20na%20aprendizagem%20colaborativa%20baseada%20em%20projetos.pdf","Training of high performance groups and agile methods in Project-based collaborative learning","('Geiser Chalco Challco',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/2039","Campus A.C. Simões","Instituto de Computação","Dissertação","Um método para apoiar a engenharia de requisitos de qualidade que envolvem ajustes dinâmicos do software","('Vanessa Pinheiro Rodrigues',)","('Patrick Henrique da Silva Brito',)","('Alan Pedro da Silva', 'Ariadne Maria Brito Rizzoni Carvalho')","A evolução atual das plataformas de software e a adoção de serviços críticos de alta demanda mostra a grande dependência de softwares que possuem alta complexidade de desenvolvimento. Além do mais, as tendências atuais devem acentuar ainda mais a necessidade de garantir a qualidade do software. A partir de tais necessidades os requisitos de qualidade, considerados como não-funcionais, são considerados cada vez mais essenciais. A engenharia de requisitos tradicional ocorre de forma estática e com um foco fundamentalmente funcional, enquanto que sistemas com alta demanda de qualidade precisam se preocupar de forma sistemática com eventuais variações comportamentais dinâmicas, de forma a preservar restrições de qualidade. Umdos desafios para lidar com a adaptação dinâmica do software é o aumento da complexidade do seu projeto, aumentando a necessidade se ter uma preocupação sistemática com a arquitetura de software. Com base nas informações apresentadas e nos desafios da engenharia de requisitos, este trabalho propõe a construção de umprocesso para auxiliar nas fases de elicitação e especificação dos requisitos de qualidade que possuam impacto no comportamento do sistema em tempo de execução. Os resultados preliminares mostramque o processo proposto interferiu positivamente na qualidade dos requisitos especificados, beneficiando principalmente desenvolvedores menos experientes.","The current evolution of software platforms and the adoption of software in critical services show the increasing dependence of complex software systems. Moreover, current trends should further accentuate the need to ensure software quality. From these needs, the nonfunctional requirements, also known as quality requirements, are considered more and more as mandatory features. Traditional requirements engineering occurs in a static way with a fundamentally functional focus, while high quality systems must systematically concern themselves with possible dynamic behavioral variations in order to preserve quality constraints. One of the challenges to dealing with dynamic software adaptation is to increase the complexity of the project, increasing the need to have a systematic concern with the software architecture. Based on the information presented and the requirements engineering challenges, this work proposes a process to assist in the elicitation and specification phases of the quality requirements that have an impact on the behavior of the system at run time. The preliminary results show that the proposed process interfered positively in the quality of the specified requirements, benefiting mainly less experienced developers.","('Requisitos não-funcionais', 'Engenharia de requisitos', 'Adaptação dinâmica', 'Requisitos de qualidade', 'Especificação de requisitos', 'Elicitação de requisitos', 'Dynamic adaptation', 'Requirements engineering', 'Non-functional requirements', 'Quality requirements', 'Requirements elicitation', 'Requirements analysis')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/2039","2016-12-13","https://www.repositorio.ufal.br/bitstream/riufal/2039/1/Um%20m%c3%a9todo%20para%20apoiar%20a%20engenharia%20de%20requisitos%20de%20qualidade%20que%20envolvem%20ajustes%20din%c3%a2micos%20do%20software.pdf","A method to support the engineering of quality requirements that involve dynamic software adjustments",""
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/12319","Campus A.C. Simões","Instituto de Computação","Dissertação","Um método para desambiguação em língua portuguesa, integrado ao processo de tradução do Sistema Falibras","('Willian Victor da Silva',)","('Patrick Henrique da Silva Brito',)","('Evandro de Barros Costa', 'José Mario de Martino')","Há no mundo mais de 1 bilhão de pessoas com algum tipo de deficiência. No Brasil, essa realidade corresponde a cerca de 23,9% dos 190 milhões de brasileiros; entre estes 9,8 milhões têm alguma deficiência auditiva. A surdez dificulta consideravelmente a interação social, uma vez que inibe o indivíduo de se comunicar através da via oral-auditiva. Esses problemas de comunicação costumam prejudicar consideravelmente a interação dos alunos surdos com colegas ouvintes, prejudicando o processo de integração social. Para facilitar a comunicação entre pessoas surdas e ouvintes, ferramentas de tradução automática Português-Libras podem ser utilizadas. Porém, de acordo com relatos na literatura, cerca de 75% da comunidade surda se sente insatisfeita com a tradução das ferramentas existentes e dentre as principais causas dessa insatisfação estão o uso de sinais inadequados para palavras com ambiguidade semântica (e.g., direito, público). Neste trabalho é proposto o aperfeiçoamento do módulo de tradução do Sistema Falibras, com o objetivo de melhorar a qualidade da tradução no tocante às críticas observadas na literatura. Os principais objetivos do projeto proposto são: (1) conhecer o estado da arte no tocante à resolução de ambiguidades em língua portuguesa; e (2) combinar as técnicas existentes para desenvolver um módulo de resolução de ambiguidades para o Falibras. A avaliação dos resultados considerou a métrica da acurácia, de forma comparativa com trabalhos existentes na literatura. A avaliação foi conduzida baseada no método Goal-Question-Metric e os resultados são promissores.","There are more than 1 billion people in the world with some type of disability. In Brazil, this reality corresponds to about 23.9 % of the 190 million Brazilians; among these 9.8 million have some hearing impairment. Deafness makes social interaction considerably more difficult, since it inhibits the individual from communicating through the oral-auditory pathway. These communication problems usually impair considerably the interaction of deaf students with fellow listeners, impairing the process of social integration. To facilitate communication between deaf people and listeners, Portuguese-Libras machine translation tools can be used. However, according to reports in the literature, about 75 % of the deaf community feels dissatisfied with the translation of the existing tools and among the main causes of this dissatisfaction are the use of inappropriate signs for words with semantic ambiguity (eg, direito, público ). In this work, the improvement of the Falibras System translation module is proposed, with the objective of improving the quality of the translation with respect to the criticisms observed in the literature. The main objectives of the proposed project are: (1) to know the state of the art regarding the resolution of ambiguities in Portuguese; and (2) combining existing techniques to develop an ambiguity resolution module for Falibras. The evaluation of the results have considered the accuracy metric, in a comparative way with existing works in the literature. The evaluation was conducted based on the Goal-Question-Metric method and presented promising results.","('Desambiguação (Português)', 'Processamento de Linguagem Natural', 'Grupos semânticos', 'Sistema Falibras (Tradutor)', 'Análise de vizinhança', 'Disambiguation (Portuguese)', 'Natural Language Processing', 'Semantic groups', 'Falibras System (Translator)', 'Analysis of neighborhood')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/12319","2022-08-30","https://www.repositorio.ufal.br/bitstream/123456789/12319/1/Um%20m%c3%a9todo%20para%20desambigua%c3%a7%c3%a3o%20em%20l%c3%adngua%20portuguesa%2c%20integrado%20ao%20processo%20de%20tradu%c3%a7%c3%a3o%20do%20Sistema%20Falibras.pdf","",""
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/1613","Campus A.C. Simões","Instituto de Computação","Dissertação","Joint-e: um framework para avaliação de desempenho e escalabilidade de apis de persistência em ontologias","('Endhe Elias Soares',)","('Ig Ibert Bittencourt Santana Pinto',)","('Clovis Torres Fernandes', 'Leandro Dias da Silva', 'Márcio de Medeiros Ribeiro')","A Web Semântica (WS) vem se tornando um importante tópico de pesquisa na Ciência da Computação. Uma das razões é a possibilidade de representar a informação de maneira semântica por meio de ontologias. Como consequência, inúmeras aplicações têm sido desenvolvidas utilizando as tecnologias da Web semântica, tais como, RDF, SPARQL e as próprias ontologias. Embora o desenvolvimento de software utilizando estas tecnologias seja complicado e custoso, a comunidade da WS vem produzindo ferramentas e APIs (application programming interface) para apoiar programadores no desenvolvimento de aplicações semânticas. Nesse cenário, existem atualmente duas principais abordagens utilizadas por essas APIs para manipulação de ontologias: triplas RDF e Programação Orientada a Objetos (POO). Por um lado, o uso de APIs para manipular triplas RDF permite que o desenvolvedor crie aplicações mapeando as propriedades das classes presentes nas triplas RDF em código utilizando uma linguagem de programação (e.g. Java). Por outro lado, existem as APIs para manipular ontologias utilizando o paradigma de orientação a objetivo. Isso permite que desenvolvedores continuem utilizando um paradigma jÃ¡ conhecido e largamente utilizado. Embora várias APIs tenham sido desenvolvidas para manipular ontologias no nível de objeto, a maioria não foi adequadamente avaliada, principalmente no que se refere aos atributos de qualidade de desempenho e escalabilidade. Além disso, a alta quantidade e a variabilidade das APIs faz com que seja necessário construir uma abordagem genérica que lide com essas questões, uma vez que construir um sistema de avaliação para cada API isoladamente é inviável. Dessa forma, este trabalho apresenta um framework centrado na arquitetura, chamado JOINT-E (Java Ontology Integration Toolkit-Evaluator), que permite a desenvolvedores avaliar as APIs para manipulação de ontologias. Para realizar esta avaliação foi objetivo deste trabalho definir um conjunto de métricas de desempenho e escalabilidade. Frisa-se que o framework e as métricas definidas possibilitam a análise e comparação das APIs com apoio estatístico, aumentando a credibilidade e confiabilidade dos resultados. Para validar os resultados obtidos foi proposto um experimento com três cenários usando as principais APIs (Alibaba e Jastor) utilizadas pela comunidade de desenvolvimento de aplicativos semântico. De acordo com este experimento a Jastor apresentou melhor performance em relação ao Alibaba levando em consideração as métricas propostas. Por fim, realizou-se também uma pesquisa de opinião com desenvolvedores para verificar se o framework JOINT-E oferece informações importantes para tomada de decisão referente a escolha de uma API. Os resultados desta pesquisa constaram que o framework oferece meios mais precisos para avaliação das APIs e atende a demanda dos desenvolvedores.","The Semantic Web (WS) is be coming an important research topic in Computer Science. One of reasons is the possibility of representing information in semantic way using ontologies, assisting in the building of applications which are able to use data, be coming more scalable and intelligent. As a result, many new applications have been developed using the Semantic Web technologies such as RDF, SPARQL and ontologies themselves. Although software development using these technologies is complicated and costly, the community of WS has been producing tools and APIs (application programming interface) to support programmers in the development of semantic applications. Among the most important APIs developed by the community are those that provide mechanisms for handling ontologies. Currently, there are two main approaches used by manipulation APIs: i) RDF triples and objet-oriented programming (OOP). On the one hand, using the RDF triples, the developers have to manipulate the ontologies using only triples, making the development process more complicated. On the other hand, the OOP APIs promote ontologies manipulation using object, which facilitates the development. Although several APIs are been developed in order to manipulate ontologies at object level, most of them are not being evaluated, especially when related to the quality of attributes, such as performance and scalability. Moreover, the high quantity and variability of APIs require a more generic approach in order to deal with these issues, be cause building an evaluation system for each API is a costly task and does not allow the reuse of the solution, neither of its modules. Therefore, this work presents an architecture-entered framework, named JOINT-Evaluator (JOINT-E), where the developers will be able to evaluate the APIs based on a set of pre-defined performance and scalability metrics. It is important to note that the framework also enables the analysis and comparison of the data with statistical support, in creasing the credibility and reliability of the results. To validate the work three scenarios were created on experiment. The main APIs (Alibaba and Jastor) used by developers were tested and evaluated. Furthermore, a qualitative analysis is presented, showing the statistical results and highlighting the advantages and disadvantages of each API. The results have showed that Jastor surpass Alibaba in many issues. Finally, a survey was applied to developers in order to validate the framework. This suvery have presented that this work attend a developers demand.","('Desempenho de softwares', 'Escalabilidade de softwares', 'Framework', 'Performance', 'Scalability')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1613","2014-05-23","https://www.repositorio.ufal.br/bitstream/riufal/1613/1/Joint-e%3a%20um%20framework%20para%20avalia%c3%a7%c3%a3o%20de%20desempenho%20e%20escalabilidade%20de%20apis%20de%20persist%c3%aancia%20em%20ontologias.pdf","Joint-e: a framework to evaluate performance and scalability of ontology persistence apis","('Seiji Isotani',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/1609","Campus A.C. Simões","Instituto de Computação","Dissertação","Joint-de: sistema de mapeamento objeto-ontologia com suporte a objetos desconectados","('Olavo de Holanda Cavalcanti Neto',)","('Ig Ibert Bittencourt Santana Pinto',)","('Evandro de Barros Costa', 'Leandro Dias da Silva', 'Sean Wolfgand Matsui Siqueira')","Nos últimos anos, é crescente o desenvolvimento e o uso de ontologias na criação de aplicações mais inteligentes e eficazes que têm como objetivo solucionar problemas encontrados comumente na Web. Toda essa popularidade se deve ao fato de que ontologias tentam oferecer semântica aos dados consumidos pelas máquinas de forma que ela possa raciocinar sobre estes dados. Todavia, a larga adoção da Web Semântica pode ser ainda acelerada ao prover ferramentas sofisticadas que diminuam a barreira de desenvolvimento de aplicações baseadas em RDF e OWL. Desenvolvedores de aplicações com bancos de dados relacionais já estão acostumados com ferramentas como o Hibernate, que oferecem um mapeamento objeto-relacional e o gerenciamento de estados dos objetos. Na verdade, o principal estado de objeto que o Hibernate disponibiliza é o desconectado. Entretanto, a grande maioria dos sistemas de mapeamento objeto-ontologia (OOMS) apenas disponibiliza objetos persistentes. A grande diferença entre os dois tipos de objetos é que o primeiro tem seu ciclo de vida independente da conexão com o banco de dados RDF, já o último é limitado à conexão. Neste contexto, este trabalho propõe a criação de um sistema de mapeamento objeto-ontologia que suporta objetos desconectados, chamado JOINT-DE. Com este sistema, desenvolvedores de aplicações baseados em ontologias podem: i) utilizar os objetos oriundos do banco de dados RDF como objetos do modelo de negócio, transitando nas diversas camadas da aplicação; ii) utilizar esses objetos como objetos de transferência de dados (DTOs) entre subsistemas e iii) desenvolver pequenas transações com objetos desconectados que representam uma unidade longa de transação para o usuário da aplicação. Para exemplificar os benefícios do sistema proposto, um estudo de caso de uma aplicação real é apresentado, expondo as limitações arquiteturais dessa aplicação ao utilizar um OOMS existente na literatura, além de mostrar resultados favoráveis à implantação do JOINT-DE. Por fim, um experimento foi planejado e executado com o objetivo de comparar o JOINT-DE com outro OOMS bastante utilizado pela comunidade: Alibaba. As análises estatísticas realizadas nesse experimento apontaram resultados satisfatórios com relação ao JOINT-DE.","In the last few years, it is increasing the development and use of ontologies in creating more intelligent and effective applications that aim to solve problems commonly found on the Web. This popularity is due to the fact that ontologies attempt to provide semantics to the data consumed by machines, so that they can reason about these data. However, the large adoption of the Semantic Web can be further accelerated by providing sophisticated tools that lower the barrier to the development of applications based on RDF and OWL. Developers of applications with relational databases are already familiar with tools like Hibernate, which provide an object-relational mapping and the management of the objects states. Actually, the main object state that Hibernate provides is the detached. Nevertheless, the great majority of the object-ontology mapping systems (OOMS) only provide persistent objects. The big difference between these two types of objects is that the former one has its life cycle independent of the underlying triple store connection, but the latter one is bounded to the connection. In this context, this paper proposes the creation of an object-ontology mapping systems that supports detached objects, called Joint-DE. With this system, developers of ontology-based applications can: i) use the objects coming from the triple store as objects of the business model; ii) use such objects as data transfer objects ( DTOs) between subsystems and; iii) develop small transactions with detached objects that represent a long transaction unit for the application user. To illustrate the benets of the proposed system, a case study of a real application is presented, outlining the architectural limitations of the application using an existing OOMS in the literature, as well as showing positive results to the use of JOINT-DE. Finally, an experiment was planned and executed aiming to compare the JOINT-DE with another OOMS widely used by the community: Alibaba. The statistical analyzes performed in this experiment showed satisfactory results with regard to JOINT-DE.","('Mapeamento -Objeto-ontologia', 'Aplicações baseadas em ontologias', 'Objetos desconectados', 'Sistema de mapeamento', 'Object-Ontology mapping', 'Ontology-based applications', 'Detached Objects.')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1609","2014-05-22","https://www.repositorio.ufal.br/bitstream/riufal/1609/1/Joint-de%20-%20sistema%20de%20mapeamento%20objeto-ontologia%20com%20suporte%20a%20objetos%20desconectados.pdf","Joint-de: object-ontology mapping system with support to detached objects","('Seiji Isotani',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/6488","Campus A.C. Simões","Instituto de Computação","Dissertação","A framework of unsupervised techniques for anomaly-based intrusion detection","('Anderson Santos da Silva',)","('Baldoíno Fonseca dos Santos Neto',)","('Leandro Dias da Silva', 'Rafael Ferreira Leite de Mello')","Dezenas de algoritmos foram propostos para detecção de anomalias e, quando aplicados à detecção de intrusão, eles podem detectar ataques suspeitos sempre que forem observados desvios relevantes do comportamento esperado. A comunidade de pesquisa ainda carece de uma avaliação comparativa universal, bem como de conjuntos padrão de dados disponíveis ao público. É geralmente um desafio fornecer uma descrição que seja suficiente em detalhes e que seja fácil de entender e comparar. Pode parecer que soluções valiosas são apresentadas e especialmente testadas de forma que a reimplementação por terceiros ou a comparação com outras soluções é difícil, demorada e o resultado pode nem ser o mesmo. Por exemplo, uma etapa do algoritmo pode dizer: ""Escolhemos um elemento do conjunto de fronteiras"", mas qual elemento você escolhe? O primeiro fará? Por que algum elemento é suficiente? Como outro exemplo, o autor provavelmente pode querer fornecer mais detalhes de implementação, mas está restrito pelo limite de páginas de um artigo. Além disso, às vezes a descrição do autor alinha outros algoritmos ou estruturas de dados que talvez apenas esse autor esteja familiarizado. Em geral, é uma problema comum pesquisar e mostrar uma comparação quantitativa que evidencie a qualidade de uma solução. Embora isso seja, sem dúvida, essencial para novas pesquisas e melhorias no tema, é um desafio criar uma comparação quantitativa que permita uma comparação justa de diferentes técnicas de detecção de anomalias. Portanto, é necessária uma análise comparativa para algoritmos de detecção de anomalias, que possa ser usado por qualquer pessoa e, eventualmente, permitir que alguém contribua com esses testes estando em um formato padrão.","Dozens of algorithms have been proposed for anomaly detection, and, when applied to intrusion detection, they can detect suspect attacks whenever relevant deviations from the expected behavior are observed. The research community still lacks a universal comparative evaluation as well as standard publicly available datasets. It is in general challenging to provide a description that suffices in details, and that is easy to understand and compare. It may often appear that valuable solutions are presented and specially tested in such a way that re-implementation by a third party or comparison with others solutions is difficult, time-consuming and the result might not even be the same. For example, a step in the algorithm might say: ""We pick an element from the frontier set"" but which element do you pick? Will the first one do? Why Will any element suffice? As another example, the author may probably want to give more implementation details but is constrained by the paper page limit. Additionally, sometimes the author’s description in-lines other algorithms or data structures that perhaps only that author is familiar. In general, it is a common struggle to research and show a quantitative comparison that gives evidence of the quality of a solution. While this is undoubtedly essential for further researches and improvements in the topic, it is challenging to create a quantitative comparison which allows a fair comparison of different anomaly detection techniques. Thus, a public quantitative analysis for anomaly detection algorithms, which can be used by anyone and eventually allow anyone to contribute to, implying that the tests are in a standard format, is much needed.","('Algoritmos -Anomalias', 'Detecção de intrusão', 'Algoritmos não supervisionados', 'Ciberterrorismo', 'Algorithms – Anomalies', 'Intrusion detection', 'Unsupervised algorithms', 'Cyber Terrorism')","Ciência da Computação","eng","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/6488","2019-01-24","https://www.repositorio.ufal.br/bitstream/riufal/6488/1/A%20framework%20of%20unsupervised%20techniques%20for%20anomaly-based%20intrusion%20detection.pdf","Um framework de técnicas não supervisionadas para detecção de intrusão baseada em anomalias",""
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/13387","Campus A.C. Simões","Instituto de Computação","Dissertação","Framework para teleoperação de robôs móveis","('Andressa Martins Oliveira',)","('Ícaro Bezerra Queiroz de Araújo',)","('Tiago Figueiredo Vieira', 'Allan de Medeiros Martins')","Apesar dos notáveis avanços em robôs autônomos, certas atividades ainda requerem supervisão humana devido a várias barreiras encontradas na interação complexa com ambientes em constante mudança e situações imprevisíveis. Por conseguinte, o desenvolvimento de sistemas telerobóticos tem ganhado destaque em diversas áreas de atuação. Nesse contexto, este trabalho propõe o desenvolvimento de um sistema de teleoperação para robô móvel, capaz de ser aplicado em diferentes arquiteturas de controle de robôs teleoperados. Esse sistema implementa os modos de controle compartilhado e supervisor, utilizando o framework ROS (Robot Operating System) e suas ferramentas de comunicação e visualização entre o operador e o robô. O sistema desenvolvido integra-se com a estrutura do ROS e aproveita suas funcionalidades para a teleoperação do robô móvel. O controle compartilhado permite que o operador forneça comandos de controle em tempo real, enquanto o modo supervisor permite que o robô execute tarefas com certa autonomia, utilizando dados do ambiente e do sensoriamento.","Despite the notable advancements in autonomous robots, certain activities still require human supervision due to various barriers encountered in complex interactions with everchanging environments and unpredictable situations. Consequently, the development of telerobotic systems has gained prominence in various fields of application. In this context, this work proposes the development of a teleoperation system for a mobile robot, capable of being applied in different architectures for controlling teleoperated robots. This system implements shared control and supervisory control modes, using the ROS (Robot Operating System) framework and its communication and visualization tools between the operator and the robot. The developed system integrates with the ROS framework and leverages its functionalities for teleoperating the mobile robot. The shared control mode allows the operator to provide real-time control commands, while the supervisory mode enables the robot to perform tasks with a certain level of autonomy, utilizing environmental and sensory data.","('Teleoperação', 'Robótica móvel', 'Framework de teleoperação', 'Aplicações web', 'Robôs -Sistemas de controle', 'Teleoperation', 'Mobile Robotics', 'Teleoperation Framework', 'Web application', 'Robots -Control systems')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/13387","2023-07-19","https://www.repositorio.ufal.br/bitstream/123456789/13387/1/Framework%20para%20teleopera%c3%a7%c3%a3o%20de%20rob%c3%b4s%20m%c3%b3veis.pdf","",""
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/7348","Campus A.C. Simões","Instituto de Computação","Dissertação","Identificação automática da presença social em discussões online escritas em português","('Jean Barros Teixeira',)","('Evandro de Barros Costa',)","('Patrick Henrique da Silva Brito', 'Rafael Ferreira Leite de Mello', 'Rodrigo Lins Rodrigues')","Esta dissertação de mestrado apresenta um método que permite a identificação automática de mensagens provenientes de fóruns online de ensino a distância escritas em português brasileiro. Particularmente, analisa o problema da codificação de mensagens de discussão segundo as categorias de presença social, um importante construto do modelo de Comunidade de Investigação amplamente utilizado na aprendizagem online. Apesar de existirem técnicas de codificação para a presença social na língua inglesa, a literatura ainda é carente em métodos para as demais línguas, como o português. O método aqui proposto utiliza-se de um conjunto de características provenientes da frequência de palavras e 158 características extraídas de dois recursos, LIWC e Coh-Metrix, disponíveis para análise textual através de técnicas de Mineração de Texto, para criar um classificador para cada uma das três categorias da presença social (Afetiva, Interativa e Coesiva). Para isso foram utilizados três tipos de algoritmos, Random Forest, AdaBoost e XGBoost onde o melhor modelo desenvolvido utilizou o algoritmo XGBoost atingindo 85,68% de acurácia e índice Kappa (k) de 0,71, o que representa uma concordância substancial, e está bem acima do grau de puro acaso. Este trabalho também provê uma análise da natureza da presença social, observando as características de classificação que foram mais relevantes para distinguir as três categorias da presença e uma análise comparativa sobre as principais características identificadas nas fases da presença social em diferentes domínios.","This M.Sc. dissertation presents a method that allows the automatic identification of messages from distance learning online forums written in Brazilian Portuguese. In particular, it analyzes the problem of coding discussion messages according to the categories of social presence, an important construct of the Community of Inquiry (CoI) model widely used in online learning. Although there are coding techniques for social presence in the English language, the literature is still lacking in methods for other languages, such as Portuguese. The method proposed here uses a set of characteristics derived from the frequency of words and 158 characteristics extracted from two resources, LIWC and Coh-Metrix, available for textual analysis using Text Mining techniques, to create a classifier for each one of the three categories of social presence (Affective, Interactive and Cohesive). For that, three types of algorithms were used, Random Forest, AdaBoost and XGBoost where the best model developed used the XGBoost algorithm reaching 85.68% accuracy and Kappa index (k) of 0.71, which represents a substantial agreement, and is well above the level of pure chance. This work also provides an analysis of the nature of social presence, observing the classification characteristics that were most relevant to distinguish the three categories of presence and a comparative analysis on the main characteristics identified in the phases of social presence in different domains.","('Codificação de mensagens', 'Discussões online', 'Presença social', 'Comunidades de investigação', 'Mineração de textos', 'Social presence', 'Community of inquiry (CoI) model', 'Online discussion', 'Text classification')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/7348","2020-08-28","https://www.repositorio.ufal.br/bitstream/riufal/7348/3/Identifica%c3%a7%c3%a3o%20autom%c3%a1tica%20da%20presen%c3%a7a%20social%20em%20discuss%c3%b5es%20online%20escritas%20em%20portugu%c3%aas.pdf","Automatic identification of social presence in online discussions written in portuguese","('Rafael Ferreira Leite de Mello',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/5974","Campus A.C. Simões","Instituto de Computação","Dissertação","Um framework para a construção de um objeto de aprendizagem digital para o ensino bilíngue de pessoas surdas","('Danilo Victor Barbosa da Costa',)","('Patrick Henrique da Silva Brito',)","('Evandro de Barros Costa', 'Aydano Pamponet Machado')","Apesar da atual proposta de educação bilíngue, as iniciativas não têm sido suficientes para a promoção de uma aquisição plena da modalidade de leitura e escrita da língua portuguesa para as pessoas surdas. Estudos revelam que as práticas de leitura e de escrita são insuficientes, levando a um baixo nível de conhecimento sobre a língua portuguesa (segunda língua para surdos brasileiros), de modo que, as habilidades de diversos alunos estão limitadas a saber codificar e decodificar os símbolos gráficos, sem relacionar sentido ao texto lido. Esse fato é agravado ainda mais, se observarmos dados desde a década de 1990, presentes em diversos trabalhos, onde até então a grande maioria das pessoas surdas (cerca de 90%) são filhos de pais ouvintes. Em geral, crianças surdas, nestas condições, normalmente não têm contato adequado com a educação bilíngue, principalmente no ambiente familiar, o que reduz a chance de uma imersão cultural. Logo, este estudo busca amenizar o problema causado pela falta de contato bilíngue no cotidiano da pessoa surda, proporcionando contato por meio de um objeto de aprendizagem composto por um Serious Game e um conjunto de serviços Web, voltados à avaliação formativa. Sendo o problema de pesquisa: ""Como promover o contato frequente com o bilinguismo Libras-Português, em contextos bem definidos, utilizando um objeto de aprendizagem digital (OAD), de modo a ter um impacto positivo para o desenvolvimento da segunda língua (L2) de estudantes surdos?"". Deste modo, este trabalho permitir que, través de um estudo no campo da engenharia de software, desenvolvedores de jogos pudessem ter acesso há um framework conceitual para a produção de um OAD voltado para o ensino da L2 a estudantes surdos, composto por um Serious Game e um conjunto de serviços Web, voltados à avaliação formativa, tendo como foco a geração de um produto que agregue valor no sentido de responder às necessidades dos elementos envolvidos no processo de ensino da língua portuguesa. Assim, para viabilizar este trabalho foi executado um experimento piloto que permitiu evidenciar os problemas da educação da pessoa surda e identificar características para ensino de L2. Logo após, foram executadas as etapas do projeto que permitiram a produção de instrumentos para a promoção da prática bilíngue do aluno surdo para aquisição da língua portuguesa como segunda língua e o favorecimento do acompanhamento, por parte do educador, sobre o andamento do progresso do aluno surdo. Para avaliar estes instrumentos foi realizada uma análise qualitativa, sendo a coleta dos dados feita por questionários numa abordagem semiestruturada, destinados a dois perfis de avaliadores: o primeiro, especialistas em computação para avaliar aspectos da Interação Humano-Computador (IHC); o segundo, especialistas na educação de pessoas surdas para avaliar os elementos de ensino-aprendizagem aplicados ao OAD. Por fim, os resultados obtidos apontam um impacto positivo para o uso do OAD na educação bilíngue.","Despite the current proposal of bilingual education, the initiatives have not been enough to promote a full acquisition of the Portuguese language for the deaf. Studies show that reading and writing practices are insufficient, leading to a low level of knowledge about the Portuguese language (second language for deaf people in Brazil), so that the abilities of several students are limited to knowing how to code and decode the symbols graphics, without relating meaning to the text read. This fact is aggravated even more if we observe data from the 1990s, present in several works, where until then the great majority of the deaf people (about 90 %) are children of hearing parents. In general, deaf children under these conditions usually do not have adequate contact with bilingual education, especially in the family environment, which reduces the chance of cultural immersion. Therefore, this study seeks to alleviate the problem caused by the lack of bilingual contact in the daily life of the deaf person, providing contact through a learning object composed of a Serious Game and a set ofWeb services, focused on formative evaluation. As the research problemis: ""How to promote frequent contact with Portuguese-Portuguese bilingualism, in well defined contexts, using a digital learning object (DLO), so as to have a positive impact on the development of the second language (L2) of deaf students? "" In this way, this work allows that, through a study in the field of software engineering, game developers could have access there is a conceptual framework for the production of an DLO aimed at teaching L2 to deaf students, composed of for a Serious Game and a set of Web services, focused on formative evaluation, focusing on the generation of a product that adds value in order to respond to the needs of the elements involved in the process of teaching the Portuguese language. Thus, to make this work viable, a pilot experiment was carried out to highlight the problems of deaf education and to identify characteristics for teaching L2. Subsequently, the project stages were carried out, which allowed the production of tools to promote the bilingual practice of the deaf student to acquire the Portuguese language as a second language and favor the follow-up by the educator on the progress of the student deaf. In order to evaluate these instruments, a qualitative analysis was carried out. The data collection was done by questionnaires in a semistructured approach, for two profiles of evaluators: the first, computer specialists to evaluate aspects of Human-Computer Interaction (HCI); the second, specialists in the education of deaf people to evaluate the teaching-learning elements applied to the DLO. Finally, the results obtained indicate a positive impact for the use of DLO in bilingual education.","('Framework (Arquitetura de Software)', 'Surdos -Educação', 'Jogos digitais – Colaboração', 'Educação bilíngue', 'Avaliação de potencial de aprendizagem', 'Framework (Software Architecture)', 'Deaf – Education', 'Digital Games – Collaboration', 'Bilingual education', 'Learning Potential Assessment', 'Evaluation of learning')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/5974","2019-06-13","https://www.repositorio.ufal.br/bitstream/riufal/5974/1/Um%20framework%20para%20a%20constru%c3%a7%c3%a3o%20de%20um%20objeto%20de%20aprendizagem%20digital%20para%20o%20ensino%20bil%c3%adngue.pdf","A framework for building a digital learning object for bilingual teaching of deaf people",""
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/7302","Campus A.C. Simões","Instituto de Computação","Dissertação","Geração sistemática de feedback em projetos Canvas na área de TI","('Laise Damasceno Lucas',)","('Patrick Henrique da Silva Brito',)","('Leonardo Melo de Medeiros', 'Simone Cristiane dos Santos Lima')","De acordo com dados do SEBRAE, em 2016, o número de pessoas entre 18 e 34 anos que resolveram se tornar empreendedores subiu de 50% para 57%, totalizando 15,7 milhões de jovens que buscam informações sobre como proceder para iniciar um negócio. Porém, a mesma pesquisa aponta que a grande maioria dos jovens empreendedores chega a esse status apenas por oportunidade, sem haver preparação prévia ou sequer aptidão para empreendedorismo. Desta forma, é necessário que o empreendedor encontre o diferencial que possam colocar seu negócio em evidência. Um passo importante na elaboração dos planos de negócio é a utilização da ferramenta Canvas, que concentra a atenção em questões estratégicas do plano de negócio, como por exemplo, proposta de valor e a estrutura de custos. Com base no cenário apresentado, observou-se que no Brasil, muitos empreendedores são inexperientes e produzem seus planos de negócio com problemas graves, sendo alguns mais sutis e outros mais implícitos. Para amenizar esse problema, o Brasil possui instituições de referência para elaboração dos planos de negócio e a utilização da ferramenta Canvas, tais como SEBRAE, SENAC e SENAI, que dentre outras funções, avaliam e fornecem feedback para ajuste e adequação. O feedback será baseado em um conjunto de diretrizes consolidadas a partir de uma combinação das diretrizes apresentadas pelos órgãos de referência nacionais. Tais diretrizes são representadas na forma de um conjunto de regras, que são utilizadas por um sistema especialista. Para a geração das regras e avaliação dos resultados foi utilizado um corpus de projetos da ferramenta Canvas, disponibilizados pelo SEBRAE.","According to data from SEBRAE, in 2016, the number of people between 18 and 34 years old who decided to become entrepreneurs rose from 50% to 57%, totaling 15.7 million Young people looking for information on how to start a business. However, the same research shows that the vast majority of young entrepreneurs achieve this status only by opportunity, without prior preparation or even aptitude for entrepreneurship. Thus, it is necessary for the entrepreneur to find the differential that can put his business in evidence. An important step in the preparation of business plans is the use of the Canvas tool, which focuses attention on strategic issues in the business plan, such as, for example, the value proposal and the cost structure. Based on the scenario presented, it was observed that in Brazil, many entrepreneurs are inexperienced and produce their business plans with serious problems, some of which are more subtle and others more implicit. To alleviate this problem, Brazil has reference institutions for the preparation of business plans and the use of the Canvas tool, such as SEBRAE, SENAC and SENAI, which among other functions, evaluate and provide feedback for adjustment and adequacy. The feedback will be based on a set of guidelines consolidated from a combination of the guidelines presented by the national reference bodies. Such guidelines are represented in the form of a set of rules, which are used by an expert system. For the generation of rules and evaluation of results, a corpus of projects using the Canvas tool, made available by SEBRAE, was used.","('Canvas (Programa de computador)', 'Empreendedorismo', 'Feedback', 'Mineração de dados (Computação)', 'Apriori (Algoritmo)', 'Canvas', 'Entrepreneurship', 'Automatic Feedback', 'Data Mining', 'Association Rules')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/7302","2020-02-14","https://www.repositorio.ufal.br/bitstream/riufal/7302/3/Gera%c3%a7%c3%a3o%20sistem%c3%a1tica%20de%20feedback%20em%20projetos%20Canvas%20na%20%c3%a1rea%20de%20TI.pdf","Systematic feedback generation in canvas projects in the it area","('Evandro de Barros Costa',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/13484","Campus A.C. Simões","Instituto de Computação","Dissertação","Investigando a relação entre garra, aprendizagem e experiência de fluxo em ambientes educacionais gamificados e estereotipados","('Elisangela Martins do Nascimento',)","('Ig Ibert Bittencourt Santana Pinto',)","('Diego Dermeval de Medeiros da Cunha Matos', 'Sheyla Christine Santos Fernandes', 'Geiser Chalco Challco')","Esta dissertação é composta por três estudos que visam explorar a influência da gamificação, que refere-se à integração de elementos e mecânicas de jogos em contextos não relacionados a jogos, como ambientes educacionais, no desempenho e engajamento de estudantes e impacto de estereótipos de gênero, correlacionando-os com o traço de personalidade Garra . Este traço é caracterizado por uma combinação de paixão e perseverança em direção a objetivos de longo prazo, no qual abrange qualidades como resiliência, determinação e capacidade de manter o esforço e o interesse diante de desafios e contratempos. Diante disso, três estudos foram conduzidos, o primeiro estudo é uma revisão sistemática da literatura que investiga a correlação entre Garra e sistemas gamificados, sugerindo que a gamificação influencia positivamente o engajamento e o desempenho dos alunos. O segundo estudo enfoca as diferenças de gênero em sistemas de tutoria gamificados estereotipados, sugerindo que a Garra por si só pode não ser suficiente para reduzir essas disparidades, indicando nos resultados que os estereótipos de gênero podem afetar negativamente o desempenho e o engajamento para mulheres com baixos níveis de Garra. O terceiro estudo é uma análise qualitativa que explora as percepções emocionais dos participantes em um ambiente gamificado estereotipado, identificando sentimentos negativos de falta de controle. No geral, as descobertas destacam a necessidade de ambientes gamificados equitativos e cuidadosamente projetados para evitar efeitos negativos no desempenho e engajamento dos estudantes. Pesquisas futuras devem considerar uma abordagem holística, investigando correlações complexas entre traços de personalidade, métodos de engajamento e desempenho acadêmico e o impacto do estereótipo de gênero. Estudos futuros também devem orientar o desenvolvimento de metodologias de ensino e aprendizado.","This dissertation is composed of three studies that aim to explore the influence of gamification, which refers to the integration of game elements and mechanics in non-game contexts, such as educational environments, on student performance and engagement and the impact of gender stereotypes. , correlating them with the Grit personality trait. This trait is characterized by a combination of passion and perseverance towards long-term goals, which encompasses qualities such as resilience, determination and the ability to maintain effort and interest in the face of challenges and setbacks. Given this, three studies were conducted, the first study is a systematic review of the literature that investigates the correlation between Grit and gamified systems, suggesting that gamification positively influences student engagement and performance. The second study focuses on gender differences in stereotypical gamified tutoring systems, suggesting that Grit alone may not be enough to reduce these disparities, indicating in the results that gender stereotypes can negatively affect performance and engagement for women with low levels of Grit. The third study is a qualitative analysis that explores participants’ emotional perceptions in a stereotyped gamified environment, identifying negative feelings of lack of control. Overall, the findings highlight the need for equitable and carefully designed gamified environments to avoid negative effects on student performance and engagement. Future research should consider a holistic approach, investigating complex correlations between personality traits, engagement methods and academic performance, and the impact of gender stereotyping. Future studies should also guide the development of teaching and learning methodologies.","('Gamificação', 'Estereótipos de gênero', 'Garra', 'Desempenho acadêmico', 'Gamification', 'Stereotypes', 'Education', 'Grit', 'Informatics in education')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/13484","2023-10-13","https://www.repositorio.ufal.br/bitstream/123456789/13484/1/Investigando%20a%20rela%c3%a7%c3%a3o%20entre%20garra%2c%20aprendizagem%20e%20experi%c3%aancia%20de%20fluxo%20em%20ambientes%20educacionais%20gamificados%20e%20estereotipados.pdf","","('Marcelo Reis',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/9045","Campus A.C. Simões","Instituto de Computação","Dissertação","Framework de monitoramento persistente multiagente em ambientes marítimos","('Glauber Rodrigues Leite',)","('Heitor Judiss Savino',)","('Thiago Damasceno Cordeiro', 'Allan de Medeiros Martins')","Monitorar o oceano de forma eficiente é essencial para planejar estratégias que permitem a manutenção da saúde do litoral. Isso fica evidente em cenários de desastre ambiental, como o derramamento de óleo reportado em 2019 que atingiu uma grande extensão da costa nordestina brasileira, trazendo consequências tanto ambientais quanto socioeconômicas para os locais afetados. O evento mostrou a necessidade de expansão da rede de monitoramento nacional, composta principalmente por boias marítimas, que são componentes estáticos ou passivos, nessa tarefa. Com base nesta problemática, este trabalho propõe um framework para sistema de monitoramento persistente com sensoriamento ativo, a partir de veículos autônomos colaborativos envolvidos em uma missão marítima. Esse sistema é capaz de gerenciar simulações de um processo de dispersão e sincronizar agentes em uma miss ̃ao, trabalhando em uma política de patrulhamento.","Efficiently monitoring the ocean is essential to plan strategies that enable the health of the coast to be maintained. This is evident in environmental disaster scenarios, such as the oil spill reported in 2019 over a large stretch of the northeastern Brazilian coast, bringing environmental and socioeconomic consequences to the affected locations. The event showed the need to expand the national monitoring network, composed mainly of marine buoys, which are static or passive components in this task. Based on this problem, this work proposes a framework for a persistent monitoring system with active sensing from autonomous collaborative vehicles involved in a maritime mission. This system manages simulations of a dispersion process and synchronizes agents on a mission, working on a patrol policy.","('Monitoramento ambiental', 'Robôs cooperativos', 'Derramamento de óleo', 'Busca e rastreamento', 'Sensoriamento remoto', 'Environmental Monitoring', 'Cooperative Robots', 'Oil spill response', 'Search and tracking', 'Remote sensing')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/9045","2022-02-28","https://www.repositorio.ufal.br/bitstream/123456789/9045/1/Framework%20de%20monitoramento%20persistente%20multiagente%20em%20ambientes%20mar%c3%adtimos.pdf","","('Ícaro Bezerra Queiroz de Araújo',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/15575","Campus A.C. Simões","Instituto de Computação","Dissertação","Evaluating the impact of EDFA response modeling in the optical network QoT estimation","('Allan Amaro Bezerra da Silva',)","('Erick de Andrade Barboza',)","('Ícaro Bezerra Queiroz de Araújo', 'Carmelo José Albanez Bastos Filho')","Ausente","Estimating the quality of transmission (QoT) in optical networks is a key metric for planning, managing, and optimizing networks. QoT estimation depends on good modeling of the internal components of the optical link to accurately simulate transmission and consequent signal degradation. The amplifier is a source of noise and signal distortion; therefore, amplifier modeling plays a crucial role in the estimation of QoT. We present an evaluation of the impact of different amplifier models on the estimation of QoT in four single-link scenarios and two optical network topologies. We based our simulation on GNPy, a QoT estimator widely used to simulate and optimize the design of optical networks. Our main contributions are: (1) a new version of the GNPy in which the amplifier can be modeled using a power mask; (2) a benchmark considering GNPy’s advanced amplifier model (Advanced Model) and the estimator based on a numerical simulator that uses power masks with real-world amplifier data (Power Mask Model); and (3) an analysis of the impacts in the network QoT for each amplifier model. The results show that, considering single link scenarios, the Power Mask Model achieved better approximations to the OptiSystem simulator used as a benchmark, presenting a good advantage over the Advanced Model. In the network scenarios, the results show that the Advanced Model tends to deliver more optimistic and flat estimates even in cases of high tilt, whereas the Power Mask Model is more sensitive to transmission noise in these cases, estimating lower GSNR and transmission rates, including several cases of connection blocking. The findings of this study may be useful to optical network researchers and operators who want to have more flexible network management and optimization through simulations and software-controlled networks.","('Redes ópticas', 'Telecomunicações', 'Amplificador óptico', 'Simulação (Computadores)', 'Máscara de potência', 'Telecommunications', 'Optical Networks', 'Simulation', 'Optical Amplifier', 'Power mask')","Ciência da Computação","eng","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/15575","2024-05-28","https://www.repositorio.ufal.br/bitstream/123456789/15575/1/Evaluating%20the%20impact%20of%20EDFA%20response%20modeling%20in%20the%20optical%20network%20QoT%20estimation.pdf","Avaliação do impacto da modelagem de resposta EDFA na estimativa de QoT da rede óptica",""
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/2194","Campus A.C. Simões","Instituto de Computação","Dissertação","Um estudo da relação entre complexidade estrutural e vulnerabilidades de software","('Henrique Ferreira Alves',)","('Baldoíno Fonseca dos Santos Neto',)","('Patrick Henrique da Silva Brito', 'Regina Lúcia de Oliveira Moraes')","A necessidade de desenvolver, gerir e evoluir os produtos de software está em alta, isso se deve à dependência que as pessoas têm das novas tecnologias.Ouso de programas computacionais já está impregnado nas atividades cotidianas. Entretanto, há um problema que os desenvolvedores e gestores enfrentam e que compromete a integridade das funcionalidades dos sistemas, as vulnerabilidades de software. Pesquisas mostram que a maneira mais barata de se evitar uma vulnerabilidade é a utilização de inspeção de código. Entretanto, não é possível realizar esse processo em todo o software, existe uma grande quantidade de algoritmos e fluxos de tarefas em um software que inviabilizam tal atividade. Como estratégia, desenvolvedores focam seus olhos em partes de código mais relevantes, para isso contam com estratégias que identifiquem as partes mais complexas do software. A literatura estuda o uso de técnicas como o uso de métricas de software para direcionar a atenção dos revisores às partes que, supostamente, seriam as mais propensas a conter vulnerabilidade. Emnosso trabalho, vamos realizar umestudo exploratório em sete projetos open source:Mozilla Firefox, Xen Hipervisor, Linux Kernel, Httpd Server, Glibc, Tomcat e Derby, no qual vamos extrair métricas de software de suas classes, arquivos e funções a fim de relacioná-las às vulnerabilidades. A intenção principal é contribuir comnovas pesquisas, disponibilizar dados e guiar novas investigações com informações relevantes dessa relação.","The need to develop, manage and evolve the software is on the rise, this is due to dependence that people have on new technologies. The use of computer programs already are steeped in daily activities. However there is a problem that developers and managers face and that compromises the integrity of the features of theses programs, software vulnerabilities. Research shows that the cheapest way to avoid vulnerability is the use of code inspection, however it is not possible to carry out this process across the whole software, there is an exorbitant amount of algorithms and job streams in software that prevent such activity. As a strategy, developers focus their eyes on the most important pieces of code for that have strategies to identify the most complex pieces of software. The literature studies the use of techniques such as the use of software metrics to direct the attention of reviewers to the parties that are supposed to be themost likely to contain vulnerabilities. In our work, we will conduct an exploratory study in seven open source projects:Mozilla Firefox, Xen Hypervisor, Linux Kernel, Httpd Server, Glibc, Tomcat and Derby, which software metrics from their classes, files and functions were extracted in order to relate them to vulnerabilities. The main intention is to contribute with new research, to provide data and to guide new investigations with relevant information of this relation.","('Banco de dados', 'Mineração de dados (computação)', 'Métrica de software', 'Aprendizagem de máquina', 'Software – Vulnerabilidade', 'Vulnerabilities', 'Dataset', 'Data mining', 'Machine learning', 'Evaluation')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/2194","2017-09-12","https://www.repositorio.ufal.br/bitstream/riufal/2194/1/Um%20estudo%20da%20rela%c3%a7%c3%a3o%20entre%20complexidade%20estrutural%20e%20vulnerabiliddes%20de%20software.pdf","A study of the relationship between structural complexity and software vulnerabilities","('Nuno Manoel dos Santos Antunes',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/13413","Campus A.C. Simões","Instituto de Computação","Dissertação","Evaluating the resilience of cloud NLP services across Amazon, Microsoft, and Google","('Juliano Rocha Barbosa',)","('Baldoíno Fonseca dos Santos Neto',)","('Marcelo Costa Oliveira', 'Leopoldo Motta Teixeira')","O Processamento de Linguagem Natural (PLN) revolucionou indústrias, agilizando o atendimento ao cliente por meio de aplicações na área de saúde, finanças, direito, recursos humanos e simplificando tarefas como pesquisa médica, análise financeira e análise de sentimentos. Para evitar os altos custos de construção e manutenção da infraestrutura de PLN, as empresas recorrem aos serviços de PLN em nuvem oferecidos por grandes provedores de nuvem como Amazon, Google e Microsoft. No entanto, há pouco conhecimento sobre o quão resilientes esses serviços são quando sujeitos a ruídos. Este artigo apresenta um estudo que analisa a resiliência dos serviços de PLN em nuvem, avaliando a eficácia dos serviços de análise de sentimentos fornecidos pela Amazon, Google e Microsoft quando submetidos a 12 tipos de ruído, incluindo ruídos sintáticos e semânticos. Os resultados indicam que o Google é o mais resiliente a ruídos sintáticos, e a Microsoft é a mais resiliente a ruídos semânticos. Essas descobertas podem ajudar desenvolvedores e empresas na escolha do provedor de serviços mais adequado e lançar luz sobre a melhoria das técnicas de ponta para serviços de PLN em nuvem eficazes.","Natural Language Processing (NLP) has revolutionized industries, streamlining customer service through applications in healthcare, finance, legal, and human resources domains, and simplifying tasks like medical research, financial analysis, and sentiment analysis. To avoid the high costs of building and maintaining NLP infrastructure, companies turn to Cloud NLP services offered by major cloud providers like Amazon, Google, and Microsoft. However, there is little knowledge about how resilient these services are when subjected to noise. This paper presents a study that analyzes the resilience of Cloud NLP services by evaluating the effectiveness of sentiment analysis services provided by Amazon, Google, and Microsoft when subjected to 12 types of noise, including syntactic and semantic noises. The findings indicate that Google is the most resilient to syntactic noises, and Microsoft is the most resilient to semantic noises. These findings may help developers and companies in selecting the most suitable service provider and shed light towards improving state-of-the-art techniques for effective cloud NLP services.","('Processamento de Linguagem Natural', 'Serviço de nuvem', 'Ruídos (Informática)', 'Natural Language Processing', 'Cloud Services', 'Noise (Computing)')","Ciência da Computação","eng","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/13413","2023-08-30","https://www.repositorio.ufal.br/bitstream/123456789/13413/1/Evaluating%20the%20resilience%20of%20cloud%20NLP%20services%20across%20Amazon%2c%20Microsoft%2c%20and%20Google.pdf","Avaliando a resiliência de serviços NLP na Amazon, Microsoft e Google","('Márcio de Medeiros Ribeiro',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/10769","Campus A.C. Simões","Instituto de Computação","Dissertação","É uma exceção testar comportamento excepcional? Uma avaliação empírica utilizando testes automatizados em Java","('Francisco Dalton Barbosa Dias',)","('Márcio de Medeiros Ribeiro',)","('Baldoíno Fonseca dos Santos Neto', 'Rohit Gheyi')","Executar testes de software é uma atividade crucial para avaliar a qualidade interna de um sistema. Durante os testes, os desenvolveres geralmente criam testes para o comportamento esperado de uma determinada funcionalidade (e.g., o arquivo foi corretamente enviado para a nuvem”). No entanto, pouco é conhecido se os desenvolvedores também criam testes para comportamentos excepcionais (e.g., o que acontece se a conexão de rede for interrompida enquanto o arquivo é enviado?). Para minimizar essa lacuna de conhecimento, neste trabalho nós desenhamos e executamos um estudo de método misto para entender se e até que ponto 417 projetos Java de código aberto estão testando o comportamento excepcional usando os frameworks JUnit e TestNG, e a biblioteca AssertJ. Através de uma análise estática, nós descobrimos que 254 (60,91%) projetos possuem ao menos um método de teste dedicado ao comportamento excepcional. Também descobrimos que o número de métodos de testes para o comportamento excepcional em relação ao total de testes está entre 0% e 10% em 317 (76,02%) projetos. Além disso, 239 (57,31%) projetos testam apenas até 10% das exceções usadas no código do sistema em teste —System Under Test (SUT)—. Quando avaliamos aplicativos para dispositivos móveis, nós observamos que, em geral, os desenvolveres dedicam menos atenção aos testes de comportamentos excepcionais quando comparados aos desenvolvedores de aplicações para desktop/servidores e multi-plataforma. Em geral, nós encontramos mais métodos de testes cobrindo exceções customizadas (as que são criadas dentro do próprio projeto) do que as exceções padrões disponíveis no Java Development Kit (JDK) ou em bibliotecas de terceiros. Além disso, nós também realizamos uma análise dinâmica em um subconjunto de 39 projetos, com dados de cobertura de linha publicamente disponíveis, para investigar se e até que ponto as suítes de testes excercitam os throw statements encontrados no código do sistema testado. Os resultados da nossa análise dinâmica indicam que as suítes de testes não exercitam a maioria dos throw statements, mesmo em projetos onde parece haver preocupações relacionadas à cobertura de código. Nós também enriquecemos o entendimento sobre como os desenvolvedores escrevem seus testes de comportamentos excepcionais em termos de construções do JUnit, TestNG, e do AssertJ. Para triangular os resultados, nós conduzimos uma pesquisa com 66 desenvolvedores dos projetos que estudamos. Em geral, os resultados da pesquisa confirmaram nossas descobertas. Em particular, a maioria dos participantes concordam que os desenvolvedores frequentemente negligenciam testes de comportamentos excepcionais. Como implicações, nossos números podem ser importantes para alertar os desenvolvedores de que mais esforço deve ser feito na criação de testes para comportamentos excepcionais.","Software testing is a crucial activity to check the internal quality of a software. During testing, developers often create tests for the normal behavior of a particular functionality (e.g., was this file properly uploaded to the cloud?). However, little is known whether developers also create tests for the exceptional behavior (e.g., what happens if the network fails during the file upload?). To minimize this knowledge gap, in this work we designed and performed a mixed-method study to understand whether and to what extent 417 open source Java projects are testing the exceptional behavior using the JUnit and TestNG frameworks, and the AssertJ library. Through static analysis, we found that 254 (60.91%) projects have at least one test method dedicated to test the exceptional behavior. We also found that the number of test methods for exceptional behavior with respect to the total number of test methods lies between 0% and 10% in 317 (76.02%) projects. Also, 239 (57.31%) projects test only up to 10% of the used exceptions in the System Under Test (SUT). When it comes to mobile apps, we found that, in general, developers pay less attention to exceptional behavior tests when compared to desktop/server and multi-platform developers. In general, we found more test methods covering custom exceptions (the ones created in the own project) when compared to standard exceptions available in the Java Development Kit (JDK) or in third-party libraries. Moreover, we also performed a dynamic analysis on a subset of 39 projects, with publicly available line coverage reports, to investigate whether and to what extent the test suites exercises the throw statements found in the SUT. The results of the dynamic analysis indicate that the test suites do not exercise the most of throw statements, even in projects where there seem to have concerns about code coverage. We also enriched the understanding of how developers write their exceptional behavior tests in terms of constructs from JUnit, TestNG, and AssertJ. To triangulate the results, we conduct a survey with 66 developers from the projects we study. In general, the survey results confirm our findings. In particular, the majority of the respondents agrees that developers often neglect exceptional behavior tests. As implications, our numbers might be important to alert developers that more effort should be placed on creating tests for the exceptional behavior.","('Java (Linguagem de programação de computador) -Comportamento excepcional', 'Software -Testes', 'Exceptions', 'Exceptional behavior', 'Software testing', 'Testes de software')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/10769","2020-05-29","https://www.repositorio.ufal.br/bitstream/123456789/10769/1/%c3%89%20uma%20exce%c3%a7%c3%a3o%20testar%20comportamento%20excepcional_Uma%20avalia%c3%a7%c3%a3o%20emp%c3%adrica%20utilizando%20testes%20automatizados%20em%20Java.pdf","",""
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/16994","Campus A.C. Simões","Instituto de Computação","Dissertação","Um estudo sobre a participação do usuário final no ciclo de vida de desenvolvimento de aplicações de saúde: da análise do estado da arte à proposição de boas práticas de elicitação de requisitos utilizando o padrão arquétipo OpenEHR","('José Vitor de Abreu Silva',)","('André Magno Costa de Araújo',)","('Rodrigo Gusmão de Carvalho Rocha', 'Maria Lúcia Bento Villela')","Os Sistemas de Informação em Saúde (SIS) desempenham um papel fundamental na sociedade, fornecendo uma base tecnológica sólida para coletar, armazenar, processar e tomar decisões no setor de saúde. Devido ao aumento significativo de soluções de software e as limitações decorrentes das dificuldades associadas ao domínio da saúde, é fundamental a inclusão dos usuários finais no ciclo de vida de desenvolvimento de sistemas de software. Dentre os processos presentes no ciclo de vida, a fase de elicitação de requisitos desempenha um papel fundamental, pois é nesta fase que as necessidades e os objetivos do usuários são identificados e compreendidos, o que requer a utilização de técnicas que garanta a compreensão mais eficaz das necessidades do usuário e que atenda às suas expectativas. O padrão OpenEHR, por exemplo, oferece uma estrutura robusta para a modelagem e representação de informações clínicas, permitindo que os requisitos dos usuários sejam capturados, o que torna possível o desenvolvimento de sistemas de software que atendam às necessidades específicas dos profissionais de saúde e dos pacientes. Dessa forma, este estudo tem como objetivo buscar evidências no estado da arte e da prática a respeito das fases do processo de desenvolvimento o qual os profissionais de saúde são inseridos e as técnicas de elicitação de requisitos presentes no ciclo de vida de desenvolvimento de aplicações de saúde. Este trabalho realizou ainda um estudo com profissionais de saúde e engenheiros de requisitos para analisar se o conhecimento do especialista do domínio especificado por meio do arquétipo OpenEHR pode ser útil para representar os requisitos necessários para o desenvolvimento de aplicações de saúde. A partir de uma análise temática das respostas obtidas com a condução de entrevistas e aplicação de formulário online, foram identificados desafios e limitações que são enfrentados com as aplicações utilizadas. Submetendo os dados obtidos à análises estatísticas, como Alpha de Cronbach, ANOVA e correlação de Spearman, confirmou-se que o baixo envolvimento de profissionais da saúde no ciclo de vida do software implica diretamente na falta de adaptação dessas ferramentas às suas rotinas, pois elas não refletem as suas reais necessidades. Considerando as perspectivas dos engenheiros de requisitos, ressaltou-se a importância do estreitamento entre eles e os especialistas de domínio, evidenciando como a interação pode contribuir para a criação de soluções mais adequadas às exigências clínicas e mais eficazes a longo prazo. Por fim, estes resultados fundamentam um conjunto de boas práticas voltadas para a elicitação e validação de requisitos, que se utilizam da capacidade do arquétipo openEHR de representar cenários e necessidades das partes interessadas com clareza em alto nível de detalhamento. Essas práticas visam reduzir o distanciamento entre o desenvolvimento técnico e as necessidades clínicas, promovendo um alinhamento mais preciso e centrado no usuário final.","Health Information Systems (HIS) play a fundamental role in society by providing a solid technological foundation for collecting, storing, processing, and making decisions in the healthcare sector. Due to the significant increase in software solutions and the limitations arising from the complexities of the healthcare domain, it is essential to include end users in the software development lifecycle. Among the processes in this lifecycle, the requirements elicitation phase plays a key role, as it is during this phase that users’ needs and objectives are identified and understood. This requires the use of techniques that ensure a more effective understanding of user needs and meet their expectations. The OpenEHR standard, for example, offers a robust framework for modeling and representing clinical information, allowing user requirements to be captured, which enables the development of software systems that meet the specific needs of healthcare professionals and patients. Thus, this study aims to seek evidence in the state of the art and practice regarding the phases of the development process in which healthcare professionals are involved and the requirements elicitation techniques present in the healthcare application development lifecycle. This work also conducted a study with healthcare professionals and requirements engineers to analyze whether domain expertise specified through the OpenEHR archetype can be useful in representing the necessary requirements for developing healthcare applications. Through a thematic analysis of responses obtained from interviews and an online survey, challenges and limitations faced with current applications were identified. By subjecting the collected data to statistical analyses, such as Cronbach’s Alpha, ANOVA, and Spearman’s correlation, it was confirmed that the low involvement of healthcare professionals in the software lifecycle directly impacts the lack of adaptation of these tools to their routines, as they do not reflect their real needs. Considering the perspectives of requirements engineers, the study highlighted the importance of closer collaboration between them and domain experts, showing how this interaction can contribute to creating solutions that are more suited to clinical demands and more effective in the long term. Finally, these results support a set of best practices aimed at requirements elicitation and validation, utilizing the OpenEHR archetype’s ability to represent stakeholder scenarios and needs with clarity and a high level of detail. These practices aim to bridge the gap between technical development and clinical needs, promoting a more precise and user-centered alignment.","('Engenharia de software', 'Elicitação de requisitos', 'Ciclo de vida de desenvolvimento de software', 'Aplicações de saúde', 'Arquétipo OpenEHR', 'Software engineering', 'Requirements elicitation', 'Software development lifecycle', 'Health applications', 'OpenEHR archetype')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/16994","2024-11-29","https://www.repositorio.ufal.br/bitstream/123456789/16994/1/Um%20estudo%20sobre%20a%20participa%c3%a7%c3%a3o%20do%20usu%c3%a1rio%20final%20no%20ciclo%20de%20vida%20de%20desenvolvimento%20de%20aplica%c3%a7%c3%b5es%20de%20sa%c3%bade%3a%20da%20an%c3%a1lise%20do%20estado%20da%20arte%20%c3%a0%20proposi%c3%a7%c3%a3o%20de%20boas%20pr%c3%a1ticas%20de%20elicita%c3%a7%c3%a3o%20de%20requisitos%20utilizando%20o%20padr%c3%a3o%20arqu%c3%a9tipo%20OpenEHR.pdf","A study on end-user participation in the healthcare application development life cycle: from state-of-the-art analysis to the proposal of good requirements elicitation practices using the openEHR archetype standard","('Fábio José Coutinho da Silva',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/2038","Campus A.C. Simões","Instituto de Computação","Dissertação","Extração e recomendação de boas e más práticas pedagógicas a partir de processos de ensino e aprendizagem usando um sistema tutor inteligente gamificado","('Sivaldo Joaquim de Santana',)","('Ig Ibert Bittencourt Santana Pinto',)","('Patrick Henrique da silva Brito', 'José Armando Valente', 'Patrícia Leone Espinheira Ospina')","Recentemente, alguns indicadores educacionais revelaram que uma parcela significativa dos estudantes da educação básica apresenta domínio insuficiente em leitura (Língua Portuguesa) e na resolução de problemas (Matemática). Diante disto, nota-se que a educação, equitativa e de qualidade, ainda é um desafio para o Brasil. Entretanto, existe uma grande expectativa de que o acesso às tecnologias de aprendizagem adaptativa e sua adoção na escola seja uma ferramenta potencial para auxiliar o professor e impactar de forma significativa os resultados pedagógicos. Porém, esse tipo de tecnologia têm apresentado alguns problemas, tais como, o uso inadequado, tédio, falta de interesse ou motivação, entre outros fatores e necessita de mais investigações empíricas. Para minimizar esse tipo de comportamento, estudos recentes propõe o uso de elementos de gamificação para aumentar o engajamento e promover a aprendizagem em ambientes educacionais online. Neste contexto, esta dissertação tem como objetivo extrair boas e más práticas pedagógicas a partir de processos de ensino e de aprendizagem usando um Sistema Tutor Inteligente gamificado no Ensino Fundamental. Para tanto, realizou-se um estudo empírico misto com professores e estudantes do ensino fundamental, no domínio de Língua Portuguesa e Matemática. O presente estudo com design de experimento controlado foi realizado no município de São Sebastião, localizado na região agreste do Estado de Alagoas, com aplicação de pré-teste e pós-teste, com 191 estudantes e envolveu doze professores de quatro escolas públicas. No grupo experimental, os estudantes e professores utilizaram um STI gamificado (denominado MeuTutor) durante um período de nove meses, enquanto que, os participantes do grupo de controle não utilizaram nenhuma tecnologia adaptativa. Após o término do experimento, foi realizada a análise estatística dos dados através do modelo de regressão beta e análises de diagnóstico para verificar se um determinado modelo é uma representação adequada dos dados. Além disso, foi aplicado o Framework Analysis como abordagem de análise qualitativa. O Framework Analysis é um processo analítico, com um número distinto de etapas interligado que envolve um processo sistemático de filtragem, mapeamento e classificação do material de acordo com as questões de pesquisa. Os resultados mais relevantes mostram: i) melhoria na aprendizagem dos estudantes com o uso do STI gamificado, no domínio de Língua Portuguesa e Matemática; ii) estudantes do gênero masculino obtiveram um desempenho em Matemática de 18.13% superior aos estudantes do gênero feminino; iii) uso da plataforma MeuTutor pelos estudantes do gênero masculino apresentou um aumento no desempenho de 49.18%, contra 22.14% para os estudantes do gênero feminino no domínio de Língua Portuguesa; iv) os elementos de gamificação “nível” e “troféu” evidenciou um aumento no desempenho dos estudantes, de 2.1% em Língua Portuguesa e 3.0% no domínio de Matemática. Porém, os elementos de gamificação pontos e ranking não apresentaram evidências significantes; v) extração das boas e más práticas pedagógicas com o uso de um STI gamificado, no contexto da educação básica. Portanto, podemos concluir que o uso de STI gamificado alinhado aos processos de ensino e de aprendizagem contribui significativamente para melhoria do desempenho dos estudantes da educação básica em domínios específicos do conhecimento.","Recently, some indicators have revealed that a significant part of students from basic education present insufficient domain on reading (Portuguese language) and on problem resolution (Mathematics). Such fact demonstrates that equitable education and of quality still is a challenge to Brazil. However, there is a large expectation from that the access to adaptive learning technologies and their adoption on schools be a potential tool to support teachers and to significantly impact the pedagogical results. This kind of technologies have present some drawbacks such as unsuitable usage, boredom, lack of interest or motivation, among others factors, claiming more empirical investigations. To minimize this kind of behavior, recent studies propose the usage of gamifying elements to increase the commitment and promote the apprenticeship into online educational environments. In this context, this work aims to extract good and bad pedagogical practices from teaching and learning processes using a Gamified Intelligent Tutor System (ITS) in the Elementary School. We performed a mixed empirical study with teachers and students from elementary school, on the domain of Portuguese language and Mathematics. The present study with controlled experimental design was held at the São Sebastião municipality, located on the state of Alagoas, with pre-test and post-test application, with 191 students and 12 teachers of 4 randomly selected public schools. At the experimental group, students and teachers utilized a gamified ITS (called MeuTutor) during nine months, whereas participants of the control group don’t utilize adaptive technology. After the end of the experiment, we performed a statistical analysis of the data through beta regression model and diagnosis analysis to check whether a certain model is a suitable representation of the data. Furthermore, we applied the Framework Analysis as a qualitative analysis approach. This framework is an analytical process, with some stages that involve a filtering systematic process, mapping, and material's classification in accordance with the research questions. The results stated: (i) improvement on the apprenticeship of students with the usage of the gamified ITS, on the domain of Portuguese language and Mathematics; (ii) male students obtained a performance on math of 18.13% higher than female students; (iii) usage of the MeuTutor's platform by male students presented a growth of 49.18% against 22.14% for female students on the domain of the Portuguese language; (iv) the elements of gamification ""level"" and ""trophy"" indicated a growth in the performance of students of 2.1% on Portuguese language and 3% on the domain of Mathematics. However, the gamification elements ""points"" and ""ranking"" don’t present significant evidences; (v) extraction of good and bad pedagogical practices with the usage of a gamified ITS, on the context of the basic education. Therefore, we conclude the usage of a gamified ITS aligned to the teaching-learning processes significantly contributes to the improvement of performance of students in specific knowledge domains.","('Sistema tutor inteligente', 'Gamificação', 'Língua portuguesa', 'Matemática', 'Experimento controlado', 'Ensino Fundamental', 'Práticas pedagógicas', 'Ensino assistido por computador', 'Intelligent tutoring systems', 'Gamification', 'Portuguese language', 'Mathematics', 'Controlled experiment', 'Elementary school', 'Good and bad pedagogical practices')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/2038","2017-02-23","https://www.repositorio.ufal.br/bitstream/riufal/2038/1/Extra%c3%a7%c3%a3o%20e%20recomenda%c3%a7%c3%a3o%20de%20boas%20e%20m%c3%a1s%20pr%c3%a1ticas%20pedag%c3%b3gicas%20a%20partir%20do%20processo%20de%20ensino%20e%20aprendizagem%20usando%20um%20sistema%20tutor%20inteligente%20gamificado.pdf","Extraction and recommendation of good and bad pedagogical practices from teaching and learning processes using a gamified intelligent tutor system","('Rafael de Amorim Silva',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/13393","Campus A.C. Simões","Instituto de Computação","Dissertação","Exploring the relationship between smells, bugs and harmful code through transfer learning","('Durval Pereira César Neto',)","('Baldoíno Fonseca dos Santos Neto',)","('Marcelo Costa Oliveira', 'Leopoldo Motta Teixeira')","A presença de code smells em um projeto de software é um forte indicativo da baixa qualidade do mesmo no contexto de sua implementação e em uma parcialidade de casos podem estes mesmos code smells serem os trechos de código nocivos para a aplicação, tornando-se os culpados na geração de bugs. Atualmente, existem diferentes abordagens para a detecção de code smells e recentemente houve um maior aprofundamento na análise da correlação entre estes code smells e a nocividade dos mesmos para o código, mas ainda há muito a ser pesquisado no contexto de como podemos melhorar a acurácia na detecção destes códigos potencialmente nocivos. Pensando nisto, este trabalho visa ampliar os métodos para detecção de códigos nocivos utilizando o aprendizado por transferência para construir um grande conjunto de dados para treinamento e validação dos modelos de aprendizagem de máquina.","The presence of code smells in a software project is a strong indication of its low quality in the context of its implementation, and in many cases, these same code smells can be harmful code segments for the application, becoming the culprits in bug generation. Currently, there are different approaches for detecting code smells, and there has been a recent deeper analysis of the correlation between these code smells and their harmfulness to the code. However, there is still much to be researched in the context of how we can improve the accuracy of detecting these potentially harmful codes. With this in mind, this work aims to expand the methods for detecting harmful code by using transfer learning to build a large dataset for training and validating machine learning models.","('Qualidade de software', 'Engenharia de software', 'Transferência de aprendizagem', 'Aprendizado de máquina', 'Software Quality', 'Software Engineering', 'Transfer of learning', 'Machine Learning')","Ciência da Computação","eng","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/13393","2023-08-28","https://www.repositorio.ufal.br/bitstream/123456789/13393/1/Exploring%20the%20relationship%20between%20smells%2c%20bugs%20and%20harmful%20code%20through%20transfer%20learning.pdf","Compreendendo código nocivo por meio de transfer learning",""
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/5935","Campus A.C. Simões","Instituto de Computação","Dissertação","Um estudo exploratório sobre os aspectos que influenciam na eficiência da predição de sucesso acadêmico de alunos de programação introdutória","('José Estevam Vilar Borges',)","('Evandro de Barros Costa',)","('Baldoíno Fonseca dos Santos Neto', 'Rafael Ferreira Leite de Mello')","Existe uma carência de ferramentas inteligentes para auxiliar os professores na análise de grande massa de dados gerada sobre os alunos de um determinado curso, permitindo mensurar o nível de aprendizado dos alunos ou ainda auxiliar na identificação daqueles que não estão conseguindo obter um bom rendimento no aprendizado. Para amenizar esse tipo de lacuna, atualmente existem diversos estudos na área de Mineração de Dados e Aprendizagem de Máquina, abordando o processo de obtenção de conhecimento para ajudar na tomada de decisões. Assim essa área, tem sido explorada para apoiar o ensino e pesquisa, permitindo a extração de informação relevante, dentre os dados disponíveis, para suportar a tomada de decisões pelos educadores, principalmente, e também gestores. Este trabalho busca explorar os fatores, dentro do processo de predição, que possuem influência na eficiência das técnicas já conhecidas de predição de sucesso dentro do âmbito educacional. Para isso, foram aplicadas em um banco de dados real quatro abordagens distintas, porém correlacionadas, para mensurar a eficiência de cada técnica. Tais abordagens consideram características particulares de cada aluno, além de explorar também a eficiência de cada técnica relacionadas à parcela amostral de treino e teste, características específicas dos algoritmos de árvore de decisão e aspectos temporais da predição.","There is a lack of intelligent tools to assist teachers in the analysis of the large amount of data generated on the students of a particular course, allowing to measure the level of learning of the students or to assist in the identification of those who are not achieving a good performance in learning . To mitigate this type of gap, there are currently several studies in the area of Data Mining and Machine Learning, addressing the process of obtaining knowledge to assist in decision making. Thus, this area has been exploited to support teaching and research, allowing the extraction of relevant information, among the available data, to support decision-making by educators, mainly as well as managers. This work seeks to explore the factors, within the prediction process, that influence the efficiency of the already known techniques of prediction of success within the educational scope. For this purpose, four different but correlated approaches were applied to a real database to measure the efficiency of each technique. These approaches take into account the particular characteristics of each student, as well as to explore the efficiency of each technique related to the training sample and test, specific characteristics of the decision tree algorithms and temporal aspects of the prediction.","('Mineração de dados educacionais', 'Mineração de dados (Computação)', 'Aprendizagem por computador', 'Seleção de atributos', 'Algoritmos de predição', 'Educational Data Mining', 'Data Mining (Computing)', 'Computer learning', 'Attribute Selection', 'Prediction Algorithms')","Sistemas de Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/5935","2019-05-07","https://www.repositorio.ufal.br/bitstream/riufal/5935/1/Um%20estudo%20explorat%c3%b3rio%20sobre%20os%20aspectos%20que%20influenciam%20na%20efici%c3%aancia%20da.pdf","An exploratory study on the aspects that influence the predicting efficiency of academic success for introductory programming students",""
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/8823","Campus A.C. Simões","Instituto de Computação","Dissertação","Estimação de parâmetros do modelo do circuito equivalente do sistema cardiovascular humano usando deep learning","('Jorge Santos Leandro',)","('Thiago Damasceno Cordeiro',)","('Xu Yang', 'Antônio Marcus Nogueira de Lima')","Pacientes portadores de doenças cardíacas graves ainda encontram no transplante cardíaco a melhor opção de tratamento. Entretanto, os chamados Dispositivos de Assistência Ventricular (DAVs) vêm sendo utilizados com sucesso no suporte ao bombeamento do músculo cardíaco na tentativa de suprir as necessidades do sistema cardiovascular humano (SCH). Os chamados modelos a parâmetros concentrados possuem grande importância para a realização de simulações computacionais de variáveis hemodinâmicas (VHs), seja utilizando modelos do SCH ou modelos do DAV, o que viabiliza a análise de desempenho de diferentes modos de operação antes mesmo de implantar o dispositivo no paciente. Além disso, modelos específicos para um determinado paciente permitem que a sintonia de sistemas de controle seja realizada de acordo com a situação clínica deste paciente. Sabe-se que processo de estimação paramétrica de tais modelos necessita dados do paciente e nem sempre as VHs de interesse encontram-se disponíveis e de maneira não invasiva. Em face ao exposto, deve-se buscar a utilização de VHs que sejam preferencialmente obtidas por meio de técnicas não invasivas. Neste trabalho, investiga-se a viabilidade de implementação de um processo de estimação paramétrica de um modelo do sistema cardiovascular. Para este propósito, são utilizadas técnicas de aprendizagem profunda, tendo como sinal de entrada apenas o sinal de pressão arterial sistêmica em forma de onda, uma vez que esta VH pode ser obtida utilizando-se métodos não invasivos. Com base no modelo, uma base de dados sintética foi gerada e subdividida em 3 partes: treinamento, validação e teste. Estas subdivisões foram utilizadas para treinar os modelos das redes neurais. Um estudo de sensibilidade paramétrica analisa a influência da variação de cada um dos parâmetros deste modelo em todas as VHs, uma vez que esta correlação está diretamente relacionada à precisão dos valores estimados dos parâmetros. Os resultados destacam baixíssima sensibilidade da pressão sistêmica com relação a determinados parâmetros, o que prejudica a estimação destes e confirma a necessidade da adição de mais VHs como entrada para o estimador. O estudo de sensibilidade também destaca que a variação de alguns parâmetros não têm influência significativa em nenhuma das VH, prejudicando todo o processo de estimação para um paciente específico.","For patients with severe heart diseases, heart transplantation is still the best treatment option. However, the so-called Ventricular Assist Devices (VADs) have been used successfully to support the pumping of the cardiac muscle to meet the needs of the human cardiovascular system (CVS). The so-called lumped parameter (0D) models are of great importance for computational simulations of hemodynamic variables (HVs), either using CVS models or VAD models, making it possible to analyze the performance of different operation modes even before implanting the device in the patient. Furthermore, specific models for a given patient allow the tuning of control systems to be carried out according to the clinical situation of that patient. It is known that the parametric estimation process of such models requires patient data and the HVs of interest are not always. Thus, using HVs preferably obtained through non-invasive techniques and those considered common in the medical-hospital environment should be sought. This work investigates the feasibility of implementing a parametric estimation process of a 0D model of the human CVS for specific patients. For this purpose, deep learning techniques are used, having only the arterial systemic blood pressure signal as input signal since it is can be obtained using non-invasive methods. The synthetic database was generated and divided in 3 subsets: training, validation and test. This subsets was used for training the neural network models.The sensitivity function is calculated to investigate the influence of the CVS parameter variation on all HVs since this correlation is directly related to the accuracy of the estimated parameter values. The results highlight the very low sensitivity of systemic pressure for certain parameters. This fact impairs their estimation and confirms the need to add more HVs as inputs to the estimator. The sensitivity study also highlights that some parameters’ variation does not significantly influence any of the HVs, impairing the entire estimation process for a specific patient.","('Estimação paramétrica', 'Variáveis hemodinâmicas – Simulação (Computadores)', 'Modelagem computacional específica para o paciente', 'Aprendizagem profunda', 'Redes neurais', 'Parametric Estimation', 'Hemodynamic Variables', '0D Models', 'Patient Specific', 'Deep Learning')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/8823","2021-08-27","https://www.repositorio.ufal.br/bitstream/123456789/8823/1/Estima%c3%a7%c3%a3o%20de%20par%c3%a2metros%20do%20modelo%20do%20circuito%20equivalente%20do%20sistema%20cardiovascular%20humano%20usando%20Deep%20Learning.pdf","Estimation of equivalent circuit model parameters of the cardiovascular system human using deep learning",""
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/11777","Campus A.C. Simões","Instituto de Computação","Dissertação","Estereótipos sexuais, expectativa de desempenho e experiência de fluxo em sistemas de tutoria gamificados: uma perspectiva LGBTQIAP+","('Breno Felix de Sousa',)","('Ig Ibert Bittencourt Santana Pinto',)","('Diego Dermeval de Medeiros da Cunha Matos', 'Leogildo Alves Freires', 'Telma Low Silva Junqueira')","A educação em Statistic, Technology, Engineering and Mathematics (STEM) é permeada por uma tradicional cultura cis-heteronormativa que dita quem permanece a estes espaços e quem será a evasão nesses cursos. Existe a Ideia de que a heteronormatividade é o status quo padrão e tudo o que foge disso é tido como grupos minorizados em STEM. A literatura apresentada evidencia a importância deste trabalho, ao passo que também mostra com teorias e quasi-experimentos essas supões existentes em ambientes tradicionais de ensino em STEM, como sala de aula e em ambientes virtuais de ensino. STEM em seu modelo de ensino e inclusão atual continua a perpetuar essa tradição não inclusiva. O uso de tecnologias educacionais está cada vez mais presente em sala de aula, principalmente em um cenário atual em que a educação remota se faz tão necessária. Neste sentido, surge a gamificação como uma alternativa poderosa capaz de propiciar ambientes virtuais de ensino. Gamificação pode ser entendida como a utilização de conceitos de jogos em ambientes de não jogos, é a utilização de conceitos, técnicas, formas, métodos, elementos e variáveis características de jogos que podem ser utilizadas no desenvolvimento de um ambiente de ensino. A utilização da gamificação em ambientes educacionais pode ser uma alternativa para viabilizar um ensino à distância eficaz. A gamificação em ambientes virtuais de ensino pode ser considerada uma técnica poderosa de interação de estudantes e professores com o ambiente de ensino. A preocupação com o ensino e aprendizado não é recente, na literatura é fácil encontrar estudos relacionados a essa preocupação. A gamificação pode replicar estereótipos tradicionalmente convencionalizados em STEM, quando os elementos de gamificação como cores, frases, avatares, efeitos sonoros e outros são aplicados de forma correta contribui positivamente para o aprendizado, ao passo que, quando desenhados sem uma análise contextual-cultural pode reafirmar estereótipos de ambientes tradicionais em ambientes gamificados. Tecnologias gamificadas e estereotipadas podem impactar diretamente no desempenho de estudantes, interferindo na aprendizagem e até mesmo na sua evolução no ensino. Neste contexto, este estudo apresentou e identificou efeitos de estereótipos em ambientes gamificados de ensino e sua relação com a experiência de fluxo, expectativa de desempenho e desempenho de grupos minorizados socialmente como lésbicas, gays, bissexuais, travestis, homens transexuais, queer, intersexo, asexuais, pansexuais, mais diversidade (LGBTQIAP+) em cursos STEM. Para isso, é apresentada uma revisão sistemática seguida de uma metanálise, um quasiexperimento e um estudo qualitativo. Desta forma, portanto, esse estudo contribui para a compreensão do impacto que estereótipos sexuais em ambientes gamificados têm no desempenho de estudantes. Espera-se que com os resultados desta pesquisa possa também contribuir para uma melhor inclusão da diversidade sexual.","Education in Statistic, Technology, Engineering and Mathematics (STEM) is permeated by a traditional cis-heteronormative culture that dictates who stays in these spaces and who will evade these courses. There is the idea that heteronormativity is the default status quo and everything that deviates from it is seen as minority groups in STEM. The literature presented in this dissertation confirms these statements and highlights the importance of this work, while also showing with theories and quasi-experiments these assumptions existing in traditional STEM teaching environments, such as the classroom and in virtual teaching environments. STEM in its current teaching and inclusion model continues to perpetuate this non-inclusive tradition. The use of educational technologies is increasingly present in the classroom, especially in a current scenario where remote education is so necessary. In this sense, gamification emerges as a powerful alternative capable of providing virtual teaching environments. Gamification can be understood as the use of game concepts in non-game environments, it is the use of concepts, techniques, forms, methods, elements and variables characteristic of games that can be used in the development of a teaching environment. The use of gamification in educational environments can be an alternative to enable effective distance learning. Gamification in virtual teaching environments can be considered a powerful technique for students and teachers to interact with the teaching environment. The concern with teaching and learning is not recent, in the literature it is easy to find studies related to this concern. Gamification can replicate stereotypes traditionally conventionalized in STEM, when gamification elements such as colors, phrases, avatars, sound effects and others are applied correctly, it contributes positively to learning, while, when designed without a contextual-cultural analysis, it can reaffirm stereotypes of traditional environments in gamified environments. Gamified and stereotyped technologies can directly impact student performance, interfering with learning and even their evolution in teaching. In this context, this study presented and identified the effects of stereotypes in gamified teaching environments and their relationship with the flow experience, performance expectation and performance of socially minorized groups such as lesbians, gays, bisexuals, transvestites, transgender men, queer, intersex, asexuals, pansexuals, more diversity (LGBTQIAP+) in STEM courses. For this, a systematic review is presented followed by a meta-analysis, a quasi-experiment and a qualitative study. In this way, therefore, this study contributes to the understanding of the impact that sexual stereotypes in gamified environments have on student performance. It is hoped that the results of this research can also contribute to a better inclusion of sexual diversity.","('Gamificação', 'Educação', 'Movimento LBGT', 'Educação', 'Tecnologia de desempenho', 'Habilidades cognitivas -Teoria do fluxo', 'Gamification', 'Education', 'Performance expectation', 'Flow theory', 'Stereotype', 'STEM')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/11777","2022-12-08","https://www.repositorio.ufal.br/bitstream/123456789/11777/1/Estere%c3%b3tipos%20sexuais%2c%20expectativa%20de%20desempenho%20e%20experi%c3%aancia%20de%20fluxo%20em%20sistemas%20de%20tutoria%20gamificados_uma%20perspectiva%20LGBTQIAP%2b.pdf","Do gamified tutoring systems hinder sexual diversity? An experimental study with cis-heteronormative stereotypes","('Geiser Chalco Challco',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/1722","Campus A.C. Simões","Instituto de Computação","Dissertação","Um estudo comparativo das técnicas de predição na identificação de insucesso acadêmico dos estudantes durante cursos de programação introdutória","('Marcelo Almeida Santana',)","('Evandro de Barros Costa',)","('Patrick Henrique da Silva Brito', 'Ryan Shaun Joazeiro de Baker')","As altas taxas de insucesso nas universidades nos cursos que contemplam a disciplina de programação introdutória na sua grade curricular tem alarmado e preocupado muitos educadores, pois o insucesso dos estudantes podem gerar prejuízos dos mais diversos tipos e interesses. Assim, há relevantes motivos para se tentar esclarecer eventuais fatores que afetam tal insucesso. Ainda neste contexto, um dos desafios importantes é o de identificar antecipadamente os estudantes propensos ao insucessos na disciplina de programação introdutória, assumindo-se em tempo hábil para permitir intervenção pedagógica eficaz. Deste modo, buscou-se neste trabalho um estudo em técnicas de mineração de dados educacionais , objetivando-se comparar a eficácia dos algoritmos de predição capazes de identificar, em tempo hábil para intervenção pedagógica, os estudantes propensos ao insucesso. Neste estudo, avaliou-se a eficácia de algoritmos de predição em duas fontes de dados diferentes e independentes, uma na modalidade presencial e outra na modalidade de ensino a distância sobre as disciplinas de programação introdutória. Os resultados mostraram que as técnicas analisadas no estudo são eficazes na identificação dos estudantes propensos ao insucesso no início da disciplina. Além disso, mostrou-se também que após a realização das etapas de pré-processamento e ajustes nos parâmetros de algoritmos, tais algoritmos analisados tiveram uma melhora em seus resultados. Ao fim do processo, o algoritmo máquina de vetor de suporte (SVM: Support Vector Machine) apresentou os melhores resultados, tanto na modalidade de ensino presencial quanto na modalidade a distância, alcançando uma taxa de f-measure de 83% e 92%, respectivamente.","The high failure rates of students in the introductory programming course within the universities worldwide have alarmed and worried many educators. Those rates can lead to losses of various types and interests. Thus, there are important reasons to try to clarify the main factors that possibly influence such failures. Furthermore, one of the major challenges is on how to early identify the students likely to in the introductory programming course, eventually allowing effective pedagogical interventions. Thus, in this study we aim to explore educational data mining techniques, in order to compare the effectiveness of prediction algorithms capable of identifying students likely to fail, in a timely manner suitable for pedagogical intervention. This study evaluated the efficacy of prediction algorithms in two different and independent data sources one in the classroom teaching mode and the other in the distance education mode in the disciplines in the introductory programming. The results showed that the techniques discussed in this study are effective in this task of prediction. In addition, it was shown also that after the completion of the pre-processing and adjustments to the parameters of the algorithms analyzed had an improvement in their results. At the end of the process, the Supported Vector Machine (SVM) algorithm showed the best results, both in the classroom teaching mode as in the distance, reaching an f-measure rate of 83% and 93% respectively.","('Programação (Computadores)', 'Avaliação educacional', 'Mineração de dados (Computação)', 'Programming (Computers)', 'Educational assessment', 'Data mining (computing)')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1722","2015-11-06","https://www.repositorio.ufal.br/bitstream/riufal/1722/1/Um%20estudo%20comparativo%20das%20t%c3%a9cnicas%20de%20predi%c3%a7%c3%a3o%20na%20identifica%c3%a7%c3%a3o%20de%20insucesso%20acad%c3%aamico%20dos%20estudantes%20durante%20cursos%20de%20programa%c3%a7%c3%a3o%20introdut%c3%b3ria.pdf","A comparative study of prediction techniques in identifying academic failure of students for programming introductory courses","('Baldoíno Fonseca dos Santos Neto',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/10765","Campus A.C. Simões","Instituto de Computação","Dissertação","Especificação e análise de um mecanismo de controle de admissão bidirecional para protocolos de roteamento oportunístico em redes ad hoc sem fio","('Adriano da Silva Araújo',)","('Leandro Dias da Silva',)","('Álvaro Alvares de Carvalho César Sobrinho', 'Rafael de Amorim Silva', 'Ivanovitch Medeiros Dantas da Silva')","Rede Ad Hoc sem fio é um modelo de comunicação que caracteriza-se pela ausência de um gerenciador central, em que as ligações entre os nós ocorrem de forma independente em relação às demais, ao ponto que, caso uma ligação falhe, as demais não são impactadas. Neste contexto, uma das abordagens de encaminhamento/roteamento de pacotes propostas na literatura é o Roteamento Oportunístico (RO). No RO, existe uma maior probabilidade de entrega dos pacotes, pois todos os caminhos da origem ao destino são avaliados no roteamento. Tal fato pode ser considerado uma vantagem para o atendimento dos requisitos de Qualidade de Serviço (Quality of Service -QoS) das aplicações. No entanto, prover QoS em ambientes de redes Ad Hoc sem fio oportunistas não é uma tarefa trivial. Para contribuir com a melhoria deste cenário, o Controle de Admissão (CA) de fluxos é um mecanismo viável para garantir que novos fluxos só serão admitidos na rede se houver recursos disponíveis. Este trabalho tem o objetivo de propor, especificar e analisar um mecanismo de controle de admissão de fluxos de dados bidirecional em redes Ad Hoc sem fio oportunísticas. Neste sentido, foram utilizados o OMNeT++, um simulador de eventos discretos de rede, para realizar a avaliação experimental do mecanismo proposto e uma modelagem formal em Redes de Petri Coloridas (Colored Petri Nets -CPN ) na ferramenta de software CPN/Tools com o propósito de aumentar a cobertura de simulação e testes. Com os resultados obtidos foi possível identificar que para o modelo proposto, um fluxo será admitido somente se, após a descoberta de rede, existir nos nós encaminhadores recursos disponíveis para a transmissão e recepção de dados conforme requerido pela aplicação.","Wireless Ad Hoc Network is a communication model characterized by the absence of a central manager where the connections between nodes happen independently to the others. In case a link fails, it will not impact the others. In this context, a packet routing approach proposed in the literature is Opportunistic Routing (OR). In OR, there is a greater probability of packet delivery because all paths from source to destination are evaluated in routing, this fact can be considered an advantage for meeting the Quality of Service (QoS) requirements of the applications. However, providing QoS in opportunistic wireless Ad Hoc network environments is not a trivial task. To contribute to the improvement of this scenario, the Admission Control (AC) of flows is a viable mechanism to guarantee that new flows will only be admitted into the network if resources are available. This work aims to propose, specify and analyze an admission control mechanism for bidirectional data flows in opportunistic wireless Ad Hoc networks. In this sense, OMNeT++, a discrete network event simulator, was used to perform the experimental evaluation of the proposed mechanism and a formal model in Colored Petri Nets (CPN) in the CPN/Tools software tool in order to increase the coverage simulation and testing. With the results obtained, it was possible to identify that for the proposed model, a flow will be admitted only if, after the network discovery, there are resources available in the forwarding nodes for the transmission and reception of data as required by the application.","('Informática', 'Redes ad hoc', 'Sistemas de comunicação sem fio – Qualidade de serviços', 'Sistemas de comunicação sem fio -Controle de admissão', 'Redes de computador -Roteamento oportunístico', 'Wireless ad hoc networks', 'Opportunistic routing', 'Quality of service', 'Admission control')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/10765","2021-04-30","https://www.repositorio.ufal.br/bitstream/123456789/10765/1/Especifica%c3%a7%c3%a3o%20e%20an%c3%a1lise%20de%20um%20mecanismo%20de%20controle%20de%20admiss%c3%a3o%20bidirecional%20para%20protocolos%20de%20roteamento%20oportun%c3%adstico%20em%20redes%20ad%20hoc%20sem%20fio.pdf","","('Ivo Augusto Andrade Rocha Calado',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/1615","Campus A.C. Simões","Instituto de Computação","Dissertação","Especificação formal do gerenciamento de risco de equipamentos médicos baseado na ISO 14971:2009 utilizando Redes de Petri Coloridas","('José Cavalcante Reis Neto',)","('Leandro Dias da Silva',)","('Evandro de Barros Costa', 'Kyller Costa Gorgônio')","O avanço da medicina e da tecnologia da informação (TI) tem propiciado o surgimento de novas técnicas e equipamentos que, gradativamente, oferecem melhorias diretas ou indiretas à saúde dos pacientes como, por exemplo, as técnicas cirúrgicas minimamente invasivas e os novos equipamentos para diagnóstico e monitoramento de pacientes (HOLSBACH; NETO; HOLSBACH, 2013). É com a utilização destes equipamentos que se torna possível ter melhores condições de diagnóstico e tratamento de doenças, menor tempo de internação, maior praticidade e privacidade, permitindo inclusive ao paciente proceder com o tratamento domiciliar, contudo, o crescimento da quantidade de dispositivos nem sempre está aliada à qualidade. A má qualidade destes equipamentos é um problema que pode comprometer a saúde do paciente e do operador e, por isso, se faz necessária a utilização de técnicas e padrões que permitam a fabricação de equipamentos médicos mais seguros, tais como a técnica Análise dos Modos de Falha Efeitos e Criticidade (FMECA) e o padrão International Organization for Standardization (ISO) 14971 (ABNT -ASSOCIAÃ‡ÃƒO BRASILEIRA DE NORMAS TÃ‰CNICAS, 2009). A ISO 14971 foi desenvolvida com o propósito de indicar os controles e os cuidados básicos que devem ser observados pelo fabricante em todo o ciclo de vida de um equipamento médico. De acordo com esta ISO, segurança é a ausência de riscos não aceitáveis e a verificação se os riscos encontrados são aceitáveis ou não acontece durante o processo de gerenciamento de risco, porém, os fabricantes ao adotar o gerenciamento de risco descrito em linguagem natural, que é ambigua, estão suscetáveis a problemas tais como, falta de compreensão das etapas do processo de gerenciamento de risco, criação de processo demasiadamente complexo ao qual terão dificuldade de aplicar ou simplista demais que não contempla todo o gerenciamento de risco. Com a finalidade de solucionar o supracitado problema é apresentado neste trabalho um estudo de caso explorando o processo de gerenciamento de risco baseado na ISO 14971 com a técnica FMECA, com o objetivo de realizar a especificação de segurança de um equipamento médico de Eletrogastrografia (EGG). Esse estudo de caso foi realizado no Hospital Universitário da Universidade Federal de Alagoas e contou com o auxílio de um especialista em desenvolvimento de sistemas de aquisição de sinais biomédicos. Esse estudo é a base para a construção do modelo formal em Redes de Petri Coloridas do processo de gerenciamento de risco. O modelo em Redes de Petri Coloridas auxilia no entendimento da ISO, ao reduzir a subjetividade inerente a descrição em linguagem natural. Além disto, este modelo auxilia nas etapas de verificação e validação do equipamento médico e possibilita uso do modelo como uma ferramenta didática para o ensino e treinamento do processo de gerenciamento de risco.","The advance of medicine and Information Technology (IT) has allowed the emergence of new techniques and medical device to provide direct or indirect improvements to the people's health, such as the minimally invasive surgical techniques and new devices for diagnosis and patient monitoring (HOLSBACH; NETO; HOLSBACH, 2013). The use of such devices provides a better diagnosis procedure and better diseases treatment, shorter hospital stay, convenience and privacy, as well as the possibility of the patient to proceed with home treatment. However, the growth of the number of devices is not always based on quality. The poor quality of such device is a problem that may compromise people's health. Therefore, in order to mitigate the risks of failures during the development of these medical devices, the manufacturers must follow safety standards specifications, such as the International Organization for Standardization (ISO) 14971 (ABNT -ASSOCIAÃ‡ÃƒO BRASILEIRA DE NORMAS TÃ‰CNICAS, 2009) and the technique Failure Mode, Effects and Criticality Analysis (FMECA). The ISO 14971 was specified to guide the controls and basic care to be observed by the manufacturer throughout the development of all stages during the medical device's life cycle. According to this standard, security is freedom from unacceptable risk, and the discovery and verification if the risk is unacceptable or not happen during the risk management process. However the ISO 14971 was described in natural language, which is an error-prone description, ambiguous and is susceptible to problems such as misunderstanding of the stages of the risk management process, creating too complex process which will be difficult to be applied or too simplistic that does not address all risk management. Within this context, we use the ISO 14971 standard with the FMECA technique to provide a case study that performs the security specification of the Electrogastrography (EGG) device. This case study was performed at the Federal University of Alagoas Hospital, with the support of an expert in the development of biomedical signal acquisition systems. This case study was the basis to develop a Colored Petri Net that describes the risk management process, reducing the problems on natural language descriptions. In addition, this model helps in the verification and the validation steps of medical devices manufacturing and allows the use of modeling as a tool for teaching and training the risk management process.","('Gerenciamento de risco', 'Redes petri coloridas', 'ISO 14971:2009', 'Equipamentos médicos -Utilização', 'Colored petri net', 'Risk management')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1615","2014-12-29","https://www.repositorio.ufal.br/bitstream/riufal/1615/1/Especifica%c3%a7%c3%a3o%20formal%20do%20gerenciamento%20de%20risco%20de%20equipamentos%20m%c3%a9dicos%20baseado%20na%20ISO%2014971%3a2009%20utilizando%20Redes%20de%20Petri%20Coloridas.pdf","A colored petri nets model for the risk management process based on the ISO 14971:2009 standard",""
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/9690","Campus A.C. Simões","Instituto de Computação","Dissertação","Estudo comparativo sobre meta-heurísticas em GPU para clusterização de dados","('Mario Diego Ferreira dos Santos',)","('Bruno Costa e Silva Nogueira',)","('Erick de Andrade Barboza', 'Ermeson Carneiro de Andrade')","Clusterização é uma classe fundamental de problemas com aplicações em muitas áreas do conhecimento, incluindo: bioinformática, visão computacional, mineração de dados, mineração de texto e agrupamento de páginas na Web. Dado um conjunto de n objetos, a clusterização objetiva agrupar automaticamente tais objetos em k grupos, geralmente disjuntos, denominados clusters ou agrupamentos utilizando uma medida de similaridade preestabelecida. Problemas de clusterização em geral têm alta complexidade computacional e envolvem uma grande quantidade de dados de entrada. Dessa forma, o uso de arquiteturas paralelas como Graphics Processing Units (GPUs) são alternativas interessantes para acelerar o processo de clusterização. Neste trabalho, foi conduzido um estudo comparativo de meta-heurísticas aceleradas por GPU para agrupamento de dados. Três meta-eurísticas populacionais foram implementadas na GPU: Particle Swarm Optimization (PSO), Differential Evolution (DE) e Scatter Search (SS). A implementação dessas meta-heurísticas foi dividida em duas partes: a parte independente do problema e a parte dependente problema. A parte independente do problema se refere aos operadores de seleção, reposição e combinação de cada meta-heurística, enquanto que a parte dependente se refere a função objetivo. A parte independente foi implementada usando o framework libCudaOptimize, e a parte dependente foi criada transformando o problema de clusterização em um problema de otimização global sujeito a restrições de caixa. As metaheurísticas propostas foram comparadas com o melhor algoritmo de clusterização da atualidade C-GRASP-Clu considerando o tempo de execução e qualidade da solução. Os resultados indicam que o PSO baseado em GPU (GPU-PSO) obteve os melhores resultados em comparação com as outras meta-heurísticas baseadas em GPU e o melhor método da atualidade. Além disso, nossa implementação em GPU da função objetivo obteve um speedup médio de 175x sobre a versão sequencial. Os resultados demonstram que uma abordagem de GPU para o problema de clusterização é muito promissora.","Clustering is a fundamental class of problems with applications in many areas of knowledge, including: bioinformatics, computer vision, data mining, text mining, and web page grouping. Given a set of n objects, clustering aims to automatically group such objects in k groups, usually disjunct, called clusters or groupings using a pre-established similarity measure. Clustering problems in general have high computational complexity and involve a large amount of input data. Thus, the use of parallel architectures such as Graphics Processing Units (GPUs) is interesting alternatives to accelerate the clustering process. In this work, we conducted a comparative study of GPU-accelerated metaheuristics for grouping data. Three population meta-heuristics were implemented in the GPU: Particle Swarm Optimization (PSO), Differential Evolution (DE), and Scatter Search (SS). The implementation of these meta-heuristics was divided into two parts: the independent part of the problem and the dependent part of the problem. The independent part of the problem refers to the selection, replacement, and combination operators for each meta-heuristic, while the dependent part refers to the objective function. The independent part was implemented using the libCudaOptimize framework, and the dependent part was created by transforming the clustering problem into a global optimization problem subject to cash constraints. The proposed meta-heuristics were compared with the best current clustering algorithm C-GRASP-Clu considering the execution time and quality of the solution. The results indicate that the GPU-based PSO (GPU-PSO) obtained the best results in comparison with the other GPU-based metaheuristics and the best method today. Also, our GPU implementation of the objective function obtained an average speedup of 175x over the sequential version. These results demonstrate that a GPU approach to the clustering problem is very promising.","('Clusterização de dados', 'Meta-heurística', 'Unidades de processamento gráfico', 'Otimização', 'Data clustering', 'Metaheuristics', 'GPU', 'Optimization')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/9690","2021-04-30","https://www.repositorio.ufal.br/bitstream/123456789/9690/1/Estudo%20comparativo%20sobre%20meta-heur%c3%adsticas%20em%20GPU%20para%20clusteriza%c3%a7%c3%a3o%20de%20dados.pdf","A comparative study of GPU metaheuristics for data clustering","('Rian Gabriel Santos Pinheiro',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/11922","Campus A.C. Simões","Instituto de Computação","Dissertação","Estereótipos de gênero, pensamento negativo e experiência de fluxo em tecnologias digitais educativas gamificadas","('Jessica Fernanda Silva Barbosa',)","('Ig Ibert Bittencourt Santana Pinto',)","('Diego Dermeval de Medeiros da Cunha Matos', 'Leonardo Brandão Marques')","A utilização da gamificação dentro da sala de aula, tornou-se uma alternativa muito atrativa em tecnologias digitais educativas, visando tornar atividades de aprendizagem entediantes em atividades engajadoras, entretanto sua utilização nem sempre traz os resultados esperados. Entre os fatores que podem afetar negativamente a aprendizagem em tecnologias digitais gamificadas, a estereotipação de gênero é uma delas, a qual pode diminuir o desempenho do aluno ou ainda despertar interferência cognitivas no indivíduo tais como pensamento negativo. Nesse sentido, o estudante ao invés de direcionar esforço e concentração nas atividades de aprendizagem, ele é direcionado para pensamentos que os desconcentram e fazem cair seu desempenho. Nesse sentido, este estudo visa identificar e analisar os efeitos do estereótipo de gênero na experiência de fluxo (estado de total imersão almejado por todo ambiente educativo), pensamento negativo em tecnologias digitais gamificadas. Para isso, serão realizadas revisões sistemáticas da literatura (meta-análises) e condução de estudos quase-experimentais. Revisões sistemáticas possibilitam obter um panorama geral de como estereótipos e gamificação afetam nos pensamentos negativos, experiência de fluxo e a aprendizagem. Estudos quase-experimentais de tipo quantitativo e qualitativo serão conduzidos visando explicar os efeitos observados de estereótipo em tecnologias digitais gamificadas. Desta forma as contribuições deste estudo visam fornecer evidências se estereótipos de gênero em tecnologias digitais gamificadas podem causar pensamentos negativos, se eles afetam a experiência de fluxo e se eles contribuem num desempenho ruim da aprendizagem dos alunos. Almejamos também, identificar se existe um gênero que possa ser mais afetado pelo estereótipo e compreender as causas desses efeitos. Esses resultados esperam contribuir na geração de diretrizes, recomendações e práticas das adaptações e implementações de tecnologia digital gamificadas sem ameaça de estereótipo, tecnologia mais justa e tecnologia que promova a equidade de gênero.","Using gamification in classrooms has become an interesting attractive alternative in educational digital technologies, with the objective convert tedious learning activities into engaging ones. Nonetheless, its use sometimes fails to bring the expected results. Stereotyping is between the factors that may negatively affect learning in gamified digital technologies, thus hindering student performance or even inducing cognitive interference in the individual, such as negative thinking. Under these circumstances, instead of directing effort and concentration in learning activities, students are conducted to disperse leading to a performance drop. Considering this possibility, the present study aims to identify and analyze effects of gender stereotypes on the flow experience, negative thinking and learning performance in gamified digital technologies. In order to achieve this goal, systematic literature reviews and quasi-experimental studies will be conducted. The former may provide an overview of how stereotypes and gamification effects over negative thinking, flow experience and learning performance, whilst the latter will be conducted in order to try to explain consequences of gender stereotyping in gamified digital technologies. Therefore, this study has the potential to provide evidence of stereotypes’ influence in gamified digital technologies: either leading to negative thoughts, affecting the flow experience and contributing to poor learning performances. Furthermore, we aim to identify if a gender is more affected by stereotyping and list possible causes of these effects. Results expected may be able to contribute to develop guidelines, advices and practices adapted to avoid the stereotype threat while implementing gamified digital technologies, seeking equitable environments and promoting gender equity.","('Gamificação', 'Estereótipos de gênero', 'Pensamentos negativos', 'Aprendizagem – Desempenho', 'Tecnologia educacional', 'Gamification', 'Gender stereotypes', 'Negative thinking', 'Learning – Performance', 'Educational technology')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/11922","2022-12-08","https://www.repositorio.ufal.br/bitstream/123456789/11922/1/Estere%c3%b3tipos%20de%20g%c3%aanero%2c%20pensamento%20negativo%20e%20experi%c3%aancia%20de%20fluxo%20em%20tecnologias%20digitais%20educativas%20gamificadas.pdf","","('Geiser Chalco Challco',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/11921","Campus A.C. Simões","Instituto de Computação","Dissertação","Estereótipos de gênero, autoeficácia e experiência de fluxo em ambientes educacionais online gamificados","('Francys Rafael do Nascimento Martins',)","('Ig Ibert Bittencourt Santana Pinto',)","('Diego Dermeval de Medeiros da Cunha Matos', 'Leonardo Brandão Marques')","O uso da gamificação vem sendo amplamente estudado nos últimos anos, em particular quando ela é utilizada como intervenção para aumento de motivação e engajamento em cenários educativos. Mesmo tendo-se evidências de que a gamificação causa impactos positivos, também existem estudos que apontam problemas na sua aplicação. Em alguns casos, resultados positivos não são alcançados por influência de diversos fatores, um deles é a da ameaça de estereótipo de gênero, a qual pode impactar no nível de autoeficácia do estudante e no desempenho na aprendizagem. Isto ocorre porque a autoeficácia é o sentimento de se sentir com a capacidade de atingir as metas. Assim, quando determinada tarefa é proposta e o indivíduo não acredita ter as capacidades necessárias em sua execução, o êxito na conclusão da tarefa é fraco. Tal fator, influencia no desempenho da aprendizagem, podendo causar impactos negativos. Por exemplo, o estereótipo de que homens têm mais habilidade em matemática pode influenciar negativamente em algumas mulheres fazendo com que elas tenham uma percepção de autoeficácia muito baixa, causando problemas na aprendizagem, mesmo que as atividades sejam realizadas em um ambiente gamificado. Assim, nesta dissertação nosso objetivo é identificar e explicar como estereótipos de gênero impactam na autoeficácia, na experiência de fluxo (estado de total imersão almejado em cenários educativos) e no desempenho da aprendizagem dos estudantes em ambientes educacionais online gamificados. Para isso, será realizada uma revisão sistemática da literatura (metanálise) e condução de estudos quase-experimentais. A revisão sistemáticas possibilitará a obtenção de um panorama geral de como estereótipos de gênero e gamificação afetam a autoeficácia, experiência de fluxo e desempenho da aprendizagem. Os estudos quasiexperimentais de tipo quantitativo e qualitativo serão conduzidos para identificar e explicar os efeitos causados pelo estereótipo de gênero em ambientes educacionais online gamificados. Desta forma almejamos fornecer evidências no referido a se estereótipos de gênero afetam a experiência de fluxo, se eles afetam a autoeficácia e se eles contribuem num desempenho ruim de aprendizagem dos alunos. Como resultado também esperamos identificar se existe um gênero que possa ser mais afetado pelo estereótipo e compreender as causas desses efeitos. Essas evidências irão contribuir na geração de diretrizes, recomendações e práticas que resultem em adaptações e implementações de ambientes educacionais online gamificados sem ameaça de estereótipo, a elaboração de ambientes mais justos e que promovam a equidade de gênero.","The use of gamification has been widely studied in recent years, particularly when it is used as an intervention to increase motivation and engagement in educational settings. Even with evidence that gamification causes positive impacts, there are also studies that point to problems in its application. In some cases, positive results are not achieved due to the influence of several factors, one of which is the threat of gender stereotyping, which can impact the student’s level of self-efficacy and performance in learning. This is because self-efficacy is the feeling of having the ability to achieve goals. Thus, when a given task is proposed and the individual does not believe he has the necessary capabilities to perform it, success in completing the task is weak. This factor influences the learning performance and can cause negative impacts. For example, the stereotype that men are more skilled in math can negatively influence some women, causing them to have a very low perception of self-efficacy, causing problems in learning, even if the activities are carried out in a gamified environment. Thus, in this dissertation, our objective is to identify and explain how gender stereotypes impact on self-efficacy, on the flow experience (a state of total immersion desired in educational settings) and on student learning performance in gamified online educational environments. For this, systematic literature review (meta-analysis) and quasi-experimental studies will be conducted. The systematic reviews provided an overview of how gender stereotypes and gamification affect self-efficacy, flow experience and learning performance. Quantitative and qualitative quasi-experimental studies will be conducted to identify and explain the effects caused by gender stereotyping in gamified online educational environments. Thus, we aim to provide evidence regarding whether gender stereotypes affect the flow experience, whether they affect self-efficacy and whether they contribute to poor student learning performance. As a result, we also hope to identify if there is a gender that might be more affected by stereotype and understand the causes of these effects. This evidence will contribute to the generation of guidelines, recommendations and practices that result in adaptations and implementations of gamified online educational environments without the threat of stereotyping, the creation of fairer environments that promote gender equity.","('Gamificação', 'Estereótipos de gênero', 'Autoeficácia', 'Aprendizagem – Desempenho', 'Educação', 'Gamification', 'Gender stereotype', 'Self-efficacy', 'Learning – Performance', 'Education')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/11921","2022-12-08","https://www.repositorio.ufal.br/bitstream/123456789/11921/1/Estere%c3%b3tipos%20de%20g%c3%aanero%2c%20autoefic%c3%a1cia%20e%20experi%c3%aancia%20de%20fluxo%20em%20ambientes%20educacionais%20online%20gamificados.pdf","Gender stereotypes, self-efficacy, and experience flow in gamified online educational environments","('Geiser Chalco Challco',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/6049","Campus A.C. Simões","Instituto de Computação","Dissertação","Diretrizes de software para o design de aplicativos gamificados para monitorar crianças com TDAH","('Tássio José Gonçalves Gomes',)","('Patrick Henrique da Silva Brito',)","('Evandro de Barros Costa', 'Maria de Fátima de Souza Santos')","O Transtorno do Déficit de Atenção e Hiperatividade (TDAH) tem sido um dos tópicos mais estudados relativos a crianças em idade escolar, em face de suas dificuldades no dia a dia. Ao mesmo tempo, a gamificação, que usa a mecânica dos jogos em um contexto que não é jogo, tais como incentivos e ludicidade, é uma estratégia usada para engajar as pessoas no alcance de seus objetivos em diferentes contextos. Assim, este trabalho tem como objetivo apresentar diretrizes de software para o design de ferramentas gamificadas para pacientes com TDAH. Os requisitos foram especificados com base nos resultados de um estudo realizado com pais, psicopedagogos, psicólogos e fonoaudiólogos. A pesquisa foi dividida em duas etapas, a primeira na realização de entrevistas semi estruturadas onde duas principais categorias de diretrizes foram encontradas: (i) estratégias comportamentais e (ii) elementos de gamificação usados, sendo o primeiro composto por 17 estratégias e o segundo por 12 elementos de gamificação. E em seguida foi realizada uma segunda etapa com a aplicação de questionários onde, a partir da análise de dados baseados nessas categorias, foram validados 24 requisitos de sistema para o desenvolvimento de aplicativos gamificados para pessoas com Transtorno do Déficit de Atenção e Hiperatividade.","Attention Deficit Hyperactivity Disorder has been one of the most studied topics in schoolage children, given their day-to-day difficulties. At the same time, gamification, which uses game mechanics in a non-gaming context, is a strategy used to engage people in reaching their goals in different contexts. Thus, this paper aims to present software guidelines for the design of gamified tools for patients with this deficit. The requirements were compiled based on the results of a study with parents, psychopedagogues, psychologists and speech therapists. The research was divided into two stages, the first in semi-structured interviews, where two main categories of guidelines were found: (i) behavioral strategies and (ii) first composed of 17 strategies and the second by 12 gamification elements. Then, a second phase was carried out with the application of questionnaires where, from these categories and data analysis, 24 system requirements were proposed for the development of gamma applications for people with Attention Deficit Hyperactivity Disorder.","('Transtorno do déficit de atenção com hiperatividade', 'Informática e educação', 'Gamificação', 'Attention deficit hyperactivity disorder', 'Informatics and education', 'Gamification')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/6049","2019-07-11","https://www.repositorio.ufal.br/bitstream/riufal/6049/1/Diretrizes%20de%20software%20para%20o%20design%20de%20aplicativos%20gamificados%20para%20monitorar%20crian%c3%a7as%20com%20TDAH.pdf","Software Guidelines for Designing Gamified Applications for Monitoring ADHD Children","('Leonardo Brandão Marques',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/1724","Campus A.C. Simões","Instituto de Computação","Dissertação","Empirical studies on fine-grained feature dependencies","('Iran Rodrigues Gonzaga Júnior',)","('Márcio de Medeiros Ribeiro',)","('Patrick Henrique da Silva Brito', 'Paulo Henrique Monteiro Borba')","Manter famílias de programas não é uma tarefa trivial. Desenvolvedores comumente introduzem erros quando não consideram dependências existentes entre features. Quando tais features compartilham elementos de programa, como variáveis e funções, utilizar estes elementos inadvertidamente pode resultar em erros de variabilidade. Neste contexto, trabalhos anteriores focaram apenas na ocorrência de dependências intraprocedurais, ou seja, quando features compartilham elementos de programa dentro de uma mesma função. Mas ao mesmo tempo, ainda não temos estudos investigando dependências que extrapolam os limites de uma função, já que esses casos também podem causar erros. De fato, neste trabalho nós trazemos evidências de que erros de variabilidade também podem ocorrer devido a dependências interprocedurais ou a variáveis globais. Para avaliar até que ponto esses diferentes tipos de dependências entre features existem na prática, nós realizamos um estudo empírico abrangendo 40 famílias de programas de diferentes domínios e tamanhos. Nossos resultados mostram que dependências intraprocedurais e interprocedurais são comuns na prática: 51; 44% 17; 77% das funções com diretivas de pré-processamento têm dependências intraprocedurais, enquanto 25; 98% 19; 99% de todas as funções possuem dependências interprocedurais. Após estudar a ocorrência de dependências entre features na prática, nós conduzimos outro estudo empírico, desta vez direcionado a encontrar erros de variabilidade relacionados a dependências entre features. Aqui nos concentramos em variáveis não declaradas, funções não declaradas, variáveis sem uso e funções sem uso. Este estudo utiliza 15 sistemas para responder a questões de pesquisa relacionadas a como os desenvolvedores introduzem esses erros e sua frequência. Nós detectamos e confirmamos a existência de 32 erros de variabilidade. O conjunto de erros que coletamos é uma fonte valiosa para fundamentar a pesquisa sobre esse tema e para auxiliar desenvolvedores de ferramentas, de forma que eles forneçam meios em suas ferramentas de evitar tais problemas.","Maintaining program families is not a trivial task. Developers commonly introduce bugs when they do not consider existing dependencies among features. When such implementations share program elements, such as variables and functions, inadvertently using these elements may result in bugs. In this context, previous work focuses only on the occurrence of intraprocedural dependencies, that is, when features share program elements within a function. But at the same time, we still lack studies investigating dependencies that transcend the boundaries of a function, since these cases might cause bugs as well. Indeed, in this work we bring evidence that variability bugs can also occur due to interprocedural dependencies and global variables. To assess to what extent these different types of feature dependencies exist in practice, we perform an empirical study covering 40 program families of different domains and sizes. Our results show that the intraprocedural and interprocedural feature dependencies are common in practice: 51:44% 17:77% of functions with preprocessor directives have intraprocedural dependencies, while 25:98% 19:99% of all functions have interprocedural dependencies. After studying the feature dependencies occurrence in practice, we perform another empirical study now focusing on finding actual bugs related to feature dependencies. Here we focus on undeclared variables, undeclared functions, unused variables, and unused functions. This study uses 15 systems to answer research questions related to how developers introduce these bugs and their frequency. We detect and confirm 32 variability bugs. The corpus of bugs we gather is a valuable source to ground research on this topic and to help tool developers, so they can provide means in their tools to avoid these problems.","('Engenharia de software', 'Computadores e família', 'Software engineering', 'Computers and family')","Ciência da Computação","eng","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1724","2015-08-10","https://www.repositorio.ufal.br/bitstream/riufal/1724/1/Empirical%20studies%20on%20fine-grained%20feature%20dependencies.pdf","Estudos empíricos sobre dependência entre features de granularidade fina","('Baldoíno Fonseca dos Santos Neto',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/6146","Campus A.C. Simões","Instituto de Computação","Dissertação","Developer´s assumptions on identifying bug-introducing changes","('Jairo Raphael Moreira Correia de Souza',)","('Baldoíno Fonseca dos Santos Neto',)","('Márcio de Medeiros Ribeiro', 'Gustavo Henrique Lima Pinto')","Durante a revisão de código, desenvolvedores podem realizar premissas que podem guiar o seu processo de revisão de código (por exemplo, os desenvolvedores podem considerar que o código com baixa cobertura de teste tem mais probabilidade de apresentar erros. Assim, eles podem concentrar sua atenção nesse trecho de código). Embora os estudos anteriores tenham investigado as premissas dos desenvolvedores envolvendo diferentes preocupações, nenhum deles concentram-se em analisar as premissas dos desenvolvedores durante a revisão de código para identificar alterações que introduzem bugs. Portanto, nosso estudo tem como objetivo investigar essas premissas, quão relevantes elas são para os desenvolvedores, por que os desenvolvedores colocam mais ou menos relevância para algumas premissas e quais premissas são consenso ou dissenso entre os eles. Para isso, utilizamos a metodologia Q para conduzir nosso estudo contendo 41 desenvolvedores analisando 41 premissas extraídas de diferentes fontes. Os resultados indicam que: (i) as premissas dos desenvolvedores estão relacionadas às características das mudanças, linguagem de programação, experiência e hábitos dos desenvolvedores, práticas organizacionais, manutenção do código, propriedade e testes; (ii) existem cinco pontos de vista comuns entre os desenvolvedores sobre a relevância das premissas; (iii) complexidade e propriedade de código (code onwership), tempo de entrega curto, práticas de desenvolvimento e familiaridade com o código são as principais razões para os desenvolvedores colocarem mais e/ou menos relevância em certas premissas; e (iv) premissas envolvendo alto número de funcionalidades (features), linguagens de programação e aceitação de solicitações de mudanças (pull-requests) apresentam mais consenso entre os desenvolvedores, enquanto que premissas envolvendo commits de merge, histórico de software, familiaridade com a linguagem de programação, reutilização de código e propriedade de código apresentam mais dissensos. Essas descobertas são um conhecimento valioso para profissionais e pesquisadores no sentido do aprimoramento de ferramentas e/ou técnicas de revisão de código para identificar mudanças que introduzem bugs.","During the code review, developers can make assumptions that may guide their review process (e. g., developers may consider that code with low test coverage is more likely to introduce bugs. Thus, they can focus their attention on this code). Although studies have investigated developers’ assumptions involving different concerns in software engineering, none of those studies focus on analyzing developers’ assumptions when reviewing code to identify bug-introducing changes. Our study investigates those assumptions, how relevant they are for developers, why developers put more/less relevance for some assumptions, and which assumptions are consensus/dissensus among groups of developers. We apply the Qmethodology to conduct our study with 41 developers analyzing 41 assumptions extracted from different sources. The results indicate: (i) the developers’ assumptions involve concerns related to the programming language, developers’ experience and habits, organizational practices as well as code maintenance, ownership and testing; (ii) five common viewpoints among developers regarding the relevance of assumptions; (iii) code complexity and ownership, short delivery time, developers practices and familiarity with the code are the main reasons for developers to put more/less relevance to some assumptions; and (iv) while assumptions involving programming languages, features invocation and pull-request acceptance present more consensus among developers, assumptions involving merge commits, software history, familiarity with the programming language, code reuse and ownership present more dissensus. These findings are valuable knowledge for both practitioners and researchers towards improving state-of-the-art code review tools/techniques to identifying bug-introducing changes.","('Computação', 'Software -Desenvolvimento', 'Software -Confiabilidade', 'Computation', 'Software – Development', 'Software -Reliability')","Ciência da Computação","eng","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/6146","2019-10-04","https://www.repositorio.ufal.br/bitstream/riufal/6146/1/Developer%c2%b4s%20assumptions%20on%20identifying%20bug-introducing%20changes.pdf","Premissas dos Desenvolvedores na Identificação de Mudanças que Introduzem Bugs",""
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/13018","Campus A.C. Simões","Instituto de Computação","Dissertação","Detecção de microações em vídeos faciais para análise de carga cognitiva em ambientes de aprendizado multimídia","('Cristóvão da Silva Rodrigues Costa',)","('Thales Miranda de Almeida Vieira',)","('Bruno Almeida Pimentel', 'Diego Carvalho do Nascimento')","A evolução tecnológica dos últimos anos, acelerada pela pandemia do Covid19, foi responsável por uma rápida e contínua quebra de paradigmas no ensino, com a adoção de ambientes de aprendizagem multimídia. Durante o processo de aprendizagem nestes ambientes, a absorção do conteúdo pelo discente cai com o aumento do volume de informação transmitida aos alunos, ou seja, quando há uma sobrecarga cognitiva em um ou em ambos os canais visual e verbal. Atualmente são escassos os estudos que utilizam ferramentas de Visão Computacional e Ciência de Dados para a análise da Carga Cognitiva. Ferramentas desta natureza possibilitariam uma análise automatizada de grandes volumes de vídeos, e consequentemente a avaliação e geração de conteúdo multimídia que otimizem o aprendizado dos alunos. Neste trabalho adotou-se um estudo piloto com uma amostra de 13 alunos da faculdade de medicina da Universidad de Atacama, Chile. Assim, foi desenvolvida uma metodologia para extrair e investigar correlações entre características visuais da face dos alunos e a carga cognitiva. Foi usada uma base de vídeos faciais dos alunos assistindo, pela tela do computador, aulas com recursos multimídia. Esta base de vídeos foi inicialmente organizada e pré-processada, aplicando-se em seguida modelos de Aprendizado Profundo para extrair pontos de interesse visuais da face em cada quadro. As micro ações foram previamente anotadas pelo pesquisado e os dados resultantes foram avaliados para identificação de padrões relevantes relacionados à carga cognitiva. Além de responder à investigação principal desta pesquisa, os resultados deste estudo incluem uma prova de conceito para a análise da correlação das expressões faciais com a nota da prova do indivíduo para posterior análise da carga cognitiva em ambientes de aprendizagem multimídia. O código do experimento e das ferramentas foi disponibilizado publicamente através da URL: https://github.com/cristovaor/CAST.","The technological evolution of recent years, accelerated by the Covid-19 pandemic, has been responsible for a rapid and continuous paradigm shift in education, with the adoption of multimedia learning environments. During the learning process in these environments, the absorption of content by students decreases as the volume of information transmitted to them increases. In other words, there is a cognitive overload in one or both visual and verbal channels. Currently, there is a scarcity of studies that use Computer Vision and Data Science resources for the analysis of Cognitive Load. Tools of this nature would enable automated analysis of large volumes of videos and, consequently, the evaluation and generation of multimedia content that optimize student learning. In this work, a pilot study was conducted with a sample of 13 students from the School of Medicine at the Universidad de Atacama, Chile. Thus, a methodology was developed to extract and investigate correlations between visual characteristics of the students’ faces and cognitive load. A database of facial videos of students watching multimedia-enhanced lectures on their computer screens was used. This video database was initially organized and preprocessed, followed by the application of Deep Learning models to extract visual points of interest from the face in each frame. Micro-actions were previously annotated by the researcher, and the resulting data were evaluated to identify relevant patterns related to cognitive load. In addition to addressing the main investigation of this research, the results of this study include a proof of concept for analyzing the correlation of facial expressions with individual exam scores, for further analysis of cognitive load in multimedia learning environments. The code for the experiment and the tools was made publicly available at the URL: https://github.com/cristovaor/CAST.","('Aprendizado de máquina', 'Teoria da carga cognitiva', 'Visão computacional', 'Aprendizagem significativa', 'Rede neural artificial', 'Machine learning', 'Cognitive toad theory', 'Computer vision', 'Deep learning', 'Artificial neural network', 'Meaningful learning')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/13018","2023-07-31","https://www.repositorio.ufal.br/bitstream/123456789/13018/3/Detec%c3%a7%c3%a3o%20de%20microa%c3%a7%c3%b5es%20em%20v%c3%addeos%20faciais%20para%20an%c3%a1lise%20de%20carga%20cognitiva%20em%20ambientes%20de%20aprendizado%20multim%c3%addia.pdf","",""
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/13596","Campus A.C. Simões","Instituto de Computação","Dissertação","Efeitos de estereótipos de gênero, e raça, em mediadores psicológicos da aprendizagem durante o uso de ambientes educacionais online gamificados","('Joao Vitor Lourenco Batista do Nascimento',)","('Ig Ibert Bittencourt Santana Pinto',)","('Diego Dermeval de Medeiros da Cunha Matos', 'Ivanderson Pereira da Silva', 'Flávia Maria Santoro')","Devido a pandemia da COVID-19 as tecnologias educacionais se tornam cada vez mais comuns em ambientes de ensino principalmente no contexto da graduação. Diversos autores discutem problemas que estão relacionados fortemente as tecnologias educacionais digitais, estando alguns deles não relacionados diretamente a ciência da computação como os estereótipos, que são questões multidisciplinares a serem trabalhadas em interface com a psicologia social. A problemática das tecnologias educacionais digitais estereotipadas está na possiblidade de milhares de alunos estarem tendo seu desempenho acadêmico afetado negativamente por estereótipos: raciais e de gênero. Este trabalho de dissertação discute a influência dos estereótipos raciais e de gênero em ambientes educacionais online gamificados utilizados por estudantes de graduação. O objetivo geral da pesquisa é compreender os efeitos desses estereótipos presentes no desenvolvimento de um ambiente educacional gamificado, analisando três construtos psicológicos que afetam a performance e a aprendizagem: Flow, Selfhandicapping e Ansiedade. Para alcançar este objetivo, lançaremos mão da realização de experimentos. Como resultados dessa pesquisa, temos que, ao verificar a influência dos estereótipos de gênero, que eles influenciam negativamente nos níveis de fluxo e de desempenho de mulheres quando em ambientes de gênero oposto ao seu. Essa influência, não afetou muito os homens, que apesar de estarem na condição de ameaça dos estereótipos continuaram tendo classificações mais altas. Por sua vez, ao verificar as influências dos estereótipos raciais, nos níveis de fluxo, ansiedade e desempenho, de estudantes de graduação, encontramos que houve sim um aumento de ansiedade e de fluxo, e que houve diferenças no desempenho dos estudantes, em especial entre os homens brancos não-cotistas, e as mulheres pretas cotistas, mas que estas diferenças não foram estatisticamente significantes entre os grupos. Inferimos também, a partir do segundo estudo, que há influência dos mediadores psicológicos no desempenho dos estudantes. Inspirado nos resultados desses estudos foi produzido um artigo que propõe uma metodologia batizada de olhar caleidoscópico que apresenta uma proposta de produzir designs de tecnologias que considerem as nuances sociais inerentes aos sujeitos alvo das soluções. A relevância da pesquisa está na possibilidade de contribuir com as áreas de informática na educação, na elaboração de tecnologias educacionais digitais e psicologia, na compreensão da influência dos estereótipos. Ademais este trabalho contribui para pensar o desenvolvimento de tecnologias educacionais sob uma perspectiva que leve em conta a interseccionalidade inerente aos seus usuários, tornando estas mais eficazes ao considerar o contexto social no qual estes estão inseridos.","Due to the COVID-19 pandemic, educational technologies are becoming increasingly common in learning environments, especially in the context of undergraduate education. Several authors discuss problems that are strongly related to digital educational technologies, with some of them not directly related to computer science, such as stereotypes, which are multidisciplinary issues to be addressed in interface with social psychology. The problem of stereotyped digital educational technologies lies in the possibility that thousands of students may have their academic performance negatively affected by racial and gender stereotypes. This dissertation work discusses the influence of racial and gender stereotypes in gamified online educational environments used by undergraduate students. The overall objective of the research is to understand the effects of these stereotypes present in the development of a gamified educational environment, analyzing three psychological constructs that affect performance and learning: Flow, Self-handicapping, and Anxiety. To achieve this goal, we will conduct experiments. As a result of this research, we find that, when examining the influence of gender stereotypes, they negatively impact the levels of flow and performance of women when in gender-opposite environments. This influence did not affect men significantly, as they continued to have higher ratings despite being in a stereotype-threat condition. On the other hand, when examining the influences of racial stereotypes on the levels of flow, anxiety, and performance of undergraduate students, we found that there was indeed an increase in anxiety and flow, and that there were differences in the performance of students, especially between white male nonaffirmative action students and black female affirmative action students, but these differences were not statistically significant between the groups. We also infer from the second study that there is an influence of psychological mediators on student performance. Inspired by the results of these studies, an article proposing a methodology called the kaleidoscopic perspective was produced, which presents a proposal to produce technology designs that consider the social nuances inherent to the target subjects of the solutions. The relevance of the research lies in the possibility of contributing to the areas of computer science in education, the development of digital educational technologies, and psychology in understanding the influence of stereotypes. Furthermore, this work contributes to thinking about the development of educational technologies from a perspective that takes into account the intersectionality inherent to their users, making them more effective by considering the social context in which they are embedded.","('Decolonialidade', 'Estereótipos (Psicologia)', 'Gamificação', 'Informática e educação', 'Mediadores psicológicos da aprendizagem', 'Tecnologia educacional digital', 'Decoloniality', 'Stereotypes (Psychology)', 'Gamification', 'Computers and education', 'Psychological mediators of learning', 'Digital educational technologies')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/13596","2023-10-30","https://www.repositorio.ufal.br/bitstream/123456789/13596/1/Efeitos%20de%20estere%c3%b3tipos%20de%20g%c3%aanero%2c%20e%20ra%c3%a7a%2c%20em%20mediadores%20psicol%c3%b3gicos%20da%20aprendizagem%20durante%20o%20uso%20de%20ambientes%20educacionais%20online%20gamificados.pdf","Effects of gender and race stereotypes on psychological mediators of learning during the use of gamified online educational environments","('Jário José dos Santos Júnior',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/2517","Campus A.C. Simões","Instituto de Computação","Dissertação","A disciplinaridade das anotações condicionais de pré-processamento #ifdef TAG Não #endif importa","('Romero Bezerra de Souza Malaquias',)","('Márcio de Medeiros Ribeiro',)","('Ig Ibert Bittencourt Santana Pinto', 'Rohit Gheyi')","O pré-processador do C é uma ferramenta simples, efetiva e independente de linguagem. Na prática o pré-processador é visto como uma solução para problemas de portabilidade e variabilidade. Para utilizá-lo, basta anotar trechos do código com diretivas condicionais. Estas definem se aquele trecho de código será incluído ou excluído. Apesar de ser largamente utilizado, o pré-processador é amplamente criticado. Seu uso é relacionado a impactos negativos na manutenibilidade e legibilidade do código. Em particular, esses problemas podem ser piores quando se utiliza anotações não disciplinadas. Contudo, um experimento controlado realizado anteriormente indicou que a disciplinaridade não afeta a manutenibilidade e a legibilidade do código. Esse resultado contradiz as críticas recebidas e alguns guias para desenvolvimento de código (como por exemplo as do Linux, que explicitamente pedem para que os desenvolvedores evitem anotações não disciplinadas). Um exemplo de anotação não disciplinada ocorre quando são anotadas apenas partes de unidades sintáticas do C. Dado este cenário, onde há uma divergência entre a prática e a teoria, existe a necessidade de se compreender melhor a importância dada por desenvolvedores à disciplinaridade das anotações condicionais e se ela de fato causa algum impacto no desenvolvimento de sistemas. Nesse trabalho conduziremos um método misto de pesquisa que envolve três estudos. O primeiro consiste em sugerir transformações de código não disciplinado em disciplinado para sistemas open source. Nesse contexto, identificamos 110 anotações não disciplinadas em sistemas C/C++ de código aberto no GitHub. Estes sistemas têm diferentes domínios, tamanhos e popularidades em métricas do GitHub. A partir disso, nós refatoramos as anotações identificadas para que se tornassem disciplinadas. Por fim, submetemos nossas sugestões através de pull requests. A maioria das refatorações foram aceitas e agora integram o código do sistemas. Foi conseguida uma taxa de aceitação de 71%. O segundo estudo consiste em minerar repositórios open-source buscando commits que contenham transformações de anotações não disciplinadas em disciplinadas. Foram encontradas 90 transformações. Estas, foram classificadas em refatoração ou não. Adicionalmente, entramos em contato com o desenvolvedor a fim de entender o que o motivou a realizar tal alteração. No terceiro estudo, foi conduzido um experimento controlado. Este tem várias diferenças em relação ao executado anteriormente, como o bloqueio a algumas variáveis de confusão e mais réplicas. De acordo com os resultados, temos evidências de que realizar manutenção em código com anotações não disciplinadas é uma tarefa com um custo maior de tempo e é mais propensa a erros que as mesmas tarefas na forma disciplinada. Essas evidências se contrapõem ao resultado encontrado no experimento anterior. De forma geral, nesse trabalho, foi concluído que a disciplinaridade das anotações não deve ser negligenciada.","The C preprocessor is a simple, effective, and language-independent tool. Developers use the preprocessor in practice to deal with portability and variability issues. Despite the widespread usage, the C preprocessor suffers from severe criticism, such as negative effects on code understandability and maintainability. In particular, these problems may get worse when using undisciplined annotations, i.e., when a preprocessor directive encompasses only parts of C syntactical units. Nevertheless, despite the criticism and guidelines found in systems like Linux to avoid undisciplined annotations, the results of a previous controlled experiment indicated that the discipline of annotations has no influence on program comprehension and maintenance. To better understand whether developers care about the discipline of preprocessor-based annotations and whether they can really influence on maintenance tasks, in this work we conduct a mixed-method research involving three studies. In the first one we identify undisciplined annotations in 110 open source C/C++ systems of different domains, sizes, and popularity GitHub metrics. We then refactor the identified undisciplined annotations to make them disciplined. Right away, we submit pull requests with our suggestions. The majority of our pull requests have been accepted and are now merged. We reach a total acceptance rate of 71%. In the second study, we mined opensource repositories to find commits where the developer transforms undisciplined codes into disciplined ones. In that context, we found 90 transformations. Those transformations were classified in refactoring or not, and we contacted the responsible to ask why he did that code change. In the third study, we conduct a controlled experiment. We have several differences with respect to the aforementioned one, such as blocking of cofounding effects and more replicas. We have evidences that maintaining undisciplined annotations is more time consuming and error prone, representing a different result when compared to the previous experiment. Overall, we conclude that undisciplined annotations should not be neglected.","('Engenharia de software', 'Disciplinaridade das anotações', 'Ifdefs', 'Condicionais de compilação de códigos', 'Compiladores (Programas de computador)', 'Discipline of annotations', 'Conditional compilation')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/2517","2017-10-09","https://www.repositorio.ufal.br/bitstream/riufal/2517/1/A%20disciplinaridade%20das%20anota%c3%a7%c3%b5es%20condicionais%20de%20pr%c3%a9-processamento%20%23ifdef%20TAG%20N%c3%a3o%20%23endif%20importa.pdf","The discipline of prepocessor-based annotations does #ifdef TAG n't #endif matter",""
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/11776","Campus A.C. Simões","Instituto de Computação","Dissertação","Detecção automática da camada epitelial da córnea a partir de imagens de Scheimpflug","('Marcus Vinícius Lima Santos',)","('Aydano Pamponet Machado',)","('Marcelo Costa Oliveira', 'João Marcelo de Almeida Gusmão Lyra')","Introdução: A córnea é responsável pela recepção dos raios luminosos e é a parte mais exposta do olho é composta histologicamente por 5 camadas, que da parte mais externa para a interna estão dispostas: epitélio, membrana de Bowman, estroma, membrana de Descemet e o endotélio. O epitélio é a camada mais exposta da córnea. Existem doenças que afetam a córnea como por exemplo o ceratocone causando alterações nas camadas da córnea a investigação dessas doenças tem grande relevância para a prática clínica e permitem a detecção, muitas vezes precoce, dessas doenças. Também existem equipamentos que auxiliam no diagnostico dessas doenças, fornecendo informações importantes. Utilizar técnicas para extrair novas informações referentes ao epitélio para esses equipamentos, contribui ainda mais para um diagnostico mais preciso, visto que o epitélio é a primeira camada que é impactada com doenças como o ceratocone. Objetivo: Identificar o epitélio de forma automatizada nas imagens obtidas pela câmera Scheimpflug. Metodologia: A metodologia proposta consiste em analisar 279 exames de córneas normais obtidas através das capturas realizadas pela câmera Scheimpflug aplicar os métodos clássicos de detecção de bordas existentes na literatura para identificar, isolar, validar e analisar informações do epitélio. Resultados: Os algoritmos Canny, Zerocross e Log conseguiram detectar o epitélio na medida total as menores médias encontradas em ambas espessuras foram com os métodos log e zerocross com suas variações, que tiveram 79.74 µm, 79.85 µm e 80.38 µm na espessura e 65.91 µm, 66.08 µm e 67.25 µm na espessura pela distância euclidiana. Porém zerocross teve o menor número de imagens defeituosas e log teve mais de 50% das imagens da base com problemas. Na medida central as menores média encontradas em ambas espessuras também foram com os métodos log e zerocross com suas variações, que tiveram 75.50 µm, 75.58 µm e 75.75 µm na espessura e 61.61 µm, 61.70 µm e 62.04 µm na espessura pela distância euclidiana. Conclusão: Conseguimos realizar a identificação do epitélio de forma automatizada com as imagens da câmera Scheimpflug com os métodos de detecção de bordas Canny, Log e Zerocross e conseguimos ter um aproveitamento maior das imagens utilizando Zerocross com Theshold: 0.0003.","Introduction: The cornea is responsible for receiving light rays and is the most external part of the eye. It is histologically composed of 5 layers, which from the outermost to the inner part are arranged: epithelium, Bowman’s membrane, stroma, Descemet’s membrane, and the endothelium. The epithelium is the most exposed layer of the cornea. Some diseases affect the cornea causing alterations in the corneal layers. The investigation of these diseases is of great relevance to clinical practice and allows the detection, often early, of these diseases. There is also equipment that helps in the diagnosis of these diseases, providing important information. Using techniques to extract new information regarding the epithelium for these devices further contributes to a more accurate diagnosis. The epithelium is the first layer that is impacted by diseases such as keratoconus. Objective: Identify the epithelium in an automated way in the images obtained by the Scheimpflug camera. Methodology: The proposed methodology analyzes 279 exams of normal corneas obtained through the captures by the Scheimpflug camera, applying the classic methods of detection of edges existing in the literature to identify, isolate, validate and analyze information from the epithelium. Results: The Canny, Zerocross, and Log algorithms were able to detect the epithelium in the total measure, the lowest averages found in both thicknesses were with the log and zerocross methods with their variations, which had 79.74 µm, 79.85 µm and 80.38 µm in thickness and 65.91 µm, 66.08 µm and 67.25 µm in thickness by Euclidean distance. However, zerocross had the lowest number of defective images, and log had more than 50% of the base images with problems. In the central measure, the lowest average found in both thicknesses was also with the log and zerocross methods with their variations, which had 75.50 µm, 75.58 µm and 75.75 µm in the thickness and 61.61 µm, 61.70 µm and 62.04 µm in the thickness by the Euclidean distance. Conclusion:We were able to perform the identification of the epithelium in an automated way with the images of the Scheimpflug camera with the edge detection methods Canny, Log, and Zerocross and we were able to have better use of the images using Zerocross with Threshold: 0.0003.","('Córnea', 'Epitélio', 'Processamento de imagens', 'Câmera de Scheimpflug', 'Cornea', 'Epithelium', 'Image processing', 'Scheimpflug')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/11776","2022-05-30","https://www.repositorio.ufal.br/bitstream/123456789/11776/1/Detec%c3%a7%c3%a3o%20autom%c3%a1tica%20da%20camada%20epitelial%20da%20c%c3%b3rnea%20a%20partir%20de%20imagens%20de%20Scheimpflug.pdf","Automatic detection of the corneal epithelial layer from Scheimpflug images","('Edileuza Virginio Leão',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/12286","Campus A.C. Simões","Instituto de Computação","Dissertação","Efeitos de ambientes gamificados estereotipados de gênero sobre a autoeficácia, engajamento e desempenho de estudantes: análises quantitativas e qualitativas","('Maria José dos Santos Takeshita',)","('Ig Ibert Bittencourt Santana Pinto',)","('Diego Dermeval de Medeiros da Cunha Matos', 'Leonardo Brandão Marques', 'Jário José dos Santos Júnior')","O uso da gamificação, deve-se destacar, quando amplamente estudada e aplicada na área educacional, proporciona que o ensino seja realizado de forma inovadora, introduzindo na educação novos recursos que auxiliam professores e estudantes no processo da aprendizagem. Gamificação tem sido aplicada para aprimorar o engajamento e a motivação de estudantes, e comumente utilizada online. Apesar desses benefícios, estudos comprovaram que efeitos negativos podem ser obtidos, especialmente quando os estudantes são expostos a ambientes gamificados com estereótipos, como por exemplo os de gênero. Tais estereótipos podem afetar a confiança e crenças em suas capacidades, resumidamente chamada de autoeficácia. Surgem então questões pertinentes: Qual é o impacto de mensagens estereotipadas de gênero sobre o desempenho e engajamento de estudantes? Mensagens de motivação ou “boost” podem aumentar o engajamento e o desempenho dos estudantes nas atividades realizadas em ambientes gamificados? Com o intuito de buscar evidências para responder essas questões, foram conduzidos três estudos no presente trabalho: (1) uma meta-análise com uma revisão bibliográfica sistemática sobre os efeitos do uso de ambientes gamificados sobre a autoeficácia e aprendizado dos estudantes, (2) um estudo experimental usando mensagens de impulso estereotipadas de acordo com gênero identificando a existência de diferenças sobre engajamento, autoeficácia e desempenho de estudantes em sistemas de tutoria gamificados, e (3) um estudo qualitativo sobre os efeitos dos estereótipos na autoeficácia, estado de fluxo e performance, identificando fatores subjetivos não controlados no estudo experimental. É possível afirmar que existe uma carência de estudos relacionando designs gamificados e o traço de autoeficácia, apesar de efeitos positivos do uso dessa técnica sobre desempenho e confiança de estudantes. Além disso, resultados indicam que ambientes gamificados positivamente afetam o desempenho e crenças de autoeficácia, permitindo mais confiança e melhores resultados acadêmicos.","The use of gamification, it should be noted, when widely studied and applied in the educational area, allows teaching to be carried out in an innovative way, introducing new resources in education helping teachers and students in the learning process. Gamification has been applied to improve the student’s engagement and motivation, and is commonly used online. Despite these benefits, studies have presented evidence that negative effects can be obtained, especially when students are exposed to gamified environments with stereotypes, such as gender-related ones. Such stereotypes can affect confidence and beliefs in one’s skills, which in turn can be called self-efficacy. Pertinent questions might rise from these: What is the impact of genderstereotypical messages on student’s performance and engagement? Can motivational or “boost” messages increase student engagement and performance in activities carried in gamified environments? In order to seek evidence to answer these questions, three studies were conducted in the present work: (1) a meta-analysis with a systematic literature review on the effects of gamified environments use on students' self-efficacy and learning, (2) an experimental study with gamified tutoring systems using gender-stereotyped impulse messages in order to identify differences in student engagement, selfefficacy and performance, and (3) a qualitative study of the effects of stereotypes on self-efficacy, flow state and performance, identifying subjective factors not controlled in the experimental study. It is possible to state that there is a lack of studies relating gamified designs and the self-efficacy trait, despite the positive effects of using this technique on student performance and confidence. In addition, results indicate that gamified environments present positive effects over performance and self-efficacy beliefs, allowing for more confidence and better academic results among students.","('Gamificação', 'Estereótipo', 'Autoeficácia', 'Gênero', 'Gamification', 'Stereotype', 'Self-efficacy', 'Gender')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/12286","2023-04-04","https://www.repositorio.ufal.br/bitstream/123456789/12286/1/Efeitos%20de%20ambientes%20gamificados%20estereotipados%20de%20g%c3%aanero%20sobre%20a%20autoefic%c3%a1cia%2c%20engajamento%20e%20desempenho%20de%20estudantes%3a%20an%c3%a1lises%20quantitativas%20e%20qualitativas.pdf","","('Marcelo Reis',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/16886","Campus A.C. Simões","Instituto de Computação","Dissertação","Design Thinking no Desenvolvimento de Software: indícios e evidências na indústria e na literatura","('Felipe Moura de Jesus',)","('Rodrigo Gusmão de Carvalho Rocha',)","('Rian Gabriel Santos Pinheiro', 'Igor Medeiros Vanderlei')","Em um cenário cada vez mais globalizado e motivado pela tecnologia, a indústria de software busca atuar com máxima eficiência na criação de produtos inovadores alinhados com as expectativas dos usuários. Neste contexto, o Design Thinking (DT) tornou-se uma ferramenta fundamental para promover a inovação e melhoria da qualidade de software, pois foca na experiência do usuário com abordagens que proporcionam multidisciplinaridade, prototipação e colaboração ativa das partes interessadas. Nesse sentido, vários autores investigam como o DT é utilizado em cenários reais de desenvolvimento de software e quais são as partes essenciais neste contexto. O objetivo desta pesquisa é apresentar um conjunto de indícios e evidências sobre DT no contexto de desenvolvimento de software, considerando as perspectivas da indústria e da literatura. Identificando e mapeando as principais abordagens do uso do Design Thinking na produção de sistemas computacionais. A metodologia utilizada neste trabalho se fundamentou em dois estudos experimentais fundamentados em questões de pesquisa, o mapeamento sistemático, que explorou a literatura sob as diretrizes de Kitchenham, utilizando três bases científicas, IEEE, ACM e SCOPUS, e, após verificação e análise dos resultados, foram identificados 95 estudos primários. Em seguida, foi aplicada uma pesquisa com 105 profissionais de tecnologia de diferentes organizações, buscando coletar de profissionais da área dados relevantes sobre o contexto de Design Thinking. Este estudo evidenciou um conjunto de 116 práticas, 45 modelos, 60 papéis, 75 ferramentas e 28 desafios associados a adoção do Design Thinking no desenvolvimento de software. Esses resultados podem ajudar profissionais e pesquisadores da área a entender melhor os desafios e implementar soluções mais eficazes para melhorar suas tarefas no desenvolvimento de software usando abordagens de Design Thinking. Dessa forma, este trabalho contribui com recursos importantes para o ecossistema de construção de software, permitindo o compartilhamento de conhecimento sobre os principais elementos de DT no desenvolvimento de software.","In an increasingly globalized and technology-driven scenario, the software industry seeks to act with maximum efficiency in creating innovative products aligned with user expectations. In this context, Design Thinking (DT) has become a fundamental tool for promoting innovation and improving software quality, as it focuses on the user experience with approaches that provide multidisciplinarity, prototyping and active collaboration of stakeholders. In this sense, several authors investigate how DT is used in real software development scenarios and what are the essential parts in this context. The objective of this research is to present a set of indications and evidence about DT in the context of software development, considering the perspectives of the industry and the literature. Identifying and mapping the main approaches to the use of Design Thinking in the production of computer systems. The methodology used in this work was based on two experimental studies based on research questions, systematic mapping, which explored the literature under Kitchenham’s guidelines, using three scientific databases, IEEE, ACM and SCOPUS, and, after verification and analysis of the results, 95 primary studies were identified. Then, a survey was applied to 105 technology professionals from different organizations, seeking to collect relevant data from professionals in the area about the context of Design Thinking. This study revealed a set of 116 practices, 45 models, 60 roles, 75 tools and 28 challenges associated with the adoption of Design Thinking in software development. These results can help professionals and researchers in the area to better understand the challenges and implement more effective solutions to improve their tasks in software development using Design Thinking approaches. In this way, this work contributes important resources to the software construction ecosystem, allowing the sharing of knowledge about the main elements of DT in software development.","('Design thinking', 'Desenvolvimento de software', 'Engenharia de sistemas computacionais', 'Mapeamento sistemático', 'Método Survey', 'Software development', 'Computer Systems Engineering', 'Systematic Mapping', 'Survey')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/16886","2024-10-31","https://www.repositorio.ufal.br/bitstream/123456789/16886/1/Design%20Thinking%20no%20Desenvolvimento%20de%20Software_ind%c3%adcios%20e%20evid%c3%aancias%20na%20ind%c3%bastria%20e%20na%20literatura.pdf","Design Thinking in Software Development: industry and literature evidence",""
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/8703","Campus A.C. Simões","Instituto de Computação","Dissertação","Desenvolvimento de sistema IoT de baixo custo para monitoramento integrado de variáveis climáticas e de geração fotovoltaica","('Gustavo Costa Gomes de Melo',)","('Erick de Andrade Barboza',)","('Bruno Costa e Silva Nogueira', 'Maurício Beltrão de Rossiter Corrêa')","A participação das energias renováveis na geração de eletricidade vem crescendo em todo o mundo. O monitoramento e a aquisição de dados são essenciais para reconhecer os recursos renováveis disponíveis no local, avaliar a eficiência da conversão elétrica, detectar falhas e otimizar a produção elétrica. Os sistemas comerciais para o monitoramento de sistemas fotovoltaicos são geralmente caros e fechados para modificações. Este trabalho propõe um sistema IoT em tempo real e de baixo custo, para sistemas de micro e mini geração fotovoltaica, que pode monitorar tensão contínua, corrente contínua, potência (corrente alternada) e sete variáveis meteorológicas. O sistema proposto mede todas as variáveis meteorológicas relevantes, mede variáveis de geração fotovoltaica diretamente da planta (não do inversor), é implementado usando software aberto, conecta-se com a internet sem fios, armazena dados localmente e na nuvem, e usa Network Time Protocol (NTP) para sincronizar os relógios dos dispositivos. Segundo nossa revisão sistemática da literatura, nenhum outro trabalho apresenta todas essas características. Além disso, os experimentos realizados com o sistema proposto mostraram boa eficácia e confiabilidade. Este sistema permite o uso de fog e computação em nuvem em um sistema fotovoltaico, e a criação de um conjunto de dados de medições de séries temporais, que permite o uso de aprendizado de máquina para criar sistemas fotovoltaicos inteligentes.","The share of renewable energies in electricity generation has been growing worldwide. Monitoring and acquiring data is essential to recognize the renewable resources available on-site, evaluate the efficiency of electrical conversion, detect failures and optimize electrical production. Commercial monitoring systems for the photovoltaic system are generally expensive and closed for modifications. This work proposes a low-cost real-time IoT system, for micro and mini photovoltaic generation systems, that can monitor DC voltage and current, AC power, and seven meteorological variables. The proposed system measures all the relevant meteorological variables, measures PV generation variables directly from the plant (not from the inverter), is implemented using open software, connects with the internet without cables, storages data locally and in the cloud, and uses Network Time Protocol (NTP) to synchronize the devices’ clocks. According to a systematic literature review, no work reported in the literature presents these features altogether. Besides, experiments carried out with the proposed system showed good effectiveness and reliability. This system enables the use of fog and cloud computing in a photovoltaic system, and the creation of a time series measurements dataset, which enables the use of machine learning to create smart photovoltaic systems.","('Variáveis climáticas – Monitoramento', 'Aquisição de dados', 'Energia -Fontes alternativas', 'Climate variables -Monitoring', 'Data acquisition systems', 'Renewable energy')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/8703","2021-04-28","https://www.repositorio.ufal.br/bitstream/123456789/8703/1/Desenvolvimento%20de%20sistema%20IOT%20de%20baixo%20custo%20para%20monitoramento%20integrado%20de%20vari%c3%a1veis%20clim%c3%a1ticas%20e%20de%20gera%c3%a7%c3%a3o%20fotovoltaica.pdf","Development of a low-cost IoT system for integrated monitoring of climatic variables and photovoltaic generation","('Davi Bibiano Brito',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/15686","Campus A.C. Simões","Instituto de Computação","Dissertação","Defining optical amplifiers gains using reinforcement learning","('José Carlos Pinheiro Filho',)","('Erick de Andrade Barboza',)","('Joaquim Ferreira Martins Filho', 'Baldoíno Fonseca dos Santos Neto')","The dynamic nature of future optical networks requires that amplifiers autonomously ad just their gain in response to changing network conditions, such as the addition or removal of channels, to maintain signal power and General Signal-to-Noise Ratio (GSNR) across a cascade of amplifiers. This challenge is known as the Adaptive Control of Optical Amplifier Operating Point (ACOP). Solutions for the ACOP problem have been proposed using tech niques such as cognitive learning, supervised learning, and evolutionary algorithms. Among these, the evolutionary approach has achieved the best results in terms of transmission qual ity. However, it has a relatively high response time, which is a significant drawback for operational deployment. On the other hand, reinforcement learning techniques are impor tant in the field of artificial intelligence to solve problems in real-time with trained models. This work proposes the first modeling of the ACOP problem using reinforcement learning,, specifically employing the Proximal Policy Optimization (PPO) algorithm integrated with the GNPy simulator. The objective is to improve signal quality by maximizing the GSNR through interaction with the gains of the amplifiers in the link. In four scenarios with varying numbers of channels, this approach achieved results close to the evolutionary approach, but with a speed-up of 300 times.",".","('Amplificadores ópticos', 'Inteligência artificial', 'Comunicação óptica', 'Optical amplifiers', 'Artificial intelligence', 'optical communication')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/15686","2024-07-28","https://www.repositorio.ufal.br/bitstream/123456789/15686/1/Defining%20optical%20amplifiers%20gains%20using%20reinforcement%20learning.pdf","",""
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/10764","Campus A.C. Simões","Instituto de Computação","Dissertação","Controle natural humano-robô orientado a usuário com Thin-plate Splines e LRCN","('Bruno Gabriel Cavalcante Lima',)","('Tiago Figueiredo Vieira',)","('Thales Miranda de Almeida Vieira', 'Ícaro Bezerra Queiroz de Araújo', 'Douglas Cedrim Oliveira')","Este trabalho propõe uma nova abordagem no ramo da teleoperação de braços robóticos baseada em visão computacional, Thin-Plate Splines e Redes Recorrentes. Utilizando uma única câmera de profundidade como sensor de entrada, tal abordagem isenta o usuário da necessidade de utilizar quaisquer dispositivos vestíveis. Através da aplicação de uma interface natural de usuário, esta abordagem inovadora facilita o ajuste fino paramétrico outrora necessário para a calibração de usuário para o controle robótico de posição, transformando o processo de calibração numa direta captura de poses do corpo humano. Utilizando a mão do usuário como forma de controle, a abordagem proposta é constituída por duas partes principais. A primeira é um mapeamento de posição customizável com componentes lineares e não-lineares, baseado em Thin-Plate Splines (TPS), para transferir diretamente o movimento do braço humano para o movimento do braço robótico. Tal mapeamento permite a correspondência de corpos dissimilares com diferentes restrições cinemáticas e diferentes formatos de espaço de trabalho. A segunda é um classificador dinâmico do estado da mão do usuário, baseado em Redes Recorrentes Convolucionais de Longo-Prazo (LRCN), que explora a coerência temporal dos dados de profundidade adquiridos. Ao fim, é realizada uma validação e avaliação da abordagem proposta. Para o classificador da mão, é realizada uma validação cruzada comparando a abordagem proposta com um baseline. Resultados revelam uma elevação na acurácia do classificador ao se explorar as relações temporais entre as imagens de profundidade. Para o mapeamento de movimento, é realizado um estudo com usuários envolvendo variantes da tarefa de pick-and-place em um cenário simplificado de manufatura. Para esse estudo, um ambiente de validação foi desenvolvido utilizando o Robot Operaing System (ROS) como framework principal. Também comparado a um baseline, a abordagem utilizando TPS revelou maior conforto e precisão no controle dos usuários em regiões próximas dos limites do espaço de trabalho do robô, nas quais a abordagem convencional se mostrava prejudicada. Além disso, resultados sugerem que a nova abordagem não apresentou aumento na dificuldade das tarefas.","This work proposes a novel vision-based robotic-arm teleoperation approach. By using a single depth-based camera, such an approach exempts the user from using any wearable devices. Through applying a natural user interface, such an approach also leverages the conventional fine-tuning process of the robotic position control calibration, turning the process into a direct capture of the human body. The proposed approach consists of two main parts. The first is a nonlinear customizable movement mapping based on Thin-Plate Splines (TPS), to directly transfer human body motion to robotic arm motion. Such mapping allows for matching dissimilar bodies, with different kinematics constraints and different workspace shapes. The second is a Deep Neural Network hand-state classifier based on Long-term Recurrent Convolutional Networks (LRCN), which exploits the temporal coherence of the acquired depth data. In the end, validation and evaluation of the proposed approach are performed. For the hand-state classifier, a cross-validation experiment comparing the current approach with a baseline is performed. Results reveal an increase in the classifier accuracy through exploring the temporal coherence present in sequential depth data. For the movement mapping, a user study is performed over a set of practical experiments involving variants of pick-and-place tasks in a simplified manufacturing environment. For this study, we developed a validation environment using Robot Operating System (ROS) as the main framework. Also compared to a baseline, the position mapping approach using TPS revealed better comfort and precision of user control in regions near to robot workspace boundaries, where the baseline approach showed a poor performance. Moreover, results suggested that the new approach did not present an increase in the experiment’s task difficulty.","('Interação homem-robô', 'Teleoperação', 'Mapeamento cinemático', 'Inteligência artificial', 'Human-robot interaction', 'Teleoperation', 'Natural user interface', 'Kinematics mapping', 'Thin Plate Spline', 'Long-term recurrent convolutional networks')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/10764","2021-05-26","https://www.repositorio.ufal.br/bitstream/123456789/10764/1/Controle%20natural%20humano-rob%c3%b4%20orientado%20a%20usu%c3%a1rio%20com%20Thin-plate%20Splines%20e%20LRCN.pdf","",""
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/17363","Campus A.C. Simões","Instituto de Computação","Dissertação","A comprehensive framework for atrial fibrillation classification : from ecg images to multimodal analysis","('Rafael Monteiro Laranjeira',)","('Thiago Damasceno Cordeiro',)","('Bruno Almeida Pimentel', 'Estela Ribeiro')","Esta pesquisa apresenta um framework abrangente para a detecção automatizada de fib rilação atrial (FA) que preenche a lacuna entre a prática clínica e as técnicas avançadas de aprendizado de máquina. Introduzimos um fluxo de processamento que transforma imagens padrão de exames de ECG de 12 derivações em múltiplas representações complementares, permitindo uma investigação sistemática de diferentes abordagens para a detecção de FA. O framework processa imagens brutas de ECG para extrair dados da derivação II, que são então transformados em três modalidades distintas: imagens processadas, séries temporais e espectrogramas. Cada modalidade é então analisada usando arquiteturas de redes neurais especializadas que são otimizadas para suas características específicas. A investigação envolve dois cenários experimentais: uma comparação balanceada entre FA e ritmos normais e um cenário clinicamente realista que mantém as distribuições naturais das classes (FA e não FA), usando uma base privada (InCor-DB) e uma base pública (Zheng DB). No cenário balanceado, a abordagem multimodal alcançou um F1-score de 99, 28% ± 0, 02%, enquanto as modalidades individuais alcançaram consistentemente valores acima de 98.36% ± 0.17%. No cenário clinicamente realista, onde os casos de FA representaram 8, 45% dos dados, a robustez do framework foi demonstrada com a abordagem multimodal alcançando um F1 score de 88, 59%. A validação externa usando o conjunto de dados Zheng DB confirmou a generalização do framework, com a abordagem multimodal mantendo um bom desempenho (F1 score de 98, 13 ± 0, 36%) em condições balanceadas. Uma parte importante da nossa abordagem é o mecanismo de fusão ponderada que com bina recursos de cada modalidade, usando pesos aprendidos para determinar como as difer entes representações contribuem para a análise final. Nossos experimentos mostram que esses pesos se adaptam à complexidade da tarefa, mantendo contribuições equilibradas entre as modalidades (imagem: 0, 3382 ± 0, 0025, espectrograma: 0, 3450 ± 0, 0033, série tempo ral: 0, 3167 ± 0, 0045) para discriminar a FA de ritmos normais, ao mesmo tempo em que mostra especialização (série temporal: 0, 5025 ± 0, 1252) para discriminar a FA de várias ar ritmias. Esse comportamento adaptativo demonstra a capacidade do mecanismo de otimizar o uso de recursos com base em desafios de classificação específicos, contribuindo para um desempenho consistente em diferentes cenários clínicos. Esta pesquisa contribui para o campo da análise automatizada de ECG, fornecendo ev idências empíricas para a eficácia de diferentes representações de dados na detecção de FA. Também foi observado que não é muito comum encontrar trabalhos que abordem espectro gramas, imagens e séries temporais simultaneamente. Esse estudo busca mostrar a viabil idade dessa combinação dessas entradas e o relacionamento entre elas. A capacidade do framework de processar imagens de ECG padrão o torna compatível com os ambientes onde apenas o formato de imagem está disponível, o que pode facilitar sua adoção em ambientes com menos recursos e médicos disponíveis.","This research presents a comprehensive framework for automated atrial fibrillation (AF) classification that bridges the gap between clinical practice and advanced machine learn ing techniques. We introduce a pipeline that transforms standard 12-lead electrocardiogram (ECG) examination images into multiple complementary representations, enabling a system atic investigation of different approaches to AF classification. The framework processes raw ECG images to extract Lead II data, which is then transformed into three distinct modali ties: processed images, time series, and spectrograms. Each modality is then analyzed using specialized neural network architectures that are optimized for their specific characteristics. The investigation involves two experimental scenarios: a balanced comparison be tween AF and normal rhythms and a clinically realistic scenario that maintains the natural class distributions (AF and non-AF), using a private dataset (InCor-DB) and a public dataset (Zheng-DB). In the balanced scenario, the multimodal approach achieved an F1-score of 99.28% ± 0.02%, while individual modalities consistently reached values above 98.36% ± 0.17%. In the clinically realistic scenario, where AF cases accounted for 8.45% of the data, the robustness of the framework was demonstrated, with the multimodal ap proach achieving an F1-score of 88.59%. External validation using the Zheng-DB dataset confirmed the generalization of the framework, with the multimodal approach maintaining strong performance (F1-score of 98.13 ± 0.36%) under balanced conditions. An important part of our approach is the weighted fusion mechanism that combines fea tures from each modality, using learned weights to determine how different representations contribute to the final analysis. Our experiments show that these weights adapt accord ingly to the task complexity, maintaining balanced contributions across modalities (image: 0.3382±0.0025, spectrogram: 0.3450±0.0033, time series: 0.3167±0.0045) to discriminate AF from normal rhythms, while showing strong specialization (time series: 0.5025±0.1252) to discriminate AF from various arrhythmias. This adaptive behavior demonstrates the mech anism’s ability to optimize feature usage based on specific classification challenges, con tributing to robust performance in different clinical scenarios. This research contributes to the field of automated ECG analysis by providing empirical evidence for the effectiveness of different data representations in AF detection. It was also observed that it is not very common to find studies that address spectrograms, images and time series simultaneously. This study seeks to show the feasibility of combining these inputs and the relationship between them. The framework’s ability to process standard ECG images makes it compatible with environments where only the image format is available, which could facilitate its adoption in environments with fewer resources and doctors available.","('Fibrilação atrial', 'Machine Learning', 'Eletrocardiografia', 'Redes neurais (Computação)', 'Atrial fibrillation', 'Machine Learning', 'Electrocardiography', 'Neural Networks')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/17363","2025-01-31","https://www.repositorio.ufal.br/bitstream/123456789/17363/1/A%20comprehensive%20framework%20for%20atrial%20fibrillation%20classification%20from%20ecg%20images%20to%20%20%20multimodal%20analysis.pdf","","('Marco Antônio Gutierrez',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/12995","Campus A.C. Simões","Instituto de Computação","Dissertação","Code smells detection across programming languages","('André Moabson da Silva Ramos',)","('Baldoíno Fonseca dos Santos Neto',)","('Márcio de Medeiros Ribeiro', 'Wesley Klewerton Guêz Assunção')","A incidência de code smells é frequentemente associada à degradação da qualidade do software. Vários estudos apresentam a importância de técnicas para detectar e combater a incidência deles no código-fonte. No entanto, as técnicas existentes para detectar code smells dependem da linguagem de programação. Consequentemente, várias linguagens de programação são amplamente empregadas pela comunidade de software sem técnicas adequadas de detecção. Nosso estudo aborda a ampliação da disponibilidade de técnicas de detecção de code smells para diferentes linguagens de programação por meio do aprendizado de transferência. Selecionamos cinco linguagens de programação entre as dez linguagens mais utilizadas de acordo com StackOverflow: Java, C++, Python, C#, e JavaScript. Além disso, algumas dessas linguagens possuem características semelhantes entre si, como Java e C#, o oposto pode-se dizer de Java e Python. Extraímos os conjuntos de dados para treinamento e teste de modelos de aprendizado profundo de 150 projetos de código aberto. Os resultados indicam que as técnicas de aprendizagem por transferência detectam de forma eficaz e eficiente os code smells, independentemente da linguagem de programação e da quantidade de camadas da arquitetura de aprendizagem profunda usada na aprendizagem por transferência. Essas descobertas podem ajudar desenvolvedores e pesquisadores a aplicar as mesmas técnicas de detecção de code smells em diferentes linguagens de programação.","The incidence of code smells is often associated with software quality degradation. Several studies present the importance of techniques to detect and tackle the incidence of smells in the source code. However, existing techniques to detect code smells depend on the programming language. Consequently, several programming languages are largely employed by the software community without proper techniques of code smell detection. Our study addresses amplifying the availability of code smell detection techniques to different programming languages through transfer learning. We select five programming languages among the ten most used languages according to StackOverflow: Java, C++, Python, C#, and JavaScript. Also, some of these languages have similar characteristics to each other, such as Java and C# as opposed to Java and Python. We extract the datasets for training and testing of deep learning models from 150 open sources projects. Results indicate that transfer learning techniques effectively and efficiently detect code smells regardless of the programming language and number of layers of the deep learning architecture used in transfer learning. These findings can help developers and researchers to apply the same code smell detection techniques in different programming languages.","('Engenharia de software', 'Aprendizado do computador', 'Aprendizagem profunda', 'Transferência de aprendizagem', 'Code smells', 'Linguagem de programação (Computadores)', 'Software engineering', 'Machine learning', 'Deep learning', 'Transfer of learning', 'Programming language (Computers)')","Ciência da Computação","eng","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/12995","2023-06-30","https://www.repositorio.ufal.br/bitstream/123456789/12995/1/Code%20smells%20detection%20across%20programming%20languages.pdf","","('Rafael Maiani de Mello',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/8767","Campus A.C. Simões","Instituto de Computação","Dissertação","Classifying heartbeats from electrocardiogram signals using a siamese convolutional neural network","('Eduardo Moraes de Miranda Vasconcellos',)","('Thiago Damasceno Cordeiro',)","('Baldoíno Fonseca dos Santos Neto', 'Filipe Rolim Cordeiro')","O Eletrocardiograma (ECG) é um exame de baixo custo comumente usado para diagnosticar anormalidades no ciclo cardíaco, tais como arritmias e problemas no músculo do coração. Com o avanço das técnicas de aprendizagem de máquinas (ML) nos últimos anos, a classificação automática de ECG está obtendo um interesse crescente na comunidade científica. Entretanto, o processo de anotar grandes e diversos conjuntos de dados para serem usados no treinamento de técnicas ML ainda é muito demorado e propenso a erros. Assim, técnicas ML cujo treinamento não requer um grande e bem anotado conjunto de dados estão se tornando cada vez mais proeminentes. Isto significa que os dados subrepresentados nos conjuntos de dados ECG, como raros distúrbios cardiológicos, ainda podem ser devidamente identificados e classificados. Neste trabalho, é investigado o uso de Redes Neurais Convolucionais Siamêsas, populares em problemas de classificação de imagens, para classificar batimentos cardíacos de 12 derivações em sinais de ECG. Os primeiros resultados indicam uma precisão de até 95% em um conjunto de dados públicos, utilizando modelos compostos de diferentes combinações de funções de similaridade e perda. Os resultados da classificação classe por classe também são comparados com os de métodos similares encontrados na literatura, obtendo-se métricas ao par e até mesmo excedendo-as na classificação de algumas classes.","The Electrocardiogram (ECG) is a low-cost exam commonly used to diagnose abnormalities in the cardiac cycle such as arrhythmias and problems in the heart’s muscle. With the advance of machine learning (ML) techniques in recent years, the automatic classification of ECG signals garnered interest in the scientific community. However, the process of annotating large and diverse datasets to support the training of ML techniques is still very time-consuming and error-prone. Thus, ML techniques whose training does not require a large, well-annotated datasets are becoming even more prominent. This means that underrepresented data in ECG datasets, like rare cardiologic disturbs can still be properly identified and classified. In this work, the use of Siamese Convolutional Neural Networks, popular in imaging classification problems, to classify 12-Lead ECG heartbeats is investigated. The early results indicate accuracy of up to 95% in a public dataset by using models composed of different combinations of similarity and loss functions. The class by class classification results are also compared with those of similar methods found in the literature, obtaining metrics on par and even exceeding them in the classification of some classes.","('Eletrocardiografia', 'Aprendizagem de máquina', 'Few Shot Learning', 'Redes neurais de computação', 'Batimento cardíaco – Classificação', 'Electrocardiogram', 'Machine Learning', 'Few-Shot Learning', 'Siamese Neural Networks', 'Heartbeat Classification')","Ciência da Computação","eng","Centro Universitário CESMAC","CESMAC","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/8767","2022-02-24","https://www.repositorio.ufal.br/bitstream/123456789/8767/1/Classifying%20heartbeats%20from%20electrocardiogram%20signals%20using%20a%20siamese%20convolutional%20neural%20network.pdf","Classificação dos batimentos cardíacos partir de sinais de eletrocardiograma usando uma rede neural convolucional siamesa",""
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/1758","Campus A.C. Simões","Instituto de Computação","Dissertação","Classificação da marcha em parkinsonianos: análise dos algoritmos de aprendizagem supervisionada","('Hugo Araújo Souza',)","('Marcelo Costa Oliveira',)","('Leandro Dias da Silva', 'Marcelo Zanchetta do Nascimento')","A Doença de Parkinson é a segunda doença neurodegenerativa mais prevalente em idosos, embora seu domínio e incidência variem de acordo com a idade, sexo e raça/etnia. Estudos apontam que a prevalência aumenta com a idade, tendo estimativa de 5 a 26 casos a cada 100 mil pessoas por ano, sendo de aproximadamente 1% entre os indivíduos de 65 a 69 anos e, variando de 3% a 14,3% entre os idosos acima de 85 anos. Os sinais clínicos mais comuns no processo inflamatório incluem a presença de tremor em repouso, rigidez muscular, bradicinesia e instabilidade postural. O diagnóstico da doença não é uma tarefa simples, pois sabe-se que há padrões de estágios no avanço da doença no organismo humano. Porém, muitos pacientes não seguem esse progresso devido a heterogeneidade de manifestações que podem surgir. A análise da marcha tornou-se um mecanismo quantitativo atrativo e não invasivo que pode auxiliar na detecção e monitoramento de portadores de DP. A extração de características é uma tarefa de suma importância para a qualidade dos dados a serem empregados pelos algoritmos de AM, visando como principal objetivo a redução na dimensionalidade dos dados em um processo de classificação. A partir da redução da dimensionalidade é possível identificar, principalmente, quais atributos são importantes e facilitar a visualização dos dados. Para dados relacionados à marcha humana, o propósito é detectar relevantes atributos que possam ajudar na identificação das fases do ciclo da marcha, como as fases de apoio e swing, cadência, comprimento da passada, velocidade, entre outras. Para tal, é preciso identificar e selecionar quais atributos são mais relevantes, assim como o método de classificação. Este trabalho avalia o desempenho de algoritmos de aprendizagem supervisionada na classificação das características da marcha humana em uma base de dados aberta, também identifica quais atributos são mais relevantes para o desempenho dos classificadores no auxílio à identificação de características da marcha em portadores da DP.","Parkinson’s disease is the second most prevalent neurodegenerative disease in the elderly, although its dominance and incidence vary according to age, gender and race/ethnicity. Studies indicate that the prevalence increases with age, with an estimate of 5 to 26 cases per 100,000 people per year, being approximately 1% among individuals aged 65-69 and ranging from 3% to 14.3% among the elderly over 85 years. The most common clinical signs in the inflammatory process include the presence of resting tremor, muscle stiffness, bradykinesia and postural instability. The diagnosis of the disease is not a simple task, as it is known that there are stages patterns of disease progression in the human organism. However, many patients do not follow this progress because of the heterogeneity of manifestations that may arise. The gait analysis has become an attractive and non-invasive quantitative mechanism that can aid in the detection and monitoring of PD patients. Feature extraction is a very important task for quality of the data to be used by the algorithms, aiming as main objective the reduction in the dimensionality of the data in a classification process. From the reduction of dimensionality it is possible to identify which attributes are important and to facilitate the visualization of the data. For data related to human gait, the purpose is to detect relevant attributes that may help in identifying gait cycle phases, such as support and swing phases, cadence, stride length, velocity, etc. To do this, it is necessary to identify and select which attributes are most relevant, as well as the classification method. This work evaluates the performance of supervised learning algorithms in the classification of human gait characteristics in an open database, also identifies which attributes are most relevant to the performance of the classifiers in aiding the identification of gait characteristics in PD patients.","('Aprendizagem supervisionada -Algoritmos', 'Classificação de dados', 'Seleção de atributos', 'Marcha humana', 'Doença de Parkinson', 'Machine learning', 'Data classification', 'Feature selection', 'Human gait', 'Parkinson disease')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1758","2017-04-12","https://www.repositorio.ufal.br/bitstream/riufal/1758/1/Classifica%c3%a7%c3%a3o%20da%20marcha%20em%20parkinsonianos%3a%20an%c3%a1lise%20dos%20algoritmos%20de%20aprendizagem%20supervisionada.pdf","Classification of the parkinsonian gait: analysis of supervised learning algorithms","('Leonardo Melo de Medeiros',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/9269","Campus A.C. Simões","Instituto de Computação","Dissertação","Biased random-key genetic algorithms for the minimum broadcast time problem","('Alfredo Lima Moura Silva',)","('Rian Gabriel Santos Pinheiro',)","('André Luiz Lins de Aquino', 'Fábio Protti')","O problema TEMPO MÍNIMO DE TRANSMISSÃO (TMT) é um problema conhecido de disseminação de dados, com o objetivo é encontrar um esquema de transmissão que minimize o número de passos necessários para executar a operação de transmissão. O TEMPO MÍNIMO DE TRANSMISSÃO COM PESO (TMTP) é uma generalização do TMT, de forma que cada operação tem um custo. Ambos os problemas têm diversas aplicações em sistemas distribuídos, por exemplo, o processo de atualização de dispositivos em uma rede ponto-a-ponto. Este trabalho propõe Algoritmos Genéticos de Chave-Aleatória Enviesados (AGCAE) para o TMT e o TMTP. Um algoritmo híbrido (AGCAE + Programação Linear Inteira) para o TMT. Algoritmos para calcular um limite inferior para o TMT e o TMTP. Uma abordagem de refinamento, e métodos para criar instâncias com ótimos conhecidos para TMT e TMTP. Além disso, um método para diminuir os grafos para o TMTP. Foi realizado experimentos com o AGCAE em instâncias comumente utilizadas na literatura e também em instâncias sintéticas massivas (até 1000 vértices), o que permite cobrir muitas possibilidades de topologias reais da indústria. A proposta comparou métodos exatos e heurísticas do estado-da-arte dos problemas. Os algoritmos superaram as heurísticas mais conhecidas para TMT e TMTP. Os experimentos demonstraram que estes algoritmos são uma boa alternativa quando métodos exatos não podem ser aplicados. Para todas as instâncias do TMT com valor ótimo conhecido, os algoritmos alcançaram o valor ótimo ou no máximo uma unidade para encontrar o tempo mínimo de transmissão. Para todas as instâncias do TMTP, as abordagens alcançaram ou melhoraram os resultados da literatura.","The MINIMUM BROADCAST TIME (MBT) is a well-known data dissemination problem whose goal is to find a broadcast scheme that minimizes the number of steps needed to execute the broadcast operation. The WEIGHTED MINIMUM BROADCAST TIME (WMBT) is a generalization of the MBT, such that each operation has a cost. Both problems have many applications in distributed systems, e.g., the devices update process in a peer-to-peer network. This work proposes Biased Random-Key Genetic Algorithms (BRKGA) for the MBT and WMBT. A hybrid algorithm (BRKGA + Integer Linear Programming) for the MBT. Algorithms to calculate a lower bound for the MBT and WMBT. A refinement approach and methods to create instances with known optima for the MBT and WMBT. Moreover, reducing rules for the WMBT. We carry out experiments with our BRKGA on instances commonly used in the literature and also on massive synthetic instances (up to 1000 vertices), allowing us to cover many possibilities of real industry topologies. Our proposal compared state-of-the-art exact methods and heuristics. Our algorithms outperformed the best-known heuristics for the MBT and WMBT. The experiments demonstrated they are a very good alternative when exact methods cannot be applied. For all instances for the MBT with known optima value, our approaches either attained the optimal value or missed it by at most one broadcast step. For all instances for the WMBT, our approaches attained or improved the results of literature.","('Otimização combinatória', 'Tempo mínimo de transmissão', 'Metaheurísticas', 'Chave aleatória enviesados (Algoritmos genéticos)', 'Combinatorial Optimization', 'Minimum Broadcast Time', 'Metaheuristics', 'Biased Random-Key (Genetic Algorithms)')","Ciência da Computação","eng","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/9269","2021-11-12","https://www.repositorio.ufal.br/bitstream/123456789/9269/3/Biased%20random-key%20genetic%20algorithms%20for%20the%20minimum%20broadcast%20time%20problem.pdf","","('Bruno Costa e Silva Nogueira',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/15940","Campus A.C. Simões","Instituto de Computação","Dissertação","Uma avaliação sistemática de técnicas de aprendizado de máquina baseadas em ensemble para previsão de índices do mercado de ações usando séries temporais financeiras","('João Victor Ribeiro Ferro',)","('Evandro de Barros Costa',)","('Bruno Almeida Pimentel', 'Ícaro Bezerra Queiroz de Araújo', 'George Darmiton da Cunha Cavalcanti')","A previsão de índices de séries temporais nos mercados de ações tem despertado crescente interesse, fornecendo aos investidores informações valiosas sobre as tendências econômicas futuras de um país a curto, médio e longo prazo. Esse tipo de predição tem sido amplamente realizado por meio de modelos de aprendizado de máquina. No entanto, devido à volatilidade, ao ruído e à estocasticidade dos dados, os modelos individuais (single) frequentemente apresentam limitações em termos de precisão. Para mitigar esses problemas, surgiram as técnicas de ensemble, que combinam múltiplos modelos para aumentar a robustez e a acurácia das previsões. As abordagens de ensemble exploram a diversidade dos modelos e técnicas de machine learning, aproveitando as características individuais de cada um para obter resultados mais confiáveis do que aqueles gerados por modelos isolados. Dessa forma, foi realizada uma revisão sistemática da literatura voltada para a predição de índices da bolsa de valores utilizando séries temporais financeiras e abordagens de ensemble, com o objetivo de mapear os princi pais artigos, autores, tipos de técnicas utilizadas e lacunas na literatura. A revisão revela que muitas análises comparativas se limitam ao uso de métricas de desempenho tradicionais, como erro quadrático médio, raiz do erro quadrático médio, erro absoluto médio e erro percentual absoluto médio, o que pode introduzir vieses nas comparações. Além disso, essas análises fre quentemente omitem testes estatísticos robustos, focam-se apenas em um tipo de mercado e adotam protocolos de comparação inadequados. Este estudo investiga como diferentes técnicas de ensemble podem aprimorar a previsão em séries temporais financeiras, adotando um protocolo meticuloso para eliminar vieses nos dados e padronizar comparações entre metodologias. Além das métricas tradicionais, foi introduzida uma análise de custo-benefício para uma avaliação mais abrangente das arquiteturas de ensemble. O teste de hipótese de Wilcoxon foi aplicado para validar as descobertas, juntamente com os testes de Friedman e Nemenyi. Os resultados destacam a importância de executar os algoritmos em diferentes ambientes, como os selecionados IBOVESPA e S&P 500, pois há divergências no desempenho das métricas de avaliação e nos testes estatísticos, o que ressalta a necessidade de utilizar a métrica de custo-benefício para verificar se há um ganho real na performance geral da arquitetura utilizada em comparação aos modelos single, estabelecendo assim uma estruturação para a construção e avaliação das abordagens de ensemble. Com estes resultados, espera-se contribuir para a construção de metodologias mais robustas e eficazes no uso de técnicas de ensemble para a predição de índices de ações, garantindo uma melhor compreensão das vantagens e limitações dessas técnicas em diferentes ambientes de mercado.","The prediction of time series indices in stock markets has been garnering increasing interest, providing investors with valuable information about a country’s future economic trends in the short, medium, and long term. This type of prediction has been widely performed through machine learning models. However, due to the volatility, noise, and stochasticity of the data, single models often present limitations in terms of accuracy. To mitigate these issues, ensem ble techniques have emerged, combining multiple models to increase the robustness and accu racy of predictions. Ensemble approaches exploit the diversity of models and machine learning techniques, leveraging the individual characteristics of each to achieve more reliable results than those generated by isolated models. Thus, a systematic literature review was conducted focusing on stock index prediction using financial time series and ensemble approaches, with the aim of mapping the main articles, authors, types of techniques used, and gaps in the literature. The review reveals that many comparative analyses are limited to the use of traditional performance metrics, such as mean squared error, root mean squared error, mean absolute error, and mean absolute percentage error, which can introduce biases in comparisons. Furthermore, these analyses often omit robust statistical tests, focus on only one type of market,and adopt nadequate comparison protocols. This study investigates how different ensemble techniques can enhance prediction in financial time series, adopting a meticulous protocol to eliminate data biases and standardize comparisons between methodologies. In addition to tra ditional metrics, a cost-benefit analysis was introduced for a more comprehensive evaluation of ensemble architectures. The Wilcoxon hypothesis test was applied to validate the findings,along with the Friedman and Nemenyi tests. The results highlight the importance of running algorithms in different environments, such as the selected IBOVESPA and S&P 500, as there are divergences in the performance of evaluation metrics and statistical tests, emphasizing the need to use the cost-benefit metric to verify whether there is a real gain in the overall performance of the architecture compared to single models. This establishes a framework for constructing and evaluating ensemble approaches. With these results, the aim is to con tribute to the development of more robust and effective methodologies in the use of ensemble techniques for stock index prediction, ensuring a better understanding of the advantages and limitations of these techniques in different market environments.","('Análise de séries temporais', 'Inteligência artificial', 'Mercado financeiro', 'Índices de mercados e ações', 'Machine Learning', 'Comparative Analysis', 'Machine Learningt', 'Ensemble', 'Financial Time Series', 'Index Market')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/15940","2024-09-10","https://www.repositorio.ufal.br/bitstream/123456789/15940/1/Uma%20avalia%c3%a7%c3%a3o%20sistem%c3%a1tica%20de%20t%c3%a9cnicas%20de%20aprendizado%20de%20m%c3%a1quina%20baseadas%20em%20ensemble%20para%20previs%c3%a3o%20de%20%c3%adndices%20do%20mercado%20de%20a%c3%a7%c3%b5es%20usando%20s%c3%a9ries%20temporais%20financeiras.pdf","",""
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/10016","Campus A.C. Simões","Instituto de Computação","Dissertação","Avaliação de desempenho do tráfego urbano usando simulação : estudo de caso em Maceió/AL","('Flávio Vasconcelos Pais',)","('Bruno Costa e Silva Nogueira',)","('André Luiz Lins de Aquino', 'Eduardo Antonio Guimaraes Tavares')","As metrópoles brasileiras vêm enfrentando graves problemas de congestionamento de trânsito em consequência do rápido crescimento populacional, aumento do número de veículos e ineficiência das políticas públicas. A maioria das cidades não possui sistema de controle de tráfego urbano em tempo real para otimizar o fluxo de veículos. Nesse contexto, a utilização de softwares de simulação de tráfego surgem como alternativas de baixo custo para avaliar diversos problemas e promover possíveis melhorias no tráfego de veículos nas grandes cidades. Assim, por meio do Simulador de Mobilidade Urbana (SUMO), este trabalho propôs avaliar o desempenho de tráfego urbano de uma via proeminente da cidade de Maceió, Alagoas, Brasil. A via escolhida foi a avenida Fernandes Lima, por representar um dos mais importantes corredores viários da cidade. A abordagem de simulação de tráfego proposta permitiu entender o comportamento do fluxo de veículos da via, que possui peculiaridades, como a faixa azul (exclusiva para o transporte coletivo) e três trechos com semáforos de pedestre. A validação da simulação foi feita considerando dados obtidos a partir de observações reais, e os resultados indicam que é capaz de prover estimativas com erros menores que 5% relacionados ao volume de tráfego de veículos nas interseções semafóricas e menores que 10% relacionados ao tempo médio de viagem total dos veículos que percorrem toda a avenida. Por fim, comparando os resultados experimentais dos 8 estudos de caso propostos: atual (1), sem faixa azul (2), sem semáforos de pedestre (3), sem faixa azul e semáforos de pedestre (4), acidente trecho 1 (5), acidente trecho 2 (6), semáforos com ajuste de -5 segundos (7) e semáforos com ajuste de +5 segundos (8), foi possível obter melhorias nos indicadores de eficiência (tempo de viagem, tempo de espera, consumo de combustíveis e emissão de gás carbônico) e ganhos volumétricos no tráfego de veículos, com destaque para os cenários 2, 3, 4 e 8, que alcançaram ganhos no volume de tráfego de veículos de, respectivamente, 9,95%, 7,88%, 10,77% e 1,21%.","Brazilian metropolises have been facing serious traffic congestion problems as a consequence of rapid population growth, the increasing vehicles number and inefficient public policies. Most cities do not have a real-time urban traffic control system to optimize the flow of vehicles. In this context, the use of traffic simulation software appears as low-cost alternatives to evaluate various problems and promote possible improvements in vehicle traffic in large cities. Thus, through the Urban Mobility Simulator (SUMO), this paper proposed to evaluate the urban traffic performance of a prominent road in the city of Maceió, Alagoas, Brazil. The chosen road was Fernandes Lima Avenue, as it represents one of the most important road corridors of the city. The proposed traffic simulation approach allowed us to understand the behavior of the flow of vehicles on the road, which has peculiarities, such as the blue lane (exclusive for public transport) and three sections with pedestrian traffic lights. The simulation validation was performed considering data obtained from real observations, and the results indicate that it is capable of providing estimates with errors lower than 5% and 10% for, respectively, the vehicle traffic volume and the total travel time. Finally, comparing the experimental results of the 8 proposed case studies: current (1), no blue lane (2), no pedestrian traffic lights (3), no blue lane and pedestrian traffic lights (4), accident section 1 (5), accident section 2 (6), traffic lights with adjustment of -5 seconds (7) and traffic lights with adjustment of +5 seconds (8), it was possible to obtain improvements in the efficiency indicators (travel time, waiting time, consumption of fuels and carbon dioxide emissions) and volumetric gains in vehicle traffic, with emphasis on scenarios 2, 3, 4 and 8, which achieved gains in vehicle traffic volume of, respectively, 9.95%, 7.88% , 10.77% and 1.21%.","('Tráfego urbano -Maceió (AL)', 'Simulação (Computadores)', 'Semáforos', 'Simulador de Mobilidade Urbana', 'Urban Traffic', 'Simulation', 'Traffic-Lights', 'SUMO')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/10016","2022-08-31","https://www.repositorio.ufal.br/bitstream/123456789/10016/1/Avalia%c3%a7%c3%a3o%20de%20Desempenho%20de%20Tr%c3%a1fego%20Urbano%20Usando%20Simula%c3%a7%c3%a3o%20-%20Estudo%20de%20Caso%20em.pdf","Performance Evaluation of Urban Traffic Using Simulation: A Case Study in Maceió/AL","('Rian Gabriel Santos Pinheiro',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/1720","Campus A.C. Simões","Instituto de Computação","Dissertação","Auxílio computadorizado ao diagnóstico do câncer de pulmão otimizado por GPU","('José Raniery Ferreira Júnior',)","('Marcelo Costa Oliveira',)","('Paulo Mazzoncini de Azevedo Marques', 'Tiago Figueiredo Vieira')","O câncer de pulmão é o tipo de câncer que mais causa mortes no mundo e sua principal manifestação ocorre devido ao aparecimento de nódulos pulmonares. A classificação dos nódulos pulmonares é uma tarefa complexa que está sujeita a diversos erros de interpretação. Dessa forma, é importante integrar ferramentas computacionais ao processo de classificação de nódulos pulmonares, pois elas têm potencial de auxiliar no processo de diagnóstico do câncer de pulmão. Técnicas de recuperação de imagens baseada em conteúdo (CBIR -Content-Based Image Retrieval) têm sido descritas como ferramentas de diagnóstico diferencial promissoras, pois elas são capazes de recuperar em grandes bases de dados casos similares previamente diagnosticados. Contudo, a CBIR possui algumas limitações, como o processo de extração de características das imagens e o tempo de execução na comparação de uma imagem de referência com uma base de imagens. Neste contexto, o objetivo deste trabalho é desenvolver um algoritmo para o auxílio computadorizado à classificação de nódulos pulmonares utilizando CBIR, com a integração das técnicas: Análise de Textura 3D e Análise de Nitidez de Borda 3D para a caracterização dos nódulos pulmonares, e otimização no tempo de execução da comparação entre os nódulos pulmonares com paralelismo em uma unidade de processamento gráfico (GPU -Graphics Processing Unit). As imagens utilizadas neste trabalho são de tomografia computadorizada provenientes do projeto público Lung Image Database Consortium, que possui nódulos pulmonares identificados e classificados por especialistas segundo a probabilidade de malignidade da lesão radiológica. Atributos de Textura (AT) foram extraídos a partir da matriz de coocorrência obtida sobre o volume do nódulo. Atributos de Nitidez de Borda (ANB) foram extraídos a partir de linhas ortogonais traçadas sobre as bordas da lesão em todas as fatias do volume. Atributos Integrados (AI) foram criados a partir da concatenação dos AT e ANB. Distância Euclidiana foi utilizada como métrica de similaridade entre os vetores de características. A avaliação do algoritmo de CBIR desenvolvido utilizou as métricas de Precisão vs. Revocação e precisão para os 10 casos mais similares segundo a probabilidade de malignidade dos nódulos, em arquiteturas single-core, multi-core e many-core. Os resultados mostraram que os ANB obtiveram maior eficiência na recuperação dos nódulos pulmonares, na maioria dos cenários da avaliação de precisão, com aumento de precisão de 2 pontos percentuais em relação aos AT e AI na recuperação dos 10 casos mais similares. Os AT obtiveram mesma eficiência que os AI e apresentaram maior precisão média apenas na recuperação de nódulos benignos, com aumento de precisão de 3 pontos percentuais em relação aos ANB, quando empregada Precisão vs. Revocação. Os resultados mostraram também que a GPU conseguiu diminuir o tempo de execução na comparação dos vetores de características e aumentar o desempenho da distância Euclidiana na recuperação dos nódulos pulmonares, com ganhos de performance de até 19x. Com isto, a CBIR aliada aos atributos de nitidez de borda 3D e otimização em GPU possuem grande potencial como ferramenta computacional ao diagnóstico do câncer de pulmão e classificação de nódulos pulmonares.","Lung cancer is the leading cause of cancer-related deaths in the world and its main manifestation occurs due to the appearance of pulmonary nodules. Pulmonary nodule classification is a complex task because it is a subjective and qualitative process that might be compromised by interpretation errors. Therefore, it is important to integrate computational tools to the pulmonary nodule classification process, since they have the potential to characterize objectively and quantitatively the lesions, so they can aid lung cancer diagnosis process. Content-Based Image Retrieval (CBIR) has been described as one of the most promissing differential diagnosis tool, since it is capable of retrieving similar cases from large image databases that were previously diagnosed. However, CBIR has some limitations, like the image feature extraction process and the time to compare one reference image with an image database. In this context, the goal of this work is to develop an algorithm to aid the diagnosis of lung cancer and the pulmonary nodule classification, using CBIR with the integration of three methods: 3D Texture Analysis and 3D Margin Sharpness Analysis for nodule characterization, and optimization on the execution time of the nodule comparison with paralelism on a Graphics Processing Unit (GPU). Images used in this work were computed tomography scans provided by the Lung Image Database Consortium, which has pulmonary nodules identified and classified by specialists according to the lesion’s likelihood of malignancy. Texture Attributes (TA) were extracted from a co-occurrence matrix obtained from the nodule volume. Margin Sharpness Attributes (MSA) were extracted from perpendicular lines drawn over the borders on all nodule slices. Integrated Attributes (IA) were created by concatenating TA and MSA. Euclidean distance was employed as similarity metric between feature vectors. CBIR algorithm’s precision was evaluated on the 10 most similar cases according to the likelihood of malignancy and with Precision and Recall parameters, on single-core, multi-core and many-core architectures. Results showed that MSA obtained more efficiency on pulmonary nodule retrieval, in the majority of precision evaluation scenarios, with the precision increase of 2% compared with TA. Texture attributes obtained the same efficiency as IA and presented higher mean precision only on benign nodule retrieval with Precision vs. Recall metric, with the precision increase of 3% compared with MSA. Results also showed that GPU, represented by the many-core device, was able to decrease execution time on image feature vector comparison and increase Euclidean distance performance on pulmonary nodule retrieval, with speedups of 16x, 17x and 19x. Therefore, CBIR allied to 3D margin sharpness descriptors and GPU optimization have big potential as a computer-based tool on lung cancer diagnosis and pulmonary nodule classification.","('Pulmões -Câncer', 'Processamento eletrônico de dados', 'Diagnóstico por imagem', 'Lung-Cancer', 'Electronic data processing', 'Diagnostic Imaging')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1720","2015-05-11","https://www.repositorio.ufal.br/bitstream/riufal/1720/1/Aux%c3%adlio%20computadorizado%20ao%20diagn%c3%b3stico%20do%20c%c3%a2ncer%20de%20pulm%c3%a3o%20otimizado%20por%20GPU.pdf","Computer-aided diagnosis of lung cancer otimized by GPU",""
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/1718","Campus A.C. Simões","Instituto de Computação","Dissertação","Auxílio computadorizado à identificação do câncer de pulmão baseado em mapas de conexidade Fuzzy 3-D","('Jose Oswaldo Cavalcante da Silva Filho',)","('Marcelo Costa Oliveira',)","('Tiago Figueiredo Vieira', 'Bruno José Torres Fernandes')","De todos os tipos, o câncer de pulmão é o mais incidente e letal do mundo. Atualmente, as melhores chances de cura residem no diagnóstico precoce. No processo de diagnóstico, o especialista deve segmentar o nódulo suspeito e analisar sua forma para classificá-lo como benigno ou maligno. A segmentação é tipicamente realizada de forma manual e, por isso, é considerada tediosa, consome muito tempo e sofre de variações do observador, estando sujeita à falha humana. Aspectos como cansaço visual, fatores emocionais e mesmo a experiência do médico, podem comprometer o diagnóstico. Assim, o uso de um processo semiautomático de segmentação fornece ao médico uma ferramenta capaz de auxiliá-lo na detecção precoce, favorecendo um aumento nas chances de sobrevivência do paciente. A literatura apresenta níveis satisfatórios de 84% de aceitação dos especialistas na segmentação semiautomática baseada em mapas de conexidade Fuzzy. Assim, este trabalho objetiva o uso de uma versão otimizada do algoritmo de formação dos mapas de conexidade Fuzzy 3-D, aplicada ao contexto de nódulos pulmonares, combinada com outros algoritmos de segmentação para formar um método robusto de segmentação de nódulos pulmonares. O método aplica uma combinação de três algoritmos para obter a segmentação nodular: um pré-processamento por segmentação adaptativa local que exclui anexos vasculares e outras estruturas indesejadas, ao mesmo tempo em que forma uma máscara ideal que contém o nódulo e obtém uma semente ideal para o método; em seguida, um mapa de conexidade Fuzzy 3-D é formado pela avaliação de pertinência de todos os voxels da imagem em relação à semente ideal obtida; por fim, um algoritmo de crescimento de região esférico baseado em contraste estabelece um critério de parada automatizado baseado no mapa de conexidade Fuzzy. Como resultado, o método apresenta uma solução ideal e diversas soluções alternativas para a escolha do especialista. O método foi avaliado utilizando uma base de referência de nódulos pulmonares manualmente segmentados por especialistas e utilizada em diversos estudos de câncer de pulmão. Foram utilizados 140 nódulos para os testes, separados em dois grupos de acordo com seus graus de malignância. O método foi capaz de segmentar nódulos de diferentes tipos, com uma média satisfatória entre os índices de precisão de outros trabalhos na literatura que também utilizaram a mesma base de nódulos manualmente segmentados. O trabalho também encontrou valores de referência para as constantes dos algoritmos de segmentação e avaliou o impacto da versão otimizada dos mapas de conexidade no custo de processamento.","Lung cancer is the most common and deadly of all kinds of cancers. Nowadays, the best chances of cure rely on early diagnosis. During diagnosis, the specialist must perform segmentation of a suspect nodule and analyze its shape to classify the nodule as benign or malignant. Nodule segmentation is commonly performed manually, and because of that, it is considered tedious, time consuming and can be compromised from observer variations. It may still be subject to human fail, and aspects like eyestrain, emotional factors, and even the specialist experience can. Hence the use of a semiautomatic process of segmentation provides the specialist a tool capable of aiding the early detection, which improves the patient’s chance of survival. Current segmentation techniques based on fuzzy connectivity maps provide a satisfatory level of 84% of acceptance by specialists. Therefore, the purpose of this work is to combine an optimized version of an algorithm based on fuzzy connectivity maps with other segmentation algorithms obtain a robust method for lung nodules segmentation. The method combines three algorithms to obtain the nodule segmentation; a pre-processsing stage based on local adaptive segmentation, which removes vascular attachments and undesired structures, and forms an optimum mask containing the nodule and obtains an optimum seed for the method; a 3-D fuzzy connectivity map, formed by the evaluation of relevance through all image voxels according to the optimum seed; a contrast-based sphericity oriented region growing algorithm, which establishes an automated halting criteria for the fuzzy connectivity map. As a result, the method presents an optimal solution and several alternative solutions for the specialist. The method was evaluated using a benchmark of lung nodules, composed of images manually segmented by specialists, applied in several studies of lung cancer. The test used 140 nodules, divided in two groups according to its malignancy levels. The method showed capable of segmenting different kinds of nodules with a satisfactory precision between others works in literature that used the same dataset. The work has also found reference values of segmentation algorithms constants and evaluated the impact of the optimized fuzzy connectivity maps to the processing cost.","('Pulmões -Câncer', 'Neoplasias', 'Diagnóstico por imagem', 'Informática na medicina', 'Lung-Cancer', 'Neoplasms', 'Diagnostic Imaging', 'Computing in medicine')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1718","2015-04-27","https://www.repositorio.ufal.br/bitstream/riufal/1718/1/Aux%c3%adlio%20computadorizado%20%c3%a0%20identifica%c3%a7%c3%a3o%20do%20c%c3%a2ncer%20de%20pulm%c3%a3o%20baseado%20em%20mapas%20de%20conexidade%20Fuzzy%203-D.pdf","Computer supported aid to lung cancer identification based on 3-D Fuzzi connectedness maps",""
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/10781","Campus A.C. Simões","Instituto de Computação","Dissertação","Brazilian data scientists: revealing their challenges and practices on machine learning model development","('João Lucas Marques Correia',)","('Baldoíno Fonseca dos Santos Neto',)","('Thiago Damasceno Cordeiro', 'Alessandro Fabrício Garcia')","Cientistas de dados com frequência desenvolvem modelos de aprendizagem de máquina para resolver uma variedade de problemas tanto na indústria como na academia. Para construir esses modelos, estes profissionais executam atividades que também são executadas no ciclo tradicional do desenvolvimento de software, como a elicitação e implementação de requisitos. É factivel argumentar que os cientistas de dados poderiam tirar vantagem dos métodos utilizados pela engenharia de software tradicional para construir modelos de aprendizagem de máquina. Entretanto, o desenvolvimento de código voltado para aprendizagem de máquina possui particularidades que podem levar a desafios que podem que necessitam da adoção de novas práticas de desenvolvimento. De modo que a literatura atual não caracteriza esse tipo de conhecimento do ponto de vista dos cientistas de dados. Neste trabalho, nós caracterizamos os desafios e práticas a respeito da engenharia de modelos de aprendizagem de máquina que merecem atenção da comunidade de pesquisa. Para isto, nós executamos um estudo qualitativo com oito desenvolvedores de software membros de cinco companhias distintas, com diferentes níveis de experiência no desenvolvimento de modelos de aprendizagem de máquina. Nossos achados sugerem que: (i) o processamento de dados e a engenharia de atributos são os estágios de desenvolvimento mais desafiadores durante o desenvolvimento de um modelo de aprendizagem de máquina; (ii) é essencial uma sinergia entre os cientistas de dados e especialistas no domínio da aplicação do modelo; e (iii) o desenvolvimento de modelos de aprendizagem de máquina sofre da falta de suporte de um processo de engenharia bem definido.","Data scientists often develop machine learning models to solve a variety of problems in the industry and academy. To build these models, these professionals usually perform activities that are also performed in the traditional software development lifecycle, such as eliciting and implementing requirements. One might argue that data scientists could rely on the engineering of traditional software development to build machine learning models. However, machine learning development presents certain characteristics, which may raise challenges that lead to the need for adopting new practices. The literature lacks in characterizing this knowledge from the perspective of the data scientists. In this work, we characterize challenges and practices addressing the engineering of machine learning models that deserve attention from the research community. To this end, we performed a qualitative study with eight data scientists across five different companies having different levels of experience in developing machine learning models. Our findings suggest that: (i) data processing and feature engineering are the most challenging stages in the development of machine learning models; (ii) it is essential synergy between data scientists and domain experts in most of stages; and (iii) the development of machine learning models lacks the support of a well engineered process.","('Engenharia de software', 'Aprendizagem de máquina', 'Estudo empírico', 'Software engineering', 'Machine learning', 'Practitioner', 'Empirical study')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/10781","2021-06-09","https://www.repositorio.ufal.br/bitstream/123456789/10781/1/Brazilian%20data%20scientists_revealing%20their%20challenges%20and%20practices%20on%20machine%20learning%20model%20development.pdf","Cientistas de dados brasileiros: revelando seus desafios e práticas no desenvolvimento de modelos de aprendizado de máquina","('Rafael Maiani de Mello',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/1716","Campus A.C. Simões","Instituto de Computação","Dissertação","Atualização local automática de pesos para recuperação de nódulos similares de câncer pulmonar","('David Jones Ferreira de Lucena',)","('Marcelo Costa Oliveira',)","('Evandro de Barros Costa', 'Marcelo Zanchetta do Nascimento')","O câ¢ncer de pulmão se tornou a neoplasia maligna mais letal do mundo nas últimas décadas. E, apesar dos avanços na medicina, houve pouco progresso com relação à cura da doença. Segundo o INCA, na última estimativa mundial sobre a incidência de câncer pulmonar, em 2012, foram registrados 1,82 milhão de casos de câncer, sendo 1,24 milhão entre os homens e 583 mil entre as mulheres. O principal causador do câncer pulmonar é o tabagismo sendo responsável por 90% dos casos diagnosticados. O diagnóstico do câncer pulmonar é feito, principalmente, com base em imagens de TC e, hoje, é considerada a principal técnica de visualização para detecção de nódulos pulmonares. Entretanto, o processo de identificação e classificação de nódulos é complexo e envolve fatores subjetivos e qualitativos que acabam induzindo os especialistas ao erro. Este panorama exige o emprego de técnicas computacionais que permitam efetivamente manipular os dados e proporcionar meios para diagnósticos mais precisos. Sistemas computacionais têm sido desenvolvidos com o objetivo de buscar e recuperar imagens de exames já diagnosticados, que são similares a um novo caso com patologia ainda desconhecida segundo a similaridade entre as suas características. Essa propriedade é intrínseca aos sistemas CBIR. Os exames diagnosticados recuperados podem ser utilizados como uma segunda opinião para guiar os especialistas no momento do diagnóstico, fornecendo informações adicionais. Contudo, CBIR apresenta algumas limitações referentes ao processo de extração e representação de características das imagens, por meio de atributos, e a determinação de uma métrica de similaridade adequada. Este trabalho apresenta um algoritmo de ajuste local de pesos aplicado à DEP em uma arquitetura CBIR com o objetivo de verificar se a DEP com os pesos ajustados é mais precisa do que a DE na recuperação de imagens contendo nódulos de câncer pulmonar. Para isso, foram utilizados os AT 3D e os ANB 3D para representar os nódulos. O processo apresentado é composto por duas fases que são executadas de forma sequencial e cíclica sendo uma Fase de Avaliação e uma de Fase de Treinamento. A cada iteração os pesos são ajustados segundo os nódulos recuperados. Ao término do ciclo de execuções das fases, obtém-se um conjunto de pesos de atributos que otimizam a recuperação de nódulos semelhantes. Os resultados alcançados pela atualização dos pesos foram promissores aumentando a precisão em 10% e 6% em média para recuperação de nódulos benignos e malignos, respectivamente, com revocação de 25%. No melhor caso, o ANB 3D proporcionou 100% para recuperação das duas classes com revocação de 90%. Isso comprova a eficácia do algoritmo alcançando os objetivos almejados para o trabalho e confirmando a hipótese de que a DEP com os pesos ajustados proporciona maior precisão do que DE como métrica de similaridade em sistemas CBIR.","Lung cancer has become the most lethal malignancy in the world in recent decades. And despite advances in medicine, there has been little progress regarding the cure of the disease. According to the National Cancer Institute in the last global estimate of the incidence of lung cancer in 2012, there were 1.82 million cases of cancer, with 1.24 million among men and 583 thusand among women. The main cause of lung cancer is smoking that is responsible for 90 % of diagnosed cases. The diagnosis of lung cancer is done mainly based on CT images, and today it is considered the main visualization technique for detecting pulmonary nodules. However, the process of identifying and classi cation of nodules are complex and involves subjective and qualitative factors that lead experts to error. This scenario requires the use of computational techniques to e ectively manipulate the data and provide the means for more accurate diagnoses. Computer systems have been developed in order to search and retrieve imaging exams already diagnosed which are similar to a new case with unknown pathology according to the similarity between their characteristics. This property is intrinsic to Content-Based Image Retrieval (CBIR). Diagnosed exams retrieved can be used as a second opinion to guide those specialists in the diagnosis, providing more information. However, CBIR presents some limitations regarding to the process of segmentation and representation of image characteristics through of attributes, as well as determine an appropriate similarity metric. This paper presents a local update weighing algorithm applied to the Weighted Euclidean Distance (WED) in a CBIR architecture in order to verify if the WED with adjusted weights is more accurate than the Euclidean Distance in image retrieval of pulmonary nodules. For this, the 3D Texture Attributes (3D AT) and 3D Margin Sharpness Attributes (3D MSA) were used to represent nodules. Presente process consists of two phases that are performed sequentially and cyclically being an Assessment Phase and Training Phase. At each iteration the weights are adjusted according to the retrieved nodules. At the end of cycles execution, it is obtained a set of attribute weights that optimize the recovery of similar nodes. The results achieved by updating the weights were promising and increase precision by 10% to 6% on mean for recovery of benign and malignant nodules respectively with recall 25%. In the best case, the 3D MSA provided 100% of precision for the two classes with recall 90%. This proves the e ectiveness of the algorithm achieving the goals to this work and con rms the hypothesis that the DEP, with adjusted weights, provides greater precision than DE as a similarity metric in CBIR systems.","('Sistemas de recuperação da informação', 'Processo decisório', 'Algoritmos', 'Information retrieval systems', 'Decision-making process', 'Algorithms')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1716","2016-02-12","https://www.repositorio.ufal.br/bitstream/riufal/1716/1/Atualiza%c3%a7%c3%a3o%20local%20autom%c3%a1tica%20de%20pesos%20para%20recupera%c3%a7%c3%a3o%20de%20n%c3%b3dulos%20similares%20de%20c%c3%a2ncer%20pulmonar.pdf","Automatic update weighing to retrieve similar nodules of lung cancer","('Aydano Pamponet Machado',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/7798","Campus A.C. Simões","Instituto de Computação","Dissertação","Atoms of confusion do really cause confusion? A controlled experiment using eye tracking","('Benedito Fernando Albuquerque de Oliveira',)","('Márcio de Medeiros Ribeiro',)","('Alan Pedro da Silva', 'Leopoldo Motta Teixeira')","Compreensão de código é crucial nas atividades de manutenção de software, entretanto ela pode ser prejudicada por mal-entendidos e padrões código confusos, ou seja, átomos de confusão. Eles são pequenos trechos de código usando construções específicas de uma linguagem de programação, como Operadores Condicionais e Operadores Vírgula. Um estudo anterior mostrou que os átomos de confusão afetam o desempenho dos desenvolvedores, ou seja, o tempo e a precisão, e aumentam os mal-entendidos com relação ao código. No entanto, o conhecimento empírico do impacto de tais átomos na compreensão do código ainda é escasso, especialmente quando se trata de analisar esse impacto na atenção visual dos desenvolvedores. O presente estudo avalia se os desenvolvedores interpretam mal o código na presença de átomos de confusão com um rastreador ocular. Para isso, medimos o tempo, a precisão e analisamos a distribuição da atenção visual. Conduzimos um experimento controlado com 30 alunos e profissionais de software. Pedimos aos sujeitos que especifiquem a saída de três tarefas com átomos e três sem átomos designados aleatoriamente usando um Quadrado Latino. Usamos uma câmera de rastreamento ocular para detectar a atenção visual dos participantes enquanto resolvemos as tarefas. De uma perspectiva agregada, observamos um aumento de 43,02% no tempo e 36,8% nas transições de olhar em trechos de código com átomos. Além disso, observamos um aumento de 163,06% no número de regressões quando o átomo está presente. Para precisão, nenhuma diferença estatisticamente significativa foi observada. Também confirmamos que as regiões que recebem mais atenção foram as regiões com átomos. Nossas descobertas reforçam que os átomos atrapalham o desempenho e a compreensão dos desenvolvedores. Portanto, os desenvolvedores devem evitar escrever código com eles.","Code comprehension is crucial in software maintenance activities, though it can be hindered by misunderstandings and confusion patterns, namely, atoms of confusion. They are small pieces of code using specific programming language constructs, such as Conditional Opera-tors and Comma Operators. A previous study showed that these atoms of confusion impact developers’ performance, i.e., time and accuracy, and increase code misunderstandings. However, empirical knowledge of the impact of such atoms on code comprehension is still scarce, especially when it comes to analyzing that impact on developers’ visual attention. The present study evaluates whether developers misunderstand the code in the presence of atoms of confusion with an eye tracker. For this purpose, we measure time, accuracy, and analyze the distribution of visual attention. We conduct a controlled experiment with 30 students and software practitioners. We ask the subjects to specify the output of three tasks with atoms and three without atoms randomly assigned using a Latin Square design. We use an eye-tracking camera to detect the visual attention of the participants while solving the tasks. From an aggregated perspective, we observed an increase by 43.02% in time and 36.8% in gaze transitions in code snippets with atoms. Also, we observed na increase of 163.06% in the number of regressions when the atom is present. For accuracy, no statistically significant difference was observed. We also confirm that the regions that receive most of the eye attention were the regions with atoms. Our findings reinforce that atoms hinder developers’ performance and comprehension. So, developers should avoid writing code with them.","('Compreensão de código', 'Átomos de confusão (Códigos)', 'Rastreamento visual', 'Rastreamento visual', 'Atoms of confusion', 'Eye-tracking')","Engenharia de Software","eng","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/7798","2020-11-26","https://www.repositorio.ufal.br/bitstream/riufal/7798/1/Atoms%20of%20confusion%20do%20really%20cause%20confusion%3f%20A%20controlled%20experiment%20using%20eye%20tracking.pdf","Átomos de confusão realmente causam confusão? Um experimento controlado usando rastreamento visual",""
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/7338","Campus A.C. Simões","Instituto de Computação","Dissertação","Uma análise empírica de abordagens para a geração de testes abstratos baseados em modelos de redes Petri coloridas","('Ially Cristina Silveira de Almeida',)","('Leandro Dias da Silva',)","('Leonardo Melo de Medeiros', 'Angelo Perkusich', 'Lenardo Chaves e Silva')","O teste baseado em modelos (Model-Based Testing-MBT) utiliza modelos do comportamento do sistema para gerar testes abstratos. Testadores reutilizam especificações formais (e.g., modelos de redes de Petri coloridas (Coloured PetriNets-CPN)) para projetar testes para sistemas críticos seguros. Neste trabalho, por uma revisão terciária,foi identificado um número considerável de revisões de literatura focadas na análise do uso de linguagens de especificação para realizar MBT. Entretanto, ainda existe uma lacuna de pesquisa em relação à análise de abordagens baseadas em CPN para geração de testes abstratos. Para preencher essa lacuna de pesquisa, neste trabalho, uma análise empírica de abordagens para geração de testes abstratos com base em modelos CPN foi também realizada, por meio de uma revisão sistemática da literatura e um estudo de caso sobre sistemas médicos: eletrocardiografia e bomba de infusão de insulina. A partir da análise empírica, são fornecidas informações para os testadores que precisam selecionar a abordagem de geração de testes abstratos mais adequada ao aplicar MBT usando CPN. Com os resultados obtidos, é possível identificar que a escolha depende do tamanho do espaço de estados do modelo CPN.","The model-based testing (MBT) relies on models of the system’s behavior to generate test sequences. Testers usually reuse formal models designed using specification languages such as coloured Petri nets (CPN) and state machines to design tests for safety-critical systems. There is a considerable number of research studies focused on analyzing the usage of specification languages to conduct MBT. However, there is still a research gap regarding the analysis of test sequence generation approaches designed for CPN (e.g., state space-and simulation-based approaches). In this article, we present a comparative analysis of test sequence generation approaches based on CPN models by means of literature reviews and a case study on medical systems: electrocardiography and insulin infusion pump. The results presented in this article provide insights for testers who need to select the most adequate test sequence generation approach when applying the MBT using CPN. The state space analysis and exploration guided by model checking showed to be the most cost-effective approach during our empirical evaluation.","('Tipos abstratos de dados (Computação)', 'Petri, Redes de', 'Tradução de linguagem de programação', 'Model-based testing', 'Abstract tests', 'Formal specifications', 'Petri nets')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/7338","2020-08-28","https://www.repositorio.ufal.br/bitstream/riufal/7338/3/Uma%20an%c3%a1lise%20emp%c3%adrica%20de%20abordagens%20para%20a%20gera%c3%a7%c3%a3o%20de%20testes%20abstratos%20baseados%20em%20modelos%20de%20redes%20Petri%20coloridas.pdf","An empirical analysis of approaches for the generation of abstract tests based on colored Petri nets models","('Álvaro Alvares de Carvalho César Sobrinho',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/12285","Campus A.C. Simões","Instituto de Computação","Dissertação","Assessing the reliability of machine learning cloud services through fault injection","('Filipe Falcão Batista dos Santos',)","('Baldoíno Fonseca dos Santos Neto',)","('Marcelo Costa Oliveira', 'Rohit Gheyi')","Construir sistemas de Aprendizado de Máquina (AM) pode ser complexo, e as tecnologias de AM são conhecidas por terem uma curva de aprendizado acentuada. Essas dificuldades levaram à popularização dos serviços de AM. Embora muitos estudos recentes tenham abordado a vulnerabilidade dos modelos de AM para ataques direcionados, pouca atenção foi direcionada ao efeito de falhas de dados típicas na confiabilidade dos serviços de AM. Tais falhas podem ter origem nas aplicações que dependem de serviços de AM, causadas por falhas de hardware ou conexão, bugs ou comportamento indefinido. Consequentemente, essas falhas podem ser refletidas nos dados produzidos por tais aplicações e enviados aos serviços de AM. Buscando avaliar a confiabilidade desses serviços e com foco no domínio da Visão Computacional, este trabalho apresenta um estudo empírico sobre a injeção de falhas comuns de dados nos dados enviados aos serviços de visão computacional. Os resultados de 11 serviços comerciais indicam que falhas de dados podem afetar significativamente a confiabilidade dos serviços, conforme evidenciado por taxas de classificação incorreta que variam de 14% a até 63%. Por outro lado, as falhas de dados não parecem ter o mesmo impacto na equidade dos serviços, embora algumas configurações de falhas levem a impactos significativos na equidade.","Building Machine Learning (ML) systems can be tricky, and ML technologies are known to have a steep learning curve. Those difficulties led to the popularization of ML services. Although many recent studies have addressed the vulnerability of ML models to target attacks, not enough attention has been directed to the effect of typical data faults on the reliability of ML services. Such faults may originate in the applications that rely on ML services, caused by hardware or connection failures, bugs, or undefined behaviour. Consequently, those faults can be reflected in the data produced by such applications and sent to the ML services. Seeking to evaluate the reliability of these services and focusing on the Computer Vision (CV) domain, this work presents an empirical study on the injection of common data faults into the data sent to CV services. The results from 11 commercial CV services indicate that data faults may significantly affect the reliability of the CV services, as evidenced by misclassification rates ranging from 14% to up to 63%. On the other hand, data faults do not seem to have the same impact on the fairness of CV services, even though some fault configurations lead to significant fairness impacts.","('Computação em nuvem', 'Injeção de falhas (Engenharia de software)', 'Aprendizagem de máquina', 'Cloud computing', 'Fault Injection (Software Engineering)', 'Machine Learning')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/12285","2022-09-23","https://www.repositorio.ufal.br/bitstream/123456789/12285/1/Assessing%20the%20reliability%20of%20machine%20learning%20cloud%20services%20through%20fault%20injection.pdf","Avaliando a confiabilidade de serviços em nuvem de aprendizado de máquina através da injeção de falhas","('Márcio de Medeiros Ribeiro',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/6652","Campus A.C. Simões","Instituto de Computação","Dissertação","Uma arquitetura de aplicação gamificada para o monitoramento e tratamento da doença renal crônica","('Carlos Antonio Fernandes da Silva',)","('Leandro Dias da Silva',)","('Leonardo Melo de Medeiros', 'Lenardo Chaves e Silva')","A Doença Renal Crônica (DRC) é caracterizada pela necessidade de tratamento permanente e contínuo. Considerando dados disponibilizados em 2017 pela Sociedade Brasileira de Nefrologia, o número total estimado de pacientes em tratamento de diálise no Brasil foi de 126.583. Neste contexto, encontram-se no mercado algumas aplicações computacionais com foco no apoio ao tratamento terapêutico da DRC. Porém, até o presente momento, não foi constatada na literatura nenhuma arquitetura de software considerando os diversos estágios que o portador da DRC pode apresentar, buscando a mudança de estilo de vida de pacientes pela realização de incentivos e atividades associadas às recomendações de nefrologistas. Diante deste cenário, a gamificação é uma ferramenta útil para a disponibilização de mecanismos dos jogos para incentivar a adesão de pacientes ao tratamento de DRC, proporcionando desafios e recompensas no mundo real, de maneira similar a um jogo digital. Neste trabalho é apresentada uma arquitetura de aplicação gamificada com foco no monitoramento e tratamento da DRC em diferentes estágios. Componentes arquiteturais foram identificados por meio de uma abordagem extrativa e incorporados como parte da arquitetura definida. Uma avaliação da arquitetura foi realizada com profissionais da área da saúde e um desenvolvedor de software, com uma abordagem baseada em cenários. Um protótipo de aplicação foi implementado utilizando tecnologias Web para apresentar um cenário de uso da arquitetura proposta.","Chronic Kidney Disease (CKD) is characterized by the need for permanent and continuous treatment. Data available in 2017 by the Brazilian Society of Nephrology, the estimated total number of patients undergoing analytical treatment in Brazil, were 126,583. In this context, we address some computational applications focusing on supporting the therapeutic treatment of CKD. However, to date, no software architecture has been found in the literature, considering the various factors that CKD patients may exhibit, seeking a change in the lifestyle of patients by conducting incentives and activities related to the evaluation of nephrologists. Against this background, gamification is a useful tool for providing game mechanisms to encourage patients to adhere to DRC treatment, challenges, and real-world rewards, similar to a digital game. In this paper, a gamified application architecture Project is published focusing on the monitoring and treatment of DRC at different stages. Architectural components were used by an extractive and embedded approach as part of the defined architecture. An architecture assessment was conducted with healthcare professionals and a software developer with a scenario-based approach. An application prototype was implemented using web technologies to present a scenario of using the proposed architecture.","('Arquitetura de software', 'Gamificação', 'Insuficiência renal crônica', 'Software Architecture', 'Gamification', 'Chronic Kidney Disease')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/6652","2019-11-18","https://www.repositorio.ufal.br/bitstream/riufal/6652/1/Uma%20arquitetura%20de%20aplica%c3%a7%c3%a3o%20gamificada%20para%20o%20monitoramento%20e%20tratamento%20da%20doen%c3%a7a%20renal%20cr%c3%b4nica.pdf","A Gamified Application Architecture for Chronic Kidney Disease Monitoring and Treatment","('Álvaro Alvares de Carvalho César Sobrinho',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/15434","Campus A.C. Simões","Instituto de Computação","Dissertação","Uma arquitetura computacional baseada em tecnologia blockchain para habilitar a transparência dos serviços de audiência e pagamentos em plataformas de streaming","('Rendrikson de Oliveira Soares',)","('André Magno Costa de Araújo',)","('Fábio José Coutinho da Silva', 'Paulo Caetano da Silva')","A tecnologia Blockchain possibilita o registro seguro e o compartilhamento de informações sem uma autoridade central, usando criptografia em uma rede distribuída de computadores. Amplamente utilizada na indústria de software, oferece recursos de autenticidade e segurança em transações online. Plataformas de streaming, como YouTube, Spotify, dentre outras, são exemplos de sistemas que lidam com a transmissão de dados de diferentes tipos, como vídeos, músicas e podcasts, e que precisam oferecer recursos de transparência, rastreabilidade e segurança na manipulação desses dados em sistemas de software. No campo de pesquisa da indústria do entretenimento digital, identificou-se no estado da arte uma lacuna de pesquisa no que diz respeito à aplicação da tecnologia Blockchain para habilitar a transparência nos serviços de audiência e pagamentos em plataformas de streaming. Este trabalho propõe a inserção de uma camada Blockchain à infraestrutura operacional existente em plataformas de streaming disponíveis no mercado. Essa camada é encarregada de gerenciar informações individuais dos conteúdos, servindo como meio de verificação e auditoria das transações associadas a cada mídia digital. Além disso, ela permite a transferência de recursos monetários por meio da rede Blockchain. Para atingir o objetivo proposto, elaborou-se uma arquitetura de software contendo os componentes, interfaces, relacionamentos e restrições dos requisitos funcionais que representam esse domínio de aplicação. Nesse processo, adotou-se o modelo de especificação de arquitetura denominado C4 model, escolhido devido à sua característica de documentação compreensível tanto para um público técnico quanto não técnico. Após a especificação da arquitetura, foram implementados os componentes fundamentais para os testes e operação da solução proposta nesta pesquisa. Dessa maneira, desenvolveu-se um middleware encarregado de capturar e gerenciar os mecanismos de audiência de cada conteúdo de maneira individual. Isso ocorre por meio de um serviço de geração automática de contratos inteligentes que é executado quando os conteúdos são disponibilizados e consumidos nas plataformas de streaming. Posteriormente, desenvolveu-se uma aplicação web que simula as operações de uma plataforma de streaming para integrar ao middleware desenvolvido, permitindo a realização de testes, tanto financeiros, quanto funcionais. Os testes foram conduzidos em três redes Blockchain distintas, revelando a viabilidade técnica da solução proposta. Isso foi alcançado por meio da interceptação e do gerenciamento automático das informações de audiência e pagamentos utilizando contratos inteligentes. Além disso, a viabilidade financeira da implementação foi analisada, resultando em um custo médio de US$ 0,000518 em uma das redes Blockchain. Adicionalmente, realizou-se uma pesquisa envolvendo criadores de conteúdo com canais monetizados e desenvolvedores de software especializados em Blockchain. O objetivo da consulta a estes profissionais foi avaliar e obter feedback sobre a nova arquitetura de software e a viabilidade da solução proposta. Dessa forma, os resultados englobaram feedbacks que validaram a implementação da solução computacional, confirmando também a operacionalização da plataforma por parte dos criadores de conteúdo de plataformas de streaming.","Blockchain technology enables secure recording and sharing of information without a central authority, using encryption across a distributed network of computers. Widely used in the software industry, it offers authenticity and security features in online transactions. Streaming platforms, such as YouTube and Spotify, among others, are examples of systems that deal with the transmission of data of different types, such as videos, music, and podcasts, and that need to offer transparency, traceability, and security features when handling this data in software systems. In the digital entertainment industry, a research gap was identified in the state of the art concerning the application of Blockchain technology to enable transparency in audience services and payments on streaming. This work proposes inserting a Blockchain layer into the existing operational infrastructure of streaming platforms available on the market. This layer manages individual content information and verifies and audits transactions associated with each digital media. Furthermore, it allows the transfer of monetary resources through the Blockchain network. A software architecture was created to achieve the proposed objective containing the components, interfaces, relationships, and constraints of the functional requirements representing this application domain. In this process, an architecture specification model, the C4 model, was adopted due to its understandable documentation characteristic for both technical and non-technical audiences. After specifying the architecture, the fundamental components for testing and operating the solution proposed in this research were implemented. In this way, middleware was developed to capture and manage the audience mechanisms for each piece of content individually. This occurs through an automatic smart contract generation service executed when content is available and consumed on streaming platforms. Subsequently, a web application was developed that simulates the operations of a streaming platform to integrate with the middleware developed, allowing tests to be carried out, both financial and functional. The tests were conducted on three different Blockchain networks, revealing the technical feasibility of the proposed solution. This was achieved through the interception and automatic management of audience and payment information using smart contracts. Furthermore, the financial viability of the implementation was analyzed, resulting in an average cost of US$0.000518 on one of the Blockchain networks. Additionally, the research involved content creators with monetized channels and software developers specializing in Blockchain. The objective of consulting these professionals was to evaluate and obtain feedback on the new software architecture and the feasibility of the proposed solution. Thus, the results included feedback that validated the implementation of the computational solution, confirming the platform’s operationalization by content creators on streaming platforms.","('Arquitetura de software', 'Blockchains (Base de dados)', 'Smart contract', 'Tecnologia streaming (Telecomunicação)', 'Software -Desenvolvimento', 'Armazenamento de dados', 'Software Architecture', 'Blockchain', 'Streaming platform', 'Streaming technology (Telecommunication)', 'Software -Development', 'Data Storage')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/15434","2024-02-26","https://www.repositorio.ufal.br/bitstream/123456789/15434/1/Uma%20arquitetura%20computacional%20baseada%20em%20tecnologia%20blockchain%20para%20habilitar%20a%20transpar%c3%aancia%20dos%20servi%c3%a7os%20de%20audi%c3%aancia%20e%20pagamentos%20em%20plataformas%20de%20streaming.pdf","A computational architecture based on blockchain technology to enable transparency of audience services and payments on streaming platforms",""
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/1612","Campus A.C. Simões","Instituto de Computação","Dissertação","Aplicabilidade e desempenho do global média transmission protocol (GMTP)","('Wendell Silva Soares',)","('Leandro Melo de Sales',)","('Heitor Soares Ramos Filho', 'Marco Aurélio Spohn')","Neste trabalho, apresenta-se um estudo do Global Media Transmission Protocol (GMTP), identificando-se limitações e propondo-se melhorias, através da sua implementação no sistema operacional Linux. As aplicações para transmissão de mídias ao vivo na Internet atuais dependem de vários middlewares incompatíveis entre si, projetados para prover serviços de rede específicos dessa classe de aplicações, cada um focado em um determinado requisito da aplicação. Como consequência, não há a possibilidade de que dois ou mais nós cooperem entre si quando estão conectados através de aplicações distintas, mas interessados em obter o mesmo fluxo de dados a partir de um servidor, resultando no aumento do consumo de recursos de rede. Por esse motivo foi proposto o GMTP, um protocolo de distribuição de mídias ao vivo pela Internet que desacopla a forma que o conteúdo é reproduzido pela aplicação da forma que tal conteúdo é transportado através da rede. Isto ocorre com a utilização de algoritmos P2P em nível de socket a fim de construir uma rede de favores entre roteadores. As parcerias entre os roteadores são determinadas pelos nós servidores, conforme medições das capacidades de transmissão dos canais já em uso para disseminar o conteúdo, obtidas por meio de um algoritmo de controle de congestionamento assistido pela rede. Neste trabalho, propõem-se melhorias no GMTP através de sua implementação no núcleo do Linux. Avaliou-se a implementação do GMTP no Linux por meio de experimentos executados em máquinas virtuais. Através dos experimentos, constatou-se que a abordagem do protocolo GMTP, acrescido das modificações propostas neste trabalho, é viável e praticável para implantação em um sistema operacional e para uso em aplicações de rede. Na perspectiva de desempenho, avaliou-se o GMTP-Linux segundo métricas de qualidade de serviço e constatou-se que tal implementação tem um desempenho compatível com os resultados apresentados no trabalho que defïne a especifïcação do GMTP.","This work presents a study about the implementation of the Global Media Transmission Protocol (GMTP) in the Linux operating system. Currently, Internet live streaming applications require various middlewares incompatible among them, as they have different network services requirements. As a consequence, two end-systems using distinct applications can not cooperate to share a given data flow from a streaming server, increasing network resource consumption. For that reason, the GMTP was proposed as a network protocol that decouples the functions used for rendering the media flow to the user from the functions used for disseminating the data through the network. The GMTP protocol uses P2P algorithms at the socket level in order to build a network of favors among cooperative routers. The network of favors is managed by streaming servers, which orchestrate router partnerships based on the capacity of each router transmission channel. The capacity of transmission channels are obtained through network assisted congestion control algorithms. We evaluated the correctness of GMTP-Linux based on experiments in virtual machines. The experiments show that GMTP approach can be used to deploy it in a operating system and can be used in network applications for transmitting live streaming content over the network. In the performance perspective, GMTP-Linux was studied according to some quality of service metrics and it shown that GMTP achieved a performance similar to the results presented in the definition work of GMTP.","('GMTP (Protocolo de rede de computação)', 'Redes P2P', 'Redes multimídia', 'Multimedia networks')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1612","2016-04-01","https://www.repositorio.ufal.br/bitstream/riufal/1612/1/Aplicabilidade%20e%20desempenho%20do%20global%20media%20transmission%20protocol%20GMTP.pdf","Applicability and overall average performance transmission protocol (GMTP)","('André Lages Freitas',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/15830","Campus A.C. Simões","Instituto de Computação","Dissertação","Aprendizagem de máquina para correção do espectro de emissão de nanopartículas usadas para nanotermometria em aplicações biológicas","('Edvonaldo Horácio dos Santos',)","('Bruno Almeida Pimentel',)","('Evandro de Barros Costa', 'Wagner Ferreira da Silva', 'Erving Clayton Ximendes')","No campo da nanotermometria o uso das emissões de nanopartículas (NPs) têm se mostrado uma importante ferramenta em diversas áreas, em particular, para o diagnóstico precoce de câncer e de inflamações localizadas. Isso porque as regiões com essas características apresentam temperaturas distintas de um tecido normal. Embora o uso das emissões de NPs para atuarem como nanotermômetros seja uma área bastante promissora, há diversos obstáculos a serem superados, como as distorções espectrais causadas pelos tecidos. Este trabalho usou Aprendizagem de Máquina (AM) para correção espectral em dados de tecidos usando o coeficiente de absorção µa (massa cinzenta do cérebro, mama pré-menopausa, fígado, pele, pele variando a concentração de água e água), e o coeficiente de espalhamnento (µs) da massa cinzenta do cérebro, mama pré-menopausa, fígado e pele. Os algoritmos que tiveram melhores resultados na correção espectral foram a Árvore de Decisão, Floresta Aleatória e o k Vizinhos Mais Próximos. Eles obtiveram, em média, valores de MAE, MSE, MAPE, R² e σ dentre os melhores possíveis. A Árvore de Decisão foi o que mais se destacou em razão de seu baixo custo de tempo, bem como na sustentação da hipótese, usando o teste de ilcoxon, de que sua capaci dade preditiva para este cenário alcançou resultados exatos e precisos. Cada uma das correções espectrais também foi usada para determinação da temperatura dos tecidos. Os modelos que mais se destacaram foram a Árvore de Decisão, a Floresta Aleatória e o k Vizinhos Mais Próximos. O gráfico de violino de temperatura de cada um desses preditores mostrou exatidão e precisão, determinando corretamente a temperatura com uma casa decimal.","In the field of nanothermometry, the use of nanoparticle (NP) emissions has proven to be an important tool in various areas, particularly for the early diagnosis of cancer and localized inflammations. This is because regions with these characteristics exhibit temperatures different from normal tissue. Although the use of NP emissions as nanothermometers is a very promising area, there are several obstacles to overcome, such as spectral distortions caused by tissues. This work used Machine Learning (ML) for spectral correction in tissue data using the absorption coefficient µa (brain gray matter, premenopausal breast, liver, skin, skin with varying water concentration, and water) and the scattering coefficient (µs) of brain gray matter, premenopausal breast, liver, and skin. The algorithms that achieved the best results in spectral correction were Decision Tree, Random Forest, and k-Nearest Neighbors. On average, they obtained MAE, MSE, MAPE, R², and σ values among the best possible. The Decision Tree stood out the most due to its low time cost and for supporting the hypothesis, using the Wilcoxon test, that its predictive capacity for this scenario achieved accurate and precise results. Each of the spectral corrections was also used to determine the temperature of the tissues. The models that stood out the most were Decision Tree, Random Forest, and k-Nearest Neighbors. The temperature violin plot of each of these predictors showed accuracy and precision, correctly determining the temperature to one decimal place.","('Nanotermometria', 'Nanopartículas', 'Aprendizagem de máquina', 'Biological', 'Machine Learning', 'Nanoparticles', 'Nanothermometry', 'Regression', 'Spectroscopy')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/15830","2024-07-25","https://www.repositorio.ufal.br/bitstream/123456789/15830/1/Aprendizagem%20de%20m%c3%a1quina%20para%20corre%c3%a7%c3%a3o%20do%20espectro%20de%20emiss%c3%a3o%20de%20nanopart%c3%adculas%20usadas%20para%20nanotermometria%20em%20aplica%c3%a7%c3%b5es%20biol%c3%b3gicas.pdf","","('Rafael de Amorim Silva',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/12314","Campus A.C. Simões","Instituto de Computação","Dissertação","Análise de dados da ambiência em Unidades de Terapia Intensiva","('Arthur Monteiro Alves Melo',)","('André Luiz Lins de Aquino',)","('Bruno Costa e Silva Nogueira', 'Rian Gabriel Santos Pinheiro', 'Heitor Soares Ramos Filho')","A Unidade de Terapia Intensiva é um ambiente essencialmente artificial, pois concentra pacientes criticamente enfermos, profissionais altamente especializados e equipamentos de ponta para diagnóstico, tratamento e monitorização contínuos. Sua dinâmica de funcionamento pode resultar em um ambiente pouco acolhedor, afetando a saúde e bem-estar de seus ocupantes. Variáveis ambientais são frequentemente relacionadas a diversos problemas de saúde, tais como: exposição a altos níveis de ruído por longos períodos pode resultar em aumento da pressão arterial e frequência cardíaca, além de distúrbios auditivos; iluminação inadequada pode provocar fadiga visual, cefaleia, distúrbios de sono e irritação; a temperatura do ambiente associada à umidade relativa pode causar secura em pele, olhos e garganta; e temperatura e umidade podem influenciar na proliferação de fungos, ácaros, vírus e bactérias. Excesso de ruído e iluminação inadequada estão relacionados à perturbação do sono em pacientes internados em Unidades de Terapia Intensiva. Isto pode ocasionar disrupção no ciclo circadiano e, por fim, potencializar o surgimento de delirium: um estado grave de confusão mental que dificulta a recuperação do paciente, interfere no prognóstico e pode deixar sequelas cognitivas. Para os profissionais, o ambiente pode ser um amplificador dos níveis de estresse e fadiga, contribuindo com o desenvolvimento de sintomas da síndrome de Burnout. O prejuízo na performance pode levar ao aumento na taxa de erros e culminar em pior qualidade da assistência e prejuízo à segurança do paciente. Além disso, a falta de controle sobre a temperatura e umidade do ar podem prejudicar desde o funcionamento de equipamentos até a qualidade de insumos. Variáveis como ruído, iluminância, temperatura e umidade são raramente monitoradas em conjunto e de modo contínuo. Sem essas informações, dificilmente estabelecimentos hospitalares têm indicadores e protocolos eficazes para auxiliar na criação de um espaço produtivo, acolhedor e humano – cerne do modelo atual de gestão na saúde. Motivado por esse ambiente delicado, este trabalho apresenta um sistema embarcado de monitoramento de variáveis ambientais, a coleta e avaliação de dados captados em Unidades de Terapia Intensiva Adulta (UTI) e neonatal (UTIN). Esse sistema monitora as variáveis ruído, luminosidade, temperatura e umidade durante 24 horas por dia e 7 dias da semana. Coletamos dados de variáveis ambientais (ruído, luminosidade, temperatura e umidade). Os dados foram coletados com a frequência de 30 segundos durante 1 mês em cada local. O monitoramento ocorreu em uma UTIN e em uma UTI Adulta, que na época estava focada no tratamento dos pacientes com Covid-19. Essas informações serviram para as UTIs monitoradas como um retrato de sua ambiência durante, demonstrando o que está indo bem e o que precisa ser melhorado para chegar em um resultado ótimo. Para a avaliação dos dados foram usadas, métricas da estatística descritiva como média, máximo, mínimo e desvio padrão. Além dessas métricas, com o objetivo de identificar padrões e características mais relacionadas aos sistemas dinâmicos que descrevem os dados utilizamos métricas mais sofisticadas como a entropia clássica de Shannon.","The Intensive Care Unit is an essentially artificial environment, as it concentrates critically ill patients, highly specialized professionals and state-of-the-art equipment for continuous diagnosis, treatment and monitoring. Its operating dynamics can result in an unwelcoming environment, affecting the health and well-being of its occupants. Environmental variables are often related to various health problems, such as: exposure to high levels of noise for long periods can result in increased blood pressure and heart rate, in addition to hearing disorders; inadequate lighting can cause eyestrain, headache, sleep disturbances and irritation; ambient temperature associated with relative humidity can cause dryness of the skin, eyes and throat; and temperature and humidity can influence the proliferation of fungi, mites, viruses and bacteria. Excessive noise and inadequate lighting are related to sleep disturbance in patients admitted to Intensive Care Units. This can disrupt the circadian cycle and, ultimately, potentiate the emergence of delirium: a severe state of mental confusion that makes it difficult for the patient to recover, interferes with the prognosis and can leave cognitive sequelae. For professionals, the environment can be an amplifier of stress and fatigue levels, contributing to the development of symptoms of Burnout syndrome. Impaired performance can lead to an increase in the error rate and culminate in poorer quality of care and impaired patient safety. In addition, the lack of control over the temperature and humidity of the air can affect from the operation of equipment to the quality of inputs. Variables such as noise, illuminance, temperature and humidity are rarely monitored together and continuously. Without this information, hospitals hardly have indicators and effective protocols to help create a productive, welcoming and humane space – the core of the current health management model. Motivated by this delicate environment, this work presents an embedded system for monitoring environmental variables, collecting and evaluating data captured in Adult Intensive Care Units (ICU) and Neonatal Intensive Care Units (NICU). This system monitors noise, luminosity, temperature and humidity variables 24 hours a day and 7 days a week. We collected data on environmental variables (noise, light, temperature and humidity). Data were collected at a frequency of 30 seconds for 1 month at each site. Monitoring took place in a NICU and an Adult ICU, which at the time was focused on treating patients with Covid-19. This information served to the monitored ICUs as a portrait of their environment during, demonstrating what is going well and what needs to be improved to reach an optimal result. For data evaluation, descriptive statistics metrics such as mean, maximum, minimum and standard deviation were used. In addition to these metrics, in order to identify patterns and characteristics more related to the dynamic systems that describe the data, we use more sophisticated metrics such as Shannon’s classical entropy.","('Análise de dados – UTI', 'Dados estatísticos – UTI', 'Monitoramento ruídos', 'Data analysis – ICU', 'Statistical data – ICU', 'Noise monitoring')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/12314","2022-03-11","https://www.repositorio.ufal.br/bitstream/123456789/12314/1/An%c3%a1lise%20de%20dados%20da%20ambi%c3%aancia%20em%20Unidades%20de%20Terapia%20Intensiva.pdf","Ambience data analysis in Intensive Care Units",""
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/7800","Campus A.C. Simões","Instituto de Computação","Dissertação","Análise de confiabilidade de monitores multiparamétricos utilizados em unidades de terapia intensiva","('Matheus Soares de Araujo',)","('Leandro Dias da Silva',)","('Thiago Damasceno Cordeiro', 'Gilberto Francisco Martha de Souza', 'Leonardo MontecchI')","Um sistema de monitoramento multiparâmetro geralmente é aplicado para monitorar a condição clínica de pacientes em Unidades de Terapia Intensiva (UTIs). As UTIs são ambientes de monitoramento contínuo utilizados para hospedar pacientes em estados graves de saúde. Esses sistemas de sistemas (Systems of Systems (SoS)), usados em UTIs, são compostos por conjuntos de sistemas constituintes (Constituent Systems (CS)) para medir valores deparâmetros, como, por exemplo, frequência cardíaca, frequência respiratória e temperatura. Devido à natureza crítica e relevância de UTIs, este tipo de SoS deve ser o mais confiável possível. Principalmente, em situações de emergência, como é o caso da pandemia de COVID-19, que resultou na sobrecarga de sistemas de saúde em todo o mundo. Sistemas de monitoramento multiparâmetro em UTIs devem possuir altos níveis de confiabilidade, dado que falhas podem acarretar riscos à integridade física de pacientes. Neste trabalho, foram realizadas análises de confiabilidade e fornecidas recomendações para auxiliar no gerenciamento dos sistemas de monitoramento multiparâmetro utilizados em UTIs, considerando também estratégias de manutenção preventiva. Foram elicitados requisitos com base em entrevistas com um profissional que possui mais de quinze anos de experiência em manutenção em hospitais. Além disso, foram analisados sistemas existentes e desenvolvidas revisões da literatura. Foi definido um modelo de sistemas de monitoramento multiparâmetro para UTIs usando a linguagem de modelagem CHESS-ML. Posteriormente, foram realizadas análises de confiabilidade aplicando a análise baseada em estados do plugin CHESS-SBA, simulando diferentes cenários. Com base nas análises, foi identificado que a fonte de alimentação principal e a bateria são os CS que apresentaram maiores impactos negativos na confiabilidade de todo o sistema em situações de falha. Em situações de emergência, intervalos de tempo reduzidos de manutenção preventiva, quando aplicados durante um curto período, mostraram-se estratégias promissoras para aumentar a confiabilidade de sistema.","A multi-parameter monitoring system is usually applied to keep track of the clinical condition of patients in Intensive Care Units (ICUs). ICUs are continuous monitoring environments used to host patients in serious health conditions. These Systems of Systems (SoS), used in ICUs comprise of a set of Constituent Systems (CS) to measure parameters such as heart rate, respiratory frequency, and temperature. Due to the critical nature and relevance of ICUs, such SoS shall be as reliable as possible. This is specially true in emergency situations, as is the case of the COVID-19 outbreak, which resulted in the burden of health care systems. Multi-parameter monitoring systems in ICUs shall have high levels of reliability, given that failures can provide risks to the safety of patients. We performed relia-bility analysis and provided insights to assist the management of multi-parameter monitoring systems used in ICUs, also considering preventive maintenance. We elicited requirements by interviewing a professional with more than fifteen years of hospital experience in maintenance. In addition, we analyzed existing systems and literature reviews. Therefore, we modeled multi-parameter monitoring systems for ICUs using the CHESS-ML modeling language. Afterward, we conducted reliability analysis by applying the CHESS-SBA plugin state-based analysis, simulating different scenarios. Based on the reliability analysis, we identified that main power supply and the battery are the CS that present major negative impacts in the total reliability the entire system in failure situations. In emergency situations, reduced time ranges of preventive maintenance, when applied during a short period, showed to be promising strategies to increase quality of multiparameter monitoring systems for ICUs.","('Confiabilidade de software', 'Modelagem computacional', 'Monitor multiparamétrico', 'Unidades de terapia intensiva', 'Chess, Metodologia', 'Reliability', 'Modeling', 'Multi-parameter', 'Insensitive care units', 'CHESS Methodology')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/7800","2020-11-30","https://www.repositorio.ufal.br/bitstream/riufal/7800/1/An%c3%a1lise%20de%20confiabilidade%20de%20monitores%20multiparam%c3%a9tricos%20utilizados%20em%20unidades%20de%20terapia%20intensiva.pdf","Reliability analysis of monitor multiparameter used in units of intensive therapy","('Álvaro Alvares de Carvalho César Sobrinho',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/15790","Campus A.C. Simões","Instituto de Computação","Dissertação","Análise da percepção de estudantes on-line sobre painéis de bordo para orientar seus objetivos de aprendizagem","('José Williams Barbosa Nobre',)","('Ranilson Oscar Araújo Paiva',)","('Leonardo Brandão Marques', 'Thales Miranda de Almeida Vieira', 'Rafael Dias Araújo')","Com o avanço do ensino on-line, impulsionado pela necessidade de democratização do acesso à educação e pelas medidas de contenção da COVID-19, o ambiente virtual tornou-se uma parte significativa da vida dos estudantes. Contudo, a evasão escolar persiste, destacando-se a falta de suporte, dúvidas pedagógicas e a sobrecarga de trabalho dos professores como principais desafios. Para enfrentar esse problema, propõe-se a criação de um Dashboard contendo visualizações de dados e recomendações para apoiar a autorregulação da aprendizagem dos estudantes. O Dashboard visa apoiar o estudante em um processo que utiliza dados para apresentar seu estado atual em relação aos objetivos de aprendizagem estabelecidos pelo professor, incluindo interações com recursos de aprendizagem (textos, vídeos etc.) e desempenho na resolução de questões e problemas. Com base no estado atual, e nos objetivos do estudante, serão oferecidas recomendações, orientando-o a atingir seus objetivos de aprendizagem. O Dashboard deve ajudar o estudante a assumir maior responsabilidade sobre sua aprendizagem, resultando em menor carga de trabalho para os professores, resultando, potencialmente, na melhoria da qualidade do curso/disciplina. Para tanto, esta pesquisa coletou percepções de 22 (vinte e dois) estudantes do ensino superior, por meio de um questionário do Google, abordando, além das características sociodemográficas e educacionais dos participantes, as suas opiniões sobre 3 dashboards propostos, no que se refere a: capacidade de os dashboards informarem o estudante sobre seu nível atual no curso, o nível esperado com base nos objetivos escolhidos, e as ações necessárias para atingir esses objetivos. Os resultados mostram que o uso de dashboards tem o potencial de apoiar a autorregulação da aprendizagem dos participantes, promovem a consciência metacognitiva e a autorreflexão dos participantes, capacitando-os a desempenhar um papel ativo em sua aprendizagem. Dessa forma, a proposta contribui para um ambiente educacional mais dinâmico, facilitando a adaptação dos estudantes às demandas do ensino on-line e mitigando a evasão escolar.","With the advancement of online education, driven by the need to democratize access to education and COVID-19 containment measures, the virtual environment has become a significant part of students' lives. However, school dropout persists, with lack of support, pedagogical doubts, and teacher workload overload standing out as main challenges. To tackle this problem, the creation of a data visualization and personalized recommendations system is proposed to support students' self-regulated learning. The system will integrate the student into a process that uses data to present their status in relation to goals set by the teacher, including interactions and performance in learning resources. Based on this status, personalized recommendations will be offered, guiding the student to achieve the proposed goals and maintain engagement. This approach is expected to reduce dropout rates, generating individual and institutional economic benefits. As for expected outcomes, the research aims to improve the quality of online learning and decrease the feeling of abandonment by guiding students in the self-regulation process. The study collected insights from 22 students through a Google questionnaire, addressing sociodemographic characteristics, experiences with digital educational technologies, and opinions about the proposed dashboards. The dashboards inform the student about their current level in the course, the expected level based on chosen goals, and the actions needed to achieve these goals. The analysis revealed that the integration of dashboards and data analysis positively influences students' self-regulation, providing an integrated and adaptable educational environment. The results indicate that dashboards, by offering personalized support, promote metacognitive awareness and student self-reflection, empowering them to play an active role in their learning. Thus, the proposal contributes to a more dynamic educational environment, facilitating students' adaptation to the demands of online education and mitigating school dropout.","('Ambiente de ensino on-line', 'Autorregulação da aprendizagem', 'Dashboards', 'Visualização de dados', 'Online learning environment', 'Self-regulation of learning', 'Dashboard', 'Data visualization')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/15790","2024-03-27","https://www.repositorio.ufal.br/bitstream/123456789/15790/1/An%c3%a1lise%20da%20percep%c3%a7%c3%a3o%20de%20estudantes%20on-line%20sobre%20pain%c3%a9is%20de%20bordo%20para%20orientar%20seus%20objetivos%20de%20aprendizagem.pdf","","('Diego Dermeval de Medeiros da Cunha Matos',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/2922","Campus A.C. Simões","Instituto de Computação","Dissertação","Analisando as relações entre mudanças no código fonte e bugs no software","('Marcus Aurélio Cordeiro Piancó Júnior',)","('Baldoíno Fonseca dos Santos Neto',)","('Patrick Henrique da Silva Brito', 'Regina lúcia de Oliveira Moraes')","Com a evolução dos sistemas de software, alguns serviços, outrora realizados de maneira manual, têm migrado para aplicações computadorizadas, tais como: software complexas para controle financeiro ou sistemas que controlam vôos em aeronaves. Embora estes serviços tenham sido facilitados pelo auxílio da tecnologia,mantê-los disponíveis requer cuidados, seja durante a fase de desenvolvimento da aplicação que provê serviços ou pelos usuários que fazem uso destas aplicações. Um problema ainda predominante em sistemas é a ocorrência de bugs no software. Estes que, comumente, são associados a anomalias em unidades elementares dos sistemas, tais como arquivos, classes, funções ou métodos, podem ser demasiadamente longas ou complexas, o que pode comprometer as tarefas de inspeções e correções de bugs. Para tanto, este trabalho descreve o uso de um mecanismo de coleta e análise acerca das mudanças em códigos fonte que, comumente, podem estar associadas ao surgimento de bugs no software. Tal mecanismo baseia-se em modificações feitas ao longo do tempo em estruturas atômicas, e que são mudadas com frequência dentro do software, tais como: funções, métodos e classes. Utilizando-se da coleta e análise sobre dados de projetos, obteve-se um data set contendo o histórico de mudanças de quatorze projetos open-source, sendo três projetos desenvolvidos nas linguagens de programação C e C++, e onze projetos em JAVA. Foram realizadas também duas análises para avaliar o uso dos dados coletados, dos quais, sendo que a primeira foi uma análise acerca do histórico de mudanças associadas à vulnerabilidades de software (bugs de segurança) para os projetos C,C++, e a segunda acerca das relações entre mudanças e bugs em projetos JAVA. A partir das análises feitas, é possível afirmar que histórico de mudanças pode servir como referência a diversas estratégias que buscam o aprimoramento do processo de desenvolvimento de software, seja na criação de modelos para predição ou detecção de bugs, ou na geração de códigos de maneira automática.","Considering the evolution of software systems, some services that were performed manually have migrated to computer applications such as complex software for financial control or systems that control aircraft flights. Although these services have been facilitated by the help of the technology, keeping them available requires care, either during the development phase of the program that provides these services or by the users who make use of these application. A still prevalent problem in systems is the occurrence of bugs in the software. These are commonly associated with anomalies in elementary units in systems, such as files, classes, functions, or methods. These parts of source code can often be too long or complex, which can compromise the bugs inspections and fixes. In order to do so, this work describes the use of a collection and analysis mechanism, about the changes in source codes that, commonly, can be associated to the appearance of bugs in the software. Such a mechanism is based on modifications made over time in atomic structures, which are often changed within the software, such as functions, methods and classes. As a result of the collection and analysis engine applications, we obtained a data set containing information for the change history of fourteen open-source projects, three of which were developed in C and C ++ programming languages, and eleven projects in JAVA. Two analysis were also carried out to evaluate the use of the collected data, of which the first was an analysis of the history of changes associated with software vulnerabilities (security bugs) for C, C ++ projects, and the second about the relationships between changes and bugs in JAVA projects. From the analysis made, it is possible to affirm that history of changes can serve as reference to several strategies that seek to improve the process of software development, be it in the creation of models for prediction or detection of bugs, or in the generation automatically of source codes.","('Software', 'Vulnerabilidade de software', 'Bugs de software', 'Código fonte -Mudanças', 'Software Vulnerability', 'Software Bug', 'Source Code Changes')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/2922","2017-10-19","https://www.repositorio.ufal.br/bitstream/riufal/2922/1/Analisando%20as%20rela%c3%a7%c3%b5es%20entre%20mudan%c3%a7as%20no%20c%c3%b3digo%20fonte%20e%20bugs%20no%20software.pdf","Analyzing the relationship between source code changes and software bugs","('Nuno Manoel dos Santos Antunes',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/1844","Campus A.C. Simões","Instituto de Computação","Dissertação","Alinhamento de dados conectados a partir de conceitos primários e secundários","('Armando Barbosa Sobrinho',)","('Ig Ibert Bittencourt Santana Pinto',)","('Rafael de Amorim Silva', 'Bernardo Pereira Nunes')","Nos últimos anos, dados conectados têm sido a forma mais proeminente para abertura de dados em diversos países. Tal forma utiliza padrões para descrição destes dados, promovendo a sua interoperabilidade, seu reuso e a sua integração. No entanto, integrar a informação entre diferentes conjuntos de dados surge como um empecilho para o seu desenvolvimento, principalmente se tal integração consistir na correspondência de uma determinada entidade do mundo real em conjuntos de dados distintos. Neste contexto, este trabalho propõe uma abordagem para auxiliar na identificação de instâncias correspondentes. Para isso, baseia-se na modelagem conceitual dos dados, permitindo que os relacionamentos entre os conceitos sejam utilizados para descobrir novas correspondências entre os dados. Para avaliar a eficácia da proposta foram realizados um estudo de caso e um experimento. No estudo de caso, a proposta foi utilizada para encontrar as correspondências de pesquisadores e publicações em quatro datasets (Lattes, RBIE, SBIE e WIE) e, então, responder um conjunto com mais de trinta perguntas realizadas pela comunidade de Informática na Educação. No experimento, a proposta foi utilizada em dois cenários (C1 e C2) e comparada a outras abordagens através das métricas de precisão, revocação e medida-f. De acordo com os resultados apresentados, a proposta posicionou-se em primeiro e segundo lugar nos cenários C1 e C2 respectivamente, mesmo não utilizando computações específicas para os datasets, permitindo sua utilização em outros contextos com o mínimo de esforço.","Recently linked data has been the most prominent way to open data in several countries. This way it uses standards to describe this data, promoting its interoperability, its reuse and its integration. However, integrating information between different datasets is a hindrance to their development, especially if such integration consists of matching a particular real-world entity in distinct datasets. In this context, this work proposes an approach to assist in the identification of corresponding instances. For this, it is based on the conceptual modeling of the data, allowing the relationships between the concepts to be used to discover new correspondences between the data. To evaluate the effectiveness of the proposal, a case study and an experiment were carried out. In the case study, the proposal was used to find the correspondence of researchers and publications in four datasets (Lattes, RBIE, SBIE and WIE). These correspondences was used to answer a set with more than thirty questions provided by the informatics community in Education. In the experiment, the proposal was used in two scenarios (C1 and C2) and compared to other approaches through precision, recall and f-measure metrics. According to the presented results, the proposal ranked first and second place in scenarios C1 and C2 respectively, even though it did not use specific computations for the datasets, allowing its use in other contexts with the least effort.","('Correspondência de instância', 'Alinhamento de dados', 'Datasets', 'Dados conectados', 'Web de dados', 'Instance matching', 'Data correspondence', 'Linked data', 'Web of data')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1844","2017-02-01","https://www.repositorio.ufal.br/bitstream/riufal/1844/1/Alinhamento%20de%20dados%20conectados%20a%20partir%20de%20conceitos%20prim%c3%a1rios%20e%20secund%c3%a1rios.pdf","Instance matching from primary and secondary concepts","('Sean Wolfgand Matsui Siqueira',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/10760","Campus A.C. Simões","Instituto de Computação","Dissertação","Algoritmo BRKGA multipopulacional (MultiPop-BRKGA-PCA) para o problema de clusterização automática","('Alexandre Sérgio Dantas de Lima',)","('Rian Gabriel Santos Pinheiro',)","('André Luiz Lins de Aquino', 'Jean Carlos Teixeira de Araújo')","O processo de agrupamento de dados é conhecido como clusterização. Na literatura, o processo de clusterização, ou agrupamento, tem duas variações: (i) se o número de clusters for predefinido, esse processo é conhecido como Problema de Clusterização (CP — Clustering Problem) ou Problema de k-Clusterização, e (ii) quando o número de clusters não é definido, o processo torna-se conhecido como Problema de Clusterização Automática (ACP —Automatic Clustering Problem). A importância de ter dados bem agrupados é crucial para a tomada decisões mais assertivas. A técnica de agrupamento de dados possui aplicabilidade nas mais diversas áreas do conhecimento, como: engenharia, administração, economia, biologia, física, entre outras. Os algoritmos genéticos são baseados em processos de evolução darwinistas, selecionando as melhores soluções dentro de uma população. O BRKGA (Biased Random Key Genetic Algorithm), é apresentado como uma variação dos algoritmos genéticos, em que as soluções de um problema são representadas como vetores de chaves reais, geradas aleatoriamente, no intervalo contínuo de [0,1). O fitness de uma solução viável é determinado pelo decodificador, que mapeia este vetor em um valor real. Este trabalho propõe um BRKGA multipopulacional para identificar o número ideal de clusters, de acordo com o índice de silhueta — uma medida de eficácia de agrupamento bastante utilizada na literatura. No algoritmo proposto, o espaço de soluções é particionado de forma que cada subpopulação o algoritmo represente soluções com um número k de cluster. Assim, a cada subpopulação, um BRKGA independente é aplicado. Experimentos computacionais foram realizados em cinquenta e cinco instâncias da literatura. As instâncias utilizadas neste trabalho possuem dimensões que variam de 30 a 2.000 objetos e 2 a 13 atributos, com diferentes graus de dificuldade e características, por exemplo, coesão de grupo, separação, formatos e densidades. O algoritmo proposto é comparado com métodos existentes na literatura, apresentando resultados superiores, levando ao entendimento de que o algoritmo é promissor.","he process of grouping data is known as clustering. In the literature, the clustering process, or grouping, has two variations: (i) if the number of clusters is predefined, this process is known as the Clustering Problem (CP) or k -Clustering Problem , and (ii) when the number of clusters is not defined, the process becomes known as Automatic Clustering Problem (ACP). The importance of having well-grouped data is crucial to making more assertive decisions. The data grouping technique has applicability in the most diverse areas of knowledge, such as: engineering, administration, economics, biology, physics, among others. Genetic algorithms are based on Darwinian evolution processes, selecting the best solutions within a population. The BRKGA (Bised Random Key Genetic Algorithm), is presented as a variation of the genetic algorithms, in which the solutions of a problem are represented as vectors of real keys, generated randomly, in the continuous interval of [0.1). The suitability of a viable solution is determined by the decoder that maps this vector to a real value. This work proposes a multi-population BRKGA to identify the ideal number of clusters, according to the silhouette index — a measure of clustering efficiency widely used in the literature. In the proposed algorithm, the solution space is partitioned so that each subpopulation the algorithm represents solutions with a k number of cluster. Thus, for each subpopulation, an independent BRKGA is applied. Computational experiments were carried out in fifty-five instances of the literature.The instances used in this work have dimensions ranging from 30 to 2,000 objects and 2 to 13 attributes, with different degrees of difficulty and characteristics, for example, group cohesion, separation, shapes and densities.The proposed algorithm is compared with existing methods in the literature, presenting superior results, leading to the understanding that the algorithm is promising.","('Clusterização', 'Biased Random Key Genetic Algorithm', 'Algoritmos genéticos', 'Genetic algorithm', 'Multi-population', 'BRKGA', 'Clustering')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/10760","2021-04-30","https://www.repositorio.ufal.br/bitstream/123456789/10760/1/Algoritmo%20BRKGA%20multipopulacional%20%28MultiPop-BRKGA-PCA%29%20para%20o%20problema%20de%20clusteriza%c3%a7%c3%a3o%20autom%c3%a1tica.pdf","Multipopulation BRKGA Algorithm (MultiPop-BRKGA-PCA) for Automatic Clustering Problem","('Bruno Costa e Silva Nogueira',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/16993","Campus A.C. Simões","Instituto de Computação","Dissertação","AI-driven actigraphy data reconstruction","('Rodrigo Santos da Silva',)","('Thiago Damasceno Cordeiro',)","('Bruno Almeida Pimentel', 'Glauber Rodrigues Leite', 'Allan de Medeiros Martins')","A actigrafia é uma técnica não invasiva que utiliza um dispositivo de pulso para monitorar padrões de sono e ritmos circadianos, fornecendo dados valiosos para o diagnóstico de distúrbios do sono, como insônia e hipersonia. No entanto, lacunas nos dados de actigrafia frequentemente ocorrem quando o dispositivo está ""fora do pulso"". Este estudo explora o uso de técnicas avançadas de Machine Learning e Deep Learning para imputar dados ausentes, visando melhorar a precisão e a confiabilidade das análises. O principal objetivo é desenvolver pipelines robustos de imputação de dados, utilizando uma variedade de algoritmos, incluindo modelos de regressão (Random Forests, XGBoost e Support Vector Regression), com estratégias de otimização de hiperparâmetros, como Grid Search e Randomized Search, e autoencoders otimizados pelo Keras Tuner. As principais estratégias de filtragem incluem o Dynamic Time Warping, aproveitando a variável M10, que representa as 10 horas de maior atividade diária, além de considerar os dados em torno dos períodos ""fora do pulso"". A metodologia pré-processa conjuntos de dados de actigrafia do dispositivo ActTrust (Condor), incorporando variáveis como temperatura, exposição à luz e métricas de atividade do paciente. Resultados preliminares demonstram que os modelos de autoencoder superam os métodos tradicionais na imputação de dados ausentes, reduzindo significativamente o erro médio quadrático. Modelos de ensemble, ajustados para padrões específicos de atividade, melhoram ainda mais a precisão preditiva, conforme validado por testes estatísticos, como o teste de Wilcoxon. Esses achados destacam o potencial desses modelos para aprimorar a prática clínica, permitindo avaliações personalizadas do sono e apoiando intervenções direcionadas.","Actigraphy is a non-invasive technique that uses a wrist-worn device to track sleep patterns and circadian rhythms, providing valuable data for diagnosing sleep disorders such as insomnia and hypersomnia. However, gaps in actigraphy data often occur when the device is ”off-wrist.” This study explores the use of advanced Machine Learning and Deep Learning techniques to impute missing data, aiming to improve the accuracy and reliability of the analyses. The main objective is to develop robust data imputation pipelines utilizing a range of algorithms, including regression models (Random Forests, XGBoost, and Support Vector Regression), with hyperparameter optimization strategies such as Grid Search and Randomized Search and autoencoders optimized by Keras Tuner. Along with these regression strategies, we have vital data filtering strategies, including Dynamic Time Warping, leveraging the M10 variable, which represents the 10 hours of highest daily activity, and considering data surrounding off-wrist periods. In this study, the methodology preprocesses actigraphy datasets from the ActTrust device, incorporating variables such as temperature, light exposure, and activity metrics. Preliminary results demonstrate that autoencoder models outperform traditional methods in imputing missing data, significantly reducing Mean Squared Error. Combined models tailored to specific activity patterns further enhance predictive accuracy, as validated by statistical tests such as the Wilcoxon test. These findings highlight the potential of these models to improve clinical practice by enabling personalized sleep assessments and supporting targeted interventions.","('Actigrafia', 'Aprendizado de maquina', 'Aprendizado profundo', 'Variável M10', 'Modo Integral Proporcional', 'Actigraphy', 'Machine Learning', 'Deep Learning', 'Variable M10', 'Proportional Integral Mode (PIM)')","Ciência da Computação","eng","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/16993","2024-12-12","https://www.repositorio.ufal.br/bitstream/123456789/16993/1/AI-driven%20actigraphy%20data%20reconstruction.pdf","Reconstrução de dados de actigrafia orientados por IA","('Tiago Gomes de Andrade',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/1779","Campus A.C. Simões","Instituto de Computação","Dissertação","Uma abordagem semiautomática dirigida a métricas para avaliação da qualidade de datasets conectados","('Danila Feitosa de Carvalho Oliveira',)","('Ig Ibert Bittencourt Santana Pinto',)","('Rafael de Amorim Silva', 'Bernadette Farias Lóscio')","Dados Conectados tem contribuído com uma grande quantidade de informações na Web, representadas em formatos estruturados e conectados com outras informações. O principal objetivo das iniciativas de dados conectados é criar conhecimento pela conexão de dados dispersos e relacionados. A atual Linked Open Data Cloud (LOD Cloud) consiste em mais de 50 bilhões de fatos representados como triplas RDF. Essas informações pertencem a um grande número de datasets que cobrem diversos domínios, como ciência, dados geográficos, governamentais, etc. Entretanto, estudos recentes mostram que a maioria desses datasets sofrem de vários problemas de qualidade de dados, tais como, representacionais, inconsistências e questões de interoperabilidade. Esses problemas dificultam a interpretação dos dados e afetam a qualidade dos resultados. Desta forma, um desafio da área é analisar a qualidade de datasets conectados e deixá-la explícita. Com isso, este trabalho tem como objetivo criar uma solução computacional baseada em dimensões de qualidade e boas práticas de publicação que execute a verificação e validação semiautomática da qualidade de datasets conectados. Para isto, foram analisadas dimensões de qualidade e as mesmas foram correlacionadas com as melhores práticas de qualidade de dados contidas nos documentos “Data on the Web Best Practices” e “Best Practices for Publishing Linked Data”. Para validação da proposta, foi executado um experimento com o objetivo de avaliar a solução desenvolvida, visando identificar se a mesma torna eficiente a avaliação da qualidade de datasets conectados, através da comparação da solução computacional semiautomática, proposta nesta dissertação, com a abordagem manual de avaliação da qualidade de dataset conectados. Como resultado, espera-se que a solução semiautomática seja um meio eficiente de executar a avaliação da qualidade de um dataset conectado, diminuindo o tempo de avaliação, bem como a carga de trabalho do avaliador. A contribuição dessa dissertação é disponibilizar um meio de avaliação voltado às melhores práticas do W3C, com base em dimensões de qualidade existentes na literatura.","Linked Data has contributed to a lot of information on the Web represented in structured formats and linked to other information. The main purpose of linked data initiatives is to create knowledge by linking scattered and relational data. The current Linked Open Data Cloud (LOD Cloud) consists of more than 50 billion facts represented as RDF triples. This information belongs to a large number of covering various domains, such as science, geography, government, etc. However, recent studies show that most of these datasets suffer from various data quality problems, such as representational problems, inconsistency problems, and interoperability issues. These problems make data interpretation difficult and affect the quality of the results. In this way, a challenge in the area is to analyze the quality of linked datasets and make it explicit. This work aims to create a computational solution based on quality dimensions and best practices for publishing that performs the semiautomatic verification and validation of the quality of linked datasets. For this, quality dimensions were analyzed and correlated to the best practices of data quality contained in the documents, “Data on the Web Best Practices” and “Best Practices for Publishing Linked Data”. To validate the proposal, an experiment was carried out to evaluate the developed solution and identify if it makes the evaluation of the quality of linked datasets more efficient by comparing the semiautomatic computational solution proposed in this dissertation to the manual approach of quality evaluation of linked datasets. As a result, a semiautomatic solution is expected to be an efficient way of performing the quality evaluation of a linked dataset and reduce the evaluation time as well as the workload of the user. The contribution of this dissertation is to provide an evaluation alternative focused on the best practices of the W3C, based on the quality dimensions existing in the literature.","('Dados conectados', 'Qualidade de dado -Datasets', 'Métrica', 'Publishing linked data', 'Quality dimensions', 'Best practices', 'Data quality')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1779","2017-02-07","https://www.repositorio.ufal.br/bitstream/riufal/1779/1/Uma%20abordagem%20semiautom%c3%a1tica%20dirigida%20a%20m%c3%a9tricas%20para%20avalia%c3%a7%c3%a3o%20da%20qualidade%20de%20datasets%20conectados.pdf","A semiautomatic approach to metrics for quality assessment of connected datasets",""
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/3256","Campus A.C. Simões","Instituto de Computação","Dissertação","Uma abordagem para descoberta, composição e Invocação Automática de Serviços semânticos aplicada ao Domínio de Mineração de dados","('Michel de Sousa Miranda',)","('Evandro de Barros Costa',)","('Patrick Henrique da Silva Brito', 'Rafael Ferreira Leite de Mello')","O desenvolvimento de aplicações baseadas em Serviços Web Semânticos têm evoluído e ganho uma atenção especial, tanto da academia, quanto da indústria. Essencialmente, eles têm sido utilizados para possibilitar e automatizar tarefas que envolvem aspectos, tais como: descoberta, composição e invocação automática de serviços. Para isso, a comunidade tem se dedicado na criação de modelos semânticos e ferramentas que sejam capazes de explorar os conceitos semânticos dos serviços. Nesse contexto, o trabalho em pauta propõe um framework baseado em Serviços Web Semânticos aplicados ao domínio de Mineração de Dados Educacionais baseado em um novo modelo semântico que apoie o processo de descoberta, composição e invocação de forma automática e dinâmica. Para tal, os serviços semânticos encapsulam técnica se algoritmos de mineração, pré-processamento e pós-processamento de dados. A ﬁm de avaliar o framework proposto, foi realizado um experimento baseado em cenários que simulam a execução da solução proposta em um ambiente real com a intenção de avaliar os atributos de qualidade desempenho e conﬁabilidade","The development of applications based on Semantic Web Services has evolved and gained special attention from both academia and industry. Essentially, they have been used to enable and automate tasks that involve aspects such as: discovery, composition, and automatic invocation of services. For this, the community has been dedicated in the creation of semantic models and tools that are able to explore the semantic concepts of the services. In this context, the work in question proposes a Framework based on Semantic Web Services applied to the domain of Educational Data Mining based on a new semantic model that supports the process of discovery, composition and invocation in an automatic and dynamic way. To this end, semantic services encapsulate techniques and algorithms for mining, pre-processing and post-processing of data. In order to evaluate the proposed framework, we performed an experiment based on scenarios that simulate the execution of the proposed solution in a real environment with the intention of evaluating the attributes of quality performance and reliability.","('Framework semântico', 'Mineração de dados (Computação)', 'Web semântica', 'Serviços web semânticos', 'Semantic Framework', 'Data Mining (Computing)', 'Semantic Web', 'Semantic Web Services')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/3256","2018-04-04","https://www.repositorio.ufal.br/bitstream/riufal/3256/1/Uma%20abordagem%20para%20descoberta%2c%20composi%c3%a7%c3%a3o%20e%20invoca%c3%a7%c3%a3o%20autom%c3%a1tica%20de%20servi%c3%a7os%20sem%c3%a2nticos%20aplicada%20ao%20dom%c3%adnio%20de%20minera%c3%a7%c3%a3o%20de%20dados.pdf","",""
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/1719","Campus A.C. Simões","Instituto de Computação","Dissertação","Uma abordagem não intrusiva e automática para configuração do Hadoop","('Nathália de Meneses Alves',)","('André Lages Freitas',)","('Heitor Soares Ramos Filho', 'Francisco Vilar Brasileiro')","Nas últimas décadas, a quantidade de dados gerados no mundo tem aumentado de maneira significativa. A Computação em Nuvem juntamente com o modelo de programação Map-Reduce, através do arcabouço Hadoop, têm sido utilizados para o processamento desses dados. Contudo, os sistemas contemporâneos ainda são complexos e dinâmicos, tornando-se difíceis de se configurar. A configuração automática de software é uma solução para esse problema, ajudando os programadores e administradores gerir a complexidade desses sistemas. Por exemplo, há soluções na literatura que utilizam aprendizado de máquina para a configuração automática do Hadoop com o intuito de melhorar o desempenho das suas aplicações. Apesar desses avanços, as soluções atuais para configurar automaticamente o Hadoop utilizam soluções muito específicas, aplicando algoritmos de aprendizagem de máquinas isoladamente. Assim, esses algoritmos não são comparados entre si para entender qual abordagem é mais adequada para a configuração automática do Hadoop. Além disso, essas soluções são intrusivas, ou seja, expõem detalhes operacionais para programadores e/ou administradores de sistemas. Esse trabalho tem por objetivo propor uma abordagem transparente, modular e híbrida para melhorar o desempenho de aplicações Hadoop. A abordagem propõe uma arquitetura e implementação de software transparente que configura automaticamente o Hadoop. Além disso, a abordagem propõe uma solução híbrida que combina Algoritmos Genéticos e várias técnicas de aprendizado de máquina (machine learning) implementadas em módulos separados. Um protótipo de pesquisa foi implementado a avaliado mostrando que a abordagem proposta consegue diminuir significativamente o tempo de execução das aplicações Hadoop WordCount e Terasort. Além disso, a abordagem consegue convergir rapidamente para a configuração mais adequada de cada aplicação, alcançando baixos níveis de custos adicionais (overhead).","The amount of digital data produce in the last years has increased significantly. MapRe-duce framework such as Hadoop have been widely used for processing big data on top of cloud resources. In spite of these advances, contemporary systems are complex and dy-namic which makes them hard to configure in order to improve application performance. Software auto-tuning is a solution to this problem as it helps developers and system ad-ministrators to handle hundreds of system parameters. For example, current work in the literature use machine learning algorithms for Hadoop automatic configuration to improve performance. However, these solutions use single machine learning algorithms, thus making unfeasible to compare these solutions with each other to understand which approach is best suited given an application and its input. In addition, current work is intrusive or expose operational details for developers and/or system administrators. This work proposes a transparent, modular and hybrid approach to improve the performance of Hadoop applications. The approach proposes an architecture and implementation of transparent software that automatically configures the Hadoop. Furthermore, this ap-proach proposes a hybrid solution that combines genetic algorithms with various machine learning techniques as separate modules. A research prototype was implemented and eval-uated proving that the proposed approach can significantly reduce the execution time of applications Hadoop WordCount and Terasort autonomously. Furthermore, the approach converges quickly to the most suitable configuration application with low overhead.","('Dados -Estruturas (Ciência da computação)', 'Computação em nuvem', 'Algoritmos genéticos', 'MapReduce', 'Hadoop', 'Data-structures (computer science)', 'Cloud computing', 'Genetic algorithms')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1719","2015-09-29","https://www.repositorio.ufal.br/bitstream/riufal/1719/1/Uma%20abordagem%20n%c3%a3o%20intrusiva%20e%20autom%c3%a1tica%20para%20configura%c3%a7%c3%a3o%20do%20Hadoop.pdf","An approach non intrusive and automation for Hadoop configuration","('Aydano Pamponet Machado',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/5655","Campus A.C. Simões","Instituto de Computação","Dissertação","Uma abordagem estocástica para recuperação de imagens de roupa baseada em conceito utilizando o SVM e o feedback de relevância do usuário","('Artur Maia Pereira',)","('Evandro de Barros Costa',)","('Marcelo Costa Oliveira', 'Patrick Henrique da Silva Brito', 'Patricia Cabral de Azevedo Restelli Tedesco')","Sistemas de recuperação de imagem estão se tornando cada vez mais comum em aplicações online do ramo da moda, permitindo que os consumidores busquem por itens de roupa. Entretanto, explorar um grande conjunto de imagem através de métodos simples de recuperação é geralmente ineficiente e cansativo para usuários que estão buscando por novidades. Quando o feedback do usuário é considerado, algoritmos de aprendizagem de máquina podem tirar vantagem das preferências do usuário e aprimorar a experiência de compra. Apesar disso, a maioria das abordagens que consideram feedback focam em recuperar apenas imagens relevantes para o usuário, sem se preocupar com a curva de aprendizado da máquina, resultando em uma falta de diversidade. Em particular, quando o usuário acessa o sistema pela primeira vez, não há nenhuma informação sobre ele, levando a recomendações insatisfatórias (problema da partida fria). Neste trabalho, nós propomos uma abordagem de aprendizado de máquina baseada na técnica de Relevance Feedback (RF) para recuperar imagens de roupa utilizando a seguinte estratégia: Recuperar imagens relevantes para o usuário; recuperar imagens que não vão de acordo com as preferências do usuário, para evitar a convergência para um mínimo local; e recuperar imagens da região de incerteza para melhorar a curva de aprendizado, todas essas três formas de maneira estocástica. Para contornar a problema da partida fria, nós apresentamos um novo método de seleção que visa melhorar a diversidade das imagens recuperadas combinando um método de projeção multidimensional com uma estrutura de dados espacial adaptável. Nossa abordagem foi validada através de experimentos qualitativos e quantitativos com usuários utilizando uma base de dados anotada de imagens de roupas femininas com o objetivo de avaliar a efetividade e eficiência da recuperação de imagens relevantes. Resultados mostraram que a abordagem proposta pode melhorar rapidamente a recuperação de imagens apropriadas com apenas algumas iterações do usuário, enquanto oferece uma maior diversidade em relação a outras abordagens.","Image retrieval systems have become a common approach in online fashion applications, allowing consumers to search for clothing items. However, the task of exploring large data sets of images through naive retrieval methods is generally inefficient and tedious for users. When relevance feedback (RF) from the user is considered, machine learning methods may take advantage of user preferences to enhance the experience. Nevertheless, most RF approaches focus on retrieving only user relevant images, disregarding the learning curve of the machine and resulting in a lack of diversity. In particular, when a new user begins using the system, there is a lack of information about him, resulting in unsatisfactory recommendations (the cold start problem). We propose a machine learning approach based on RF to retrieve clothing images using a threefold strategy: retrieve user relevant images; retrieve images that do not comply with user learned preferences, to avoid convergence to local minimal; and retrieve images from uncertainty regions, to improve the learning curve, all in a stochastic manner. To mitigate the cold start problem, we present a novel sampling method to improve the diversity of retrieved images that employs a combination of a multidimensional projection method with an adaptive spatial data structure. Our approach is validated through quantitative and qualitative user experiments using an annotated clothing images data set to evaluate the effectiveness and efficiency of user-relevant image retrieval. Results revealed that our approach can rapidly improve the retrieval of appropriate images in a few user iterations while providing higher diversity than straightforward approaches.","('Processamento de imagens', 'Processo estocástico', 'Máquina de Vetores de Suporte', 'Image processing', 'Stochastic process', 'Support Vector Machine')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/5655","2019-03-13","https://www.repositorio.ufal.br/bitstream/riufal/5655/1/Uma%20abordagem%20estoc%c3%a1stica%20para%20recupera%c3%a7%c3%a3o%20de%20imagens%20de%20roupa%20baseada%20em%20conceito%20utilizando%20o%20SVM%20e%20o%20feedback%20de%20relev%c3%a2ncia%20do%20usu%c3%a1rio.pdf","","('Thales Miranda de Almeida Vieira',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/11920","Campus A.C. Simões","Instituto de Computação","Dissertação","Uma abordagem de ciência de dados em uma análise socioeconômica de preços para viagens de transporte por aplicativo Uber","('Giancarlo Lima Torres',)","('Bruno Almeida Pimentel',)","('Evandro de Barros Costa', 'Rafael de Amorim Silva', 'Diego Carvalho do Nascimento')","Estudos que utilizam dados da empresa de transporte por aplicativo Uber evidenciaram que há fatores que contribuem para o aumento de preços dos seus serviços de viagens. Nesse contexto, esta pesquisa teve como objetivo analisar rotas de viagens de usuários de baixa renda e contribuir na redução desses preços. Para isso, buscou-se responder: Se um centro financeiro estivesse mais próximo de bairros economicamente mais pobres, haveria mudança nos preços médios dessas viagens? Essa mudança poderia melhorar financeiramente a vida das pessoas de baixa renda? A proposta de nossa pesquisa para responder a esses questionamentos foi a de averiguar em regiões territoriais essas concentrações financeiras por meio de um processo de Ciência de Dados, analisando preços e dados socioeconômicos da cidade sul-americana de Fortaleza, localizada no país Brasil e da cidade norte americana de Boston, localizada no país Estados Unidos da América. Assim, seria possível evidenciar se os usuários da Uber que moram em bairros mais pobres financeiramente e utilizam esse serviço de viagens acabam pagando mais caro do que os usuários dos bairros mais ricos, quando o destino é o centro financeiro. As análises e os resultados obtidos para Boston serviram de validação por analogia para os resultados obtidos para Fortaleza. A base de dados analisada para Boston se refere a um conjunto de dados real, disponível na comunidade online Kaggle. A base de dados analisada para Fortaleza foi construída durante nosso trabalho e também está disponível na comunidade online Kaggle, podendo servir de ferramenta para análises futuras em outras pesquisas. Para construção dessa base, foram utilizadas informações de Fortaleza sobre tráfego, horários de pico, dias da semana, quantidade de viagens e o simulador de preços da Uber. Para alcançar o objetivo da pesquisa, a Metodologia empregada consistiu nas etapas de Obtenção e Construção de preços, Obtenção de Dados Socioeconômicos, Análise Exploratória de Dados, Limpeza e Tratamento de Dados, Construção de Modelos de Aprendizado de Máquina e Análise entre os Dados Socioeconômicos e os preços de viagens para as cidades em estudo. Como resultados obtidos, observou-se que, em um cenário mais desconcentrado de centro financeiro, os usuários de baixa renda da Uber em Fortaleza poderiam ter os preços das viagens reduzidos em cerca de 43,07%. Essa redução representaria uma economia mensal de cerca de 18,82% de suas Rendas Médias Pessoais. Para usuários que vivem em bairros ricos (alta renda), essa descentralização aumentaria os custos de viagens para pouco mais de 100%. No entanto, esse aumento representaria 6,71% de suas Rendas Médias Pessoais. Futuras pesquisas podem expandir os resultados aqui obtidos, otimizando a base de dados criada e modificando o processo de Ciência de Dados utilizado.","Studies that use data from the transport company Uber showed that there are factors that contribute to the increase in prices of its travel services. In this context, this research aims to analyze travel routes for low-income users and contribute to reducing these prices. For this, we sought to answer: If a financial center were closer to economically poorer neighborhoods, would there be a change in the average prices of these trips? Could this change financially improve the lives of low-income people? The purpose of our research to answer these questions was to investigate this factor of financial concentration in territorial regions through a Data Science process, analyzing prices and socioeconomic data in the South American city of Fortaleza, located in the country Brazil and from the North American city of Boston, located in the United States of America. Thus, it would be possible to show whether Uber users who live in financially poorer neighborhoods and use this travel service end up paying more than users in richer neighborhoods, when the destination is the financial center. The analyzes and results obtained for Boston served as a validation by analogy for the results obtained for Fortaleza. The analyzed database for Boston refers to a real dataset, available in the Kaggle online community. The database analyzed for Fortaleza was built during our work and is also available on the Kaggle online community, which can serve as a tool for future analysis in other research. To build this base, information from Fortaleza about traffic, peak times, days of the week, number of trips and the Uber price simulator were used. To achieve the objective of the research, the methodology used consisted of the steps of Obtaining and Construction of prices, Obtaining Socioeconomic Data, Exploratory Data Analysis, Cleaning and Processing of Data, Construction of Machine Learning Models and Analysis between the Socioeconomic and travel prices to the cities under study. As results obtained, it was observed that, in a more decentralized scenario of a financial center, low-income users of Uber in Fortaleza could have their trip prices reduced by about 43.07%. This reduction would represent a monthly savings of around 18.82% of their Average Personal Income. For users living in wealthy (high-income) neighborhoods, this decentralization would increase travel costs to just over 100%. However, this increase would represent 6.71% of their Average Personal Income. Future research can expand the results obtained here, optimizing the created database and modifying the Data Science process used.","('UBER (Aplicativo de transporte)', 'Ciência de dados', 'Dados socioeconômicos', 'UBER (transport app)', 'Data science', 'Socioeconomic data', 'Transport by Application')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/11920","2022-08-17","https://www.repositorio.ufal.br/bitstream/123456789/11920/1/Uma%20abordagem%20de%20ci%c3%aancia%20de%20dados%20em%20uma%20an%c3%a1lise%20socioecon%c3%b4mica%20de%20pre%c3%a7os%20para%20viagens%20de%20transporte%20por%20aplicativo%20Uber.pdf","A data science approach in a socioeconomic analysis of prices for transport travel by Uber app",""
"PPg Informática","https://www.repositorio.ufal.br/handle/123456789/17081","Campus A.C. Simões","Instituto de Computação","Dissertação","Uma abordagem de aprendizado de máquina para identificação de tendências de sucesso de jogadores de basquete universitário americano para a liga profissional: conciliando predição e explicabilidade","('José Rubens da Silva Brito',)","('Evandro de Barros Costa',)","('Bruno Almeida Pimentel', 'Joseana Macêdo Fechine Régis de Araújo', 'Thales Miranda de Almeida Vieira', 'José Antão Beltrão Moura')","Este estudo investiga a aplicação de técnicas de aprendizado de máquina em dados históricos do basquete universitário americano (NCAA), com o objetivo de prever quais jogadores têm maior potencial de chegar à NBA. Nos últimos anos, a análise de dados no basquete ganhou destaque, indo além das estatísticas convencionais e incorporando dados de sensores e câmeras, a fim de identificar padrões que possam aprimorar o desempenho de jogadores e equipes. Contudo, embora esse crescente complexidade aumente o valor preditivo, ela também gera um conjunto de dados que pode conter características redundantes, ruidosas e irrelevantes, as quais podem impactar negativamente a atividade preditiva. Para mitigar esse problema e buscar uma solução que concilie predição e explicabilidade dos modelos preditivos, propôs-se, neste trabalho, uma abordagem composta por três etapas principais: (I) seleção dos atributos mais relevantes para auxiliar na tomada de decisão; (II) utilização de algoritmos de aprendizado de máquina; (III) análise dos resultados preditivos por meio da explicabilidade de cada modelo. Na etapa (I), foi feita a seleção de dados que, quando combinados, formam um conjunto de atributos do jogador, influenciando direta ou indiretamente sua contratação por equipes da NBA, considerando a configuração atual do time. Utilizaram-se técnicas consolidadas na literatura, como Wrapper, Filter, Embedding, além do Algoritmo Genético, com o objetivo de melhorar a precisão preditiva e reduzir o número de características. Na etapa (II), buscou-se equilibrar interpretabilidade e precisão preditiva, empregando métodos de classificação transparente, como Árvores de Decisão, Regressão Logística e o Algoritmo de Regras (PRISM). Como referência de modelo de opaco, utilizou-se a Máquina de Vetores de Suporte (SVM). Já na etapa (III), analisou-se a explicabilidade de cada modelo. Isso foi feito de duas maneiras: pela própria construção dos algoritmos, como os de indução via Árvores de Decisão e via regras, e por meio da ferramenta de explicabilidade SHAP. Para a validação da abordagem, utilizou-se a base de dados mencionada, e os resultados indicaram um impacto positivo da seleção de atributos nos modelos preditivos, com destaque para a influência benéfica do Algoritmo Genético na etapa de seleção. Essa abordagem contribuiu para a identificação de um conjunto mínimo de atributos e para a melhoria das métricas de predição dos classificadores. Especificamente, a combinação do Algoritmo Genético com SVM na função de aptidão, na etapa de seleção gerou um conjunto de atributos que, ao ser utilizado na Árvore de Decisão (CART), alcançou uma acurácia de 80%. Por fim, foi realizada uma análise da interpretabilidade dos modelos Árvore de Decisão CART e PRISM, destacando a clareza fornecida por cada um: o primeiro baseado em estrutura de Árvore de Decisão e o segundo em algoritmo de regras. Adicionalmente, utilizamos a ferramenta SHAP para analisar as saídas geradas pelos algoritmos de aprendizado de máquina, permitindo uma interpretação mais clara dos resultados, para assim, auxiliar na tomada de decisão. Espere-se com esses resultados poder contribuir para a aplicação eficiente de técnicas de aprendizado de máquina no basquete, sobretudo na predição de comportamentos futuros de jogadores com base em variáveis explicáveis e selecionadas de forma criteriosa.","This study investigates the application of machine learning techniques on historical data from American college basketball (NCAA), with the aim of predicting which players have the highest potential to make it to the NBA. In recent years, data analysis in basketball has gained prominence, going beyond conventional statistics and incorporating data from sensors and cameras to identify patterns that can enhance player and team performance. However, although this growing complexity increases the predictive value, it also generates a dataset that may contain redundant, noisy, and irrelevant features, which can negatively impact predictive accuracy. To mitigate this problem and seek a solution that balances prediction and explainability of predictive models, this work proposes an approach composed of three main steps: (I) selection of the most relevant features to aid decision-making; (II) use of machine learning algorithms; (III) analysis of predictive results through the explainability of each model. In step (I), data selection was performed, and when combined, these features form a set of player attributes that directly or indirectly influence their hiring by NBA teams, considering the team’s current configuration. Established techniques from the literature, such as Wrapper, Filter, Embedding, as well as the Genetic Algorithm, were used to improve predictive accuracy and reduce the number of features. In step (II), the goal was to balance interpretability and predictive accuracy by employing transparent classification methods such as Decision Trees, Logistic Regression, and the Rule-based Algorithm (PRISM). The Support Vector Machine (SVM) was used as a reference for opaque models. In step (III), the explainability of each model was analyzed. This was done in two ways: through constructing the algorithms themselves, such as decision tree induction and rule-based algorithms, and through the SHAP explainability tool. For validation, the mentioned dataset was used, and the results indicated a positive impact of feature selection on the predictive models, with particular emphasis on the beneficial influence of the Genetic Algorithm in the selection phase. This approach contributed to identifying a minimal set of features and improving the prediction metrics of the classifiers. Specifically, combining the Genetic Algorithm with SVM in the fitness function during the selection phase produced a set of features that, when used in the Decision Tree (CART), achieved an accuracy of 80%. Finally, an analysis of the interpretability of the CART Decision Tree and PRISM models was carried out, highlighting the clarity provided by each: the first based on a decision tree structure and the second on a rule-based algorithm. Additionally, the SHAP tool was used to analyze the outputs generated by the machine learning algorithms, allowing for a clearer interpretation of the results, and thus aiding decision-making. Hopefully, these results will contribute to the efficient application of machine learning techniques in basketball, particularly in predicting future player behaviors based on explainable variables selected in a rigorous manner.","('Aprendizado de máquina', 'Esporte universitário americano', 'Jogadores de Basquetebol', 'Performance')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/17081","2024-10-29","https://www.repositorio.ufal.br/bitstream/123456789/17081/1/Uma%20abordagem%20de%20aprendizado%20de%20m%c3%a1quina%20para%20identifica%c3%a7%c3%a3o%20de%20tend%c3%aancias%20de%20sucesso%20de%20jogadores%20de%20basquete%20universit%c3%a1rio%20americano%20para%20a%20liga%20profissional_conciliando%20predi%c3%a7%c3%a3o%20e%20explicabilidade.pdf","A machine learning approach to identify success trends in ncaa players with good chance to reach nba: a balance between prediction performance and explainability","('Roberta Vilhena Vieira Lopes',)"
"PPg Informática","https://www.repositorio.ufal.br/handle/riufal/2465","Campus A.C. Simões","Instituto de Computação","Dissertação","Uma abordagem computacional para identificação de indício de preconceito em textos baseada em análise de sentimentos","('Sebastião Rogério da Silva Neto',)","('Evandro de Barros Costa',)","('Baldoíno Fonseca dos Santos Neto', 'Rinaldo José de Lima')","Há um interesse crescente na detecção de linguagem abusiva, discurso de ódio, bullying cibernético nos últimos anos. Os sites e redes sociais também sofreram uma pressão cada vez maior para enfrentar esses problemas. O discurso de ódio geralmente é definido como qualquer comunicação que despreza uma pessoa ou um grupo com base em algumas características, como raça, cor, etinidade, gênero, orientação sexual, nacionalidade, religião ou outra característica. Na área de Inteligência Artificial, a mineração de texto pode ser definida como um conjunto de técnicas e processos para descoberta de conhecimento inovador a partir de dados textuais. Dentre as técnicas de mineração de texto a Análise de sentimento, ou como também conhecida de Mineração de opinião, atuam com o estudo de opiniões, sentimentos, avaliações, atitudes e emoções das pessoas em relação a entidades como produtos, serviços, organizações, indivíduos, problemas. Este trabalho propõe uma possível solução para descoberta de indícios de preconceito em textos em português brasileiro, onde foi desenvolvido uma abordagem híbrida combinando abordagens baseadas em aprendizagem de máquina e dicionários léxicos. Além disso, a abordagem foi utilizada num estudo piloto para identificação de comentários preconceituosos em redações.","There is a growing interest in detecting abusive language, hate speech, cyber bullying in recent years. Web sites and social networks have also been under increasing pressure to address these issues. Hate speech is usually defined as any communication that disparages a person or group based on some characteristics, such as race, color, ethnicity, gender, sexual orientation, nationality, religion, or other characteristic. In the area of Artificial Intelligence, text mining can be defined as a set of techniques and processes for discovering innovative knowledge from textual data. Among the text mining techniques is Sentiment Analysis, or also known as opinion mining, act with the study of opinions, feelings, evaluations, attitudes and emotions of people in relation to entities such as products, services, organizations, individuals, problems. This paper proposes a possible solution for the discovery of evidence of prejudice in texts in Brazilian Portuguese, where a hybrid approach was developed combining approaches based on machine learning and lexical dictionaries. In addition, the approach was used in a pilot study to identify biased comments in essays.","('Mineração de texto (Computação)', 'Linguagem abusiva', 'Análise de sentimentos', 'Preconceito', 'Mídias', 'Text Mining', 'Abusive language', 'Analysis of feelings', 'Prejudice')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/2465","2017-09-29","https://www.repositorio.ufal.br/bitstream/riufal/2465/1/Uma%20abordagem%20computacional%20para%20identifica%c3%a7%c3%a3o%20de%20ind%c3%adcio%20de%20preconceito%20em%20textos%20baseada%20em%20an%c3%a1lise%20de%20sentimentos.pdf","A computational approach to identification of prejudice in texts based on analysis of feelings","('Rafael Ferreira Leite de Mello',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/1757","Campus A.C. Simões","Instituto de Computação","Dissertação","Um método para descoberta automática de regras para a detecção de Bad Smells","('Lucas Benevides Viana de Amorim',)","('Evandro de Barros Costa',)","('Márcio de Medeiros Ribeiro', 'Patrick Henrique da Silva Brito', 'Alessandro Fabrício Garcia')","Uma das técnicas para a manutenção da qualidade de um software é o refatoramento do código, mas para que esta prática traga benefícios, é necessário saber em que partes do código ela deve ser aplicada. Um catálogo com os problemas estruturais mais comuns (Bad Smells) foi proposto na literatura como uma maneira de saber quando um fragmento de código deve ser refatorado, e que tipo de refatoramento deve ser aplicado. Este catálogo vem sendo estendido por outros pesquisadores. No entanto, a detecção desses Bad Smells, está longe de ser trivial, principalmente devido a falta de uma definição precisa e consensual de cada Bad Smell. Neste trabalho de pesquisa, propomos uma solução para o problema da detecção automática de Bad Smells por meio da descoberta automática de regras baseadas emmétricas de software. Para avaliar a efetividade da técnica, utilizamos um conjunto de dados com informações sobre métricas de software calculadas para 4 sistemas de software de código aberto programados emJava (ArgoUML, Eclipse,Mylyn e Rhino) e, por meio de umalgoritmo classificador, indutor de Árvores deDecisão, C5.0, fomos capazes de gerar regras para a detecção dos 12 Bad Smells analisados emnossos estudos. Nossos experimentos demonstramque regras geradas obtiveramumresultado bastante satisfatório quando testadas emumconjunto de dados à parte (conjunto de testes). Além disso, visando otimizar o desempenho da solução proposta, implementamos um Algoritmo Genético para pré-selecionar as métricas de software mais informativas para cada Bad Smell emostramos que é possível diminuir o erro de classificação alémde, muitas vezes, reduzir o tamanho das regras geradas. Em comparação com ferramentas existentes para detecção de Bad Smells, mostramos indícios de que a técnica proposta apresenta vantagens.","One of the techniques to maintain software quality is code refactoring. But to take advantage of code refactoring, one must know where in code it must be applied. A catalog of bad smells in code has been proposed in the literature as a way to know when a certain piece of code should be refactored andwhat kind of refactoring should be applied. This catalog has been extended by other researchers. However, detecting such bad smells is far from trivial, mainly because of the lack of a precise and consensual definition of each Bad Smell. In this researchwork,we propose a solution to the problemof automatic detection of Bad Smells by means of the automatic discovery of metrics based rules. In order to evaluate the effectiveness of the technique, we used a dataset containing information on software metrics calculated for 4 open source software systems written in Java (ArgoUML, Eclipse,Mylyn and Rhino) and, by means of a Decision Tree induction algorithm, C5.0, we were capable of generating rules for the detection of the 12 Bad Smells that were analyzed in our study. Our experiments show that the generate rules performed very satisfactorily when tested against a separated test dataset. Furthermore, aiming to optimize the proposed approach, a Genetic Algorithm was implemented to preselect the most informative software metrics for each Bad Smell and we show that it is possible to reduce classification error in addition to, many times, reduce the size of the generated rules. When compared to existing Bad Smells detection tools, we show evidence that the proposed technique has advantages.","('Inteligência artificial', 'Engenharia de software', 'Algorítmos genéticos', 'Artificial intelligence', 'Software engineering', 'Genetic algorithms')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1757","2014-05-05","https://www.repositorio.ufal.br/bitstream/riufal/1757/1/Um%20m%c3%a9todo%20para%20descoberta%20autom%c3%a1tica%20de%20regras%20para%20a%20detec%c3%a7%c3%a3o%20de%20Bad%20Smells.pdf","A method for the automatic discovery of rules for the detection of Bad Smells","('Baldoíno Fonseca dos Santos Neto',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/2975","Campus A.C. Simões","Instituto de Computação","Dissertação","Metodologia para a especificação de processos acadêmicos usando padrões de workflow e redes de Petri","('Maria do Carmo Bispo Silva',)","('Arturo Hernández-Domínguez',)","('Fábio Paraguaçu Duarte da Costa', 'Flávio Mota Medeiros')","Este trabalho propõe uma metodologia para a especificação de Processos Acadêmicos que utiliza Padrões do tipo “WCP – Workflow Control-Flow Patterns”, e utiliza técnicas de modelagem através da notação de BPMN e de Redes de Petri Coloridas. A metodologia proposta está dividida em três fases, onde na primeira é feita a identificação do modelo padronizado de workflow, adequado ao processo a ser modelado, na segunda fase é modelado o processo utilizando a notação BPMN e na última fase o mesmo processo é modelado utilizando Redes de Petri Coloridas. Testamos as três fases da metodologia proposta, modelando 10 processos acadêmicos selecionados dos cursos superiores de Tecnologia, Bacharelado e Licenciaturado Instituto Federal de Educação, Ciência e Tecnologia – IFS. Em cada um desses processos, identificamos os padrões de workflow existentes, especificamos na notação BPMN e em Redes de Petri utilizando a ferramenta CPN Tools, sendo possível verificar a qualidade do trabalho através do formalismo matemático e da semântica de representação gráfica das Redes de Petri. Os padrões mais utilizados nos processos modelados foram WCP 1 -Sequencial, WCP 4 -Escolha Exclusiva e WCP 21-Laço Estruturado. Ficou constatado que a proposta metodológica apresentada atende simultaneamente os requisitos de facilidade na compreensão dos processos acadêmicos junto ao usuário final através da modelagem na notação BPMN dos padrões de workflow identificados, bem como de validação dos modelos, através da verificação da existência de erros e ambiguidades, por meio da sua implementação em forma de Redes de Petri Coloridas.","This work proposes a methodology for the specification of Academic Processes using WCP -Workflow Control -Flow Patterns, using modeling techniques through BPMN notation and Colored Petri Nets.The proposed methodology is divided into three phases, where the first is the identification of the standardized workflow model, appropriate to the process to be modeled, in the second phase the process is modeled using BPMN notation and in the last phase the same process is modeled using Colored Petri Nets. We tested the three stages of the proposed methodology, modeling 10 selected academic processes of the higher courses of Technology, Bachelor and Graduation of the Federal Institute of Education, Science and Technology -IFS. In each of these processes we identify the existing workflow patterns, we specify them in BPMN notation and in Petri Nets, using the CPN Tools, being possible to check the quality of the work, by the mathematical formalism and the semantics of graphic representation of the Networks of Petri. The most used patterns in the modeled processes were WCP 1 -Sequential, WCP 4 -Exclusive Choice and WCP 21 -Structure Loop. It was verified that the methodological proposal presented simultaneously meets the requirements of ease in understanding the academic processes with the end user through the modeling in BPMN notation of the identified workflow patterns, as well as validation of the models, by the verification of the existence of errors and ambiguities, through its implementation in the form of Colored Petri Nets.","('Padrões de workflow', 'Processos acadêmicos', 'Business process model and notation', 'Redes de Petri coloridas', 'CPN Tools', 'Workflow Patterns', 'Academic Processes', 'BPMN', 'Colored Petri Nets')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/2975","2017-11-07","https://www.repositorio.ufal.br/bitstream/riufal/2975/3/Metodologia%20para%20a%20especifica%c3%a7%c3%a3o%20de%20processos%20acad%c3%aamicos%20usando%20padr%c3%b5es%20de%20workflow%20e%20redes%20de%20Petri.pdf","Methodology for the specification of academic processes using workflow patterns and Petri nets",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/5972","Campus A.C. Simões","Instituto de Computação","Dissertação","Uma metodologia de avaliação do design de interfaces baseado no estudo de caso do sistema Universidade Aberta do Brasil UAB/UFAL","('Jose Kleber Ivo',)","('Fábio Paraguaçu Duarte da Costa',)","('Evandro de Barros Costa', 'Filomena Maria Gonçalves da Silva Cordeiro Moita')","O presente trabalho mostra um modelo de avaliação capaz de detectar problemas de usabilidade em Ambientes Virtuais de Aprendizagem. Este estudo foi desenvolvido através da observação do contexto do Sistema da Universidade Aberta do Brasil, da Universidade Federal de Alagoas (UFAL). Tem como princípio avaliar a interface do Moodle, identificando possíveis problemas de usabilidade. Detectados os erros na interface, será apontado o critério de usabilidade que necessita ser melhorado. As dimensões ao serem medidas no modelo são: fácil de aprender, eficiente, fácil de ser lembrado, ter poucos erros e gerar satisfação. Nesse sentido, foram utilizadas a lista original e a versão revisada das heurísticas de Jakob Nielsen como elemento aferidor do estudo de caso. A metodologia adotada no modelo de avaliação encontra sustentação em Preece, et al. (2007, p. 24-55, 339-357), modelo D E C I D E de avaliação. Foi construído gráfico mediante resultado das avaliações e realizadas análises, observando cada critério de usabilidade. O modelo de avaliação sugere métricas qualitativas. O estudo de caso da Avaliação da Plataforma Moodle envolveu 10 avaliadores. O Ambiente Virtuais de Aprendizagem (AVA) obteve de total de 20 critérios avaliados; 13 critérios aprovados, segundo a análise dos avaliadores, e 7 critérios que necessitam ser melhorados. Na análise geral, foi observado que o ambiente Moodle obteve um bom nível de usabilidade, porém algum dos aspectos aferidos demonstrou insuficiência e necessita ser melhorado para uma melhor interação entre usuário e interface.","This study presents an evaluation model able to detect usability problems in Virtual Learning Environments. This study was developed through the context of the Open University System of Brazil, Federal University of Alagoas (UFAL). It’s principle evaluate the Moodle interface, identifying potential usability problems. Errors were detected on the interface, will be appointed the usability criterion that need to be improved. Dimensions measured in the model are easy to learn, efficient, easy to remember, have few errors and create satisfaction. In this sense, it were used the original list and revised version of the heuristics by Jakob Nielsen sealer as part of study of case. The methodology used in the evaluation model finds support in Preece, et al. (2007, p. 24-55, 339-357), evaluation D E C I D E model. Graphic was constructed using results of evaluations and analysis carried out by observing each criterion of usability. The evaluation model suggests qualitative metrics. The case study's Evaluation of Moodle Platform involved 10 evaluators. The Virtual Learning Environment received a total of 20 criterion evaluated; 13 criterion approved according to the analysis, and seven criterion evaluators that need to be improved. In the general analysis, it was observed that the Moodle environment has a good level of usability, but some of the aspects assessed showed inadequate and need to be improved for a better interaction between user and interface.","('Ambiente interativo de aprendizagem', 'Design', 'Interface', 'Ergonomia de software', 'Usabilidade', 'Métricas de usabilidade', 'Universidade Aberta do Brasil', 'Interactive learning environment', 'Software Ergonomics', 'Usability', 'Usability metrics', 'Open University of Brazil')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/5972","2011-04-13","https://www.repositorio.ufal.br/bitstream/riufal/5972/1/Uma%20metodologia%20de%20avalia%c3%a7%c3%a3o%20do%20design%20de%20interfaces%20baseado%20no%20estudo%20de%20caso%20do%20sistema%20Universidade%20Aberta%20do%20Brasil%20UABUFAL.pdf","",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/123456789/14341","Campus A.C. Simões","Instituto de Computação","Dissertação","Uma metodologia aplicada à seleção de contribuintes do ICMS para fins de auditoria","('Glauber Arthur Nascimento da Silva',)","('João Inácio Soletti',)","('Sandra Helena Vieira de Carvalho', 'Ricardo Poley Martins Ferreira')","Com o advento do Plano Real, os estados brasileiros iniciaram um processo de melhoria dos instrumentos de gestão em seus órgãos de administração tributária. Inclui-se entre tais instrumentos o planejamento da ação fiscal, ao qual foram incorporadas novas sistemáticas para a seleção de contribuintes do imposto sobre operações relativas à circulação de mercadorias e sobre prestações de serviços de transporte interestadual e intermunicipal e de comunicação (ICMS). Este trabalho apresenta um modelo matemático de otimização combinatória baseado no clássico problema da mochila com o objetivo de selecionar os contribuintes mais qualificados para a auditoria fiscal, considerando os critérios e regras adotados pelo agente de decisão. O modelo desenvolvido utiliza a análise multicritério e técnicas da pesquisa operacional. Por fim, o modelo obteve resultados coerentes quando submetido a um estudo de caso com dados fornecidos por uma agência tributária.","With the advent of the Real Plan, the brazilian states has initiated an improvement process of the management instruments in their tax agencies. It is included among such instruments planning of the tax case, which had been incorporated new systematics for the taxpayer selection of the value added taxes on sales and services (ICMS). This work presents a combinatorial optimization model based in the classic knapsack problem with the objective to select more qualifed taxpayers for audit proposals, considering the criteria and rules adopted for the decision agent. The developed model uses the multicriteria analysis and operational research techniques. Finally, the model got coherent results when submitted to a case study with data supplied by a tax agency.","('Otimização combinatória', 'Pesquisa operacional', 'Seleção de contribuintes do ICMS', 'Problema da mochila', 'Análise multicritério de decisão', 'Combinatorial optimization', 'Operational research', 'Taxpayer selection of ICMS', 'knapsack problem', 'Multicriteria decision analysis')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/14341","2006-12-01","https://www.repositorio.ufal.br/bitstream/123456789/14341/1/Uma%20metodologia%20aplicada%20%c3%a0%20sele%c3%a7%c3%a3o%20de%20contribuintes%20do%20ICMS%20para%20fins%20de%20auditoria.pdf","","('Henrique Pacca Loureiro Luna',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/2063","Campus A.C. Simões","Instituto de Computação","Dissertação","Mecanismo de identificação da aprendizagem cognitiva na linguagem dos idosos, baseado numa abordagem discursiva","('Fabrícia Correia de Oliveira',)","('Fábio Paraguaçu Duarte da Costa',)","('Arturo Hernández-Domínguez', 'Isa Maria Freire')","Esta pesquisa tem como objetivo apresentar uma discussão teórica e metodológica sobre os processos cognitivos dos idosos, participantes do Curso de Introdução à Informática, da Universidade Estadual de Ciências da Saúde Aberta à Terceira Idade (UNCISATI). Nosso Trabalho volta-se à análise da linguagem da pessoa idosa como participante do processo de aprendizagem usando de ferramentas computacionais de forma que estas possam ampliar seu léxico e criar maior familiaridade com a linguagem digital. Nosso objetivo é identificar dispositivos linguísticos da interação verbal que permitem uma análise do processo de aprendizagem e cognição da pessoa idosa, participantes desse curso. Assim, este estudo se propôe a criar um modelo de interação on line baseado na teoria de Construção de Conhecimento, de Vygotsky (2007), que considera a gênese do conhecimento nas relações sociais, sendo produzido na intersubjetividade e marcado por condições históricas e sócio-culturais.","This article aims to present a theoretical and methodological discussion about the cognitive processes of the elderly, participants in the Course of Digital Inclusion, Open State University Health Sciences Open for Elderly. This research is being conducted in the Masters in Computational Modeling Multidisciplinary Knowledge of the Federal University of Alagoas. Our work, back to the discourse analysis of the elderly as a participant in the learning process using computational tools so that they can expand their vocabulary and create greater awareness of the digital language. Our goal is to identify devices of discourse analysis for analyzing the process of cognitive learning and the elderly, participants in this course. This study is still in the stage of theoretical discussion on theories of knowledge construction based on Vygotsky (2007), which considers the genesis of knowledge in social relations, intersubjectivity being produced and marked by socio-cultural and historical.","('Aprendizagem cognitiva', 'Cognição em idosos', 'Interação homem-máquina', 'Cognitive learning', 'Cognition in the elderly', 'Man-machine interaction')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/2063","2013-03-01","https://www.repositorio.ufal.br/bitstream/riufal/2063/1/Mecanismo%20de%20identifica%c3%a7%c3%a3o%20da%20aprendizagem%20cognitiva%20na%20linguagem%20dos%20idosos%2c%20baseado%20numa%20abordagem%20discursiva.pdf","Identification mechanism of cognitive learning in the language of the elderly, based on a discursive approach","('Roberta Vilhena Vieira Lopes',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/5812","Campus A.C. Simões","Instituto de Computação","Dissertação","Impacto da colaboração e competição na experiência de fluxo em ambiente educacional gamificado","('Alexandre Marinho Lemos Filho',)","('Ig Ibert Bittencourt Santana Pinto',)","('Ranilson Oscar Araújo Paiva', 'Sheyla Christine Santos Fernandes', 'Isabela Gasparini')","A tecnologia presente no mundo atual tem impactado consideravelmente a maneira como as pessoas vivem, incluindo o contexto educacional, que tem que competir o interesse dos alunos com tecnologias como a internet ou videogames. Nesse sentido, a academia tem procurado maneiras de tornar o processo educacional mais atraente para os alunos, e através da Experiência de Fluxo o estudantes poderiam realizar a tarefa educacionais de uma maneira intrinsecamente gratificante. Introduzida por Csikszentmihalyi, a Teoria de Fluxo define um estado mental onde o individuo está focado em sua tarefa de forma tão profunda que nem percebe a passagem tempo, causando uma experiência autotélica. Esta pesquisa de mestrado tem como objetivo investigar as consequências de um ambiente educacional gamificado com elementos de competição e colaboração na experiência de fluxo dos estudantes. Para isso, foi realizado um experimento com 127 alunos alunos distribuídos entre quatro grupos (Individual, Em Grupo, Competição Individual e Competição em Grupo) em sessões de aprendizagem suportada por computador. Os sujeitos foram avaliados quanto a experiência de fluxo após a realização da tarefa. Os resultados obtidos sugerem que tanto a competição quanto a colaboração aplicadas isoladamente não surtem efeito na experiência de fluxo. No entanto, quando aplicadas em conjunto, apresentaram efeito significativo na experiência de fluxo.","The technology present in today’s world has impacted considerably the way people live their lives, including the educational context, which has competing students’ interest with technologies such as the internet or video games. In that sense, the academy has sought ways to make the educational process more attractive to students, and through the Flow Experience students could provide in-school tasks in an intrinsic way. Introduced by Csikszentmihalyi, Flow Theory defines a state of mind where the individual is focused on his task so deeply that he does not even notice the passing of time, causing na autotelic experience. This masters research aims to investigate the consequences of a gamified educational environment with elements of competition and collaboration in the students’ flow experience. For this, an experimento was carried out with 127 students distributed among four groups (Individual, In Group, Individual Competition and Group Competition) in computer-supported learning sessions. Subjects were evaluated for the flow experience after the task was performed. Results suggest that both competition and collaboration applied alone has no effect on the flow experience. However, when applied together, they had significant effects on the flow experience.","('Educação -Inovações tecnológicas', 'Habilidades cognitivas -Teoria de fluxo', 'Gamificação -Competição', 'Jogos digitais -Colaboração', 'Education -Technological Innovations', 'Cognitive Skills -Flow Theory', 'Gamification – Competition', 'Digital Games -Collaboration')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/5812","2019-06-21","https://www.repositorio.ufal.br/bitstream/riufal/5812/1/Impacto%20da%20colabora%c3%a7%c3%a3o%20e%20competi%c3%a7%c3%a3o%20na%20experi%c3%aancia%20de%20fluxo%20em%20ambiente.pdf","Impact of Collaboration and Competition on Flow Experience in Gamified Educational Environment","('Diego Dermeval de Medeiros da Cunha Matos',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/5725","Campus A.C. Simões","Instituto de Computação","Dissertação","Medidas de centralidade para classificação automática de doenças pulmonares intersticiais em imagens de tomografia computadorizada","('Yana Kellen Dioclécio Mendes',)","('Eliana Silva de Almeida',)","('Tácito Trindade de Araújo Tiburtino Neves', 'Raquel da Silva Cabral')","As Doenças Pulmonares Intersticiais (DPIs), também denominadas doença parenquimatosa difusa, formam um grupo com mais de 150 patologias diferentes. Para o diagnóstico das DPIs, a tomografia computadorizada é o exame de imagem mais utilizado, pois ela é mais sensível do que a radiografia torácica, fornece imagens mais detalhadas da doença, e com isso, auxilia os médicos no seu diagnóstico. Além do exame de tomografia, tem-se utilizado a Visão Computacional para auxiliar no diagnóstico, tendo em vista que esta é uma área que tem crescido consideravelmente nos últimos anos, principalmente no que concerne a aplicações que utilizam imagens médicas. O estado da arte dessa área tem como principal característica a não existência de um algoritmo genérico que simule o processo de visão, contudo, é uma área com pesquisas bastante promissoras envolvendo diversas teorias e métodos, como as Redes Complexas. Com base nesse contexto, apresenta-se aqui um método automático para classificação de imagens de tomografia computadorizada com DPIs, onde as imagens são modeladas como Redes Complexas e a medida de centralidade closeness é utilizada para gerar um vetor de características junto com características extraídas pelos descritores de Haralick e LBP. Para validar o método proposto, foi treinado um classificador K-Nearest Neighbors (KNN) e comparado os resultados obtidos com métodos tradicionais e atuais da literatura. A partir de um conjunto de dados de 3:258 ROIs, foi possível conseguir uma taxa de classificação de 89:81%.","Interstitial lung disease (ILD), also known as diffuse parenchymal disease, form a group with more than 150 different pathologies. For the diagnosis of ILD, the computed tomography scan is the most widely used image examination because it is more sensitive than chest thoracic radiography, provides more detailed images of the disease, and with that assists physicians in the your diagnosis. In addition to the computed tomography scan, Computational Vision hás been used to aid in the diagnosis, considering that this is an area that has grown considerably in the last years, especially regarding applications that use medical images. The state of the art in this area has as main characteristic the non existence of a generic algorithm that simulates the vision process, however, it is an area with very promising research involving several theories and methods, such as Complex Networks. Based on this context, presents here an automatic method for computed tomography image classification with ILD, where the images are modeled as Complex Networks and the closeness centrality measure is used to generate a vector of characteristics along with characteristics extracted by the Haralick and LBP descriptors. To validate the proposed method, a K-Nearest Neighbors (KNN) classifier was trained and compared the results obtained with traditional and current literature methods. From a dataset of 3:258 ROIs, it was possible to achieve a rating rate of 89:81%.","('Doenças pulmonares intersticiais', 'Processamento de imagem assistida por computador', 'Redes complexas', 'Closeness', 'Interstitial Lung Disease', 'Computer-aided image processing', 'Complex Networks')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/5725","2019-04-16","https://www.repositorio.ufal.br/bitstream/riufal/5725/1/Medidas%20de%20centralidade%20para%20classifica%c3%a7%c3%a3o%20autom%c3%a1tica%20de%20doen%c3%a7as%20pulmonares.pdf","Centrality measures for automatic classification of interstitial lung diseases in computed tomography images","('Fabiane da Silva Queiroz',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/5971","Campus A.C. Simões","Instituto de Computação","Dissertação","LearnCraft -uma Engine para criação de jogos RPG construcionistas","('José Carlos Costa Milito',)","('Arturo Hernández-Domínguez',)","('Leandro Dias da Silva',)","A evasão escolar constitui um problema global, também se verificando no Brasil, com altas taxas de abandono e reprovação nos ensinos fundamental e médio; dentre os motivos para tal, predomina a falta de interesse por parte do alunado. Jogos, ao se configurar como ofertantes de experiências de aprendizado, ao mesmo tempo, motivantes, engajadoras e prazerosas para os aprendizes, aparecem como um elemento significativo no auxílio à equação destes problemas. Dentro desse contexto, o construcionismo aparece como uma preciosa fonte de subsídios teóricos para a elaboração de jogos educacionais, com pesquisas demonstrando que o processo de aprendizado apresenta o potencial de ocorrer de forma mais natural e satisfatória quando o aprendiz está engajado na construção de um artefato. Dentre os gêneros de jogos, destacam-se hoje os Role Playing Games, com grande apelo dentre as novas gerações de alunos. Tendo em vista tal potencial educativo, e como uma contribuição à equação dos problemas supracitados, neste trabalho é exposta a autoria de uma ferramenta capaz de gerar jogos construcionistas dentro do gênero RPG, sem a necessidade de conhecimento de linguagem de programação por parte do autor.","School dropout is a global problem, also occurring in Brazil, with high rates of dropout and disapproval in elementary and high school; among the reasons for this, the lack of interest on the part of the student predminates. Games, as providers of learning experiences, at the same time, motivating, engaging and pleasurable for the apprentices, are an important solution of these problems. Within this context, constructionism appears as a valuable source of theoretical subsidies for the elaboration of educational games, with research demonstrating that the learning process has the potential to occur more naturally and satisfactorily when the learner is engaged in the construction of an artifact . Among the gaming genres, the Role Playing Games nowadays stand out, with great appeal among the new generations of students. Given this educational potential, and as a contribution to the solution of the above mentioned problems, in this work is exposed the authorship of a tool capable of generating constructor games within the RPG genre, without the need of knowledge of programming language by the author.","('Jogos digitais RPG', 'Ensino e aprendizagem', 'Construcionismo', 'Role playing games', 'Engines', 'Digital games', 'Teaching and learning', 'Constructionism')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/5971","2018-05-21","https://www.repositorio.ufal.br/bitstream/riufal/5971/1/LearnCraft%20-%20Uma%20Engine%20para%20cria%c3%a7%c3%a3o%20de%20jogos%20RPG%20construcionistas.pdf","LearnCraft – an Engine for the creation of constructionist RPG games","('Marcus de Melo Braga',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/6022","Campus A.C. Simões","Instituto de Computação","Dissertação","Lagmund: da modelagem diagnostica de percepção à proposição de um jogo digital para aprendizagem em educação ambiental: um foco na Laguna Mundaú","('Simone Cavalcante de Oliveira',)","('Evandro de Barros Costa',)","('Arturo Hernández-Domínguez', 'Edilson Ferneda')","Educação ambiental é um ramo de estudo relevante, amplo e diverso, tendo o assunto poluição da água como um dos seus temas de destaque, apresentando problemas importantes para serem explorados. De um ponto de vista tecnológico, parte desses problemas tem sido abordados na área de Informática na Educação Ambiental através da utilização de softwares educativos em diferentes abordagens. Assim, particularmente os jogos digitais têm sido uma das ferramentas de software educacionais usados para engajar e motivar os alunos em um processo de aprendizagem ativa, potencialmente envolvendo-os em interações de aprendizagem produtiva. O presente trabalho se situa neste contexto e, desse modo, versa sobre a concepção e o desenvolvimento de um instrumento digital para Educação Ambiental focalizando aspectos de poluição de uma laguna. Portanto, teve como objetivo geral propor um jogo digital educacional customizado, visando contribuir no processo de ensino-aprendizagem de conceitos de Educação Ambiental relacionados à Laguna Mundaú, chamado LagMund. Para tanto, este jogo foi concebido e desenvolvido de acordo com as diretrizes extraídas de um estudo diagnóstico sobre o modo como esta laguna é percebida pelos alunos de escolas públicas que vivem perto dela. A partir deste diagnóstico, foram estabelecidos objetivos de aprendizagem para orientar uma estrutura curricular customizada e, em seguida, para contribuir diretamente nos principais aspectos da concepção e desenvolvimento do jogo digital. Para a avaliação do jogo proposto foi realizado um experimento envolvendo 12 alunos de uma das duas escolas públicas de ensino fundamental mencionadas. Os resultados obtidos indicaram um interesse significativo dos alunos quando usaram o LagMund, particularmente declarando-se motivados e achando o jogo divertido. Além disso, os resultados mostraram que o jogo é uma ferramenta útil para conscientização ambiental, bem como que a maioria dos estudantes indicou alguma melhoria no nível de conhecimento sobre os conceitos envolvidos.","Environmental education is a wide, diverse, and relevant field. In particular, water pollution is one of the subjects studied in this field, presenting different and important problems to be addressed. From a technological viewpoint, part of these issues has been addressed in the area of Educational Informatics by using educational software according to several approaches. Thus, particularly digital games have been one of the educational software tools used to engage and motivate students in an active learning process, potentially involving them in productive learning interactions. The present work follows this track by proposing an educational digital game called LagMund, aiming at contributing to teaching-learning process about concepts in educational environment related to the lagoon. This game has been designed and developed according to guidelines obtained from studies about how this lagoon has been perceived by students from public schools that live close to the lagoon. From this diagnosis, we extracted learning objectives to guide a curriculum structure and then we consider the result of this diagnosis to design and development of the digital game. We have evaluated this game with an experiment involving 12 students from one of the two middle schools considered in our work. The obtained results indicate a significant interest from the students when used the proposed game, particularly stating to have motivantion and having fun in playing the game. Furthermore, the results show that the majority of the students indicate to improve their level of knowledge in the involved concepts.","('Educação ambiental – Ensino auxiliado por computador', 'Jogos eletrônicos', 'Tecnologia educacional', 'Ambiente interativo de aprendizagem', 'Environmental education -Computer Aided Learning', 'Electronic games', 'Educational technology', 'Interactive learning environment')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/6022","2016-09-28","https://www.repositorio.ufal.br/bitstream/riufal/6022/1/Lagmund%20da%20modelagem%20diagnostica%20de%20percep%c3%a7%c3%a3o%20%c3%a0%20proposi%c3%a7%c3%a3o%20de%20um%20jogo%20digital%20para%20aprendizagem%20em%20educa%c3%a7%c3%a3o%20ambiental%20um%20foco%20na%20Laguna%20Munda%c3%ba.pdf","Of the diagnostic modeling of perception to the proposition of a digital game for learning in environmental education: a focus on the Mundaú Lagoon","('Jorge Artur Peçanha de Miranda Coelho',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/1514","Campus A.C. Simões","Instituto de Computação","Dissertação","JIndie: uma abordagem baseada no reuso de software e linha de produto de software para jogos construcionistas","('Carlos Alberto Correia Lessa Filho',)","('Arturo Hernández-Domínguez',)","('Fábio Paraguaçu Duarte da Costa', 'Márcio de Medeiros Ribeiro', 'Flávio Mota Medeiros')","A educação no Brasil apresenta uma deficiência na qualidade de ensino, de forma que muitos professores e empresários sentem que os estudantes, ao se formarem ainda não estão prontos para assumir seu papel na sociedade. Um dos fatores que contribuem para a baixa qualidade do ensino, segundo Papert, pode ser observado na quebra do incentivo a busca de novos conhecimentos, ocorrida quando o estudante entra no colégio. Uma estratégia adotada para motivar o estudante buscar a novos conhecimentos ocorre através do construcionismo, no qual, o estudante para aprender sobre um determinado conteúdo por completo, necessita criar conteúdo concreto sobre o assunto estudado. O desenvolvimento desses conteúdos concretos pode se tornar mais fácil através do uso do computador e com jogos que permitem representar um mundo virtual no qual o jogador tenha todas as ferramentas necessárias para ter a liberdade de criar de sua forma um artefato concreto sobre o assunto estudado. Para facilitar o desenvolvimento desses jogos, que muitas vezes não chegam a ser concluídos devido ao esforço investido, pode-se optar pelo uso de uma Linha de Produto de Software, que se trata de um sistema de produção intensivo de softwares de um determinado domínio. Este trabalho apresenta uma abordagem e produção de uma Linha de Produto de Software, JIndie, que tem como objetivo ser uma Linha de Produto de Software para produção de jogos construcionistas. Para a avaliação da Linha de Produto proposta no trabalho, um estudo de caso foi realizado com a produção de quatro jogos com a finalidade de avaliar a viabilidade de desenvolver jogos construcionistas através do JIndie, como também avaliar o desempenho e as ferramentas utilizadas no processo. Os resultados do estudo de caso revelaram um feito satisfatório na capacidade de desenvolvimento dos jogos, como também uma produção com baixa complexidade e esforço por parte do desenvolvedor dos jogos.","The education in Brazil shows a deficiency in the quality of teaching, so that many teachers and businessmen realize that students that complete the basic education are not ready to assume their role in society yet. One of the factors contributing to the low quality of education, according Papert, can be seen in the break of the incentive to search for new knowledge, which usually occurred when the student starts to go to school. A strategy adopted to motivate the student to search for new knowledge occurs through of constructionism, in which to learn about a particular content, the student needs to create some concrete material. The development of these concrete material may become easier through the use of computers and games that provide a virtual world in which the player has all the tools necessary to create an artifact about the subject studied. To facilitate the development of these games, which often fail to be completed due to the effort invested, the developers can use a Software Product Line, which is a software intensive production system for a particular domain. This paper presents an approach and the JIndie Software Product Line that aims to be a Software Product Line for developing constructionist games. To validate Software Product Line proposed in this work, a case study was carried out with the production of four games to assess the feasibility to implement constructionist games using JIndie, as well as to evaluate the performance and tools used in the process. The case study reveals a satisfactory result in game development capabilities, as well as a production with low complexity and effort by the game developer.","('Software -Desenvolvimento', 'Software – Jogos para computador', 'Jogos educativos', 'Construcionismo', 'Educação – Meios auxiliares', 'Software Product Line', 'Games', 'Constructionism', 'Education')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1514","2016-09-06","https://www.repositorio.ufal.br/bitstream/riufal/1514/1/JIndie%20uma%20abordagem%20baseada%20no%20reuso%20de%20software%20e%20linha%20de%20produto%20de%20software%20para%20jogos%20construcionistas.pdf","JIndie: an approach based on software reuse and software product line for construcionists games",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/6100","Campus A.C. Simões","Instituto de Computação","Dissertação","Identification of anchor zones for floating content in VaNETs based on centrality measures","('Fábio Massalino',)","('André Luiz Lins de Aquino',)","('Heitor Soares Ramos Filho', 'Danielo Gonçalves Gomes', 'Raquel da Silva Cabral')","","Floating Content is the information with local and temporal validity and spatial relevance. These contents are produced and consumed by mobile nodes in a region called anchor zone. This floating content remains alive during its lifecyclewithout the need for fixed infrastructure, being maintained only by themobile nodes that consume and forward it—because of this, determining the most viable anchor zones to use floating content is one of the challenges of the Vehicular Network. This work presents the study and scientific experiment wherethe use of measures of centrality to identify the most viable anchor zones to spread the floating content proved to be effective. The study consisted of two parts: the first consisted of analyzing two real vehicular bases: one theMobile Century, which traffic of 2 900 vehicles on a section of 18km of ""Nimitz Freeway"", near Union City, California, in the United States, during February, 02 of 2008; other the T-Drive, which traffic of 8 388 vehicles from 02 to 08 of February of 2008 in a region of Beijing, China. In these two bases, two techniques were presented to identify the most viable anchor zones: GRID POSITION and BETWEENNESS CENTRALITY MEASURE. This study allowed us to observe the regions and times where there was the most significant flow of vehicles, through GRID POSITION technique and the regions where there was the most influential flow of vehicles using BETWEENNESS CENTRALITY. Due to not being able to verify which regions are more viable to use floating content, which motivated the second part of the work. The second part consisted in simulate two real bases over synthetic traffic: The first one shows the traffic of 18 000 vehicles in a section of 18km of ""Nimitz Freeway"" near Union City, California, in the United States. The second has the traffic of 100 000 vehicles in a region of Beijing, China. On these bases, we presented four model strategies, based on FLOW OF VEHICLES(State-of-The-Art), BETWEENNESS AND DEGREE CENTRALITY MEASURES and the HYBRID, mixed flow of vehicles and betweenness centrality to determine the anchor zones most viable in VANET scenarios. After identifying the most viable anchor zones in each strategy, we used a simulation where we verified in which of the strategies the floating content remained alive for longer and the number of vehicles affected. These simulation experiments showed that the strategies of centrality measures performed better than other strategies. The total simulation time was 18000s. By using centrality measures, the floating content remained alive for 17 008s on ""Nimitz Freeway"", USA and 13 579s in Beijing, China.","('Anchoring (System Modeling and Simulation)', 'Floating Point Arithmetic', 'Vehicular network', 'Centrality measures', 'Ancoragem (Modelagem e simulação de sistemas)', 'Aritmética de ponto flutuante', 'Rede veicular', 'Medidas de centralidade')","Ciência da Computação","eng","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/6100","2019-08-30","https://www.repositorio.ufal.br/bitstream/riufal/6100/1/Identification%20of%20anchor%20zones%20for%20floating%20content%20in%20VaNETs%20based%20on%20centrality%20measures.pdf","",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/1760","Campus A.C. Simões","Instituto de Computação","Dissertação","Uma linguagem para modelagem do vocabulário de pranchas de comunicação alternativa","('Natália de Melo Franco',)","('Patrick Henrique da Silva Brito',)","('Luís Cláudius Coradine', 'Márcia de Borba Campos')","Anualmente, a população mundial tem um acréscimo de, aproximadamente, cem mil pessoas cujas deficiências limitam severamente seu processo de comunicação. São inúmeras as causas destes impedimentos na fala, podendo ser de ordem física, psicológica ou cognitiva. Essas pessoas podem ter sua capacidade de comunicação limitada, acarretando em problemas de acessibilidade em seu cotidiano e, para estes casos, o uso de Tecnologias Assistivas baseadas em Pranchas de Comunicação Alternativa (PCA) serve de auxílio para a comunicação. É importante que os conteúdos da PCA reflitam as necessidades e preferências de cada paciente e que este conteúdo possa ser evoluído ou editado por profissionais e cuidadores. Dada a importância da personalização da PCA para cada tipo de paciente, as soluções vigentes tem duas importantes limitações: 1) a personalização de conteúdo, quando permitida, é feita ou por programadores, de maneira fechada, ou por meio de interface gráfica, via o preenchimento de campos pré-definidos; e 2) a falta de coesão na mensagem (e.g., “beber um biscoito de chocolate”). Uma forma de melhorar esta personalização é utilizando uma Linguagem de Modelagem Especifica de Domínio (DSML). Pois, esta permite diagramar o conteúdo utilizando os conceitos do domínio, facilitando assim, sua aprendizagem e utilização. Este trabalho se apoia na hipótese de que uma linguagem de modelagem tem a expressividade necessária para possibilitar a personalização da PCA em diversos domínios, atendendo aos diferentes interessados no seu uso. Neste contexto, esta dissertação visa à criação de um novo paradigma para a personalização dos conteúdos de uma PCA. A proposta é especificar uma linguagem de modelagem que permita a diagramação e personalização de conteúdos de forma a limitar a ocorrência de mensagens sem coesão.","Every year, the world’s population increases by, approximately, one hundred thousand people whose disabilities severely limit their communication process. The cause of these disabilities can be physical, psychological or cognitive. These people may have a limited capacity of communication, resulting in accessibility problems in their daily lives and, for these cases, Assistive Technologies based on Alternative Communication Boards (ACB) can be used to aid communication. It is important that the contents of ACB reflect the needs and preferences of each patient and that this content can be edited or evolved by professionals and caregivers. Considering the need to personalize the ACB for each patient, the existing solutions have two important limitations: 1) the personalization of content, when is possible, is made by software developers, or through Graphical User Interface (GUI), by filling predefined fields; and 2) the possibility of generating low-cohesive messages (e.g., ""drink a chocolate cookie""). A way to improve this customization is using a Domain-Specific Modeling Language (DSML). Since this allows a graphical representation of domain concepts, it improves learning and makes the use easier. This study supports the hypothesis that a modeling language has the required expressiveness to allow personalization of the ACB in several domains. In this context, this work aims to create a new paradigm for the ACB content’s personalization in order to limit the occurrence of low-cohesive messages. The specified DSML were evaluated by professionals in terms of feasibility and expressiveness.","('Tecnologia assistiva', 'Distúrbios da fala', 'Assistive technology', 'Speech disorders')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1760","2014-05-23","https://www.repositorio.ufal.br/bitstream/riufal/1760/1/Uma%20linguagem%20para%20modelagem%20do%20vocabul%c3%a1rio%20de%20pranchas%20de%20comunica%c3%a7%c3%a3o%20alternativa.pdf","A vocabulary modeling language for alternative communication boards","('Robson do Nascimento Fidalgo',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/2117","Campus A.C. Simões","Instituto de Computação","Dissertação","Gestão do conhecimento e apoio à decisão na gestão ambiental: CABRAL-case based reasoning aplicado ao licenciamento ambiental","('José Damião de Melo',)","('Patrick Henrique da Silva Brito',)","('Fábio Paraguaçu Duarte da Costa', 'Edilson Ferneda')","Este trabalho apresenta uma proposta de diagnóstico organizacional quanto ao nível do alinhamento de organizações públicas de pequeno e médio portes à Gestão do Conhecimento utilizando uma adaptação do método OKA – Organizational Knowledge Assessment. A solução também contempla a modelagem de um processo de gestão do conhecimento no domínio do Licenciamento Ambiental denominado de C@br@l – Case Base Reasoning aplicado ao Licenciamento Ambiental. Esse processo foi obtido associando a metodologia de Raciocínio Baseado em Casos -RBC como elemento central da solução baseada em conhecimento e Notação de Processos de Negócio – BPMN atuando como elemento tradutor gráfico dos detalhes do processo em nível gerencial. A pesquisa teve um viés eminentemente exploratório, baseada em pesquisa bibliográfica e documental, levantamento de dados com questionário e adoção da estratégia de Estudo de Caso para delimitação do espaço de pesquisa. Os dados coletados foram analisados quanti-qualitativamente e o processo e os dados foram validados empiricamente pela construção de um protótipo para o processo proposto. Finalmente, os resultados, as contribuições, limitações e temas para pesquisas futuras são apresentadas.","This paper presents a proposal for organizational diagnosis of the level of alignment of public organizations of small and midsize for Knowledge Management using an adaptation of the method OKA -Organizational Knowledge Assessment. The solution also includes modeling a process of knowledge management in the field of Environmental Licensing called C@br@l -Case Base Reasoning aplicado ao Licenciamento Ambiental. This process was achieved by associating the methodology of Case Based Reasoning -CBR as a central element of knowledge-based solution and we use Business Process Notation -BPMN as a element that act like translator graphic of the details of process in management high-level. The survey had a bias eminently exploratory research-based literature and documents, too, with data collection using questionnaire and the adoption of the strategy of case study for defining the research space. The collected data were analyzed quantitatively and qualitatively and the process and data were empirically validated by building a prototype for the proposed process. Finally, results, contributions, limitations and issues for future research are presented.","('Gestão do conhecimento', 'Sistemas de suporte de decisão', 'Licenças ambientais', 'Mineração de dados (Computação)', 'Knowledge management', 'Decision support systems', 'Environmental licenses', 'Data mining (computing)')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/2117","2012-12-17","https://www.repositorio.ufal.br/bitstream/riufal/2117/1/Gest%c3%a3o%20do%20conhecimento%20e%20apoio%20%c3%a0%20decis%c3%a3o%20na%20gest%c3%a3o%20ambiental%20CABRAL%20case%20based%20reasoning%20aplicado%20ao%20licenciamento%20ambiental.pdf","Gestão do conhecimento e apoio à decisão na gestão ambiental: C@BR@L-case based reasoning aplicado ao licenciamento ambiental;Knowledge management and decision support of the environmental management: CABRAL-case based reasoning applied to environmental licensing","('Evandro de Barros Costa',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/123456789/9539","Campus A.C. Simões","Instituto de Computação","Dissertação","Gamificação e modelo aberto de aprendizagem: estudo experimental sobre os efeitos nas características de autorregulação da aprendizagem","('Fabrício Domingos Ferreira da Rocha',)","('Diego Dermeval de Medeiros da Cunha Matos',)","('Ig Ibert Bittencourt Santana Pinto', 'Alan Pedro da Silva')","A busca pelo aprendizado cada vez mais eficiente em ambientes online tem incentivado o desenvolvimento crescente de pesquisas. O aprendizado é percebido muitas vezes como uma atividade tediosa, o que intensifica as altíssimas taxas de evasão escolar. Nos últimos anos tem-se aplicado diversos métodos com objetivo de manter o aluno engajado no ambiente de aprendizado de tal forma que transforme a atividade tediosa em prazerosa e divertida. Os jogos de computadores proporcionam aos alunos que experimentem maneiras de aprender que evidenciam a imersão em uma prática, dessa forma, os jogos são vistos como uma ferramenta que facilita e apoia a aprendizagem dos alunos. Nesse sentido, a Gamificação se utiliza de elementos de jogos em ambientes que não são de jogos, com objetivo de promover o engajamento dos alunos, transformando a atividade tediosa em prazerosa. Apesar de diversos trabalhos mostrarem resultados positivos com uso de gamificação é comum não se conseguir que o aluno permaneça independente no processo de aprendizagem por um longo período. A autorregulação da aprendizagem se caracteriza como a capacidade do aluno em atuar no seu ambiente de aprendizagem, refletindo e tomando decisões de qual caminho seria mais conveniente para o melhor aprendizado. Dessa forma, o aluno atua de maneira ativa e construtiva no processo, no qual estabelecem objetivos que vão conduzir as suas aprendizagens. Nesse contexto, o OLM (Modelo Aberto do Estudante), possibilita a abertura do modelo do estudante, e assim, o aluno poderá visualizar as informações relativas ao próprio processo de aprendizagem, permitindo a participação ativa no processo de aprendizagem, podendo tomar decisões de quais são os caminhos que para ele gera mais resultado no ambiente online. Dessa forma, o presente trabalho teve como objetivo verificar através de um experimento controlado, se o uso de gamificação em um ambiente online de modelo aberto traria resultados significativos na autorregulação e aprendizagem do aluno. Para isso, foram comparados dois ambientes de modelo aberto em que os alunos (escolas, institutos e universidades públicas), teriam que responder 15 questões em um aplicativo desenvolvido para Android, sendo as 10 primeiras comum a todos e as outras 5 questões personalizadas por eles, quanto ao nível (fácil, médio e difícil) e conteúdo das questões (conectivos lógicos e tabela verdade), nessas 5 questões o aluno teria a versão com ou sem gamificação, distribuída randomicamente a partir do acesso ao aplicativo. Os resultados mostraram que não houve diferença significativa entre as versões com e sem gamificação, tanto com relação à autorregulação como à aprendizagem. No entanto, alguns estudos reportaram ganhos significativos ao utilizar gamificação na autorregulação e no processo de aprendizagem. Dessa forma, sugere que mais estudos são necessários ampliando-se o tamanho da amostra, aplicando conteúdo diferente do que foi abordado e expandindo o tempo de utilização do aluno com a ferramenta.","The search for increasingly efficient learning in online environments has encouraged the growing development of research. Learning is often perceived as a tedious activity, which intensifies the very high dropout rates. In recent years there have been specialists in various methods with the aim of keeping the student engaged in the learning environment in such a way that it transforms the tedious activity into a pleasant and fun one. Computer games provide students who experience ways of learning that demonstrate immersion in a practice, thus, games are seen as a tool that facilitates and supports student learning. In this sense, Gamification uses game elements in non-game environments, with the aim of promoting student engagement, transforming tedious activity into a pleasurable one. Although several works show positive results with the use of gamification, it is common not to get the student to remain independent in the learning process for a long period. The self-regulation of learning is defined as the student's ability to act in their learning environment, reflecting and making decisions about which path would be more convenient for better learning. In this way, the student acts in an active and constructive way in the process, not setting goals that will guide their learning. In this context, the OLM (Open Student Model) enables the opening of the student model, and thus, the student can view information related to the learning process itself, allowing active participation in the learning process, being able to make decisions about which these are the paths that generate more results for him in the online environment. Thus, this study aimed to verify, through a controlled experiment, whether the use of gamification in an online environment with an open model guaranteed results in self-regulation and student learning. For this, two open model environments were compared in which students (schools, institutes and universities), with which to answer 15 questions in an application developed for Android, the first 10 being common to all and the other 5 questions customized by them, as for the level (easy, medium and difficult) and the content of the questions (logical connectives and truth table), in the 5 questions, the criterion was the version with or without gamification, randomly distributed after accessing the application. The results induced that there was no significant difference between versions with and without gamification, both in relation to selfregulation and learning. However, some studies have reported gains when using gamification in self-regulation and in the learning process. Thus, more studies are necessarily introduced by expanding the sample size, applying content different from what was covered and expanding the student's time of use with the tool.","('Autorregulação da Aprendizagem', 'Gamificação', 'Modelo Aberto do Estudante', 'Revisão Sistemática', 'Experimento', 'Self-Regulation of Learning', 'Gamification', 'Open Learner Model', 'Systematic Review', 'Experiment')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/9539","2021-11-03","https://www.repositorio.ufal.br/bitstream/123456789/9539/1/Gamifica%c3%a7%c3%a3o%20e%20modelo%20aberto%20de%20aprendizagem-%20estudo%20experimental%20sobre%20os%20efeitos%20nas%20caracter%c3%adsticas%20de%20autorregula%c3%a7%c3%a3o%20da%20aprendizagem.pdf","",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/1843","Campus A.C. Simões","Instituto de Computação","Dissertação","Um framework para mineração de dados educacionais baseado em serviços web semânticos","('Tarsis Marinho de Souza',)","('Evandro de Barros Costa',)","('Ig Ibert Bittencourt Santana Pinto', 'Aydano Pamponet Machado', 'Seiji Isotani')","Este trabalho apresenta um framework para mineração de dados educacionais baseado em serviços web semânticos como uma solução para os desa os encontrados na área, como: padronização de métodos e dados, integração entre ambientes educacionais e ferramentas de mineração e ferramentas mais intuitivas para o uso de educadores e não especialistas. A solução proposta também inclui um wizard, que auxilia na extensão e instanciação do framework proposto em diferentes produtos. Para validar a solução proposta, foi realizado um estudo de caso utilizando dados de um ambiente e-Learning real utilizado por estudantes de um curso da modalidade a distância.","This paper presents a framework for educational data mining based on semantic web services as a solution to the challenges found in this area such as data and methods standardization, educational environments integration and easier to use mining tools for both educators and non-specialist users. The solution also includes a wizard, which aims to facilitate the extension and instantiation of the proposed framework in di erent products. In order to validate the proposed solution, a case study was also performed using data from a real e-learning environment used by students from distance mode courses.","('Mineração de dados (Computação)', 'Framework (Arquivo de computador)', 'Computação semântica', 'Data mining (computing)', 'Framework (computer file)', 'Semantic computing')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1843","2011-04-29","https://www.repositorio.ufal.br/bitstream/riufal/1843/1/Um%20framework%20para%20minera%c3%a7%c3%a3o%20de%20dados%20educacionais%20baseado%20em%20servi%c3%a7os%20web%20sem%c3%a2nticos.pdf","A framework for educational data mining based on semantic web services","('Patrick Henrique da Silva Brito',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/123456789/8950","Campus A.C. Simões","Instituto de Computação","Dissertação","Um framework conceitual para jogos digitais educativos solidários","('Brunno Davisson Melo Cavalcante',)","('Arturo Hernández-Domínguez',)","('Fábio Paraguaçu Duarte da Costa', 'Leandro Dias da Silva', 'Edilson Ferneda')","Os jogos de alta violência em sua maioria são banidos no Brasil e em vários países. Jogos como Carmageddon, Doom e Grand Theft Auto (GTA) transmitem a informação de que para obter sucesso nesses jogos é preciso ter um comportamento antiético. Observando esse contexto, foi desenvolvido os Jogos Digitais Educativos Solidários (JDES) que visam ensinar ética e solidariedade em cenários relacionados com o meio ambiente e situações de catástrofe. No processo de desenvolvimento dos JDES, é fundamental não começar sempre a partir do zero, início, faz necessário o uso de técnicas de reúso de software. Neste trabalho é apresentado um Framework Conceitual cuja finalidade é agilizar e baratear no desenvolvimento dos jogos digitais educativos solidários. O Framework Conceitual foi dividido em duas etapas, na primeira foi utilizado a modelagem UML (Linguagem de Modelagem Unificada) para projetar o Framework Jogos Digitais Educativos Solidários (FJDES) e Classes Auxiliares utilizados para a criação do Jogo Digital Educativo Solidário Enchente. Na segunda etapa foi utilizado a Modelagem Ágil e o Método Scrum para criação do Framework Scrum Jogos Digitais Educativos Solidários (FSJDES), em que foi reutilizado o FJDES e Classes Auxiliares já desenvolvidos na primeira etapa para a criação do Jogo Digital Educativo Solidário Terremoto, ambos os jogos foram implementados em Java. Com isso, houve uma redução de três meses no desenvolvimento dos Jogos Digitais Educativos Solidários, constatando que para a produção do primeiro jogo levaram-se quatro meses e para o segundo jogo levou um mês.","High violence games are mostly banned in Brazil and in several countries. Games like Carmageddon, Doom and Grand Theft Auto (GTA) convey the information that to be successful in these games you need to behave unethically. Observing this context, the Solidary Educational Digital Games (JDES) were developed, which aim to teach ethics and solidarity in scenarios related to the environment and disaster situations. In the JDES development process, it is essential not to always start from scratch, beginning, it is necessary to use software reuse techniques. This work presents a Conceptual Framework whose purpose is to streamline and cheapen the development of solidary educational digital games. The Conceptual Framework was divided into two stages, in the first, UML modeling (Unified Modeling Language) was used to design the Framework Digital Games Educational Solidarity (FJDES) and Auxiliary Classes used to create the Flood Solidarity Educational Digital Game. In the second stage, Agile Modeling and the Scrum Method were used to create the Scrum Framework Educational Solidarity Digital Games (FSJDES), in which the FJDES and Auxiliary Classes already developed in the first stage were reused for the creation of the Earthquake Solidarity Educational Digital Game, both games were implemented in Java. As a result, there was a three-month reduction in the development of Solidary Educational Digital Games, noting that the production of the first game took four months and the second game took a month.","('Frameworks', 'Jogos digitais', 'Educação', 'Ética', 'Solidariedade', 'Frameworks', 'Digital Games', 'Education', 'Ethics', 'Solidarity')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/8950","2021-11-21","https://www.repositorio.ufal.br/bitstream/123456789/8950/1/Um%20framework%20conceitual%20para%20jogos%20digitais%20educativos%20solid%c3%a1rios.pdf","A conceptual framework for solidarity educational digital games",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/7247","Campus A.C. Simões","Instituto de Computação","Dissertação","Gamification analytics model for teachers","('Kamilla Kemilly Tenório Alves dos Santos',)","('Diego Dermeval de Medeiros da Cunha Matos',)","('Ranilson Oscar Araújo Paiva', 'Seiji Isotani')","Apesar dos resultados positivos obtidos através da aplicação da gamificação no contexto de aprendizagem aprimorada por tecnologia, alguns estudos encontrados na literatura relataram resultados não esperados em relação ao engajamento, a aprendizagem e a motivação dos alunos em sistemas de aprendizagem gamificados. Portanto, com o intuito de evitar possíveis resultados negativos, esta dissertação propõe o “modelo de monitoramento e adaptação do design da gamificação para professores”. Nesse modelo, o professor pode definir metas de interação, monitorar a interação dos alunos com os recursos de aprendizagem do sistema e com os elementos de gamificação e adaptar o design da gamificação por meio do uso de missões para engajar e motivar os alunos que não estão atingindo as metas de interação definidas/esperadas. No entanto, os conceitos de design baseados no refido modelo que serão implementados em futuros sistemas de aprendizagem gamificados devem ser bem planejados para respeitar as necessidades dos professores. Consequentemente, uma das contribuições desta dissertação é a validação de 20 conceitos de design baseados no modelo feita com professores por meio do método “speed dating"". Após esta fase, os conceitos de design mais bem avaliados forneceram informações relevantes para orientar o design e o desenvolvimento de uma ferramenta, chamada GamAnalytics, que visa permitir que os professores adaptem o design gamificado de sistemas de aprendizagem durante o processo de aprendizado, com base no monitoramento de painéis que expõem informações relevantes dos alunos sobre sua interação com os recursos de aprendizagem e com os elementos de gamificação de maneira intuitiva e significativa. Além disso, os professores avaliaram on-line a ferramenta desenvolvida, onde foram medidas as seguintes métricas: utilidade percebida, facilidade de uso percebida, intenção comportamental, relevância, prazer percebido e autoeficácia. Os resultados mostraram uma alta aceitação e aprovação pelos professores da ferramenta proposta em relação às métricas medidas. Além do mais, para investigar o impacto do uso do modelo por professores através da ferramenta GamAnalytics no engajamento, aprendizagem e motivação dos alunos, foi conduzido um estudo de caso. O estudo de caso foi conduzido durante quatro semanas e foi realizado com estudantes de graduação e pós-graduação da Universidade Federal de Alagoas, matriculados no curso “Gamificação na Educação”. Os resultados sugerem uma melhoria no engajamento dos alunos, nos resultados de aprendizagem e um efeito positivo na motivação dos alunos.","There is a growing interest in applying gamification in technology-enhanced learning environ-ments in order to keep students engaged and motivated during the learning process. Although the positive outcomes obtained through the application of gamification in the technology-enhanced learning context, some studies found in the literature reported unexpected results concerning students’ engagement, learning, and motivation in gamified learning systems. A possible solution to avoid these unexpected outcomes is to monitor and adapt the gamification design of gamified learning environments during the learning process when the targeted objectives are not being achieved. Moreover, considering that the existence of teachers is essential to the success of education, teachers could be responsible to monitor and adapt gamification design in these environments. However, there is a lack of contributions in the literature that allows teachers to monitor and adapt gamification design of gamified e-learning environments in an intuitive, meaningful, enjoyable way and with no advanced technical skills required. Therefore, this dissertation proposes the “gamification analytics model for teachers”. In this model, the teacher is allowed to define interaction goals, monitor students’ interaction with the system’ learning resources and the gamification elements and adapt the gamification design through missions to engage and motivate students that are not achieving the interaction goals defined. However, the gamification analytics model-based design concepts that will be implemented in the future in gamified learning systems should be well planned to respect the teachers’ needs. Consequently, one of the contributions of this dissertation is the validation made by teachers of 20 gamification analytics model-based design concepts through the speed dating method. Therefore, the most well-rated design concepts provided relevant insights to guide the design and the development of a tool, called GamAnalytics, that aims to allow teachers to adapt the gamified design of gamified learning systems during learning process based on monitoring of dashboards that expose students‘ relevant information about their interaction with learning resources and gamification elements in an intuitive and meaningful way. Moreover, teachers evaluated the developed tool online where perceived usefulness, perceived ease of use, behavioral intention, relevance, perceived enjoyment, and self-efficacy metrics were measured. Results showed a high acceptance and approval of the proposed tool by teachers concerning the measured metrics. Furthermore, in order to investigate the impact of the use of gamification analytics models by teachers through the GamAnalytics tool on students’ engagement, learning, and motivation, a case study was conducted. The case study took place for four weeks, and it was conducted with undergraduate and graduate students of the Federal University of Alagoas who were enrolled in the ”Gamification in Education” course. Finally, the results suggest an improvement in students’ engagement, learning outcomes and a positive effect on students’ motivation.","('Gamificação', 'Ambiente educativo', 'Tomada de decisão', 'Análise dos dados', 'Ambientes educacionais gamificados', 'Tomada de decisão informada por dados', 'Gamification', 'Gamified learning environments', 'Data-informed decision-making', 'Gamification analytics')","Ciência da Computação","eng","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/7247","2020-05-22","https://www.repositorio.ufal.br/bitstream/riufal/7247/3/Gamification%20analytics%20model%20for%20teachers.pdf","Modelo de análise da gamificação para professores","('Alan Pedro da Silva',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/1830","Campus A.C. Simões","Instituto de Computação","Dissertação","Uma ferramenta para construção e avaliação de mapas conceituais: aplicada ao ensino da disciplina Desenho Técnico I","('Emanuela Cristina Montoni da Silva',)","('Fábio Paraguaçu Duarte da Costa',)","('Marcus de Melo Braga', 'Andiara Valentina de Freitas e Lopes')","Esta dissertação apresenta a especificação e implementação de uma nova ferramenta baseada na Aprendizagem Significativa de Ausubel, mais especificamente nos mapas conceituais de Novak, para auxiliar o processo de ensino-aprendizagem da disciplina desenho técnico para os cursos de Engenharia Civil e Arquitetura, denominada de Dedalus. Para fundamentar o papel pedagógico da ferramenta desenvolvida será apresentado um breve resumo do trabalhado de Ausubel, do uso da informática na educação e de aplicações de mapas conceituais no desenvolvimento de softwares educativos. A funcionalidade da ferramenta Dedalus é verificar se o aluno é capaz de construir o mapa conceitual da planta baixa de uma edificação, proposta como exercício pelo professor, considerando que ele só poderá utilizar as relações fornecidas pelo professor que estejam em consonância com o conteúdo ministrado pelo mesmo até o momento atual. A metodologia adotada na realização do trabalho foi: estudar o conteúdo pedagógico da disciplina Desenho Técnico I; analisar os conceitos e as relações presentes no conteúdo estudado; desenvolver um conjunto de exercícios para cada tópico da disciplina; planejar a interface da ferramenta e implementar a ferramenta. A ferramenta foi aplicada em 2 turmas de graduação do Curso de Arquitetura e Urbanismo do Centro Universitário CESMAC. Os resultados obtidos foram satisfatórios, tanto em relação a facilidade de uso da ferramenta, quanto ao aprendizagem do conteúdo programático da disciplina Desenho Técnico I.","This paper presents the specification and implementation of a new tool based on Meaningful Learning of Ausubel, more specifically on conceptual maps of Novak, to assist the teaching and learning of technical design discipline for courses Civil Engineering and Architecture, named Dedalus. To substantiate the role of pedagogical tool developed will be presented a brief summary of worked Ausubel, the use of computers in education and application of conceptual maps in developing educational software. The functionality of the tool Dedalus is whether the student is able to build the conceptual map of the floor plan of a building, as proposed by Professor exercise, considering he can only use the links provided by the teacher that are consistent with the content taught by even until today. The methodology used in conducting the study was: to study the educational content of the discipline Technical Design I; analyzing the concepts and relations present in the content studied and develop a set of exercises for each topic of the course; planning tool interface and implement the tool. The tool was applied in two undergraduate classes in Architecture and Urbanism of the University Center CESMAC. The results were satisfactory, both for the ease of use of the tool, as the learning curriculum of discipline Technical Drawing I.","('Desenho técnico', 'Mapa conceitual', 'Technical drawing', 'Concept map')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1830","2012-12-07","https://www.repositorio.ufal.br/bitstream/riufal/1830/1/Uma%20Ferramenta%20para%20Constru%c3%a7%c3%a3o%20e%20Avalia%c3%a7%c3%a3o%20de%20Mapas%20Conceituais-%20Aplicada%20ao.pdf","A tool for building and evoluating concept maps applied to teaching discipline Technical Drawing I","('Roberta Vilhena Vieira Lopes',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/1601","Campus A.C. Simões","Instituto de Computação","Dissertação","Uma ferramenta para recomendação pedagógica em mineração de dados educacionais","('Ranilson Oscar Araújo Paiva',)","('Ig Ibert Bittencourt Santana Pinto',)","('Aydano Pamponet Machado', 'Seiji Isotani')","A presente dissertação trata da criação de uma ferramenta para a recomendação pedagógica cujo objetivo é prover aos professores de cursos baseados na web, recomendações pedagógicas personalizadas geradas com base nos resultados da Mineração dos Dados Educacionais de seus alunos. Para orientar essa criação propomos o Processo de Recomendação Pedagógica, o qual conta com o trabalho conjunto e coordenado da Inteligência Humana (especialistas nos domínios envolvidos) e da Inteligência Artificial (ferramentas computacionais). O processo é constituído de quatro etapas que ocorrem de forma cíclica e sequencial, iniciando com ""Detectar Práticas"", onde detectamos se existem ações afetando o processo de ensino e aprendizagem. Na etapa seguinte, ""Descobrir Padrões"", utilizamos as técnicas de Mineração de Dados Educacionais, por meio de Cenários de Mineração predefinidos, para encontrar padrões de interesse pedagógico acerca das práticas detectadas. Na próxima etapa, ""Recomendar"", são oferecidas recomendações apropriadas a atual situação pedagógica do aluno. Finalmente a etapa ""Monitorar e Avaliar"", onde acompanhamos e analisamos se os alunos foram afetados positivamente pelas recomendações e se estas foram relevantes. A ferramenta de recomendação proposta foi utilizada em um estudo de caso, com dados reais provenientes de um curso de Língua Espanhola com 200 alunos que produziram mais de 700 megabytes de informações dispostas em, aproximadamente, 1220000 triplas. Como resultados, fomos capazes de detectar práticas e os padrões associados a elas, que foram utilizados na criação de recomendações, avaliadas (relevância) por especialistas no domínio educacional/pedagógico, e disponibilizadas para que os usuários finais (professores) as ofereçam a seus alunos.","This work is about the creation of a tool for pedagogical recommendation which objective is to provide teachers, from web-based courses, personalized pedagogical recommendations generated based on the mining results of their students' educational data. In order to guide this creation, we propose the Pedagogical Recommendation Process that counts on the coordinated work and cooperation of the Human Intelligence (domain specialists) and the Artificial Intelligence (computational tools). The process is constituted of four steps that occur in a sequential and cyclic way, starting with ""Detect Practices"", where we detect if there are actions affecting the teaching and learning process. Is the next step, ""Discover Patterns"", we use educational data mining techniques, based on predefined mining scenarios, to find patterns with pedagogical significance for the practices detected. In the following step, ""Recommend"", it is where appropriate recommendations are offered, given the students' current pedagogical situation. Finally, the ""Monitor and Evaluate"" step, where it is analyzed whether the students were positively affected by the recommendations and if they were relevant. The proposed tool was used in a case study with real data provided by a Spanish language course with 200 students enrolled, who produced more than 700 megabytes of information contained in, approximately, 1220000 triples. As results we were able to detected practices and the patterns associated to them, which were used to create recommendations, evaluated (relevance) by specialists in the educational/pedagogical domain and made available for the final users (teachers) to suggest them to their students.","('Cursos baseados na Web', 'Mineração de dados educacionais', 'Processo de recomendação pedagógica', 'Educational Data Mining', 'Recommender Systems', 'Pedagogical Recommendation Process')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1601","2013-06-30","https://www.repositorio.ufal.br/bitstream/riufal/1601/1/Uma%20ferramenta%20para%20recomenda%c3%a7%c3%a3o%20pedag%c3%b3gica%20baseada%20em%20minera%c3%a7%c3%a3o%20de%20dados%20educacionais.pdf","A tool for pedagogical recommendation on educational data mining","('Alan Pedro da Silva',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/1731","Campus A.C. Simões","Instituto de Computação","Dissertação","FOCA: uma metodologia que utiliza princípios da representação do conhecimento para avaliação de ontologias","('Judson Melo Bandeira',)","('Ig Ibert Bittencourt Santana Pinto',)","('Bernadette Farias Lóscio', 'Alan Pedro da Silva')","Ontologia é um termo originado na Filosofia através dos termos gregos “ontos” (ser) e “logos” (estudo), que significa o estudo do ser enquanto ser. Este termo foi trazido para a Ciência da Computação como sendo um artefato computacional que representa o conhecimento de determinado universo do discurso. Uma das formas de se fazer isto é através dos cinco papeis da representação do conhecimento: substituto, compromisso ontológico, raciocínio inteligente, eficiência computacional e expressão humana. Em ciência da computação, as ontologias são aplicadas em muitas áreas como, por exemplo, em Engenharia de Requisitos, Banco de Dados, Web Semântica e Dados Conectados. A subárea responsável pelo processo de construção de ontologias é a engenharia de ontologia, que conta com aproximadamente vinte metodologias. Entretanto, conhecer bem o domínio, definir corretamente os conceitos envolvidos nele e ao mesmo tempo cumprir os papeis da representação do conhecimento tornam modelar ontologia uma tarefa bastante árdua. Desta forma, quanto maior a complexidade da ontologia, mais a sua qualidade tende a cair, reduzindo o seu potencial de reuso. Por consequência, o processo de avaliação da qualidade de uma ontologia se torna uma tarefa fundamental. A literatura da área propôs diferentes abordagens para avaliação de ontologias, porém as mesmas são baseadas em métricas de qualidade que não guiam os avaliadores na tomada de decisão sobre a qualidade da ontologia. Como resultado, o estabelecimento da qualidade da ontologia se torna uma tarefa mais dependente da experiência do avaliador e menos dependente de critérios de representação de conhecimento. Uma forma de simplificar este processo é guiar o avaliador sobre quais critérios estão relacionados com cada papel da representação do conhecimento. Este trabalho estabelece uma metodologia para avaliação de ontologias, a qual tem como base uma correspondência entre os papeis da representação do conhecimento com os principais critérios de qualidade para a avaliação de ontologia. Esta correspondência é construída através da abordagem Goal, Question, Metric. Este método consiste em três fases: Verificação do Tipo da Ontologia; Verificação das Questões e Verificação da Qualidade da ontologia. Este método foi validado através da realização de um experimento que objetiva mostrar que a metodologia conduz avaliadores com diferentes experiências em ontologia para o mesmo resultado de avaliação. Como resultado do experimento, foi possível criar uma fórmula para escores global e parcial para a qualidade da ontologia, validando-a.","Ontology is a term originated in Philosophy through the Greek terms ""ontos"" (being) and ""logos"" (study), which means the study of being qua being. This term was brought to Computer Science as a computational artifact that represents knowledge of a certain universe of discourse. One way to do this is through the five roles of knowledge representation: substitute, ontological commitment, intelligent reasoning, computational efficiency and human expression. In computer science, ontologies are applied in many areas such as Requirements Engineering, Database, Semantic Web and Linked Data. The subarea responsible for ontology building process is ontology engineering, which has about twenty methodologies. However, knowing well the domain, defining the concepts involved in it correctly and at the same time comply the knowledge representation roles make ontology modeling an arduous task. Thus, how bigger is the complexity of ontology, the more its quality tends to decrease, reducing the reuse’s potential. Consequently, the quality of the evaluation process of an ontology becomes a fundamental task. The literature of this area proposed different approaches for ontology evaluation, but they are based on quality metrics that do not guide the evaluators in decision making about the quality of ontology. As a result, the establishment of ontology quality becomes more dependent on the experience of the evaluator and less dependent on the knowledge representation criteria. One way to simplify this process is to guide the evaluator about what criteria are related to each role of knowledge representation. This work establishes a methodology for ontology evaluation, which is based on a match between the roles of knowledge representation with the main quality criteria for the ontology. This match is built by Goal, Question, Metric approach. This methodology consists of three phases: Ontology Type Verification; Questions Verification and ontology Quality Verification. This methodology was validated by conducting an experiment that aims to show that the methodology leads evaluators with different experiences in ontology to the same evaluation result. As a result of the experiment, was possible create a formula for global and partial scores for the quality of ontology, validating it.","('Ontologia', 'Ambientes virtuais de aprendizagem', 'Ontology', 'Virtual learning environments')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1731","2015-08-03","https://www.repositorio.ufal.br/bitstream/riufal/1731/1/FOCA%20-%20uma%20metodologia%20que%20utiliza%20princ%c3%adpios%20de%20representa%c3%a7%c3%a3o%20do%20conhecimento%20para%20avalia%c3%a7%c3%a3o%20de%20ontologias.pdf","FOCA: a methodology that uses principles of knowledge representation for evaluation of ontologies","('Patrícia Leone Espinheira Ospina',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/1850","Campus A.C. Simões","Instituto de Computação","Dissertação","Ferramentas interativas em ambientes virtuais de aprendizagem e sua usabilidade pedagógica nos cursos de educação a distância da UFAL e IFAL","('Flávio Pereira da Silva',)","('Anderson de Barros Dantas',)","('Arturo Hernández-Domínguez', 'André Ricardo Magalhães')","O trabalho aqui exposto visa apresentar um Modelo de Aferição de Usabilidade em Ambientes Virtuais de Aprendizagem -AVA no contexto da Educação a Distância -EaD, aplicado aos cursos desta modalidade de ensino, no âmbito das Instituições Públicas de Ensino Superior de Alagoas: Universidade Federal e Instituto Federal. Variante do conceito de Usabilidade proposto por Jakob Nielsen. É uma definição pouco estudada e difundida; Baseada nos estudos de Petri Nokelainen, a Usabilidade Pedagógica está vinculada ao contexto da produção de material na EaD para os AVA’s e nas escolhas metodológicas que o professor-autor realiza. As dimensões propostas pelo modelo são: Controle do Aprendiz, Atividade do Aprendiz, Aprendizagem Colaborativa / Cooperativa, Orientação ao Objetivo, Aplicabilidade, Valor Agregado, Motivação, Valorização do Prévio Conhecimento, Flexibilidade e Feedback. Com base nestas dimensões foi gerado um questionário, posteriormente aplicado aos alunos pertencentes a ambas instituições de ensino. Duzentos e sessenta e um estudantes foram analisados. Do processamento dos dados, realizados via Plataforma SPSS, pode-se chegar aos seguintes resultados: o Moodle foi melhor ambiente virtual avaliado em termos de usabilidade; As mulheres foram mais motivadas e independentes; O IFAL se destacou como instituição de ensino aplicando sua metodologia de preparação de material didático e pedagógico dentro dos AVA’s.","The work exposed here is to provide a Model Gauging Usability in Virtual Learning Environments -VLE in the context of Distance Learning -DL, courses applied to this type of teaching, under the Public Institutions of Higher Education of Alagoas, Brazil: Universidade Federal and Instituto Federal. Variant of the proposed concept of Usability by Jakob Nielsen. It is a setting little studied and widespread; Based on studies of Petri Nokelainen, Pedagogical Usability is tied to the context of production material in DL for the VLE and methodological choices in the teacher-author realizes. The dimensions suggested by the model are: Learner Control, Learner Activity, Cooperative / Collaborative Learning, Goal Orientation, Applicability, Added Value, Motivation, Valuation of Previous Knowledge, Flexibility and Feedback. Based on these dimensions was generated a questionnaire later applied to the students belonging to the both schools. Two hundred and sixty-one students were analyzed. The data processing was conducted by SPSS platform, you can reach the results of: Moodle virtual environment was better measured in terms of usability; Women were more motivated and independent; IFAL stood out as a educational institution applying its methodology teaching material preparation and teaching within the AVA's.","('Tecnologia educacional', 'Ensino à distância', 'Pedagogia', 'Educational technology', 'Distance learning', 'Pedagogy')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1850","2010-11-11","https://www.repositorio.ufal.br/bitstream/riufal/1850/1/Ferramentas%20interativas%20em%20ambientes%20virtuais%20de%20aprendizagem%20e%20sua%20usabilidade%20pedag%c3%b3gica%20nos%20cursos%20de%20educa%c3%a7%c3%a3o%20a%20dist%c3%a2ncia%20da%20UFAL%20e%20IFAL.pdf","Interactive tools in virtual environments learning and their pedagogical usability in the distance education courses at UFAL and IFAL","('Fábio Paraguaçu Duarte da Costa',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/5870","Campus A.C. Simões","Instituto de Computação","Dissertação","Uma ferramenta automática de apoio à avaliação funcional da mão em pacientes com artrite reumatóide","('Juliana Sette Rego de Melo',)","('Marcelo Costa Oliveira',)","('Michelle Jacintha Cavalcante Oliveira', 'Valfrido Leão de Melo Neto')","A Artite Reumatoide (AR) é uma doença inflamatória crônica, sistêmica e progressiva, que envolve principalmente punhos e mãos. É geralmente simétrica, e conduz, se não tratada, a deformidades articulares e limitação da amplitude de movimentos. Objetivouse validar o leap motion como ferramenta de avaliação funcional da amplitude de movimento do punho, articulações metacarpofalangeanas e interfalangeanas proximais em pacientes com diagnóstico de AR. Além de validar uma ferramenta, foi desenvolvido um protótipo para avaliar amplitude de movimento pelo dispositivo leap motion. Foram incluídos no estudo um total de 18 pacientes (avaliadas 36 mãos e 198 articulações): 4 (22,2%) do sexo masculino e 14 (77,8%) do sexo feminino. Todos diagnosticados com artrite reumatóide. O leap motion foi capaz de detectar a ADM de todas as articulações estudadas em todos os pacientes, exceto em um paciente que apresentava alto grau de deformidade em flexão do punho. Ademais, constatou-se a validade convergente por meio da correlação r de Pearson (variaram de 0,5 a 0,7) entre os escores médios das medidas de amplitude de movimento mensuradas pelo leap motion e pelo goniômetro convencional. Conclui-se que para o dia a dia do médico e do fisioterapeuta a utilização do leap motion na avaliação de pacientes com AR pode constituir uma ferramenta alternativa para mensurar a ADM das articulações das mãos e punhos. Outrossim, embora estudos com outras doenças osteoarticulares das mãos e punhos precisem ser realizados, o leap motion também pode constituir método propedêutico útil na avaliação da ADM deste grupo de pacientes.","Rheumatoid arthritis (RA) is a chronic, systemic and progressive inflammatory disease involving mainly wrists and hands. It is generally symmetrical, and leads, if untreated, to joint deformities and limited range of motion. The objective of this study was to validate leap motion as a tool for the functional evaluation of the range of motion of the wrist, proximal metacarpophalangeal and interphalangeal joints in patients with RA. In addition to validating a tool, a prototype was developed to evaluate the range of motion by the leap motion device. A total of 18 patients (36 hands and 198 joints) were included in the study: 4 (22.2%) were male and 14 (77.8%) were female. All diagnosed with rheumatoid arthritis. The leap motion was able to detect the ROM of all joints studied in all patients, except in one patient who presented a high degree of deformity in flexion of the wrist. In addition, the convergent validity was found through Pearson's correlation (ranging from 0.5 to 0.7) between the mean scores of the range of motion measured by the leap motion and the conventional goniometer. It is concluded that for the daily routine of the physician and physiotherapist the use of leap motion in the evaluation of patients with RA can be na alternative tool to measure the ROM of the joints of the hands and wrists. Furthermore, although studies with other osteoarticular diseases of the hands and wrists need to be performed, leap motion may also be a useful propaedeutic method for evaluating the ROM of this group of patients.","('Goniometria', 'Articulações – Amplitude de movimento – Medição', 'Artrite reumatóide', 'Leap motion – Sensor de movimento', 'Rheumatoid arthritis', 'Range of motion', 'Goniometry')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/5870","2016-01-16","https://www.repositorio.ufal.br/bitstream/riufal/5870/1/Uma%20ferramenta%20autom%c3%a1tica%20de%20apoio%20%c3%a0%20avalia%c3%a7%c3%a3o%20funcional%20da%20m%c3%a3o%20em%20pacientes%20com%20artrite%20reumat%c3%b3ide.pdf","","('Thiago Sotero Fragoso',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/3063","Campus A.C. Simões","Instituto de Computação","Dissertação","Um estudo para identificar fatores de influência na produtividade de desenvolvedores em projetos de software","('Rafael Fernandes Pugliese de Morais',)","('Evandro de Barros Costa',)","('Arturo Hernández-Domínguez', 'Baldoíno Fonseca dos Santos Neto')","Procurando aumentar a competitividade, muitas empresas investem em melhorias em processos de software. A aplicação de melhorias em processos de software trás vários benefícios (Silveira et al., 2013; Simões et al., 2011; Tonini et al., 2008; Bouer & Carvalho, 2005), dentre eles, o aumento na qualidade dos dados de predição. Na literatura (Hamdan & Madi, 2011a; Jorgensen, 2011; Lopez-Martin et al., 2012) são identificados vários aspectos negativos por conta de imprecisões em estimativas de projetos de software. Diante deste cenário, este trabalho descreve procedimentos para identificação de fatores que afetam a produtividade em projetos de software modernos, visto que esta medida é fundamental para a elaboração de estimativas de prazo, custo e esforço para projetos. Com a identificação dos fatores que afetam a produtividade de software, é possível entender o comportamento dos desenvolvedores e realizar ações para diminuir a instabilidade da produtividade e consequentemente reduzir os problemas enfrentados por empresas neste contexto, problemas esses que são citados na literatura por autores como Hamdan & Madi (2011b), Jørgensen & Sjøberg (2004) e Lopez-Martin et al. (2012). Os procedimentos elaborados utilizam como ferramentas controle estatístico de processo, regressão linear, gráfico de Pareto e são baseados no arcabouço proposto por Florac & Carleton (1999) e Montoni et al. (2007). Os procedimentos foram aplicados em projetos atuais de uma empresa de desenvolvimento de software de Alagoas e os resultados trouxeram benefícios para o processo de desenvolvimento adotado na empresa.","Looking to increase competitiveness, many companies invest in improvements in software processes. The application of improvements in software processes brings several benefits (Silveira et al., 2013; Simões et al., 2011; Tonini et al., 2008; Bouer & Carvalho, 2005), such as improvements on process prediction. In literature (Hamdan & Madi, 2011a; Jorgensen, 2011; Lopez-Martin et al., 2012) several negative aspects are identified due to inaccuracies in software projects estimates. Given this scenario, this master work describes procedures to identify factors that affect productivity in modern software projects, which is fundamental for the elaboration of time, cost and effort estimation in software projects. By identifying the factors that affect software productivity, it is possible to understand the behavior of developers and perform actions to reduce productivity instability and consequently reduce the problems faced by companies in this context, which are related in literature by authors such as Hamdan & Madi (2011b), Jørgensen & Sjøberg (2004) and Lopez-Martin et al. (2012). The elaborated procedures use statistical process control, linear regression, Pareto graph and are based on the framework proposed by Florac & Carleton (1999) and Montoni et al. (2007). The procedures were applied in current projects of a software development company in Alagoas and the results brought benefits to the development process used by the company.","('Modelagem computacional', 'Produtividade de software', 'Controle estatístico de processos', 'Regressão linear', 'Gráfico de pareto', 'Computational modeling', 'Software Productivity', 'Statistical process control', 'Linear Regression', ""Pareto's chart"")","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/3063","2018-03-07","https://www.repositorio.ufal.br/bitstream/riufal/3063/1/Um%20estudo%20para%20identificar%20fatores%20de%20influ%c3%aancia%20na%20produtividade%20de%20desenvolvedores.pdf","","('Reinaldo Cabral Silva Filho', 'Patrick Henrique da Silva Brito')"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/3361","Campus A.C. Simões","Instituto de Computação","Dissertação","Uma ferramenta de apoio a análise de risco biomecânico de trabalhadores em ambiente informatizado","('Thayse Justino Montenegro Falcão',)","('Evandro de Barros Costa',)","('Aydano Pamponet Machado', 'Ana Rosa Almeida Alves', 'Álvaro Alvares de Carvalho César Sobrinho')","A norma regulamentadora NR-17 estabelece parâmetros que permitem a adaptação das condições de trabalho às características psicofisiológicas dos trabalhadores. As adaptações envolvem uma análise ergonômica do posto de trabalho, cuja etapa principal é a de avaliação de riscos que desencadeiam efeitos musculoesqueléticos danosos e irreversíveis. Com o avanço tecnológico, tem-se visto um número crescente de postos de trabalho computador dependente, que produzem sobrecarga de trabalho estático dos músculos posturais exigindo deste músculo mecanismos de recuperação, é o caso das pausas que precisam ser feitas para que haja lubrificação dos tendões pelo liquido sinovial e retorno do fluxo normal do sangue. A literatura dispõe de ferramentas de avaliação de risco que são introduzidas na prática de forma observacional ou fazendo uso de softwares de análise angular. Tais métodos tornam-se onerosos, invasivos e bastante subjetivos, além de proporcionar grande variabilidade entre examinadores. Em face disto, objetivou-se construir uma ferramenta automática de avaliação de risco biomecânico para trabalhadores de ambiente informatizado com base no que se dispõe de limites angulares e tempo de risco presentes na literatura. Para validação foram incluídos no estudo um total de 38 trabalhadores administrativos: 26(68,42%) do gênero feminino e 12 (31,58%) do gênero masculino. Avaliados 152 movimentos e comparados a softwares já estabelecidos e usados. A solução desenvolvida foi capaz de avaliar os movimentos de Flexão cervical, inclinação de tronco, abdução e flexão de ombro e proporcionar uma avaliação em tempo real sem a necessidade de marcadores conforme fazem os outros softwares. Ademais, constatou-se por meio do teste de Wilcoxon que valores de p não apresentam diferenças significativas nos movimentos de flexão cervical e inclinação anterior de tronco, não invalidando, porém achados de valores similares entre softwares encontrados na abdução de ombro. Embora tenha sido encontrado algumas diferenças na captura de alguns movimentos, o mesmo apresenta uma estrutura que une praticidade, agilidade e devolutiva imediata ao trabalhador o que o torna um diferencial na pratica do profissional especialista. Conclui-se que esse método de avaliação predominantemente preventivo é válido em virtude de achados similares entre softwares já existentes e o modelo proposto.","The NR-17 establishes parameters that allow the adaptation of the working conditions with psychophysiological characteristics of the workers. The adaptations involve an ergonomic analysis of the workplace, whose main stage is the risk assessment that trigger damaging and irreversible musculoskeletal effects. With the technological advance, we have seen na increasing number of computer-dependent workers, which produce static work overload of the postural muscles that requires recovery mechanisms, is the case of pauses that need to be made for the lubrication of the tendons with synovial fluid and the return of normal blood flow. The literature offers risk assessment devices that are introduced in observational practice or making use of angular analysis software. Such methods become costly, invasive and highly subjective, and provide great variability among examiners. In face of this, the objective was to build an automatic biomechanical risk assessment tool for workers at computerized workstation based on angular limits and risk time present in the literature. To validation a total of 38 administrative workers were included in the study: 26 (68.42%) of the female gender and 12 (31.58%) of the male gender. Evaluated 152 movements and compared with established and used software. The solution developed was able to evaluate neck flexion, trunk inclination, shoulder abduction and flexion abduction and provide a real-time evaluation without the need for markers as the other software do. In addition, the Wilcoxon test showed p-values wich don´t present significant differences in the movements of neck flexion and anterior trunk inclination but did not invalidate similar values between softwares found in abduction of the shoulder. It is concluded that this device is a predominantly preventive evaluation method that is valid due to similar findings between softwares and between the device built with each software. Although some differences have been found in the capture of some movements, it presents a structure that combines practicality, agility and immediate return to the worker, which makes a differential in the specialists practice.","('Ferramenta de apoio -Avaliação', 'Análise de risco -Biomecânico', 'Trabalhadores -Ambiente informatizado', 'Search Engine', 'Risk Assessment -Biomechanical', 'Workers -Computerized environment', 'Computer -Use')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/3361","2018-06-19","https://www.repositorio.ufal.br/bitstream/riufal/3361/1/Uma%20ferramenta%20de%20apoio%20a%20an%c3%a1lise%20de%20risco%20biomec%c3%a2nico%20de%20trabalhadores%20em%20ambiente%20informatizado.pdf","A tool for supporting biomechanical risk analysis of workers in computerized worstation","('Leandro Dias da Silva',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/6813","Campus A.C. Simões","Instituto de Computação","Dissertação","Estudo em séries temporais financeiras utilizando redes neurais recorrentes","('Daniel Kazuyuki Fugii Matsumoto',)","('Heitor Soares Ramos Filho',)","('Osvaldo Aníbal Rosso', 'Leonardo Viana Pereira')","Entender o comportamento das séries temporais financeiras, é de suma importância para conseguir prever valores futuros e tomar decisões eficientes. Esta área é frequentemente alvo de estudos e novas propostas na tentativa de sua modelagem, pois é muito volátil em resposta ao dinamismo do mercado. Essa volatividade é definida pela alta quantidade de variáveis e diferentes fontes de informações, baixa relação entre sinal e ruído, tornando falhas as suas predições ao generalizar o problema. Além de existir relações entre variáveis exóginas desconhecidas e aleatórias, capazes de forte influência na estrutura corrente dos dados. Contudo, assim como pode causar grande revés uma informação incorreta, uma informação mais correta pode gerar lucros proporcionais, garantindo assim que este problema seja objeto de diversos estudos durante a história. Para este objetivo, foi projetado um modelo preditivo utilizando Redes Neurais Recorrentes (LSTM) alimentada de seus valores históricos (série temporal) para a previsão da tendência de variação do valor de abertura de um ativo (stock). Dessa forma, uma variedade de experimentos foram executados e seus resultados analisados em relação à métricas largamente utilizadas, como os modelos autoregressivos (ARIMA) para definir uma base comparativa e verificar a capacidade do modelo. Os resultados obtidos foram satisfatórios, obtendo uma acurárica de até 74:50% ao prever o sinal do próximo valor de abertura, inferindo se uma determinada ação irá subir ou não em um ponto no futuro.","Understanding the behavior of financial time series is very importance to forecast future values and make efficient decisions. This area is often the target of studies and new proposals in the attempt of its modeling, since it is very volatile in response to the dynamism of the market. This volatility is defined by the high number of variables and different sources of information, a low signal-to-noise ratio, and its predictions fail to generalize the problem. In addition to existing relations between unknown and random exogenous variables, capable of strong influence on the current structure of the data. However, just as incorrect information can cause great misfortune, more accurate information can generate proportional profits, thus ensuring that this problem is the subject of several studies throughout history. For this purpose a predictive model was designed using Recurrent Neural Networks (LSTM), fed from its historical dataset (time series) to forecast the oppening value trend of variation for an asset (stock). Thus a variety of experiments were performed and their results analyzed against the widely used metrics, like autoregressive models (ARIMA) to define a basis for comparisons and validate the model capacity. The results obtained were satisfactory, obtaining an acuracy of up to 74:50% by predicting the sign of the next opening value, inferring whether or not a given stock will rise in the future.","('Análise de séries temporais', 'Séries financeiras', 'Domínio de tempo', 'Redes neurais (Computação)', 'Redes neurais recorrentes', 'Mercado financeiro', 'Autoregressive integrated moving average', 'Long short-term memory', 'Time series analysis', 'Financial series', 'Time domain', 'Neural networks (Computing)', 'Recurrent neural networks', 'Financial market')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/6813","2019-12-10","https://www.repositorio.ufal.br/bitstream/riufal/6813/3/Estudo%20em%20s%c3%a9ries%20temporais%20financeiras%20utilizando%20redes%20neurais%20recorrentes.pdf","Study in financial time series using recurrent neural networks",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/1603","Campus A.C. Simões","Instituto de Computação","Dissertação","Expert mentoring: assistente inteligente para auxiliar gerentes na determinação de evidências objetivas requeridas na avaliação MA-MPS","('Livia Maria Omena da Silva',)","('Rodrigo de Barros Paes',)","('Patrick Henrique da Silva Brito', ""Cláudio Nogueira Sant'Anna"")","A avaliação de processo de software é considerada uma ferramenta importante e, comumente, usada para apontar o caminho, onde a organização precisa aplicar seus esforços em prol da melhoria dos processos. Em particular, a avaliação de processos proposta pelo MA-MPS exige a apresentação de evidências objetivas que comprovem a satisfação dos resultados esperados de processos e resultados de atributos de processos de determinado nível de maturidade. O problema da apresentação de evidências objetivas se resume na dificuldade dos gerentes responsáveis pelos processos em interpretar esses resultados descritos na Planilha de Indicadores. Além disso, há casos em que o implementador do modelo MPS não dispõe de tempo suficiente para acompanhar todo o preenchimento ou revisão da planilha, antes de submetê-la À avaliação de processos. Assim, a ocorrência de erros de preenchimento pode acontecer e comprometer o resultado da avaliação. Neste contexto, é apresentado o assistente inteligente, Expert Mentoring, cujo objetivo é apoiar, através de perguntas, os gerentes responsáveis pelos processos na interpretação dos resultados esperados de processos e resultados de atributos de processos descritos na Planilha de Indicadores, onde ao final destas perguntas sugere indicadores diretos e indiretos, que sejam mais adequados para a comprovação destes resultados. Nesse sentido, os principais resultados obtidos com a avaliação do Expert Mentoring foram: a diminuição do número de erros de preenchimento da planilha, e a recordação do nome do indicador, antes mesmo da sugestão do assistente inteligente.","The evaluation of software process is considered an important tool and commonly used to point out the way, where the organization must apply its efforts to improve processes. In particular, the assessment process proposed by the MA-MPS requires the presentation of objective evidence showing satisfaction of the expected results of processes and results of process attributes of a certain level of maturity. The problem of presentation of objective evidence boils down in the difficulty of the managers responsible for processes in interpreting these results described in the Spreadsheet of Indicators. In addition, there are cases where the implementer of the MPS model not has enough time to monitor the entire fill or revision of the spreadsheet, before submitting it for evaluation of processes. Thus, the occurrence of errors in filling can occur and affect the outcome of the evaluation. In this context, is presented the intelligent assistant, Expert Mentoring, which is designed to support, through questions, the managers responsible for processes in the interpreting the expected results of processes and results of attributes of process described in the Spreadsheet of Indicators, where the final of these questions will suggest direct and indirect indicators, which are more suitable for proof of these results. In this sense, the main results of the evaluation of the Expert Mentoring were: decreasing the number of errors in completing the spreadsheet, and recall the name of the indicator, even before the suggestion of the intelligent assistant.","('Avaliação de processo de software', 'Planilha de indicadores do MPS.BR', 'Assistente inteligente', 'Sistemas especialistas', 'Software process assessment', 'Spreadsheet of indicators the MPS.BR', 'Intelligent assistant', 'Expert systems')","Ciência da Computação","eng","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1603","2011-06-27","https://www.repositorio.ufal.br/bitstream/riufal/1603/1/Expert%20mentoring%20-%20assistente%20inteligente%20para%20auxiliar%20gerentes%20na%20determina%c3%a7%c3%a3o%20de%20evid%c3%aancias%20objetivas%20requeridas%20na%20avalia%c3%a7%c3%a3o%20MA-MPS.pdf","Expert mentoring: inteligente assistant to assist managers the determination of objetive evidence required to assess the MA-MPS","('Evandro de Barros Costa',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/853","Campus A.C. Simões","Instituto de Computação","Dissertação","FA_PorT: um framework para sistemas portfólio-tutor baseado em agentes","('Fábio Nicácio de Medeiros',)","('Arturo Hernández-Domínguez',)","('Evandro de Barros Costa', 'Fábio Paraguaçu Duarte da Costa', 'Edilson Ferneda')","A Educação a Distância (EAD) amplia o alcance da modalidade de ensino presencial, já que fornece aos indivíduos, independentemente do local onde moram ou tempo disponível, a oportunidade de iniciar ou complementar seus estudos. Em virtude da facilidade de acesso, disponibilidade e recursos de interação existentes, a Internet é uma mídia bastante utilizada na EAD. O objetivo deste trabalho Ã© projetar e implementar um framework, FA_PorT, para sistemas Portfólio-Tutor acoplado a um sistema Tutor Inteligente (STI) utilizando Agentes e apresentar duas aplicações Portfólio-Tutor, criadas a partir do framework. O FA_PorT visa propor um modelo de ambiente interativo de ensino e aprendizagem baseado numa arquitetura para sistemas Portfólio-Tutor. Cada sistema Portfólio-Tutor construído a partir do framework pode ser utilizado no contexto de ambientes de EAD na web. O framework proposto objetiva o reaproveitamento da estrutura interna (núcleo comum) de um sistema Portfólio-Tutor baseado em STI e Agentes, fazendo com que o tempo de desenvolvimento de um novo sistema Portfólio-Tutor seja reduzido","Distance Education expands the scope of the inside classroom teaching model since anybody, independent of where he lives or how much available time he has, has the opportunity to initiate or complement his studies. Considering access facility, availability and interaction resources provided, the Internet is a midia sufficiently used for Distance Education. This work has as objective the design and implementation of a framework, FA_PorT,for Portfolio-Tutoring systems coupled a Intelligent Tutoring Systems (STI) and using agents and present two applications Portfolio-Tutoring, created from the framework The FA_PorT mainly aiming the design of a model computer-based interactive learning environment for Portfolio-Tutoring systems. Each system Portfolio-Tutoring will be able to be used in the context of environment for EAD in the web. The framework proposed, aims to reuse of internal architecture (or skeleton) of a portfolio-tutoring system based on ITS and Agents, doing with that development time of a new portfolio-tutoring system will be reduced.","('Distance learning', 'Framework (Software architecture)', 'Eletronic portfolio', 'Intelligent tutorial systems', 'Ensino a distância', 'Framework (Arquitetura de software)', 'Portfólio eletrônico', 'Sistemas tutoriais inteligentes', 'Agentes dos serviços de inteligência', 'Intelligence agents')","Sistemas de Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/853","2006-12-11","https://www.repositorio.ufal.br/bitstream/riufal/853/1/FA_PorT%3a%20um%20framework%20para%20sistemas%20portf%c3%b3lio-tutor%20baseado%20em%20agentes.pdf","FA_PorT: a framework for portfolio-tutoring systems basead in agents",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/2102","Campus A.C. Simões","Instituto de Computação","Dissertação","Estudo e desenvolvimento de uma solução para o auxílio ao cuidado à saúde","('Álvaro Alvares de Carvalho César Sobrinho',)","('Leandro Dias da Silva',)","('Rodrigo de Barros Paes', 'Maria Eliete Pinheiro', 'Cleumar da Silva Moreira', 'Angelo Perkusich')","A utilização de dispositivos que possuem tecnologias como Bluetooth e Wi-Fi facilitam a troca de informações e a execução remota de ações. A computação aplicada a assistência médica tem acompanhado o crescimento das tecnologias sem o possibilitando o cuidado remoto para pacientes com di culdades de locomoção, ou para aqueles que almejam uma vida mais independente e ativa na sociedade. Tecnologias de Informação e Comunicação (TIC) podem auxiliar, por exemplo, o diagnóstico precoce e o monitoramento de doenças crônicas visando a melhoria da qualidade de vida de pacientes, ao propiciar respectivamente, o início imediato do tratamento necessário, e um controle de uma determinada doença. Um dos paradigmas que estão sendo bastante utilizados no desenvolvimento de sistemas de software para a assistência médica é a Computação Pervasiva, que possibilita o monitoramento de forma proativa, em diferentes lugares, utilizando diversos dispositivos tais como, sensores sem o e dispositivos móveis. Neste contexto, no presente trabalho é proposta a modelagem e o desenvolvimento de um sistema de software para dispositivos móveis baseado em uma análise de diretrizes médicas, e na realização de um levantamento e especi cação de requisitos no Centro Integrado de Nefrologia do Hospital Universitário Prof. Alberto Antunes (HUPAA) da Universidade Federal de Alagoas (UFAL). A realização dessa pesquisa tem o intuito de auxiliar o diagnóstico precoce da Doença Renal Crônica (DRC) através da identi cação de risco para seu desenvolvimento, e o encaminhamento do paciente para o nefrologista.","The use of devices with technologies such as Bluetooth and WiFi eases the information exchange and remote execution of actions. The computing applied to medical assistance has followed the growth of the wireless technologies allowing remote care to patients with mobility problems and that need an active and independent life in society. Information and Communication Technologies (ICTs) can aid, for example, the early diagnosis and monitoring of chronic diseases aiming to improve the patients' quality of life with the immediate treatment and the disease control. One of the paradigms that has been used in the development of software systems to medical assistance is the pervasive computing, that enables the monitoring in a proactive way and in di erent places with a lot of devices such as wireless sensors and mobile devices. In this context, the modeling and development of a software system to mobile devices based on analysis of medical guidelines and requirements speci cation in the Integrated Centre of nephology of the University Hospital Prof. Alberto Antunes (HUPAA) at Federal University of Alagoas is proposed. The realization of this research aims to aid the early diagnosis of the Chronic Kidney Disease (CKD) by the risk identi cation, and the patient's referring to a nephologist.","('Modelagem computacional', 'Petri, redes de', 'Simulação (Computadores)', 'Informática na medicina', 'Computational modeling', 'Petri, networks of', 'Simulation (Computers)', 'Computing in medicine')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/2102","2013-03-08","https://www.repositorio.ufal.br/bitstream/riufal/2102/1/Estudo%20e%20desenvolvimento%20de%20uma%20solu%c3%a7%c3%a3o%20para%20o%20aux%c3%adlio%20ao%20cuidado%20%c3%a0%20sa%c3%bade.pdf","Study and development of a solution aid the health care",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/1827","Campus A.C. Simões","Instituto de Computação","Dissertação","Uma ferramenta para aprendizagem significativa de surdos utilizando síntese automática de texto baseada em mapas conceituais","('Carlos Leopoldo Pinto Siqueira',)","('Patrick Henrique da Silva Brito',)","('Luís Cláudius Coradine', 'Andrea Karla Ferreira Nunes')","Cada vez mais pessoas têm acesso às informações, seja por meio digital, seja por meio impresso. As novas tecnologias aplicadas para a automatização de tarefas produzem demandas cada vez maiores nas ações de processamento de informações com o intuito de disponibilizar maior número de informações. Através de ferramentas computacionais, recursos de síntese de textos estão cada vez mais sendo utilizados para que sistemas produzam informações com maior índice de síntese possível, uma vez que pessoas necessitam agrupar um maior número de informações possível. Com o crescimento de demanda da acessibilidade por parte das pessoas com necessidades especiais, em particular os surdos, e com o avanço das tecnologias da informação e da comunicação, novos requisitos de apoio à educação especial estão sendo cada vez mais aprimorados. Porém, muitas das vezes, as soluções existentes enfatizam os processos de tradução entre línguas escritas e sinalizadas, o que esbarra em dificuldades de interpretação do significado da tradução. Tais dificuldades são, em parte, fruto das diferenças de estilo de escrita que, no caso de textos prolixos, provoca problemas de mudança de contexto, decorrentes dos detalhamentos fora do foco principal e estruturas, tais como o aposto. Tendo em vista o aprimoramento da aprendizagem significativa, este trabalho propõe um sintetizador automático de textos que, a partir do contexto definido pelo professor para uma determinada aula, extrai dos textos, apenas o que for relativo a esse contexto, removendo as informações adicionais e, desse ponto de vista específico, desnecessária. Portanto, este trabalho apresenta uma ferramenta que pode aumentar a aprendizagem significativa de pessoas surdas através da técnica aplicada à síntese automática de texto, tendo, para tanto, o suporte dos mapas conceituais.","More and more people have access to information, whether through digital, either through printed. New technologies applied to automate tasks produce increasing demands on information processing actions in order to provide more information. Through computational tools, resources synthesis texts are increasingly being used to produce information systems with the highest possible synthesis, since people need group a greater amount of information possible. With the growing demand of accessibility for people with disabilities, particularly the deaf, and with the advancement of information technology and communications, new requirements to support special education are being increasingly enhanced. But often, existing solutions emphasize the processes of translation between languages written and signed, which runs into difficulties in interpreting the meaning of the translation. These difficulties are partly a result of differences in writing style that in the case of texts prolix, causes problems context switching, resulting from detailing outside the main focus and structures, as the bet. Given the significant improvement of learning, this paper proposes an automated synthesizer of texts, from the context set by the teacher for a particular class, extracts the text, which is only relative to this context, removing the additional information and this particular point of view, unnecessary. Therefore, this work presents a tool that can enhance meaningful learning of deaf people through the technique applied to the automatic synthesis of text, and, therefore, support the concept maps.","('Educação especial', 'Lingüística -processamento de dados', 'Lingua Brasileira de Sinais', 'Special education', 'Linguistics-data processing', 'LIBRAS')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1827","2012-12-20","https://www.repositorio.ufal.br/bitstream/riufal/1827/1/Uma%20ferramenta%20para%20aprendizagem%20significativa%20de%20surdos%20utilizando%20s%c3%adntese%20autom%c3%a1tica%20de%20texto%20baseada%20em%20mapas%20conceituais.pdf","A tool for meaningful learning of deaf using summary automatic text-based conceptual maps","('Cleide Jane de Sá Araujo Costa',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/1849","Campus A.C. Simões","Instituto de Computação","Dissertação","Uma especificação do algoritmo genético baseado em tipos abstratos de dados para diagnóstico de arritmias ventriculares a ser aplicada a partir do eletrocardiograma","('Andréa Marques Vanderlei Ferreira',)","('Roberta Vilhena Vieira Lopes',)","('Luís Cláudius Coradine', 'Cleumar da Silva Moreira')","Sistemas Computacionais de Diagnóstico são softwares utilizados para auxiliar os profissionais da área de saúde a formular uma opinião a respeito do funcionamento de um determinado órgão do corpo humano. Para tanto, estes sistemas recebem como entrada parâmetros de normalidade obtidos da literatura, os quais serão confrontados com a anamnese e/ou exames de pacientes, gerando um diagnóstico com presença ou ausência da enfermidade. Os dados e exames de pacientes podem ser gerados aleatoriamente, extraídos por meio de sinal ou imagem, de banco de dados fidedignos, como o MIT, ou captados do próprio equipamento de exame (por exemplo: eletrocardiógrafo), quando presente um módulo com porta USB, ou simplesmente através da inserção de números dispostos em um plano cartesiano. Este trabalho apresenta um sistema computacional de diagnóstico para Arritmias Ventriculares, o qual utiliza uma abordagem de computação evolutiva, mais especificamente o algoritmo genético baseado em tipos abstratos de dados, que visa detectar anormalidades presentes no exame de eletrocardiograma (ECG), mediante uma análise criteriosa das informações fornecidas ao Sistema de Eletrocardiograma (SIECG). O sistema proposto abrange os eventos do ECG (ondas, complexos, intervalos e segmentos) com suas respectivas derivações periféricas e precordiais, além do perfil do paciente, que corresponde ao conjunto de seus dados pessoais (idade, sexo). O SIECG não apresenta porta USB, uma vez que tem como objetivo atender a saúde pública regional, a qual dispõe de eletrocardiógrafos antigos, sendo assim será alimentado por números extraídos dos ECG, que correspondem à altura e comprimento dos eventos eletrocardiográficos. Os exames gerados para emissão do laudo da equipe médica, que serão comparados com o sistema proposto foram intencionalmente elaborados com a presença de três arritmias ventriculares, a saber: Bloqueio do Ramo Direito (BRD), Bloqueio do Ramo Esquerdo (BRE) e Extrassístole Ventricular. Este sistema foi desenvolvido em Python e Mysql.","Diagnosis Computer Systems are softwares used to aid medical professionals to formulate an opinion about how a specific human organ works. Therefore, these systems receive as input parameters of normality obtained from literature, which will be confronted with the history and / or exams of patients, generating a diagnosis with the presence or absence of infirmity. The data and exams of patients can be randomly generated, extracted by means of signal or image from reliable data banks, such as MIT, or obtained by the exams equipment itself (for example: electrocardiograph), when there is a module with a USB port, or simply by inserting numbers arranged in a Cartesian plane. This work presents a computational system for diagnosing Ventricular Arrhythmias which use an evolutionary computation approach, more specifically the genetic algorithm based on abstract data types, which aims to detect abnormalities present on exam of the electrocardiogram (ECG) by a careful analysis of information provided to System Electrocardiogram (SIECG). The proposed system covers the events of the ECG (waves, complexes, intervals and segments) with their respective peripheral leads and precordial, besides profile of the patient, which comprises the set of your personal data ( age, sex). The SIECG has no USB port, since it aims to meet the regional public health, which has electrocardiographs old, so it will be powered by figures from the ECG, which correspond to the height and length of electrocardiographic events. The tests generated for the issuance of the report of the medical team, which will be compared with the proposed system was intentionally designed with the presence of three ventricular arrhythmias, namely: Right Bundle Branch Block (BBBR), Left Bundle Branch Block (BBBL) and ventricular extrasystole. This system was developed in Python and Mysql.","('Complexos Cardíacos Prematuros', 'Bloqueio de Ramo', 'Arritmias Cardíacas -Diagnóstico', 'Algorítmos genéticos', 'Heart Premature Complexes', 'Bundle branch block', 'Arrhythmia-Diagnosis', 'Genetic algorithms')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1849","2011-04-14","https://www.repositorio.ufal.br/bitstream/riufal/1849/1/Uma%20especifica%c3%a7%c3%a3o%20do%20algoritmo%20gen%c3%a9tico%20baseado%20em%20tipos%20abstratos%20de%20dados%20para%20diagn%c3%b3stico%20de%20arritmias%20ventriculares%20a%20ser%20aplicada%20a%20partir%20do%20eletrocardiograma.pdf","Uma especificação do GAADT para diagnóstico de arritmia ventricular a ser aplicada no eletrocardiograma;Specification of the genetic algorithm of ventricular arrhythmias to be applied starting the ECG","('Manoel Agamemnon Lopes',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/123456789/9019","Campus A.C. Simões","Instituto de Computação","Dissertação","O Efeito dos exercícios de Endurance na microbiota intestinal: uma revisão sistemática","('Lucas Monteiro Freire',)","('Jorge Artur Peçanha de Miranda Coelho',)","('Manoel Alvaro de Freitas Lins Neto', 'Braulio Cesar de Alcantara Mendonça')","Contexto: O exercício de Endurance é definido como aquele executado por período prolongado e em intensidades moderadas, podendo ser realizado em diferentes modalidades. Estudos sugerem que a microbiota intestinal possui diversas funções relacionadas à saúde do hospedeiro. A prática de exercícios de Endurance pode alterar a microbiota intestinal. Esta revisão sistemática tem como objetivo verificar os efeitos dos exercícios de endurance na microbiota intestinal. Métodos: A revisão sistemática foi conduzida com o objetivo de avaliar os resultados de Ensaios Clínicos Randomizados (ECR’s) e Ensaios Clínicos não Randomizados (NECR’s) sobre alterações microbianas intestinais em praticantes de exercícios de endurance. Considerouse cinco bancos de dados da literatura (EMBASE, MEDLINE, ISI -Web of Science, Scopus e CENTRAL). O protocolo que delimita este trabalho foi registrado em PROSPERO (International prospective Register of Systematic Reviews). Resultados: 1965 registros foram identificados durante a pesquisa bibliográfica. Após a revisão dos títulos e resumos, 27 publicações foram selecionadas para a leitura completa dos textos, dos quais apenas quatro atenderam aos critérios de seleção. Nenhum estudo deixou de demostrar diferença significativa no filo bacteriano, com algumas ressalvas. Quatro estudos mostraram apenas mudanças significativas apenas em alguns gêneros. A comparação dos estudos demonstra a existência de alterações na microbiota intestinal de pessoas praticantes de exercícios de endurance. Conclusões: Os resultados desta revisão sugerem que o exercício de endurance tem potencial para oferecer mudanças benéficas na microbiota intestinal. Baseada nas evidências desta revisão, algumas amostras dos trabalhos selecionados tiveram alteração na microbiota intestinal. No entanto, alguns estudos reportaram que não ocorreram mudanças significativas na diversidade da microbiota intestinal de indivíduos praticantes de exercícios de endurance. Esta situação sugere que mais estudos são necessários para determinar o tamanho do efeito dos exercícios de endurance.","Background: Endurance exercise is defined as that performed for a prolonged period and at moderate intensities, which can be performed in different modalities. Studies suggest that the intestinal microbiota has several functions related to the health of the host. The practice of Endurance exercises can alter the intestinal microbiota. This systematic review aims to verify the effects of endurance exercises on the intestinal microbiota. Methods: The systematic review was conducted with the aim of evaluating the results of Randomized Clinical Trials (RCTs) and Non-Randomized Clinical Trials (NECR’s) on intestinal microbial alterations in endurance exercise practitioners. Five literature databases were considered (EMBASE, MEDLINE, ISI -Web of Science, Scopus and CENTRAL). The protocol that delimits this work was registered in PROSPERO (International prospective Register of Systematic Reviews). Results: 1965 records were identified during the bibliographic search. After reviewing the titles and abstracts, 27 publications were selected for the complete reading of the texts, of which only four met the selection criteria. No study failed to demonstrate a significant difference in the bacterial phylum, with some caveats. Four studies showed only significant changes in only a few genders. The comparison of studies demonstrates the existence of alterations in the intestinal microbiota of people who practice endurance exercises. Conclusions: The results of this review suggest that endurance exercise has the potential to offer beneficial changes in the gut microbiota. Based on the evidence from this review, some samples of the selected works had alterations in the intestinal microbiota. However, some studies reported that there were no significant changes in the diversity of the gut microbiota of individuals engaged in endurance exercise. This situation suggests that further studies are needed to determine the size of the effect of endurance exercise","('Treino aeróbico', 'Aptidão física', 'Microbiota gastrointestinal', 'Revisão Sistemática')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/9019","2021-09-24","https://www.repositorio.ufal.br/bitstream/123456789/9019/3/O%20Efeito%20dos%20exerc%c3%adcios%20de%20Endurance%20na%20microbiota%20intestinal%3a%20uma%20revis%c3%a3o%20sistem%c3%a1tica.pdf","","('André Luiz Lins de Aquino',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/2100","Campus A.C. Simões","Instituto de Computação","Dissertação","Especificação semântica de LaND: uma linguagem para o método das diferenças finitas","('Fernando Antônio Dantas Gomes Pinto',)","('Eliana Silva de Almeida',)","('João Carlos Cordeiro Barbirato', 'Carlos Bazílio Martins')","Ciência e Engenharia Computacional (CSE) é uma disciplina relativamente nova que lida com o desenvolvimento e aplicação de modelos computacionais e simulações, muitas vezes associada à computação de alto desempenho. A utilização efetiva de métodos de CSE apresenta uma barreira para engenheiros e cientistas, sua falta de formação específica em algoritmos, estruturas de dados, programação paralela e computação de alto desempenho. Muitas linguagens artificiais, de propósito geral ou específico, têm sido desenvolvidas; Matlab, Scilab e as bibliotecas de programação numéricas Basic Linear Algebra Subprograms(BLAS), LINPACK, EISPACK, LAPACK e ScaLAPACK são alguns exemplos. Na maioria dos casos o próprio engenheiro ou cientista desenvolve, em linguagem de programação específica, o software que atende as suas necessidades. O problema deste modelo está no esforço que é transferido ao usuário no desenvolvimento destes algoritmos. Além de ter que conhecer o domínio do problema e o método numérico a ser utilizado, ele deverá tratar do desenvolvimento do programa computacional, implementando o algoritmo para solução do problema. O objetivo deste trabalho é apresentar a especificação semântica formal de LaND -Language of Numerical Discretization, uma linguagem artificial capaz de minimizar a complexidade no desenvolvimento do software científico para os problemas que envolvem simulações a partir das Equações Diferenciais Parciais com o Método das Diferenças Finitas. O pressuposto neste trabalho é que o estudante, engenheiro ou pesquisador deve apenas se preocupar com os aspectos inerentes à solução dentro do domínio de um problema, deixando a cargo da ferramenta a geração automática do programa equivalente. Esta é uma proposta inicial do modelo com foco nos problemas hiperbólicos de segunda ordem com a malha computacional geometricamente uniforme. A abordagem está fundamentada por técnicas formais da computação como a Semântica Denotacional, responsável pelo mapeamento dos objetos matemáticos presentes no modelo de aproximação numérica, dando significado a estas construções, e Communicating Sequential Processes (CSP), um formalismo utilizado para descrever os padrões de comunicação entre os nós da malha computacional.","Computer Science and Engineering (CSE) is a relatively new subject. It deals with applying and developing computer models and simulations, and it is often associated to high-performance computing. Using CSE methods effectively is currently an obstacle to engineers, due to their lack of specific training in algorithms, data structures, parallel programming and highperformance computing. Many artificial languages, either general or specific, have been recently developed: Matlab, Scilab and the numeric programming libraries Basic Linear Algebra Subprograms (BLAS), LINPACK, EISPACK, LAPACK and ScaLAPACK for instance. Generally, the engineer or scientist develops on their own a specific programming language, a software to meet their needs. The problem found within this process is the struggle transferred to the user as a consequence of these algorithms development. Besides the need to have total control over the problem and numeric method in question, they must deal with the development of the computer program implementing the algorithm for the problem resolution. The objective here is to present the formal semantic specifications for LaND -Language of Numerical Discretization, an artificial language able to reduce the complexity of scientific software development for problems involving Partial Differential Equations simulations with Finite Difference Methods. It is assumed the student, engineer or researcher only concern should be the inherent aspects of the solution within a certain problem, leaving the automatic generation of an equivalent program to the tool. This is a initial model proposal with focus on second-order hyperbolic problems with geometrically uniform computational mesh. Our approach is based on formal techniques of computing, such as denotational semantics, responsible for the mapping the mathematical objects in the numerical approximation model, giving meaning to these structures, and Communicating Sequential Processes (CSP), a formalism used to describe the communication patterns within the computational mesh.","('Computação semântica', 'Diferenças finitas', 'Semantic computing', 'Finite differences')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/2100","2013-12-20","https://www.repositorio.ufal.br/bitstream/riufal/2100/1/Especifica%c3%a7%c3%a3o%20sem%c3%a2ntica%20de%20LaND%20-%20uma%20linguagem%20para%20o%20m%c3%a9todo%20das%20diferen%c3%a7as%20finitas.pdf","Specification semantics of LaND: a language for finite difference method","('Leonardo Viana Pereira',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/123456789/8693","Campus A.C. Simões","Instituto de Computação","Dissertação","O efeito de probióticos na microbiota intestinal de pacientes obesos: revisão sistemática e metanálise","('Elton Rafael Castro Silva Matos',)","('Jorge Artur Peçanha de Miranda Coelho',)","('Manoel Alvaro de Freitas Lins Neto', 'Fernando Gomes de Barros Costa')","Contexto: A obesidade é um dos maiores problemas de saúde pública em todo o mundo. Estudos sugerem que a microbiota intestinal possui diversas funções relacionadas à saúde do hospedeiro. A administração de probióticos pode alterar a microbiota intestinal. Esta revisão sistemática tem como objetivo avaliar os efeitos da suplementação oral com probióticos na microbiota intestinal de pessoas obesas. Métodos: A revisão sistemática foi conduzida com o objetivo de avaliar os resultados de Ensaios Clínicos Randomizados (ECR’s) sobre alterações microbianas intestinais em pessoas obesas após a administração de suplementos probióticos. Considerou-se cinco bancos de dados da literatura (EMBASE, MEDLINE, ISI -Web of Science, Scopus e CENTRAL). O protocolo que delimita este trabalho foi registrado em PROSPERO (International prospective Register of Systematic Reviews). Resultados: 2.425 registros foram identificados durante a pesquisa bibliográfica. Após a revisão dos títulos e resumos, 29 publicações foram selecionadas para a leitura completa dos textos, dos quais apenas nove atenderam aos critérios de seleção e três foram incluídas para meta-análise. Dois estudos não mostraram diferença significativa no filo bacteriano. Seis estudos mostraram mudanças significativas apenas em alguns gêneros. A comparação dos estudos demonstra a existência de alterações na microbiota intestinal de pessoas obesas após o uso de probióticos. Conclusões: O desfecho desta revisão sistemática e metanálise sugere que o efeito de suplementos probióticos na microbiota intestinal de pacientes obesos tem resultado inconclusivo. Baseada nas evidências desta revisão, algumas cepas específicas de probióticos alteram a microbiota intestinal de indivíduos obesos. No entanto, alguns estudos reportaram que não ocorreram mudanças significativas na diversidade da microbiota intestinal de pessoas obesas. Esta situação sugere que mais estudos são necessários para determinar o tamanho do efeito da terapia com probióticos.","Background: Obesity is a major public health concern worldwide. Studies suggest that gut microbiota has several functions related to host health. Administration of probiotic may affect the gut microbiota. This systematic review aims to evaluate the effects of oral supplementation with probiotics on the intestinal microbiota in obese people. Methods: Our systematic review aimed to evaluate the results of Randomized Clinical Trials (RCTs) on intestinal microbial changes in obese people after the administration of probiotic supplements. We searched five literature databases (EMBASE, MEDLINE, ISI -Web of Science, Scopus and CENTRAL). The protocol this study was registered in PROSPERO (International prospective Register of Systematic Reviews). Results: 2.425 records were identified during the literature search. After the review of the titles and abstracts, 29 publications were selected for a review of the full texts, of which Only 9 met the selection criteria and three were includede to meta-analisys. 2 studies showed no significant difference in the bacterial phylum. 6 studies showed only significant changes in some genus. The comparison of studies shows the existence of changes in the intestinal microbiota of obese people after the use of probiotics. Conclusions: This systematic review and meta-analysis suggests that the effect of probiotic supplements on intestinal microbiota of obese patients has been inconclusive. Based on the evidence in this review, some specific strains of probiotics alter the intestinal microbiota in obese individuals. However, some studies have reported that there have been no significant changes on gut microbiota diversity in obese people. It suggests that further studies are needed to determine the size effect of probiotic therapy.","('Obesidade', 'Probióticos -Revisão sistemática', 'Microbiota gastrointestinal', 'Metanálise', 'Obesity', 'Probiotics -Systematic review', 'Gut microbiota', 'Meta-analysis')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/8693","2021-04-23","https://www.repositorio.ufal.br/bitstream/123456789/8693/1/O%20efeito%20de%20probi%c3%b3ticos%20na%20microbiota%20intestinal%20de%20pacientes%20obesos%20-%20revis%c3%a3o%20sistem%c3%a1tica%20e%20metan%c3%a1lise.pdf","The effect of probiotics on gut microbiota in obese patients: a systematic review and meta-analysis",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/2104","Campus A.C. Simões","Instituto de Computação","Dissertação","Um conjunto de indicadores para o processo de desenvolvimento de software","('Davy de Medeiros Baía',)","('Rodrigo de Barros Paes',)","('Evandro de Barros Costa', 'Patrick Henrique da Silva Brito', 'Hyggo Oliveira de Almeida')","Projeto de desenvolvimento de software e seus resultados vêm obtendo maior atenção por motivos de não atingirem os resultados esperados. Algumas pesquisas revelam que custo e tempo não saem de acordo com o orçado ou planejado. O gerente de projeto tem um papel importante para obtenção desse resultado. Suas atribuições de alocação de recursos, ajuste de prioridades, monitoramento e controle da evolução do produto ou processo de desenvolvimento de software impactam diretamente na obtenção das metas a serem alcançadas. Tais atividades requerem um grande número de informações. Porém, saber quais informações são importantes para auxiliar o gerente de projeto ainda é um desafio. Esta dissertação propõe um conjunto de indicadores com o objetivo de auxiliar o gerente de projeto, utilizando a visão do PMBOK para acompanhar as dimensões de custo e tempo. Para isto, foi utilizada a abordagem GQ(I)M que possui todas as características necessárias para a criação dos indicadores. Além disso, o método de criação serve como um modelo para geração de novos indicadores. Para avaliar o conjunto de indicadores foi realizado um estudo de caso qualitativo e explanatório, fornecendo uma descrição detalhada de como o conjunto de indicadores auxiliou o gerente de projeto.","The software development process and its results have received the Substantial attention from academia for the past years to the Mainly Regarding Lack of achievement of planned results. Recent researches Indicate That there is a large discrepancy Regarding to the current cost and time taken and the timetable. The project manager has an important role in Achieving planned results. It envolves Activities such as allocating resources, setting Priorities, monitoring and controlling the product evolution process, Which has a straight impact in Achieving the expected goals. Despite the management of such a large amount Activities require of information, specifying what type of information is suitable to assist the project manager remains a challenge. The present dissertation Proposes a set of indicators to better assist the project manager by using PMBOK vision to Accompany the dimentions of cost and time. In order to accomplish the dissertation goals, it Has Been used the GQ (I) M (Goal question metric Indicator) approach, Which offers all features needed to create such indicators. Thus, to Evaluate the Proposed set of indicators, it Has Been executed the qualitative and explanatory case study, providing a detailed description of how the indicator has Helped September the project manager.","('Gerenciamento de configurações de software', 'Software -Desenvolvimento', 'Software configuration management', 'Software-Development')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/2104","2013-02-25","https://www.repositorio.ufal.br/bitstream/riufal/2104/1/Um%20conjunto%20de%20indicadores%20para%20o%20processo%20de%20desenvolvimento%20de%20software.pdf","A set of indicators for the development process software",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/1842","Campus A.C. Simões","Instituto de Computação","Dissertação","Construção e refinamento de perfil baseado em dados georreferenciados e de deslocamento","('João Pedro Pontes Lima Matias',)","('Evandro de Barros Costa',)","('Henrique Pacca Loureiro Luna', 'Márcio de Medeiros Ribeiro', 'Hyggo Oliveira de Almeida')","A utilização de dispositivos móveis vem crescendo bastante mundialmente, principalmente como meio de buscar/difundir informação. E com este crescimento, começaram a surgir serviços que buscam facilitar o nosso dia-a-dia. Um que tem se destacado é o serviço baseado em localização ou location-based services (LBS). Serviços deste tipo buscam trazer informações que sejam sensíveis à localização atual do usuário, como informações turísticas, restaurantes próximos ou áreas de congestionamentos. Dentre os vários tipos de LBS, podemos destacar o que envia anúncios baseados em localização ou location-based advertising (LBA), foco do presente trabalho. Desta forma, este trabalho apresenta uma abordagem que, baseada em dados georreferenciados e de deslocamento de pessoas, propõe a construção e refinamento de perfis automaticamente, para posteriormente recomendar anúncios publicitários mais adequados a estes perfis.","The use of mobile devices has been quickly growing, mainly as a mean of seeking/disseminating information. With this growth, services that aim to facilitate our routine began to emerge. One that stands out is the location-based services (LBS). These kind of services try to gather information related to the user’s current location, such as tourist information, nearby restaurants or traffic jam area. Among the various types of LBS, we emphasize advertisements based on location, called location-based advertising (LBA), focus of the current work. Thus, this work presents an approach, based on geo-referenced data and people movement, that proposes the construction and refinement of profiles automatically, and then recommending the most appropriate advertisementsto these profiles.","('Serviços baseados em localização', 'Dados georreferenciados', 'Location-based services', 'Georeferenced data')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1842","2012-11-14","https://www.repositorio.ufal.br/bitstream/riufal/1842/1/Constru%c3%a7%c3%a3o%20e%20refinamento%20de%20perfil%20baseado%20em%20dados%20georreferenciados%20e%20de%20deslocamento.pdf","Construction and refinement of profile based on georeferenced data and displacement","('Patrick Henrique da Silva Brito',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/7799","Campus A.C. Simões","Instituto de Computação","Dissertação","Desempenho de cotistas e não-cotistas em prova de vestibular: uma análise psicométrica","('Stefan Cavalcante Gomes',)","('Jorge Artur Peçanha de Miranda Coelho',)","('Leonardo Brandão Marques', 'Leogildo Alves Freires')","Dentre as mais importantes políticas de ações afirmativas da sociedade brasileira, está o sistema de cotas para ingresso no ensino superior. Desta forma, este mecanismo precisa estar em constante avaliação, em relação a sua efetividade na questão da justiça social e quanto à eficiência na seleção dos candidatos que ingressam nas universidades. Trata-se de um estudo transversal em que buscou-se avaliar o desempenho de estudantes cotistas e de ampla concorrência do ensino médio em um processo de avaliação (vestibular) de uma universidade pública do Estado de Alagoas. Considerou-se os dados do ano 2015 de todos os avaliandos (N = 3807), sendo 2858 de ampla concorrência e 949 cotistas. Optou-se por executar as análises apenas com os candidatos do curso de Bacharelado em Medicina por possuir a maior população (N = 2722), sendo 535 (20%) cotistas e 2187 (80%) não cotistas, e por apresentar o menor erro padrão além de ser o curso com os maiores escores. O instrumento de avaliação foi a prova de vestibular nos moldes do ENEM. Utilizou-se o R e por meio do pacote mirt verificou-se os três parâmetros para cada competência e item da prova, bem como o DIF (Differential Item Functioning) para checar a diferença de probabilidade de acerto de um item entre os grupos -cotistas e não cotistas. O Modelo TRI de três parâmetros (3PL) se mostrou adequado para a análise das provas, bem como o método Expected a Posteriori para a proficiência dos candidatos. A prova de Inglês apresentou o menor escore médio de dificuldade dos itens (b = -0,98) e a de Matemática o maior (b = 1,25). A prova de Ciências da Natureza apresentou o melhor ajuste entre dificuldade da prova e proficiência dos candidatos, enquanto a de Matemática apresentou a maior discrepância. Através do método Mantel-Haenszel para DIF identificou-se 23 itens que discriminam cotistas de não cotistas, sendo a maior concentração (10 itens) na prova de Ciências Humanas. Os resultados demonstram que há DIF para alguns itens e que esse aspecto precisa ser considerado para composição do escore de rendimento na prova. Além disso, os itens que são utilizados em provas de vestibular demandam ao menos algum sistema prévio de classificação e validação do nível de dificuldade -como o método Angoff. O presente estudo salienta a relevância do funcionamento diferencial dos itens para compreensão do desempenho de estudantes cotistas e não cotistas em prova de vestibular nos moldes do ENEM.","Among the most important affirmative action policies of Brazilian society, there is the quota system for entering higher education. Thus, this mechanism needs to be constantly evaluated, in relation to its effectiveness in the issue of social justice and in terms of efficiency in the selection of candidates who enter universities. This is a cross-sectional study that sought to evaluate the performance of quota students and broad competition from high school in an evaluation process (vestibular) of a public university in the State of Alagoas. The data for the year 2015 of all appraisers was considered (N = 3807), 2858 of which were highly competitive and 949 quota holders. It was decided to perform the analyzes only with the candidates of the Bachelor of Medicine course because it has the largest population (N = 2722), being 535 (20%) quota holders and 2187 (80%) non-quota holders, and for presenting the lowest standard error in addition to being the course with the highest scores. The assessment instrument was the entrance exam according to the ENEM model. The R was used and through the mirt package, the three parameters were verified for each competence and item of the test, as well as the DIF (Differential Item Functioning) to check the difference in the probability of an item’s success between the quota holders. and non-quota holders. The three-parameter IRT Model (3LP) proved to be adequate for the analysis of the tests, as well as the Expected a Posteriori method for the proficiency of the candidates. The English test had the lowest average difficulty score of the items (b = -0.98) and the Mathematics test the highest (b = 1.25). The Natural Sciences test presented the best fit between the difficulty of the test and the proficiency of the candidates, while the Mathematics test presented the greatest discrepancy. Through the Mantel-Haenszel method for DIF, 23 items were identified that discriminate between quota holders and non-quota holders, with the highest concentration (10 items) in the Humanities test. The results demonstrate that there is DIF for some items and that this aspect needs to be considered for the composition of the performance score in the test. In addition, the items that are used in entrance exams require at least some previous system of classification and validation of the level of difficulty -such as the Angoff method. The present study highlights the relevance of the differential functioning of the items for understanding the performance of quota students and non-quota students in the entrance exam in the manner of ENEM.","('Cotas', 'Vestibular', 'Funcionamento Diferencial dos Itens (DIF)', 'Teoria de Resposta ao Item (TRI)', 'Quotas', 'University Entrance Exam', 'Differencial Item Functioning (DIF)', 'Item Response Theory (IRT)')","Teoria da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/7799","2020-11-30","https://www.repositorio.ufal.br/bitstream/riufal/7799/1/Desempenho%20de%20cotistas%20e%20n%c3%a3o-cotistas%20em%20prova%20de%20vestibular_%20uma%20an%c3%a1lise%20psicom%c3%a9trica.pdf","Performance of quotists and non-quotists in university entrance exam: a psychometric analysis",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/7266","Campus A.C. Simões","Instituto de Computação","Dissertação","Construção de chatbots AIML com a ajuda de uma ferramenta de modelagem visual baseada na linguagem BPMN","('Giseldo da Silva Néo',)","('Evandro de Barros Costa',)","('Arturo Hernández-Domínguez', 'Patrick Henrique da Silva Brito', 'Thales Miranda de Almeida Vieira')","Um chatbot é um programa de computador capaz de manter um diálogo com um ser humano. Entre as diversas técnicas existentes para a construção de chatbots existe uma especificação aberta baseado em Extensible Markup Language (XML) chamada Artificial Intelligence Markup Language (AIML). Desenhar fluxos de diálogos para os chatbots é um processo que depende da tecnologia escolhida para a sua construção. A construção desses fluxos em AIML demanda considerável conhecimento nas suas tags. Especificar fluxos de diálogo é uma tarefa difícil e propensa a erros. Uma modelagem visual para a construção dos fluxos por não programadores poderia trazer agilidade a esse processo. Existe uma notação visual para modelagem de processos chamado Business Process Model and Notation (BPMN) que tem boa aceitação tanto entre os profissionais que estão mais distantes da tecnologia quanto para os profissionais da área. Foi proposto nesta dissertação uma abordagem visual para definição desses fluxos com a ajuda do BPMN e um algoritmo para convertê-lo em AIML. A proposta é especificar o fluxo do diálogo de um chatbot, com ajuda do BPMN, e transformá-lo em AIML automaticamente, permitindo que usuários sem conhecimentos em AIML e programação possam desenhá-los de forma intuitiva. Para confirmar esse pressuposto foi construído um conversor, chamado BPMN2AIML, além de um chatbot, chamado ARI, que o incorpora. Foram mapeados alguns fluxos de diálogo, em seguida os diagramas foram convertidos e carregados no chatbot. O conversor foi avaliado por 12 botmasters que construíram vários chatbots de acordo com problemas de negócio propostos, e consideraram a experiência satisfatória e útil.","A chatbot is a computer program capable of maintaining a dialogue with a human being. Among the various existing techniques for building chatbots is an open specification based on Extensible Markup Language (XML) called Artificial Intelligence Markup Language (AIML). Designing dialogue flows for chatbots is a process that depends on the technology chosen for its construction. Building these flows in AIML requires knowledge in tags. Dialogue flows is a difficult and error-prone task. Visual modeling for the construction of flows by non-programmers could bring agility to this process. There is a visual notation for modeling processes called Business Process Model and Notation (BPMN) that has good acceptance both among professionals who are more distant from technology and for professionals in the field. It was proposed in this dissertation a visual approach to define flows with the help of BPMN and an algorithm to convert it into AIML. The proposal is to specify the dialogue flow of a chatbot, with the help of BPMN, and to transform it into AIML automatically, allowing users without knowledge in AIML and to be able to design them intuitively. To confirm this assumption, a converter, called BPMN2AIML, was built, in addition to a chatbot, called ARI, which incorporates it. Some dialog flows were mapped, then the diagrams were converted to AIML and loaded into the chatbot. The converter was evaluated by 12 botmasters who built several chatbots according to the proposed business problems, and found the experience satisfactory and useful.","('Artificial Intelligence Markup Language', 'Business Process Model and Notation', 'Chatbots -Agentes inteligentes (Software)', 'AIML', 'BPMN', 'BPMN to AIML Converter')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/7266","2020-07-14","https://www.repositorio.ufal.br/bitstream/riufal/7266/1/Constru%c3%a7%c3%a3o%20de%20Chatbots%20AIML%20com%20a%20ajuda%20de%20uma%20ferramenta%20de%20modelagem%20visual%20baseada%20na%20linguagem%20BPMN.pdf","Construction of AIML chatbots with the help of a visual modeling tool based on the BPMN language",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/5969","Campus A.C. Simões","Instituto de Computação","Dissertação","Categorização de formas de lagos amazônicos a partir de imagens CBERS","('Gilberto Pedro da Silva Júnior',)","('Alejandro César Frery Orgambide',)","('Leonardo Viana Pereira', 'Sandra Aparecida Sandri')","Nesta dissertação propomos uma técnica de análise de imagens com o objetivo de categorizar lagos da bacia do rio Amazonas. As imagens estudadas são as geradas pelo sensor CBERS, e o procedimento consiste emextrair bordas, obter atributos de forma a partir dessas bordas classificá-los em uma dentre um número conhecido de classes. A classificação é feita por máxima verossimilhança gaussiana, e os melhores atributos em termos de expressividade e custo computacional são identificados por uma busca exaustiva.","In this thesis we propose a technique of image analysis in order to categorize lakes of the Amazon River basin. The images studied are generated by the sensor CBERS, and the procedure is to extract edges, in order to get features from these edges and classify them into one of a known number of classes. The classification process is made by maximum likelihood Gaussian classifier, and the best features in terms of expressiveness and computational cost are identified by an exhaustive search.","('Imagens – Análise – Lagos amazônicos', 'Imagens – Classificação', 'Sensoriamento Remoto', 'Estimador demáxima verossimilhança', 'Reconhecimento de padrões', 'Images -Analysis -Amazon Lakes', 'Images -Classification', 'Remote sensing', 'Maximum Likelihood Classifyier', 'Pattern Recognition')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/5969","2012-05-31","https://www.repositorio.ufal.br/bitstream/riufal/5969/1/Categoriza%c3%a7%c3%a3o%20de%20Formas%20de%20Lagos%20Amaz%c3%b4nicos%20a%20partir%20de%20Imagens%20CBERS.pdf","",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/123456789/10808","Campus A.C. Simões","Instituto de Computação","Dissertação","Avaliação de técnicas de inteligência artificial para predição e classificação de séries temporais","('Daniel Gomes de Mello Farias',)","('André Luiz Lins de Aquino',)","('Jorge Artur Peçanha de Miranda Coelho', 'Fabiane da Silva Queiroz')","Este trabalho tem por objetivo avaliar o impacto das técnicas de aprendizagem profunda (Long Short Term Memory e Convolutional Neural Network) para predição e classificação de séries temporais, em duas aplicações específicas. Uma para classificar o sinal de eletroencefalograma, e outro, na predição da radiação solar. Foram utilizadas várias ferramentas nas diversas etapas de pré processamento, extração de características (transformada de Fourier, Wavelet, principais componentes de análise, entropias) e classificação/predição (convolutional neural network e long short term memory). Os modelos desenvolvidos foram comparados com a literatura utilizando métricas como: acurácia e root mean square error (RMSE), obtendo resultados significativos embora não supere o estado da arte. Na predição da radiação o RMSE foi de 78W/m2 enquanto que para a classificação do sinal cerebral, a acurácia do modelo chegou até 86%.","This work aims to apply deep learning techniques (Long Short Term Memory and Convolutional Neural Network) in time series. The study was carried out in two databases. One to classify the electroencephalogram signal, and another, to predict solar radiation. Various tools were used in the different stages of pre-processing, feature extraction and classification / prediction. The developed models were compared with the literature using metrics such as: accuracy and root mean square error (RMSE), obtaining significant results. In the radiation prediction the RMSE was 78W/m2 while for the classification of the cerebral signal, the accuracy of the model reached 86%, which represents great advances in several areas of health, engineering and meteorology.","('Aprendizagem profunda', 'Inteligência artificial', 'Análise de séries temporais', 'Sinais cerebrais', 'Radiação solar', 'Artificial intelligence', 'Brain signal', 'Deep learning', 'Solar radiation')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/10808","2020-07-17","https://www.repositorio.ufal.br/bitstream/123456789/10808/1/Avalia%c3%a7%c3%a3o%20de%20t%c3%a9cnicas%20de%20intelig%c3%aancia%20artificial%20para%20predi%c3%a7%c3%a3o%20e%20classifica%c3%a7%c3%a3o%20de%20s%c3%a9ries%20temporais.pdf","Evaluation of Artificial Intelligence Techniques for Time Series Prediction and Classification",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/1851","Campus A.C. Simões","Instituto de Computação","Dissertação","Avaliação em hardware de modelos de consumo de energia utilizados em simuladores de redes de sensores sem fio (RSSF)","('Celso Viana da Silva',)","('Alejandro César Frery Orgambide',)","('André Luiz Lins de Aquino', 'Ricardo Augusto Rabelo Oliveira')","O consumo de energia e consequentemente o tempo vida de uma rede de sensores sem Fios tem sido alvo constante de pesquisas. Nesta dissertação, medimos a corrente consumida pelo MICAz de uma fonte de energia formada por baterias alcalinas. Estas medições foram feitas através de experimentos realizados com um kit comercial de RSSF e um circuito eletrônico provido de um resistor. Os dados de consumo de corrente obtidos formaram várias séries temporais que possibilitaram a construção de várias curvas de capacidade remanescente das baterias alcalinas. O consumo foi medido até que o MICAz parasse de funcionar, e assim determinamos o seu tempo de vida, bem como a sua tensão de corte de funcionamento. De posse dos valores médios de tensão e corrente, determinamos a energia média em Joules e comparamos com o consumo de um nó sensor criado no simulador computacional NS-2. Os resultados apresentados por intermédio de tabelas e gráficos comparativos mostraramque o consumo doMICAz émaior que o consumo do nó sensor no NS-2.","Energy consumption and, consequently, lifetime in Wireless Sensor Networks is an active field of research. In this work, we measured the current consumed by MICAz from alkaline batteries. These measurements were made through experiments with a Commercial WSN kit and an electronic circuit built with a resistor. The current consumption data obtained in the form of time series allowed the construction of several curves of the remaining capacity of alkaline batteries. Consumption was measured until MICAz stops working, determining its lifetime and its voltage-off of operation. With the voltage and current, we determined the mean energy in Joules and compared itwith the consumption of a sensor node created in the computer simulatorNS-2. The results presented in tables and comparative graphics showed that consumption ofMICAz is greater than the consumption of sensor node in NS-2.","('Energia elétrica -Consumo', 'Sensores sem fio', 'Electricity-consumption', 'Wireless sensors')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1851","2011-06-22","https://www.repositorio.ufal.br/bitstream/riufal/1851/1/Avalia%c3%a7%c3%a3o%20em%20hardware%20de%20modelos%20de%20consumo%20de%20energia%20utilizados%20em%20simuladores%20de%20redes%20de%20sensores%20sem%20fio%20%28RSSF%29.pdf","Hardware evaluation of energy consumption models used in simulation of wireless sensor networks (WSN)",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/5940","Campus A.C. Simões","Instituto de Computação","Dissertação","Caracterização de dados de sobrevivência em câncer colorretal através de uma abordagem de agrupamento de dados","('Felipe Prata Lima',)","('Eliana Silva de Almeida',)","('Leonardo Viana Pereira', 'Ana Georgina Flesia', 'André Atanasio Maranhão Almeida')","O câncer colorretal é um dosmais incidentes. Na prática clínica habitual, taxas de sobrevivência são avaliadas a partir do TNM Staging System, considerado o principal sistema prognóstico para o câncer. Diversos trabalhos têmusado diferentes fatores e técnicas de aprendizado de máquina em busca de outros fatores e modelos prognósticos para diversos tipos de câncer. A base de dados do SEER (Surveillance, Epidemiology, and End Results program of the National Cancer Institute) disponibiliza publicamente registros de milhares de casos de câncer nos Estados Unidos nas últimas décadas, com disponibilidade de dados para vários fatores prognósticos relacionados à cada caso da doença. Dadas as características da base de dados do SEER, esse trabalho tem o objetivo de avaliar a aplicação de algumas abordagens baseadas em técnicas de agrupamento de dados para a análise de sobrevivência de pacientes de câncer colorretal: a primeira é uma abordagem tradicional que define uma matriz de dissimilaridade e a outra umensemble clustering para a obtenção de uma matriz de dissimilaridade a partir da acumulação de evidência. Essas técnicas são aplicadas na construção de matrizes de dissimilaridade e umsistema prognóstico. Vários algoritmos de agrupamento de dados foram aplicados com as abordagens, e para cada uma deles foi computado o valor do Akaike Information Criterion (AIC). Considerando o AIC como critério para seleção de modelos, os resultados indicam que a abordagemsem o uso do Ensemble Clustering produziu melhores resultados.","The colorectal cancer is one of the most incident. In the usual clinical practice, survival rates are evaluated from the TNM Staging System, considered the main prognostic system for the cancer. Several works have used different factors and techniques ofmachine learning in search of other factors and prognostic models for several cancer types. The SEER (Surveillance, Epidemiology, and End Results program of the National Cancer Institute) database offers publicly thousands of records of cancer cases in the United States in the last decades, with availability of data for several prognostic factors that are related to the disease. Given the SEER database features, this work has the objective of evaluate the application of some approaches based on data clustering techniques to the survival analysis of colorectal câncer patients: the first is a traditional approach which defines a dissimilaritymatrix and the other an ensemble clustering for obtain the dissimilarity matrix from the evidence accumulation. These techniques are applied in the building of dissimilarities matrices and a prognostic system. Several data clustering algorithms were applied with these approaches, and for each was computed the Akaike Information Criterion (AIC) value. Considering the AIC as criterion for model selection, the results showed that the approach without the use of the ensemble clustering gived better results.","('Câncer colorretal – Análise de sobrevivência', 'Armazenamento de dados', 'Análise espacial (Estatística)', 'Surveillance, Epidemiology, and End Results Program (SEER)', 'Modelagem computacional', 'Colorectal Cancer -Survival Analysis', 'Data storage', 'Spatial Analysis (Statistics)', 'SEER data', 'Computational Modelling', 'Data clustering')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/5940","2014-06-02","https://www.repositorio.ufal.br/bitstream/riufal/5940/1/Caracteriza%c3%a7%c3%a3o%20de%20dados%20de%20sobreviv%c3%aancia%20em%20c%c3%a2ncer%20colorretal%20atrav%c3%a9s%20de%20uma%20abordagem%20de%20agrupamento%20de%20dados.pdf","Characterization of Survival Data in Colorectal Cancer through a Data Clustering Approach","('Manoel Alvaro de Freitas Lins Neto',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/123456789/7866","Campus A.C. Simões","Instituto de Computação","Dissertação","A caracterização molecular do microbioma gastrointestinal de pessoas autistas e neurotípicos: uma revisão sistemática","('Waldnis Espirito Santo da Silva',)","('Eliana Silva de Almeida',)","('Francisca Rosaline Leite Mota',)","O Transtorno do Espectro do Autismo (TEA) é uma síndrome do neurodesenvolvimento, caracterizado por padrões de comportamentos repetitivos e dificuldade na interação social, que afeta sobremaneira o desenvolvimento da pessoa diagnosticada com essa comorbidade. Antecedentes: O TEA vem se tornando uma questão de saúde pública, na medida em que sua prevalência aumenta significativamente com o passar dos anos. Há relatos em diversos estudos recentes sugerindo sensíveis alterações na microbiota intestinal bacteriana dos autistas. O eixo intestino-cérebro induz um modelo de comunicação complexo e bidirecional, onde sinais de disbiose se relacionam com distúrbios neurocomportamentais, desordenando as habilidades sociais, emocionais e de comunicação. Métodos: A revisão bibliográfica, utilizando estudos originais de ensaios clínicos e estudos observacionais, teve como objetivo caracterizar a composição do microbioma gastrointestinal em indivíduos com TEA. Pesquisou-se em cinco bancos de dados da literatura (Cochrane via Cochrane Library, Embase, ISI -Web of Science, MEDLINE via PubMed e Scopus). Resultados: Foram encontrados 1.597 trabalhos publicados. Todavia, convergimos o escopo desta revisão para a pesquisa das alterações no microbioma gastrointestinal entre indivíduos Autistas com disbiose em comparação aos neurotípicos. Analisamos seis estudos, incluindo 303 pacientes com TEA, e descobriu-se que crianças com TEA tinham indicação de diminuição de abundância relativa dos filos Bacteroidetes, Firmicutes, Actinobacteria e Proteobacteria. Por outro lado, apresentaram aumento de abundância relativa apenas no filo Acidobacteria. Todos em comparação aos 45 irmãos neurotípicos e aos 195 indivíduos do grupo controle, representando a existência de modificações nas cepas da microflora total detectada. Conclusões: Os resultados evidenciam que há modificação na microbiota intestinal quanto aos filos (Bacteroidetes, Firmicutes, Actinobacteria, Proteobacteria e Acidobacteria). O estudo se defrontou com uma escassez de Ensaios Clínicos Randomizados (ECRs) concernente ao microbioma gastrointestinal e dada a inconsistência dos resultados reportados nas pesquisas avaliadas foi impossível a realização da metanálise. Mais estudos serão necessários para elucidar o papel específico do microbioma intestinal da patogênese no TEA, principalmente, no tocante aos aspectos comportamentais.","Autism Spectrum Disorder (ASD) is a neurodevelopmental syndrome characterized by repetitive behavior patterns and difficulty in social interaction, which significantly affects the development of the person diagnosed with this comorbidity. Background: ASD has become a public health issue, as its prevalence has increased considerably over the years. There are reports in several recent studies suggesting significant changes in the bacterial intestinal microbiota of autistic people. The gut-brain axis induces a complex and bidirectional communication model. Dysbiosis signs are related to neurobehavioral disorders, disrupting social, emotional, and communication skills. Methods: The literature review, using original studies from clinical trials and observational studies, aimed to characterize the gastrointestinal microbiome's composition in individuals with ASD. We searched five literature databases (Cochrane via Cochrane Library, Embase, ISI -Web of Science, MEDLINE via PubMed and Scopus). Results: We found 1,597 published works. However, we converged this review's scope to investigate changes in the gastrointestinal microbiome among autistic individuals with dysbiosis compared to neurotypical individuals. We analyzed six studies, including 303 patients with ASD. The results showed that children with ASD indicated a decreased relative abundance of phylum Bacteroidetes, Firmicutes, Actinobacteria, and Proteobacteria. On the other hand, they showed an increase in relative abundance only in the phylum Acidobacteria. All compared to 45 neurotypical brothers, and 195 individuals in the control group, representing the existence of changes in the strains of the total detected microflora. Conclusions: The results show a change in the intestinal microbiota regarding the phyla (Bacteroidetes, Firmicutes, Actinobacteria, Proteobacteria, and Acidobacteria). The study was faced with a shortage of Randomized Clinical Trials (RCTs) concerning the gastrointestinal microbiome, and given the inconsistency of the results reported in the evaluated studies, it was impossible to perform the meta-analysis. Further studies are needed to elucidate the specific role of the intestinal microbiome of pathogenesis in ASD, especially concerning behavioral aspects.","('Transtornos do espectro autista', 'Microbioma gastrointestinal', 'Neurotípicos', 'Disbiose', 'Metanálise', 'Revisão sistemática', 'Microbioma', 'Dysbiosis', 'Systematic review', 'Autism spectrum disorder', 'Neurotypics', 'Meta-analysis')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/7866","2020-12-11","https://www.repositorio.ufal.br/bitstream/123456789/7866/1/A%20caracteriza%c3%a7%c3%a3o%20molecular%20do%20microbioma%20gastrointestinal%20de%20pessoas%20autistas%20e%20neurot%c3%adpicos_%20uma%20revis%c3%a3o%20sistem%c3%a1tica.pdf","The molecular characterization of the gastrointestinal microbioma of autistic and neurotypical people: a systematic review","('Jorge Artur Peçanha de Miranda Coelho',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/5934","Campus A.C. Simões","Instituto de Computação","Dissertação","Concepção e implementação de um modelo de avaliação qualitativa para mapas conceituais estratificados em um estudo de caso no contexto de um curso de extensão sobre licitação na UFAL","('André Vilhena Vieira',)","('Fábio Paraguaçu Duarte da Costa',)","('Arturo Hernández-Domínguez', 'Maria Elizabeth Bianconcini Trindade Morato Pinto de Almeida')","Mapas Conceituais (MCs) são usados em diversas situações educacionais, tais como recurso para aprendizagem significativa e instrumento de avaliação. Esta dissertação propõe um modelo de avaliação qualitativa para mapas conceituais da evolução da aprendizagem significativa, denominado de Mapa Conceitual Estratificado (MCE), com facilidades para atender de maneira particular tanto o professor quanto o aluno, utilizando as informações presentes no mapa com atribuição das classes opcional, básico, obrigatório e avançado aos conceitos e características de simetria, transitividade e reflexividade as relações. O objetivo é ampliar o uso que se faz do modelo tradicional integrando as tarefas de construção e avaliação de mapas conceituais, facilitando o acompanhamento da evolução do aluno e/ou da turma, oferecendo feedback ao aluno, com possibilidade de auto avaliação e ajudando o professor na avaliação da evolução e qualidade dos conceitos mapeados. A pesquisa utilizou uma abordagem qualitativa e sua validação ocorreu durante um curso de extensão sobre Licitação na Universidade Federal de Alagoas (UFAL) com doze participantes. Como instrumentos de aquisição de dados, utilizou-se a entrevista, questionário e brainstorming. Os resultados obtidos demonstram que o modelo proposto pode auxiliar os professores numa avaliação qualitativa dos mapas de seus alunos.","Conceptual Maps (MCs) are used in various educational situations, such as meaningful learning resource and assessment tool. This dissertation proposes a qualitative evaluation model for conceptual maps of the evolution of meaningful learning, called the Stratified Conceptual Map (MCE), with facilities to attend in a particular way both the teacher and the student, using the information present in the map with attribution of the classes Optional, basic, mandatory and advanced concepts and characteristics of symmetry, transitivity and reflexivity relations. The objective is to increase the use of the traditional model by integrating the tasks of constructing and evaluating conceptual maps, facilitating the monitoring of the evolution of the student and / or the class, offering feedback to the student, with the possibility of self evaluation and helping the teacher In the evaluation of the evolution and quality of the mapped concepts. The research used a qualitative approach and its validation occurred during an extension course on Bidding at the Federal University of Alagoas (UFAL) with twelve participants. As data acquisition instruments, interview, questionnaire and brainstorming were used. The results show that the proposed model can help teachers in a qualitative evaluation of the maps of their students.","('Mapa conceitual', 'Mapa conceitual estratificado', 'Aprendizagem significativa', 'Avaliação qualitativa', 'Informática na educação', 'Conceitual map', 'Map Conceptual Stratified', 'Meaningful Learning', 'Qualitative Evaluation', 'Informatics in Education')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/5934","2017-04-07","https://www.repositorio.ufal.br/bitstream/riufal/5934/1/Concep%c3%a7%c3%a3o%20e%20implementa%c3%a7%c3%a3o%20de%20um%20modelo%20de%20avalia%c3%a7%c3%a3o%20qualitativa%20para%20mapas%20conceituais%20estratificados%20em%20um%20estudo%20de%20caso%20no%20contexto%20de%20um%20curso%20de%20extens%c3%a3o%20sobre%20licita%c3%a7%c3%a3o%20na%20UFAL.pdf","Design and implementation of a qualitative evaluation model for stratified concept maps in a case study in the context of a course of extension on bidding UFAL","('Cleide Jane de Sá Araujo Costa',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/2920","Campus A.C. Simões","Instituto de Computação","Dissertação","Classificação de rasuras em textos manuscritos","('Marcos Antonio Rocha Tenório',)","('Evandro de Barros Costa',)","('Aydano Pamponet Machado', 'Eduardo Calil de Oliveira', 'Joílson Batista de Almeida Rêgo')","Este trabalho se insere na linha de pesquisa Modelos Computacionais em Educação do Programa de Pós-graduação Interdisciplinar em Modelagem Computacional de Conhecimento, realizando um estudo sobre classificacão de rasuras em textos manuscritos. O estudo dessas rasuras é feito para a determinação das dificuldades no processo de aprendizagem, pois leva a entender o conflito do estudante em processo de aquisição da escrita, na identificação das fronteiras da palavra ortográfica. Neste contexto, o objetivo deste trabalho foi a construção de um modelo para identificação e detecção das rasuras em textos, através da análise das rasuras geradas em palavras de enunciados produzidos pelos referidos estudantes. Para representar matematicamente as imagens, devido à diferença de dimensões das imagens adquiridas, fez-se necessário a utilização de um parâmetro que caracterizasse a imagem de uma forma única, independente da mesma ser uma letra ou palavra, ou das dimensões dos caracteres utilizados na escrita. Na solução deste problema, propõe-se a identificação da direção dos traços que compõem a escrita, pois a mesma independe das dimensões e caracteriza bem principalmente as rasuras, normalmente composta por muitos traços paralelos em uma única direção. As imagens foram classificadas por processos de aprendizagem de máquina, das técnicas: Máquina de Vetores de Suporte (SVM), Árvores de Decisão (boostedand bagged trees), Vizinhos mais Próximos (KNN), Naive Bayes, análise de discriminante (QDA e outros) e Regressão Logística, que analisam os dados e reconhecem padrões, usados para classificação e análise de regressão. Os resultados obtidos mostram que os descritores de imagem quando utilizados isoladamente obtém valores limites de acurácia na ordem de 90%, porém quando combinados com outros (Histograma de Orientação de Borda + Centróide Hierárquico + Momentos de Zernike), excedem 98% de acurácia. Assim, uma das conclusões obtidas nessa pesquisa é a da apropriação de técnicas de aprendizagem de máquina para o reconhecimento de rasuras.","This work is included in the research line “Computational Models in Education” of the Interdisciplinary Postgraduate Program in Computational Modeling of Knowledge, conducting a study on erasures in texts produced by students of primary education. This study is performed aiming to detect difficulties in the learning process, because it leads to understand the conflict of the student in the process of acquisition of writing, in the identification of the orthographic word boundaries. In this context, the objective of this paper is the construction of a model for identification and detection of erasures in texts, through the analysis of erasures generated in words of statements produced by students. In order to represent the images mathematically, due to the difference in the dimensions of the images acquired, it was necessary to use a parameter that characterized the image in a unique way, regardless of whether it is a letter or word, or the dimensions of the characters used in writing. In the solution of this problem, it is proposed to identify the direction of the traces that compose the writing, since it is independent of the dimensions and characterizes mainly the erasures, usually composed by many parallel traces in a single direction. The images were classified by machine learning processes, using techniques such as: Support Vector Machines (SVM), Boosted and bagged trees, Nearest Neighbors (KNN), Naive Bayes, discriminant analysis (QDA and others) and Logistic Regression, which analyze the data and recognize used for classification and regression analysis. The obtained results show that the image descriptors when used alone obtains limits around 90% of accuracy, but when combined with others (Edge Orientation Histogram + Hierarchical Centroid + Zernike Moments), they exceed 98% of accuracy. Thus, one of the conclusions obtained in this research is the appropriation of machine learning techniques for the recognition of erasures.","('Modelagem computacional', 'Texto manuscrito – Identificação de rasuras', 'Linguística', 'Computational modeling', 'Handwritten text -Identification of Erasures', 'Linguistics')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/2920","2018-02-08","https://www.repositorio.ufal.br/bitstream/riufal/2920/1/Classifica%c3%a7%c3%a3o%20de%20rasuras%20em%20textos%20manuscritos.pdf","Erasure classification in manuscript texts","('Tiago Figueiredo Vieira',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/6174","Campus A.C. Simões","Instituto de Computação","Dissertação","Categorização de textos por aprendizagem de máquina","('Keila Barbosa Costa dos Santos',)","('Alejandro César Frery Orgambide',)","('André Luiz Lins de Aquino', 'Jorge Artur Peçanha de Miranda Coelho', 'Osvaldo Aníbal Rosso')","A categorização automática de textos em classes pré-definidas tem testemunhado um interesse crescente nos últimos anos,devido à maior disponibilidade de documentos em formato digital e à necessidade subseqüente de organizá-los. Na comunidade de pesquisa,a abordagem dominante para esses problemas é baseada em técnicas de aprendizado de máquina: um processo indutivo geral constrói automaticamente um classificador aprendendo a partir de um conjunto de documentos pré-classificados, as características das categorias.As vantagens dessa abordagem sobre a abordagem de engenharia do conhecimento (consistindo na definição manual de um classificador por especialistas de domínio) são uma eficácia muito boa, economias consideráveis em termos de força de trabalho especializada e portabilidade direta para diferentes domínios. Esta pesquisa discute as principais abordagens para classificação de texto que se enquadram no paradigma de aprendizado de máquina. Discutiremos em detalhes questões relativas a representação de documentos, construção de classificadores e avaliação de classificadores assim como os métodos Deep Learning. As Redes neurais profundas (DNNs) revolucionaram o campo do Processamento Natural de Linguagem (PNL). As Redes Neural Convolucional (CNN) e Redes Neural Recorrente (RNN), são os dois principais tipos de Arquiteturas DNN amplamente exploradas para lidar com várias tarefas de PNL. ACNN é supostamente boa em extrair recursos de posição e variáveis e RNN na modelagem de unidades em sequência. O estado da arte em muitas tarefas de PNL geralmente mudam devido à batalha de CNN se RNNs. Este trabalho é uma comparação entre os modelos clássicos de aprendizado de máquina (Maximum Entropy Modeling,Support Vector Machine, Bootstrap Aggregating, Boosting, Redes neurais da NNET, Random Forest, Análise discriminante linear escalada, DecisionTreese Naïve Bayes) e desta nova abordagem que encontra-se no estado da arte utilizando redes CNN e RNN, com objetivo principal a construção do índice da revista IEEE Geoscience and Remote Sensing Letters, observando a performance e o desempenho de diferentes modelos, a classificação é realizada a partir de dois conjuntos de dados (Título e Abstract) dos artigos da IEEEGRSL. Em contrapartida aos métodos tradicionais, introduzimos uma rede neural convolucional recorrente para classificação de texto a partir do Abstract dos artigos da revista por observar que os modelos clássicos tendem a perder precisão quando elevamos a quantidade de dados. Os resultados experimentais mostram que o método proposto tiveram uma performance satisfatória, porém a rede RCNN superou os métodos clássicos em desempenho. No entanto, ao implementar essa técnica de classificação utilizando Deep Learning, os índices de acerto para o conjunto de dados Abstract superou os modelos clássicos implementado neste trabalho, chegando a uma precisão de 94% com uma performance de 6 segundos.","Automatic categorization of texts into predefined classes has witnessed a growing interest in recent years, due to the increased availability of documents in digital format and the subsequent need to organize them. In the research community, the dominant approach to these problems is based on machine learning techniques: a general inductive process automatically builds a classifier learning from a set of pre-classified documents, the characteristics of categories. The advantages of this approach over the knowledge engineering approach (consisting of the manual definition of a classifier by domain experts) are very good effectiveness, considerable savings in terms of skilled workforce and direct portability to different domains. This research discusses the main approaches to text classification that fit the machine learning paradigm. We will discuss in detail issues relating to document representation, classifier construction, and classifier evaluation as well as the Deep Learning methods. Deep neural networks (DNNs) have revolutionized the field of Natural Language Processing (NLP). Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN) are the two main types of widely exploited DNN architectures to handle various NLP tasks. CNN is supposed to be good at extracting position and variable resources and RNN in sequence unit modeling. The state of the art in many NLP tasks usually changes due to the battle of CNNs and RNNs. This work is a comparison between the classic machine learning models (Maximum Entropy Modeling, Support Vector Machine, Bootstrap Aggregating, Boosting, NNET Neural Networks, Random Forest, Scaled Discriminant Analysis, Decision Trees and Naïve Bayes) and this new approach which is state of the art using CNN and RNN networks, with the main objective of building the index of the journal IEEE Geoscience and Remote Sensing Letters, observing the performance and the performance of different models, the classification is performed from of two datasets (Title and Abstract) from IEEEGRSL articles. In contrast to the traditional methods, we introduced a recurring convolutional neural network for text classification from the Abstract of the journal’s articles by noting that classic models tend to lose accuracy when we increase the amount of data. The experimental results show that the proposed method had a satisfactory performance, but the RCNN network surpassed the classical methods in performance. However, when implementing this classification technique using Deep Learning, the hit ratios for the Abstract dataset surpassed the classic models implemented in this paper, reaching a precision of 94 % with a performance of 6 seconds.","('Aprendizado de máquina', 'Processamento de linguagem natural (Computação)', 'Redes neurais (Computação)', 'Inteligência artificial', 'Machine Learning', 'Natural Language Processing (Computing)', 'Neural Networks (Computing)', 'Artificial intelligence', 'Artificial Neural Network', 'Recurrent Neural Networks', 'Convolutional Neural Networks')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/6174","2019-07-10","https://www.repositorio.ufal.br/bitstream/riufal/6174/1/Categoriza%c3%a7%c3%a3o%20de%20textos%20por%20aprendizagem%20de%20m%c3%a1quina.pdf","Machine learning text categorization","('Heitor Soares Ramos Filho',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/7759","Campus A.C. Simões","Instituto de Computação","Dissertação","Avaliação clínica e qualidade de vida nas hiperplasias prostáticas benignas","('Yuri Silva Toledo Brandão',)","('Jorge Artur Peçanha de Miranda Coelho',)","('Aydano Pamponet Machado', 'Manoel Alvaro de Freitas Lins Neto', 'Divanise Suruagy Correia')","A hiperplasia prostática benigna (HPB) é o tumor benigno mais comum em homens e sua prevalência está relacionada ao envelhecimento, acometendo mais de noventa por cento dos homens com idades superiores a 80 anos. O tratamento é realizado com o objetivo de corrigir as complicações relacionadas com o crescimento da glândula e reduzir os sintomas de trato urinário inferior (LUTS). Universalmente, pacientes com sintomas mais severos ou refratários ao tratamento farmacológico costumam ser sub-metidos à ressecção transuretral da próstata (RTUP) com tecnologia bipolar, que é o padrão-ouro da terapia cirúrgica. Nesse trabalho, foi feita uma análise de regressão linear múltipla com fins de predizer o sucesso cirúrgico considerando o peso da próstata antes e depois da cirurgia, o Escore Internacional de Sintomas Prostáticos (IPSS) e Qualidade de Vida (QoL). Contou-se com uma amostra de 90 pacientes submetidos à RTUP, com idade média de 67,3 anos, sendo com o peso da próstata a partir de 50 g (grande) 60 pacientes (66,7 por cento). Esse foi o nosso principal achado. O resultado da análise de regressão demonstrou a viabilidade de propor um novo ponto de corte. Comprova-se que o ponto de corte reportado na literatura -a partir de 60g -grande, ao menos na amostra, alguns pacientes mesmo após a cirurgia ainda evoluem sem melhora clínica significativa, ofuscando os benefícios da RTUP. Especificamente, apresentam uma média de IPSS pós-cirúrgico igual a 8,2(±3,6) -com significância estatística ao se comparar ao outro grupo, mas com média acima do ponto de corte. Isto é, clinicamente comprometidos. Com isso, a proposição de um critério para indicação cirúrgica é o peso prostático a a partir de 50g. Confirma-se que pacientes acima do ponto de corte de 50g e que foram submetidos à RTUP bipolar conseguiram melhores benefícios clínicos. Pondera-se que a recomendação ainda é acompanhar caso a caso. Sendo demandado investir em revisão sistemática e meta-análise para demonstrar consenso.","Benign prostatic hyperplasia (BPH) is the most common benign tumor in men and its prevalence is related to aging, affecting more than 90% of men over 80 years old. Its treatment aims to reduce clinical complications related to the benign growth of the prostate. Patients with such severe symptoms may undergo bipolar transurethral resection of the prostate (TURP), which is the gold-standard to the surgical approach in BPH. However, many patients may not benefit the most afterwards, overshadowing its clinical improvements. In this study, a multiple regression analysis has been performed in order to try to predict surgical success considering prostate weight pre and post-surgery, the International Prostate Symptom Score (IPSS), and Quality of Life (QoL). There were 90 patients included in the study sample submitted to bipolar TURP, with a mean age of 67,3 years old. Out of them, 60 (66,7%) men had a weight of prostate equal or greater than 50g. That was the greatest find of this study. Regression analysis has shown the feasibility of a new weight cutoff point. It was demonstrated that the cutoff point described in the current literature -greater than 60 g -major, at least in our sample, some patients even after surgery still presented without significant clinical improvement, overshadowing its benefits. Specifically, they have had a IPSS post-surgery mean of 8.2 (±3,6) -with statistical significance, but with the mean greater than the clinical cutoff point as for IPSS, i.e., patients remained clinically ill. It turns out that a new criteria for surgery is a prostate weight above 50g. We have found that patients above the cutoff point of 50g who underwent bipolar TURP had benefited the most. We recommend that it is yet reasonable to follow-up every BPH case, and that there should have more investment upon systematic review and meta-analysis studies to confirm this consensus.","('Próstata', 'Hiperplasia prostática', 'Modelos lineares', 'Ressecção transuretral da próstata', 'Prostate', 'Benign hyperplasia', 'Regression', 'Transurethral resection of the prostate', 'Bipolar')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/7759","2020-01-23","https://www.repositorio.ufal.br/bitstream/riufal/7759/1/Avalia%c3%a7%c3%a3o%20cl%c3%adnica%20e%20qualidade%20de%20vida%20nas%20hiperplasias%20prost%c3%a1ticas%20benignas.pdf","Clinical analysis and quality of life of benign prostatic hyperplasia",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/7041","Campus A.C. Simões","Instituto de Computação","Dissertação","Avaliação de modelos de classificação automática de atividades diárias para dispositivos de baixo custo","('Wylken dos Santos Machado',)","('Eliana Silva de Almeida',)","('Aydano Pamponet Machado', 'Carlos Maurício Serodio Figueiredo')","Neste trabalho foram utilizados algoritmos de aprendizado de máquina para identificar Atividades Diárias (ADLs) em três conjuntos de dados públicos, ARCMA, HMP e UMAFall. A ideia central é definir uma metodologia que seja capaz de avaliar um conjunto de métodos de aprendizado de máquina, em um cenário específico, com o objetivo de alcançar os melhores resultados na classificação automática de Atividades Diárias, com foco na simplificação da implantação e da estrutura necessária para a sua execução. Nos dias de hoje os estudos com melhores resultados utilizam dados de redes de sensores instalados tanto no ambiente quanto no corpo dos voluntários, esse tipo de abordagem torna a aplicação mais complexa e dificulta a sua implantação. Neste trabalho serão utilizados dados gerados apenas por um sensor inercial (acelerômetro ou magnetômetro, dependendo da base de dados), essa simplificação implica em uma menor complexidade tanto no desenvolvimento, quando na implantação, além de propiciar soluções mais baratas. Dessa forma , o objetivo deste trabalho é construir arcabouço computacional, que envolve parametrização, execução, simulação e validação, permitindo assim, encontrar modelo capaz de realizar a classificação de Atividades Diárias utilizando dispositivos de baixo custo. Para verificar o desempenho do modelo final foi utilizado o Raspberry Pi 3 B. Para alcançar esse objetivo, a metodologia proposta realiza o tratamento dos dados, com a exclusão de entradas inválidas, balanceamento das bases, extração das características relevantes, avaliação dos algoritmos, busca da melhor janela de leitura e utilização de filtro limiar para melhorar a acurácia. Para mitigar os resultados obtidos utilizamos a validação cruzada estratificada para encontrar o F-score e Acurácia dos métodos. Foram avaliados os seguintes algoritmos: k-Nearest Neighbors, Naive Bayes, Support Vector Machine, Decision Tree, Random Forest e Extra-Trees. O algoritmo Extra-Trees apresentou os melhores resultados com uma acurácia final de 92.06%, 93.97% e 97.79% e um F-score de 91.29%, 92.76% e 97.41% para as bases ARCMA, HMP e UMAFall, respectivamente, em um cenário quem que seja tolerável a exclusão de duas atividades das bases de dados. Utilizamos um filtro de decisão que escolhe se o registro deve ser descartado ou não, levando em consideração a tabela de probabilidade retornada por cada método, o que elevou a acurácia da classificação em 16.33%, 14.95% e 9.05% nas bases ARCMA, HMP e UMAFall. Toda modelagem aplicada neste trabalho é relevante para futuros estudos que tenham o objetivo de implementar uma aplicação real para realizar a detecção automática de ADLs, sendo essa portanto, a principal contribuição deixada por este trabalho.","In this work, machine learning algorithms were used to identify Activities of Daily Living (ADLs) in three public data sets, ARCMA, HMP and UMAFall. The central idea is to define a methodology that is capable of evaluating a set of machine learning methods, in a specific scenario, in order to achieve the best results in the automatic classification of Activities of Daily Living, considering the simplification of the implantation and the necessary structure for its execution.Nowadays the studies with better results use data from sensor networks installed both in the environment and in the body of the volunteers, this type of approach makes the application more complex and makes its implementation difficult.This work will use data generated only by an inertial sensor (accelerometer or magnetometer, depending on the database), this simplification implies less complexity in both development and implemen-tation, in addition to providing cheaper solutions. Thus, the objective of this work is to build a computational framework, which involves parameterization, execution, simulation and validation, thus allowing to find a model capable of performing the classification of Activities of Daily Living using low cost devices. To check the performance of the final model, the Raspberry Pi 3 B was used. To achieve this goal, the proposed methodology performs the data processing, excluding invalid entries, balancing the bases, extracting the relevant characteristics, evaluating the algorithms, search for the best reading window and using a threshold filter to improve accu-racy. To mitigate the results obtained, we use stratified cross-validation to find the F-score and Accuracy of the methods. The following algorithms were evaluated: k-Nearest Neighbors, Naive Bayes, Support Vector Machine, Decision Tree, Random Forest, and Extra-Trees. The Extra-Trees algorithm presented the best results with a final accuracy of 92.06%, 93.97% e 97.79%, and 91.29%, 92.76% e 97.41% of F-score, for the ARCMA, HMP and UMAFall bases, respectively, in a scenario who would be tolerable to exclude two activities from the databases. We use a decision filter that chooses whether the record should be discarded or not, taking into account the probability table returned by each method, this increased the accuracy of the classification by 16.33%, 14.95% and 9.05% on the ARCMA, HMP, and UMAFall bases. All modeling applied in this work is relevant for future studies that aim to implement a real appli-cation to perform automatic detection of ADLs, which is, therefore, the main contribution of this work.","('Aprendizagem de máquina', 'Atividades de vida diária', 'Arcabouço computacional', 'Algoritmos computacionais', 'Modelagem computacional', 'Machine Learning', 'ADL', 'Activities of Daily Living', 'Activity Recognition')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/7041","2020-03-06","https://www.repositorio.ufal.br/bitstream/riufal/7041/3/Avalia%c3%a7%c3%a3o%20de%20modelos%20de%20classifica%c3%a7%c3%a3o%20autom%c3%a1tica%20de%20atividades%20di%c3%a1rias%20para%20dispositivos%20de%20baixo%20custo.pdf","Evaluation of automatic classification models of activities of daily diving for low cost devices","('André Luiz Lins de Aquino',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/5793","Campus A.C. Simões","Instituto de Computação","Dissertação","AuDiNoMiC: um gerenciador autonômico para auditorias em segurança ofensiva","('Izaac Duarte de Alencar',)","('Rafael de Amorim Silva',)","('Diego Dermeval de Medeiros da Cunha Matos', 'Ivo Augusto Andrade Rocha Calado')","A segurança da informação (SI) tem significativa importância atualmente porque todos os sistemas computacionais necessitam de algum tipo de camada de segurança para manutenção de sua confiabilidade e da sua base de conhecimento. Para um sistema ter este tipo de segurança, deve-se empregar testes de invasão capazes de verificar a existência de vulnerabilidades que permitam a sua correção preventiva frente à ataques digitais reais. Tais testes constituem auditorias especializadas e requerem conhecimento específico e investimentos consideráveis, tanto para a contratação de um terceiro especializado ou para treinamento necessário de recursos humanos já disponíveis em uma instituição. Desta forma, ferramentas computacionais automatizadas podem facilitar o processo dos testes de invasão, fornecendo diagnósticos ainda passíveis de interpretação pelo especialista, durante o processo desses testes. Esta dissertação propõe uma ferramenta computacional autonômica chamada AuDiNoMiC para lidar com problemas de auditoria em segurança da informação. O objetivo desta ferramenta é automatizar a execução dos testes de invasão para prover diagnósticos semelhantes ao de um especialista em segurança da informação. Para validar a ferramenta, desenvolve-se um experimento de campo, realizando testes de invasão em domínios reais na Internet. Os resultados deste experimento indicam que a ferramenta é capaz de realizar os testes de invasão com sucesso, provendo informações equivalentes aos de um especialista humano. Portanto, a ferramenta proposta é uma alternativa viável para reduzir os investimentos operacionais dos testes e prejuízos com incidentes relacionados a segurança da informação.","Information security (IS) is of significant importance today because all computer systems need some sort of security layer to maintain their reliability and knowledge base. For a system to have this type of security, it is necessary to employ invasion tests capable of verifying the existence of vulnerabilities that allow its preventive correction against real digital attacks. Such tests are specialized audits and require specific knowledge and considerable investment, both for the hiring of a specialized third party or for necessary training of human resources already available in an institution. In this way, automated computational tools can facilitate the process of the invasion tests, providing diagnoses that can still be interpreted by the expert during the process of these tests. This dissertation proposes an autonomic computational tool called AuDiNoMiC to deal with audit problems in information security. The purpose of this tool is to automate the execution of the intrusion tests to provide diagnoses similar to those of an information security specialist. To validate the tool, a field experiment is carried out, carrying out invasion tests in real domains on the Internet. The results of this experiment indicate that the tool is able to perform the invasion tests successfully, providing information equivalent to those of a human expert. Therefore, the proposed tool is a viable alternative to reduce the operational investments of the tests and losses with incidents related to information security.","('Sistema de informação gerencial', 'Computação autonômica', 'Tecnologia da informação – Medida de segurança', 'Autoproteção', 'Auditoria', 'Management Information System', 'Autonomic Computing', 'Information Technology -Security Measure', 'Self-Protection', 'Audit')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/5793","2019-06-06","https://www.repositorio.ufal.br/bitstream/riufal/5793/1/AuDiNoMiC%3a%20%20um%20gerenciador%20auton%c3%b4mico%20para%20auditorias%20em%20seguran%c3%a7a%20ofensiva.pdf","AuDiNoMiC: an autonomic manager for offensive security audits",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/1564","Campus A.C. Simões","Instituto de Computação","Dissertação","Avaliação de desempenho de algoritmos paralelos de busca de vizinhos em cenários com distribuições espaciais distintas","('Bruno Normande Lins',)","('Leonardo Viana Pereira',)","('André Luiz Lins de Aquino', 'Orivaldo Vieira de Santana Júnior')","Algoritmos de detecção de contatos são necessários em diferentes áreas da ciência e tecnologia, de jogos digitais e computação gráfica à simulações de alto desempenho e robótica. Esses algoritmos exigem grande esforço computacional e tendem a ser os gargalos das aplicação as quais fazem parte, principalmente em sistemas de grande escala ou em tempo real. Com a popularização das placas GPUs para uso científico e comercial, é natural que surjam implementações paralelas para esse problema. Nesse trabalho os principais algoritmos de detecção de contatos para GPU são analisados e é realizado umexperimento numérico, com objetivo de descobrir qual algoritmo é o melhor emtermos de desempenho computacional e uso de memória, ou se a eficiência de cada umdepende das diferentes características do cenários. Para a realização do experimento, foi implementado em CUDA/C++ uma aplicação paralela doMétodo dos Elementos Discretos comos principais algoritmos apresentados na literatura, além desses o autor propõe e implementa a paralelização do algoritmo de detecção com ordenação e busca binária que ainda não havia sido paralelizado. Após os testes é constatado que o algoritmo com ordenação e busca é o mais eficiente para todos os cenários estudados, obtendo nos resultados um bom desempenho em tempo de execução e com uso de memória muito superior aos outros.","Contact detection algorithms are needed in different areas of science and technology. From digital games and computer graphics to high-performance simulations and robotics. These algorithms require great computational effort and are prone to become the bottlenecks of its applications, even more when this computation must be done in real-time or large-scale systems. With the popularization of GPU cards use for both science and business, it is only natural that parallel implementations for this problem arise in the scientific community. In this work the main contact detection algorithms are analyzed and a numerical experiment is performed, with the goal of finding out which algorithm has better computational performance and memory use, or if they efficiency depends on different scenario features. For performing the experiment, a parallel Discrete ElementMethod application was developed using CUDA/C++ with the main algorithms presented in literature, besides these, the author proposes and implements the Sorting Contact Detection algorithm parallelization, that hadn’t been parallelized until now. The tests have found that the parallel Sorting Contact Detection algorithm is the most efficient in all studied scenarios, achieving a good performance and a superiormemory usage than its peers.","('Processamento paralelo (Computadores)', 'Método dos elementos discretos', 'Detecção de contato', 'Busca por vizinhos', 'Parallel processing (Computers)', 'Discrete elements method', 'Contact detection', 'Neighbor search')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1564","2016-11-25","https://www.repositorio.ufal.br/bitstream/riufal/1564/1/Avalia%c3%a7%c3%a3o%20de%20desempenho%20de%20algoritmos%20paralelos%20de%20busca%20de%20vizinhos%20em%20cen%c3%a1rios%20com%20distribui%c3%a7%c3%b5es%20espaciais%20distintas.pdf","Parallel neighbor search algorithms performance evaluation in distinct spatial distributions",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/7308","Campus A.C. Simões","Instituto de Computação","Dissertação","Uma aplicação do algoritmo genético baseado em tipos abstratos de dados ao problema de separação cega de fontes","('Valter Wellington Ramos Junior',)","('Luís Cláudius Coradine',)","('Antônio Fernando de Sousa Bezerra', 'João Marcos Travassos Romano')","A presente dissertação apresenta uma modelagem de um algoritmo genético, baseado em tipos abstratos de dados, aplicada a problemas de separação cega de fontes. Nesse sentido, faz-se comparações através de abordagens utilizando o algoritmo genético de Holland e o Algoritmo Genético Baseado em Tipos Abstratos de Dados, com o objetivo de mostrar a eficiência desse algoritmo na caracterização de uma solução combinada a problemas de otimização complexa, usando de maneira parcimoniosa os recursos computacionais disponíveis. As aplicações em problemas de separação cega de fontes se concentram em duas vertentes, uma na recuperação de um sinal eletrocardiográfico em meio ruidoso, a partir do processo de separação de fontes propriamente dito, e a outra na caracterização do filtro inverso, num problema de desconvolução cega. Nessas duas abordagens, busca-se, através do processo evolutivo, ajustar os coeficientes dos sistemas ponderados a partir da consideração, como função custo, de algumas técnicas de separaçã de fontes, como a Curtose, Informação Mútua, Negentropia e principalmente a combinação delas. Os resultados obtidos por meio de simulações mostram um bom compromisso entre desempenho e custo computacional.","This dissertation presents a model of a genetic algorithm based on abstract data types, applied to problems of blind source separation. In this sense, it is through comparisons of approaches using genetic algorithm Holland and Genetic Algorithm Based on Abstract Data Types, in order to show the efficiency of this algorithm in the characterization of a combined solution of complex optimization problems, using so parsimonious computational resources. The problems in applications blind source separation are concentrated in two parts, one in the recovery of an electrocardiographic signal in noisy environment, from the source separation process itself, and the other in the characterization of the inverse filter, a problem of blind deconvolution . These two approaches, seeks to, through the evolutionary process, adjusting the weighted coefficients of the systems from consideration as the cost function, some techniques for the separation of sources, such as kurtosis, mutual information, negentropy and especially their combination. The results obtained by simulations show a good compromise between performance and computational cost.","('Inteligência artificial', 'Algorítmos genéticos', 'Separação cega de fontes', 'Artificial Intelligence', 'Genetic Algorithm', 'Blind Sources Separation')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/7308","2012-03-12","https://www.repositorio.ufal.br/bitstream/riufal/7308/3/Uma%20aplica%c3%a7%c3%a3o%20do%20algoritmo%20gen%c3%a9tico%20baseado%20em%20tipos%20abstratos%20de%20dados%20ao%20problema%20de%20separa%c3%a7%c3%a3o%20cega%20de%20fontes.pdf","An Application of the Genetic Algorithm Based on Abstract Data Types to the Blind Source Separation Problem","('Roberta Vilhena Vieira Lopes',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/123456789/12714","Campus A.C. Simões","Instituto de Computação","Dissertação","Aspectos clínicos laborais e o uso da modelagem computacional no diagnóstico da leishmaniose visceral","('Thiana Tenório Marinho',)","('Michelle Jacintha Cavalcante Oliveira',)","('Rosana Quintella Brandão Vilela', 'Cinthya Pereira Leite Costa de Araújo')","A leishmaniose é causada por parasitas do gênero Leishmania. Existem três formas principais de leishmaniose: visceral, também conhecida como Calazar, que é a forma mais grave da doença, cutânea, a mais comum, e mucocutânea. Segundo dados da organização mundial de saúde, estima-se que 700.000 a 1 milhão de novos casos e cerca de 26.000 a 65.000 mortes ocorram anualmente. Diferentes metodologias podem ser utilizadas para o diagnóstico de Leishmaniose Visceral (LV). Atualmente, há uma variedade de técnicas, mas nenhuma apresenta 100% de sensibilidade e especificidade. O requisito básico, seguro e determinante (padrão-ouro) no diagnóstico laboratorial da LV é a documentação de formas amastigotas em material obtido da punção de medula óssea. No entanto, os processos de identificação manual são trabalhosos, demorados e propensos a erros humanos. Detecção de Leishmania automaticamente é uma tarefa computacional desafiadora. O cenário atual carece de ferramentas de análise de imagens eficientes que auxiliem nessa detecção. Uma nova maneira potencial de contornar a técnica manual é a técnica de aprendizado de máquina da qual destacase a rede neural convolucional. Trata-se de um estudo retrospectivo e observacional realizado com os dados clínicos e laboratoriais de vinte pacientes com diagnóstico de Leishmaniose Visceral (LV) no período de Janeiro de 2018 a Maio de 2019 e tem como objetivo desenvolver recursos para auxílio diagnóstico de LV. Neste trabalho apresentamos a construção de uma rede neural convolucional profunda para automatizar o processo de detecção de Leishmania com uma acurácia de 83% e ainda descrevemos características do exame parasitológico e dados clínicos dos pacientes que também podem corroborar com o diagnóstico aumentando a sensibilidade do método.","Leishmaniasis is caused by parasites of the genus Leishmania. There are three main forms of leishmaniasis: visceral, also known as Calazar, which is a more serious form of the disease, cutaneous, a more common and mucocutaneous. According to data from the world health organization, it is estimated that 700,000 to 1 million new cases and about 26,000 to 65,000 deaths occur. Different methods can be used for the diagnosis of Visceral Leishmaniasis (VL). Currently, there are a variety of techniques, but none have 100% sensitivity and specificity. The basic, safe and determining requirement (gold standard) in the laboratory diagnosis of VL is the application of amastigote forms in the material applied by bone marrow puncture. However, manual identification processes are work, demonstrated and prone to human errors. Detecting Leishmania automatically is a challenging computational task. The current scenario of efficient image analysis tools that assist in this detection. A potential new way to get around a technical manual is a machine learning technique from which to save a neural convolutional. This is a retrospective and observational study conducted with the clinical and laboratory data of twenty patients diagnosed with Visceral Leishmaniasis (VL) from January 2018 to May 2019 and aims to develop resources to aid in the diagnosis of VL. In this work, we present a construction of a deep convolutional neural network to automate the detection process of Leishmania with an accuracy of 83% and also describe characteristics of the parasitological examination and clinical data of patients that can also corroborate whith diagnosis increasing the sensivity of the method.","('Leishmaniose visceral -Diagnóstico', 'Leishmania', 'Rede neural convolucional', 'Leishmaniasis, Visceral -Diagnosis', 'Convolutional Neural Network')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/12714","2020-07-22","https://www.repositorio.ufal.br/bitstream/123456789/12714/1/Aspectos%20cl%c3%adnicos%20laborais%20e%20o%20uso%20da%20modelagem%20computacional%20no%20diagn%c3%b3stico%20da%20leishmaniose%20visceral.pdf","","('Fabiane da Silva Queiroz',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/4773","Campus A.C. Simões","Instituto de Computação","Dissertação","Associação entre os scores radiômicos e fleischner para probabilidade de malignidade em nódulos pulmonares incidentais","('Maria de Fátima Alécio Mota',)","('Thiago Sotero Fragoso',)","('Flávio Teles de Farias Filho', 'Marcos Antônio Leal Ferreira')","Nódulo Pulmonar é uma opacidade arredondada, pelo menos parcialmente delimitada, menor que 3 cm e com densidade de partes moles ou cálcica. O achado de um Nódulo Pulmonar Solitário, tem se tornado o ponto chave para a detecção precoce do câncer de pulmão e sua correta interpretação é um grande desafio científico. A principal manifestação do câncer de pulmão, em fase inicial, é o nódulo pulmonar. Todavia, erros de interpretação de imagens tornam a sua classificação em maligno ou benigno uma tarefa extremamente difícil. São atualmente utilizados para o rastreamento de câncer pulmonar, a partir da descoberta aleatória de um nódulo pulmonar, as recomendações de um importante estudo: Fleischner Society Pulmonary nodule recommendations; porém, ainda com bastante limitações. Radiomia é um estudo computacional de imagem que pretende extrair o máximo de características da imagem para auxiliar no suporte a decisão, utilizando inclusive modelos matemáticos. Objetivou-se verificar a associação entre dados radiômicos de imagem de nódulo pulmonar e o score Fleischner, com o intuito de melhorar a acurácia diagnóstica de predição de malignidade de um nódulo pulmonar detectado aleatoriamente em uma tomografia computadorizada. Foram estudados 210 atributos radiômicos extraídos das imagens de tomografia computadorizada de tórax e em seguida buscado associação com os dados Fleischner no sentido de fortalecermos os dados radiômicos para possíveis futuras validações. Verificamos associação entre dados radiômicos de imagem de nódulo pulmonar e o score Fleischner, encontramos correlação entre 8 dos atributos estudados. Assim sendo, contribuirmos para melhorar a tomada de decisão médica, podendo no futuro, influenciar diretamente na sobrevida dos pacientes de câncer de pulmão, cujo diagnóstico e tratamento eficazes são um desafio cientifico.","Pulmonary nodule is a rounded opacity in the lung, at least partially delimited, smaller than 3 centimer with soft or calcic density. The existence of a the solitary pulmonary nodule, detected in incidental way or during a routine examination of the image has become the tool point for the early detection of lung cancer and its correct interpretation is a still scientific challenge. The main manifestation of lung cancer in an initial phase is pulmonary nodule, however the errors of interpretation of images make its classification in malignant or benign an extremely difficult task. Is currently used for the screening of lung cancer by the discovery of a pulmonary nodule the recommendations of an important study: Fleischner Society Pulmonary nodule recommendations but there are a lot of limitations for this. Radiomics is a computational image study that intends to extract the maximum of characteristics of the image to assist in the support of decision using mathematical models. The objective of this study was to verify the association between radiomcs data from pulmonary nodules and the Fleischner scores in order to improve the diagnostic accuracy of malignancy prediction of a randomly detected pulmonary nodule in a chest computed tomography. We studied 210 radiomcs attributes extracted from chest computed tomography and after sought an association with the Fleischner data in order to strengthen the radiomcs data to possible future Validations. Of the attributes studied, we found a correlation between 7 of them, in this case providing to improve the medical decision and influencing the survival of lung cancer patients, which diagnosis and the effective treatment process is a scientific challenge.","('Nódulos pulmonares', 'Neoplasias pulmonares', 'Tomografia computadorizada', 'Pulmonary Nodule', 'Lung cancer', 'Computed tomography', 'Fleischner', 'Radiomcs')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Embargado","http://www.repositorio.ufal.br/handle/riufal/4773","2018-09-25","https://www.repositorio.ufal.br/bitstream/riufal/4773/1/Associa%c3%a7%c3%a3o%20entre%20os%20scores%20radi%c3%b4micos%20e%20fleischner%20para%20probabilidade%20de%20malignidade%20em%20n%c3%b3dulos%20pulmonares%20incidentais.pdf","Association between radiomic scores and fleischner for probability of malignity in incidental pulmonary nodules","('Marcelo Costa Oliveira',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/6461","Campus A.C. Simões","Instituto de Computação","Dissertação","Aprendizado profundo aplicado à quantificação automática de variáveis morfométricas depodócitos em imagens de imuno-histoquímica","('Rafael Fernandes Vanderlei Vasco',)","('Michelle Jacintha Cavalcante Oliveira',)","('Aydano Pamponet Machado', 'Maria Eliete Pinheiro')","Entre os diversos tipos celulares que constituem o tecido renal destacam-se os podócitos, células altamente especializadas do glomérulo que envolvem os capilares e as células vizinhas da cápsula de Bowman. O comprometimento genético ou adquirido dos podócitos pode levar ao desenvolvimento de várias doenças proteinúricas. A hipótese da depleção de podócitos ganhou considerável atenção na última década, principalmente porque representa um conceito unificador na patologia renal o qual associa esta condição ao desenvolvimento de diversas doenças glomerulares, especialmente àquelas caracterizadas por glomerulosclerose, que evoluem para doença renal crônica. Portanto, vem-se desenvolvendo diversas metodologias de avaliação quantitativa dos podócitos por meios mais simples e amplamente disponíveis. Os objetivos do presente estudo foram: 1) verificar o uso da imuno-histoquímica (IH) como marcação alternativa à imunofluorescência (IF) para quantificação de parâmetros morfométricos, principalmente a densidade de podócitos, em biopsias renais pelo método do Fator de Correção (VENKATAREDDY et al., 2014) e 2) apresentar uma avaliação automatizada para quantificação destes atributos a partir de uma Rede Neural Convolucional. Foram estudados 16 casos de biópsias renais pré-transplante de doadores falecidos no período de 2016 a 2018. As amostras foram marcadas com IH através de anticorpo nuclear anti-WT1 (tumor de wilm’s tipo 1). Esta marcação mostrou-se capaz de apresentar resultados de densidade podocitária semelhantes aos referidos pela literatura através da IF, com Coeficiente de Variação entre os estudos de 14%. Verificou-se que a IH com anticorpo anti-WT1 demonstrou uma marcação com amplo espectro de apresentação dos pixels pertencentes às imagens dos núcleos, caracterizada por grandes variabilida-des de pigmentação entre indivíduos, entre glomérulos do mesmo indivíduo e dentro de um mesmo glomérulo. Este fator acrescentou dificuldade e mais tempo ao processo de reconhecimento pelo profissional. No desenvolvimento da Rede Neural Convolucional (U-net: Convolutional Networks for BiomedicalImageSegmentation) foram utilizadas 122 imagens glomerulares com 2.977 imagens de núcleos de podócitos. Onde vetores de características foram extraídos de 80% das imagens selecionadas aleatoriamente para treinamento do modelo de Aprendizado de Máquina e os 20% restantes foram utilizados na Rede Neural para obter as métricas desejadas. A construção da Rede Neural foi baseada nos critérios de melhor desempenho observados em relação à sensibilidade e precisão no reconhecimento de pixels pertencentes às imagens de núcleos podócitos. Todas as 6 variáveis morfológicas testadas de forma pareada não apresentaram diferenças estatísticas entre o processo de podometria manual e o uso da Rede Neural. A similaridade entre as máscaras binárias da marcação manual e da rede neural foi de 89%, medida pelo Coeficiente de Jaccard. Conclui-se que a Rede Neural apresentou um desempenho relevante para identificação e contagem de núcleos de podócitos, assim como para a medida dos diâmetros nucleares. Além disso, houve vantagem significativa na otimização do processo manual pela redução de tempo e esforço gasto nesta atividade. Considerando que o processo de Aprendizado de Máquina pode ser progressivamente melhorado com inserção de mais informações à Rede Neural, observa-se um grande potencial deste modelo à medida que for alimentado com maior número de imagens e/ou utilização de biomarcadores mais específicos.","Among the various cell types that make up renal tissue are podocytes, highly specialized glomerulus cells that surround the capillaries and neighboring Bowman capsule cells. Genetic or acquired involvement of podocytes can lead to the development of various proteinuric diseases. The hypothesis of podocyte depletion has gained considerable attention in the last decade, mainly because it represents a unifying concept in renal pathology which associates this condition with the development of several glomerular diseases, especially those characterized by glomerulosclerosis, which evolve to chronic kidney disease. Therefore, several methodologies for quantitative evaluation of podocytes by simpler and widely available means have been developed. The objectives of the present study were: 1) to verify the use of immunohistochemistry (IH) as an alternative marker to immunofluorescence (IF) to quantify morphometric parameters, especially podocyte density, in renal biopsies by the correction factor method (VENKATAREDDY et al., 2014) and 2) present an automated evaluation for quantification of these attributes from a Convolutional Neural Network. Sixteen pre-transplant renal biopsy cases from deceased donors from 2016 to 2018 were studied. Samples were labeled with IH by anti-WT1 nuclear antibody (wilm’s tumor type 1). This marking was able to present podocyte density results similar to those reported in the literature through IF, with a coefficient of variation between studies of 14%. IH with anti-WT1 antibody was found to have a broad spectrum labeling of the pixels belonging to the nucleus images, characterized by large pigmentation variability between individuals, between glomeruli of the same individual and within the same glomerulus. This factor added difficulty and more time to the process of recognition by the professional. In the development of the Convolutional Neural Network (U-net: Convolutional Networks for Biomedical Image Segmentation), 122 glomerular images with 2,977 podocyte nucleus images were used. Where feature vectors were extracted from 80% of the randomly selected images for Machine Learning model training and the remaining 20% were used in the Neural Network to obtain the desired metrics. The construction of the Neural Network was based on the best performance criteria observed regarding the sensitivity and precision in the recognition of pixels belonging to podocyte nucleus images. All 6 morphological variables tested pairwise showed no statistical differences between the manual podometry process and the use of the Neural Network. The similarity between binary markers and neural network masks was 89%, as measured by the Jaccard Coefficient. It was concluded that the Neural Network presented a relevant performance for podocyte nucleus identification and counting, as well as for the measurement of nuclear diameters. In addition, there was a significant advantage in optimizing the manual process by reducing the time and effort spent on this activity. Considering that the Machine Learning process can be progressively improved by inserting more information into the Neural Network, a great potential of this model is observed as it is fed with more images and / or use of more specific biomarkers.","('Podócitos', 'Aprendizado profundo', 'Imuno-histoquímica', 'Podocytes', 'Immunohistochemistry', 'Glomerulonrphritis', 'Deep Learning')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/6461","2019-06-05","https://www.repositorio.ufal.br/bitstream/riufal/6461/1/Aprendizado%20profundo%20aplicado%20%c3%a0%20quantifica%c3%a7%c3%a3o%20autom%c3%a1tica%20de%20vari%c3%a1veis%20morfom%c3%a9tricas%20depod%c3%b3citos%20em%20imagens%20de%20imuno-histoqu%c3%admica.pdf","Deep learning applied to the automatic quantification of morphometric variables. Podocytes in immunohistochemical images","('Fabiane da Silva Queiroz',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/6752","Campus A.C. Simões","Instituto de Computação","Dissertação","Análise da aderência de recomendações explicadas de recursos educacionais para apoiar o ensino e a aprendizagem em um ambiente educacional online","('Randerson Douglas Ribeiro dos Santos',)","('Ig Ibert Bittencourt Santana Pinto',)","('Diego Dermeval de Medeiros da Cunha Matos', 'Alan Pedro da Silva')","Com o avanço das Tecnologias da Informação e Comunicação (TICs) e da Educação a Distância (EaD), os ambientes online de aprendizagem adquiriram uma posição de destaque como ferramentas potencializadoras do processo de aprendizagem. E pode-ser ver que essas ferramentas vem ganhando uma grande popularidade pelo fato de tornar o processo de aprendizagem mais dinâmico, tornando o conteúdo adaptável para cada aluno, trazendo um ensino individualizado, dentre outros fatores. Mas, como esses ambientes disponibilizam muitos recursos para os usuários, isso pode causar uma confusão na construção do aprendizado, pois ainda que esses ambientes forneçam algumas recomendações visando auxiliar os usuários a fazerem boas escolhas, a falta de explicação pode ocasionar uma baixa aceitação, devido a falta de transparência. E isso têm sido um problema em IA, pois previsões/recomendações são feitas, mas não vem acompanhadas de explicações. Ou seja, mesmo com as recomendações, muitos usuários não conseguem progredir, pelo fato de não entenderem o que foi sugerido/recomendado e não compreenderem o motivo de tal recomendação, achando que a recomendação não se aplica ao seu perfil ou sua necessidade e simplesmente rejeitam a recomendação. Desse modo, este trabalho tem por objetivo investigar o efeito das recomendações explicadas em relação a aderência (aceitação) dos usuários em ambientes online de aprendizagem, analisando se, há ou não diferença significativa nesses ambientes (com explicação e sem explicação). Para validar a proposta, foi projetado um sistema de aprendizagem e nele foi disponibilizado um curso de estatística descritiva, onde diante das interações dos alunos, foi criado o modelo do aluno. Desse modo, retiramos um caso aleatoriamente do modelo do aluno, onde elaboramos um cenário e criamos um survey, que fornecia 4 recomendações (duas com explicações e duas sem explicações) e algumas afirmações que eram exibidas de forma gradual, para cada cenário exposto, para que os participantes pudessem responder. E para cada recomendação foi solicitado que o participante respondesse algumas afirmações que foram propostas, utilizando um escala likert. Sendo assim, foi realizada a coleta e análise dos dados, onde utilizamos uma análise fatorial, por meio de um teste pareado (Wilcoxon), para comparar os resultados de cada cenário, afim de avaliar as opiniões dos participantes. Mediante a realização do experimento, viu-se que, assim como em outros ambientes a explicação também trouxe bons resultados nas recomendações de recursos educacionais, onde houve uma maior aceitação por parte do usuário, quando ele passou a entender o motivo de tal recomendação, podendo julgar se aquilo de fato é relevante ou não.","With the advancement of Information and Communication Technologies (ICTs) and Distance Education (EaD), online learning environments have acquired a prominent position as tools that enhance the learning process. And it can be seen that these tools have been gaining a great popularity due to the fact that they make the learning process more dynamic, making the content adaptable for each student, bringing an individualized teaching, among other factors. However, as these environments provide many resources for users, this can cause confusion in the construction of learning, because although these environments provide some recommendations to help users make good choices, the lack of explanation can cause low acceptance, due to the lack of transparency. And this has been a problem in AI, as predictions / recommendations are made, but are not accompanied by explanations. That is, even with the recommendations, many users are unable to progress, due to the fact that they do not understand what was suggested / recommended and do not understand the reason for such recommendation, thinking that the commendation does not apply to their profile or their need and simply reject the recommendation. Thus, this work aims to investigate the effect of the recommendations explained in relation to adherence (acceptance) of users in online learning environments, analyzing whether or not there is a significant difference in these environments (with explanation and without explanation). In order to validate the proposal, a learning system was designed and a descriptive statistics course was made available, where, in view of the students’ interactions, the student model was created. Thus, we removed a case randomly from the student’s model, where we elaborated a scenario and created a survey, which provided 4 recommendations (two with explanations and two without explanations) and some statements that were displayed gradually, for each exposed scenario, for that participants could respond to. And for each recommendation, the participant was asked to answer some statements that were proposed, using a likert scale. Therefore, data collection and analysis was performed, where we used a factor analysis, through a paired test (Wilcoxon), to compare the results of each scenario, in order to evaluate the participants’ opinions. Upon carrying out the experiment, it was seen that, as in other environments, the explanation also brought good results in the recommendations of educational resources, where there was a greater acceptance by the user, when he started to understand the reason for such recommendation, judge whether that is really relevant or not.","('Ensino à distância', 'Sistemas de Recomendação', 'Ambiente virtual de aprendizagem', 'Inteligência artificial', 'Distance learning', 'Systems of Recommendation', 'Virtual learning environment', 'Artificial intelligence')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/6752","2019-12-18","https://www.repositorio.ufal.br/bitstream/riufal/6752/1/An%c3%a1lise%20da%20ader%c3%aancia%20de%20recomenda%c3%a7%c3%b5es%20explicadas%20de%20recursos%20educacionais%20para%20apoiar%20o%20ensino%20e%20a%20aprendizagem%20em%20um%20ambiente%20educacional%20online.pdf","Analyzing the acceptance for explained recommendations of educational resource in an online learning environment","('Ranilson Oscar Araújo Paiva',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/5938","Campus A.C. Simões","Instituto de Computação","Dissertação","Análise de medidas de centralidade utilizando distância de Hellinger","('Fabiano dos Santos Brião',)","('Raquel da Silva Cabral',)","('Marcilio Ferreira de Souza Júnior',)","A teoria das redes complexas tem entre suas características a interdisciplinaridade, além de ser concisa e clara consegue envolver simultaneamente diversas áreas com ampla aplicabilidade emmodelagens reais. Algumas redes, por exemplo, a Internet, as rotas de aeroportos, colaboradores científicos, de energia elétrica e de esgotos possuemuma estrutura física que lhes caracterizam como redes complexas. Por serem dinâmicas essas redes estão sujeitas a alterações de topologia. Sendo assim, é necessário conhecer suas características físicas e analíticas para melhor compreender tais acontecimentos. Em particular analisamos um conjunto de Sistemas Autonômos (ASs) formado por redes de clientes, redes universitárias, alémde pontos de intercâmbios, entre outros. Sendo os vértices cada AS e arestas as ligações entre estes ASs. Este estudo teve por objetivo verificar uma rede real da Internet formada por ASs, através de seu respectivo grafo para compreender seu comportamento e particularidades por vias de medidas de centralidade baseadas em vértices. Para atingir tal objetivo utilizamos estudos estatísticos associados ao MétodoMonte Carlo e modificamos de forma aleatória seu grafo comperturbações para obter novos grafosmodificados topologicamente. Através das frequências relativas das medidas de centralidade baseadas em vértices destes grafos, original e modificados, obtivemos por meio do quantificador distância de Hellinger diversos resultados relevantes. Acerca de perturbações, a remoção de arestas foi o tipo de perturbação quemais alterou a topologia entre as redes. Comreferência asmedidas de centralidade, o grau de proximidade foi o mais vulnerável de modo geral em relação as perturbações.","The theory of complex networks has among its characteristics the interdisciplinarity, besides being concise and clear can simultaneously involve several areas with broad applicability in real modeling. Some networks, for example, the Internet, airports routes, scientific collaborators, electricity and sewage have a physical structure that characterize them as complex networks. Because they are dynamics these networksmight be affected by topology changes. In this case, it is necessary to know physical and analytical characteristics to better understand such events. In particular we analyzed a set of Autonomous Systems (ASs) composed of customer networks, university networks, beyond points exchanges, and others. It is the vertices and edges each AS the connections between the ASs. This study has the objective to verify a real Internet network of ASs, through their respective graph to understand their behavior and their characteristics by way of centralizedmeasures based on vertices. To achieve this goal we use statistical studies associated of the Monte Carlo Method and modified randomly your graphwith perturbations for newgraphsmodified topologically. Through the relative frequencies of the centrality measures based on these graphs vertices, original and modified. We obtained through Hellinger distance quantifier many relevant results. About doing perturbations, removing edgeswas themost kind of perturbations that had altered the topology compared the others networking. According to the centralitymeasures, the degree of Closenessmeasure was themost vulnerable in general compared another perturbations.","('Teoria dos grafos', 'Redes complexas', 'Distâncias estocásticas', 'Perturbações', 'Medidas de centralidade', 'Graph teory', 'Complex network', 'Stochastic distances', 'Perturbations', 'Centrality measures')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/5938","2016-05-24","https://www.repositorio.ufal.br/bitstream/riufal/5938/1/An%c3%a1lise%20de%20Medidas%20de%20Centralidade%20utilizando%20Dist%c3%a2ncia%20de%20Hellinger.pdf","Analysis of centrality measures using Hellinger's Distance","('Alejandro César Frery Orgambide',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/834","Campus A.C. Simões","Instituto de Computação","Dissertação","Análise de sinais pulmonares utilizando técnicas no domínio Tempo-Frequência e Classificação Neural","('Alberto Jorge Santos de Almeida',)","('Luís Cláudius Coradine',)","('Antônio Fernando de Sousa Bezerra', 'João Marcos Travassos Romano')","A ausculta é um método da prática clinica, simples, não invasivo, utilizado no diagnóstico de doenças do sistema respiratório. Porém, trata-se de um método impreciso devido, entre outros fatores, ás limitações do sistema auditivo, a sobreposição de sons cardíacos e a diferença de sensibilidade auditiva humana, além da característica de resposta espectral limitada de muitos estetoscópios comerciais. Tais fatores contribuem para que o diagnóstico dependa muito da experiência do profissional especialista. A análise acústica de características espectrais de sinais da ventilação pulmonar pode ser uma técnica complementar de diagnóstico, facilitando o processo de detecção e identificação desses sons respiratórios, possibilitando auxiliar a avaliação da gravidade dos sintomas e a eficácia do tratamento. Neste trabalho, buscou-se estruturar um processo de análise de sinais pulmonares, para a identificação de características das patologias respiratórias. Nesse sentido, os sinais foram tratados por processos de filtragem e decompostos em sub-bandas de frequências através da Transformada de Wavelet Discreta (DWT), gerando vetores como coeficientes para classificação utilizando uma Rede Neural Artificial. Um estudo de caso com sinais obtidos por testes foi apresentado e devidamente analisado.","Auscultation is a method of clinical practice, simple, noninvasive, used to diagnose diseases of the respiratory system. However, it is an imprecise method because, among other factors, the limitations of the auditory system, the overlap of heart sounds and human hearing sensitivity difference, besides the limited spectral response characteristic of many commercial stethoscopes. These factors contribute to the diagnosis relies heavily on the experience of the professional expert. The acoustic analysis of spectral characteristics of signals of ventilation can be a complementary diagnostic technique in facilitating the process of detection and identification of breath sounds, providing aid in the assessment of symptom severity and treatment efficacy. In this study, we attempted to structure a process of analysis of pulmonary signs to identify characteristics of respiratory disorders. Accordingly, the signals were processed by filtering processes and decomposed into sub-frequency bands through discrete wavelet transform (DWT), generating vectors as coefficients for classification using an Artificial Neural Network. A case study with signals obtained from tests was presented and duly considered.","('Sings Lung', 'Wavelet transform', 'Neural Network', 'Sinais Pulmonares', 'Transformada Wavelet', 'Redes Neurais')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://repositorio.ufal.br/handle/riufal/834","2010-11-25","https://www.repositorio.ufal.br/bitstream/riufal/834/1/An%c3%a1lise%20de%20sinais%20pulmonares%20utilizando%20t%c3%a9cnicas%20no%20dom%c3%adnio%20Tempo-Frequ%c3%aancia%20e%20Classifica%c3%a7%c3%a3o%20Neural.pdf","Signal analysis in lung Using techniques Time-Frequenci domain and Neural Classification","('Roberta Vilhena Vieira Lopes',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/5561","Campus A.C. Simões","Instituto de Computação","Dissertação","Análise da evolução dos modelos mentais dos aprendizes de cinemática e dinâmica no cenário da aprendizagem baseada em problemas com auxílio de um ambiente de aprendizagem fundamentado na simulação","('Geraldo Tomaz da Silva Neto',)","('Fábio Paraguaçu Duarte da Costa',)","('Evandro de Barros Costa', 'Roberta Vilhena Vieira Lopes', 'Kleber Cavalcanti Serra')","As dificuldades apresentadas pelos alunos no âmbito dos cálculos matemáticos geram índices de reprovações em Física. A Mecânica Newtoniana se apresenta como conteúdo de fácil contextualização e aplicações ao cotidiano dos alunos. Por exemplo, a aplicação de tal tema pode ser usada quando se fala sobre trânsito. Problemas como derrapagens de automóveis e colisões por distrações de motoristas ao volante são tópicos ricos em aplicações da Física. Algumas propostas pedagógicas como a Aprendizagem Baseada em Problemas possibilita aos alunos se tornar sujeitos ativos na construção do conhecimento a partir de resoluções de situações reais de aprendizagem. Nesse sentido, a programação computacional apresenta-se como ferramenta valiosa no quesito da aprendizagem em resoluções de problemas. O presente trabalho tem como objetivo propor um conjunto de modelos mentais de Cinemática e Dinâmica baseados em Aprendizagem Baseada em Problemas, destacando a evolução dos tais com o auxílio da aprendizagem de programação computacional. Para isso foram coletados dados por meio de observação das atividades de alunos de turmas de segundo e terceiro ano do ensino médio de uma escola básica da rede privada dentro das etapas estabelecidas na Aprendizagem Baseada em Problemas. Constatou-se que os alunos que apresentavam maior familiaridade com o tema, apresentavam respostas com melhores fundamentos dentro da Física. Também ficou evidente que todas as ações denotadas no ato de programar foram cruciais para verificação dos alunos sobre as conclusões nas resoluções dos problemas. Os resultados reforçam que ao refletir e solucionar sobre problemas por meio dos ambientes de programação, os alunos ficam motivados para participar de forma direta na construção do conhecimento de Cinemática e Dinâmica.","The great difficulty presented by the students in the scope of the mathematical calculations generate great indices of reprobations in Physics. The Newtonian Mechanics presents itself as content of easy contextualization and applications to the daily life of the students. For example, the application of such a theme can be used when talking about traffic. Problems like car skidding and collisions due to distractions from drivers at the wheel are topics rich in applications of physics. Some pedagogical proposals such as Problem-Based Learning enable students to become active subjects in the construction of knowledge based on real learning situations. In this sense, the computational programming presents itself as a valuable tool in the matter of learning in problem solving. The present work aims to propose a set of mental models of Kinematics and Dynamics based on Problem Based Learning highlighting the evolution of such with the aid of learning programming. For this, data were collected by observing the activities of students in the second and third year of high school classes of a private school basic school within the stages established in Problem Based Learning. It was found that the students who were more familiar with the subject presented answers with better fundamentals within Physics. It was also evident that all the actions denoted in the programming were crucial for verifying the students about the conclusions in the resolutions of the problems. The results reinforce that when reflecting and solving problems through programming environments, students are motivated to participate directly in the construction of Kinematics and Dynamics knowledge.","('Ambiente de programação', 'Aprendizagem baseada em problemas', 'Ensino contextualizado de cinemática e dinâmica', 'Programming environments', 'Problem-based learning', 'Contextual teaching of kinematics and dynamics')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/5561","2018-04-25","https://www.repositorio.ufal.br/bitstream/riufal/5561/1/An%c3%a1lise%20da%20evolu%c3%a7%c3%a3o%20dos%20modelos%20mentais%20dos%20aprendizes%20de%20cinem%c3%a1tica%20e%20din%c3%a2mica%20no%20cen%c3%a1rio%20da%20aprendizagem%20baseada%20em%20problemas%20com%20aux%c3%adlio%20de%20um%20ambiente%20de%20aprendizagem%20fundamentado%20na%20simula%c3%a7%c3%a3o.pdf","Analysis if the evolution of the mental models of kinematic and dynamic apprenticeships in the problem-based learning scenario with aid of a simultaneous learning environment","('Cleide Jane de Sá Araujo Costa',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/6674","Campus A.C. Simões","Instituto de Computação","Dissertação","Análise da topologia de redes veiculares usando métricas de centralidade","('Igor Marcos Araujo de Oliveira',)","('Raquel da Silva Cabral',)","('André Luiz Lins de Aquino', 'Thiago Bruno Melo de Sales')","Redes Veiculares são chamadas de VANET, Vehicular Adhoc Network, em VANETs a propagação de dados é um dos temas centrais na busca da eﬁciência na transmissão de dados. Estudos vêm sendo realizados para melhorar a qualidade na transmissão de dados entre veículos, investigar o comportamento dos veículos na via em determinados períodos de tempo e prever o melhor caminho ou caminh mais curto,sempre como objetivo de propagar os dados e traçar estratégias para o caso de falhas de conexão. Desta forma, a conexão, entre os veículos é uma barreira que pode inviabilizar o objetivo da rede,considerando as falhas constantes do transito de dados entre emissor e receptor, impedindo que os dados cheguem ao destino em tempo de evitar por exemplo uma colisão entre veículos autômatos. Este trabalho busca, analisar a topologia das redes veiculares das cidades de Colônia na Alemanha, Madrie Créteil na França, mapeando as mesmas como redes complexas para cada tempo de coleta e extraindo propriedades métricas da teoria dos grafos e redes complexas como: Degree Medium, Clustering Coefﬁcient, Betweenness, Closeness, Diameter. Em seguida, é aplicado o conjunto de dados ao quantiﬁcador estocástico de Hellinger para avaliar as mudanças entre os instantes de tempo de coleta. Neste sentido, a avaliação indica possíveis divergências entre os instantes de tempo que podem justiﬁcar problemas potenciais no percurso da rede, bem como necessidade de melhorias estruturais. Este trabalho baseou-se na metodologia que consistiu nas etapas: I) deﬁnição da rede, II) tratamento da rede, III) tratamento das características da rede,IV) inspeção visual. Os resultados foram gerados numericamente e graﬁcamente para permitir a avaliação e interpretação comportamental das redes estudadas com base nas medidas de centralidade e o quantiﬁcador estocástico utilizado neste trabalho","Vehicle networks are called VANET, in VANETs data propagation is one of the central themes in the search for efﬁciency in data transmission. Studies are being conducted to improve the quality of data transmission between vehicles, to investigate vehicle behavior on the road at certain time periods and to predict the best or shortest route, always with the aim of propagating data and strategizing the case. of connection failures. Thus the connection between vehicles is a barrier that can make the network objective impossible, preventing data from reachingits destinationin time to avoid,for example, a collision between automatavehicles. This paper seeks to analyze the topology of vehicular networks in the cities of Cologne, Germany, Madrid and Créteil in France, mapping them as complex networks for each collection time and extracting metric properties from graph theory and complex network ssuch as: Degree Medium, Clustering Coefﬁcient, Betweenness, Closeness, Diameter. The datas set is then applied to Hellinger’s stochastic quantiﬁer to evaluate changes between collection time points. In this sense, the evaluation indicates possible divergences between time periods that may justify potential problems in the network path, as well as the need for structural improvements. This work was based on the methodology that consisted of the followingsteps: I)network deﬁnition,II)network treatment,III)network characteristics treatment, IV) visual inspection. The results were numerically and graphically generated to allow the evaluation and behavioral interpretation of the studied networks based on the centrality measures and the stochastic quantiﬁer used in this work","('Redes Complexas', 'Hellinger', 'Redes Veiculares', 'VANETs', 'Resiliência', 'Trafego', 'Vulnerabilidades', 'Complex Networks', 'Hellinger', 'Vehicular Networks', 'VANETs', 'Resilience', 'Trafﬁc', 'Vulnerabilities')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/6674","2019-12-17","https://www.repositorio.ufal.br/bitstream/riufal/6674/1/Igor%20Marcos%20Araujo%20de%20Oliveira%20-%20Disserta%c3%a7%c3%a3o.pdf","Analysis of vehicle network topology using centrality metrics",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/6636","Campus A.C. Simões","Instituto de Computação","Dissertação","Análise de otimização de roteamento Iot em redes LLN’s para cidades inteligentes : um estudo empírico sobre a utilização do método de enxame ACO em ambientes Iot para cidades inteligentes","('César Felipe Gonçalves da Silva',)","('Rafael de Amorim Silva',)","('Bruno Almeida Pimentel', 'Diego Dermeval de Medeiros da Cunha Matos')","Internet das Coisas é uma rede de dispositivos que possuem sensores e que tem poder de processamento, armazenamento, capacidade de interconexão e alguma inteligência. Inúmeras tecnologias IoT têm possibilitado a redução significativa de tarefas repetitivas, um tráfego rápido de dados em uma rede de comunicação, um melhor armazenamento e organização de informações, um monitoramento efetivo de ambientes diversos, entre outros benefícios a sociedade. Quando aplicada a centros urbanos, dispositivos IoT permitem o monitoramento individual de indicadores de saúde, qualidade e umidade do ar, temperatura ambiente, pressão atmosférica, tráfego terrestre e aéreo, monitoramento do solo, da agricultura e pecuária, serviços de infraestrutura pública, emissão de alertas de perigo, dentre outros. A aplicação de dispositivos IoT nestes centros urbanos é essencial para caracterizar as Smart Cities (cidades inteligentes), um conceito moderno que busca otimizar o uso destas tecnologias e a gestão do espaço urbano. Normalmente, tais dispositivos têm escassa capacidade energética, de processamento, armazenamento e conectividade e um dos principais desafios científicos da atualidade é tentar otimizar o uso destes recursos de forma inteligente, aplicando técnicas como ACO (Ant Colony Optimization), baseadas no micromundo das formigas. Portanto, a proposta deste trabalho é realizar uma análise detalhada da otimização do uso energético dos nós de uma rede IoT provida pelo método de enxame ACO, com o emprego de simulações, coleta de dados e respectiva análise para entender se sua aplicação proporciona aos dispositivos investigados um aumento efetivo no tempo de vida útil destes dispositivos em uma rede IoT. Os resultados obtidos deste estudo servirão como base para melhoria dos mecanismos empregados nos eventos de roteamentos presentes em cenários IoT.","Internet of Things is a network of sensor-enabled devices that have processing power, storage, interconnectivity, and some intelligence. Numerous IoT technologies have made it possible to significantly reduce repetitive tasks, fast data traffic on a communication network, better storage and organization of information, effective monitoring of diverse environments, and other benefits to society. When applied to urban centers, IoT devices allow individual monitoring of indicators of health, air quality and humidity, ambient temperature, atmospheric pressure, land and air traffic, soil, agriculture and livestock monitoring, public infrastructure services, hazard alerts, among others. The application of IoT devices in these urban centers is essential to characterize Smart Cities, a modern concept that seeks to optimize the use of these technologies and the management of urban space. Typically, such devices have scarce power, processing, storage, and connectivity capabilities, and one of today's key scientific challenges is trying to intelligently optimize the use of these resources by applying techniques such as Ant Colony Optimization (ACO), based on ant microworlds. Therefore, the purpose of this work is to perform a detailed analysis of the energy use optimization of the nodes of an IoT network provided by the ACO swarm method, using simulations, data collection and respective analysis to understand if its application provides the investigated devices. an effective increase in the lifetime of these devices on an IoT network. The results obtained from this study will serve as a basis for improving the mechanisms employed in routing events present in IoT scenarios","('Internet das Coisas', 'Otimização por Colônia de Formigas', 'Cidades Inteligentes', 'Eficiência Energética', 'Rede de Sensor Sem Fio', 'Internet of Things', 'Ant Colony Optimization', 'Smart Cities', 'Energy Efficiency', 'Wireless Sensor Networks')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/6636","2019-12-20","https://www.repositorio.ufal.br/bitstream/riufal/6636/2/An%c3%a1lise%20de%20otimiza%c3%a7%c3%a3o%20de%20roteamento%20Iot%20em%20redes%20LLN%e2%80%99s%20para%20cidades%20inteligentes%20%3a%20um%20estudo%20emp%c3%adrico%20sobre%20a%20utiliza%c3%a7%c3%a3o%20do%20m%c3%a9todo%20de%20enxame%20ACO%20em%20ambientes%20Iot%20para%20cidades%20inteligentes.pdf","Analysis of IoT routing optimization in LLN´s networks for smart cities",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/123456789/8993","Campus A.C. Simões","Instituto de Computação","Dissertação","Análise da confiança de estudantes de ambientes virtuais de aprendizagem em itens oferecidos por sistemas de recomendação","('Alana Viana Borges da Silva Neo',)","('Ranilson Oscar Araújo Paiva',)","('Diego Dermeval de Medeiros da Cunha Matos', 'Rafael Ferreira Leite de Mello')","Os ambientes virtuais de aprendizagem foram desenvolvidos como uma forma online para que o aluno pudesse interagir com seus professores, colegas e conteúdo do curso. Estes ambientes dispõem de recursos pedagógicos em quantidade e diversidade, permitindo recomendações desses aos estudantes, baseando-se nas suas respectivas necessidades, além das competências que deverão ser desenvolvidas. Porém, há limitações nesses sistemas de recomendação em ambientes virtuais de aprendizagem, principalmente em relação à qualidade das recomendações, levando a problemas referentes à aceitação das recomendações por parte dos estudantes. Um dos fatores que pode levar à não aceitação das recomendações recebidas é a falta de confiança. Uma possível abordagem para este problema é explicar aos estudantes como essa recomendação foi criada. Para isso, pretendemos identificar se existe diferença na confiança de estudantes em recomendações: (1) com explicação personalizada de acordo com o desempenho e interação do próprio estudante e; (2) com explicação personalizada de acordo com o desempenho e interação da turma. Para avaliar nossa pesquisa, realizamos um experimento para avaliar a preferência e percepção de estudantes do ensino superior, quanto à explicação das recomendações enviadas pelo ambiente virtual de aprendizagem. Para isso, realizamos um experimento e utilizamos os dados de interações desses estudantes com o conteúdo de um curso online de introdução à computação. A partir desses dados, selecionamos os dados de um estudante com problemas no seu desempenho e interação, e geramos recomendações alinhadas com as suas necessidades. Em seguida, criamos as explicações para essas recomendações e avaliamos, por meio de um survey, o impacto da confiança dos estudantes em relação às recomendações pedagógicas geradas de forma personalizada para o aluno e para a turma. Esperamos com este trabalho contribuir para uma melhoria na qualidade das recomendações e para aumentar a confiança dos estudantes em relação a recomendações pedagógicas em ambientes virtuais de aprendizagem.","Virtual learning environments were developed as an online way for students to interact with their teachers, peers and course content. These environments have pedagogical resources in quantity and diversity, allowing for recommendations of these to students, based on their respective needs, in addition to the skills that should be developed. However, there are limitations in these recommendation systems in virtual learning environments, especially in relation to the quality of recommendations, leading to problems regarding the acceptance of recommendations by students. One of the factors that can lead to non-acceptance of received recommendations is lack of trust. One possible approach to this problem is to explain to students how this recommendation was created. For this, we intend to identify whether there is a difference in the students' confidence in recommendations: (1) with personalized explanation according to the student's own performance and interaction; (2) with personalized explanation according to the performance and interaction of the class. To evaluate our research, we performed an experiment to assess the preference and perception of higher education students regarding the explanation of the recommendations sent by the online learning environment. For this, we performed an experiment and used data from these students' interactions with the content of an online introductory computer course. From this data, we select the data of a student with problems in their performance and interaction, and we generate recommendations aligned with their needs. We then create explanations for these recommendations and assess, through a survey, the impact of student confidence in the pedagogical recommendations generated in a personalized way for the student and the class. We hope with this work to contribute to an improvement in the quality of recommendations and to increase students' confidence in pedagogical recommendations in virtual learning environments.","('Ambientes virtuais de aprendizagem', 'Ensino remoto', 'Sistemas de recomendação', 'Virtual learning environments', 'Online teaching', 'Recommender systems')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/8993","2021-11-30","https://www.repositorio.ufal.br/bitstream/123456789/8993/1/An%c3%a1lise%20da%20confian%c3%a7a%20de%20estudantes%20de%20ambientes%20virtuais%20de%20aprendizagem%20em%20itens%20oferecidos%20por%20sistemas%20de%20recomenda%c3%a7%c3%a3o.pdf","Analysis of students' confidence in Virtual Learning Environments in items offered by Recommender Systems","('Leonardo Brandão Marques',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/2069","Campus A.C. Simões","Instituto de Computação","Dissertação","Análise da utilização de uma ferramenta de fórum de discussão baseado em mapas conceituais: um experimento no sistema UAB-UFAL","('Sunny Kelma Oliveira Miranda',)","('Fábio Paraguaçu Duarte da Costa',)","('Marcus de Melo Braga', 'Crediné Silva de Menezes')","O processo de ensino-aprendizagem on-line vem sendo fortalecido nos últimos anos com a evolução tecnológica que permite ao aluno participar de aulas e realizar suas atividades em qualquer lugar e a qualquer momento. Uma dessas atividades comuns em um ambiente virtual de aprendizagem é interagir no Fórum de Discussão com os demais alunos da turma. Entretanto, os fóruns de discussão têm apresentado uma problemática de pouca interação entre aprendizes e mais respostas diretas ao professor-tutor da turma. Como algumas possíveis causas para essa atitude indesejada dos alunos foram identificadas: o uso formal da língua, exigido nesse ambiente, pode inibir a participação dos aprendizes; dificuldade no entendimento da discussão pela estruturação de mensagens aninhadas. Como solução alternativa a esse tipo de fórum, concebeu-se uma ferramenta de formato dinâmico estruturado por mapas conceituais (denominada Fórum bMC), onde o aprendiz discute o tema proposto identificando conceitos-chave e relacionando-os com novos conceitos dispostos no mapa conceitual de forma colaborativa. Desta forma, o objetivo deste trabalho foi desenvolver e analisar a utilização dessa ferramenta na promoção de interações mais diretas, objetivas e significativas entre aprendizes, fundamentando-se em estudos anteriores. Para isso, delineou-se uma pesquisa experimental com uso da ferramenta por uma turma de um curso da graduação da Universidade Aberta do Brasil na UFAL. Os dados foram coletados e analisados qualitativamente a partir dos registros dos alunos no ambiente do experimento, de observações das interações e de questionários aplicados aos aprendizes e a docente da turma. Como resultado geral, na visão da docente, a ferramenta teve um desempenho satisfatório dos alunos, realizando boas interações argumentadas para a construção do mapa conceitual. Na visão dos alunos, a ferramenta foi bem avaliada, concluindo que a sua utilização facilitou a leitura e entendimento do que foi discutido, assim como, ajudou a assimilar melhor o conteúdo exposto.","The process of teaching and learning online has been strengthened in recent years with a technological evolution that allows the student to participate in classes and carry out their activities anywhere and at any time. One of these common activities in a virtual learning environment is to interact in the Discussion Forum with the other students in the class. However, the discussion forums have presented a problem of little interaction between learners and more direct answers to the teacher-tutor of the class. How some possible causes for this undesired attitude of the students were identified: the formal use of the language, demanded in this environment, can inhibit the participation of the learners; difficulty in understanding the discussion by structuring nested messages. As a workaround to this type of forum, a dynamic tool structured by conceptual maps (called the bMC Forum) was conceived, where the learner discusses the proposed theme by identifying key concepts and relating them to new concepts arranged in the collaborative conceptual map. In this way, the objective of this work was to develop and analyze the use of this tool in the promotion of more direct, objective and meaningful interactions among apprentices, based on previous studies. For that, an experimental research with the use of the tool was delineated by a class of a graduation course of the Open University of Brazil in UFAL. Data were collected and analyzed qualitatively from the students' records in the experiment environment, observations of the interactions and questionnaires applied to the apprentices and the class teacher. As a general result, in the teacher’s view, the tool had a satisfactory performance of the students, performing good interactions argued for the construction of the conceptual map. And in the students' view, the tool was well evaluated, concluding that its use facilitated the reading and understanding of what was discussed, as well as helped to better assimilate the exposed content.","('Educação on-line', 'Fóruns de discussão', 'Mapa conceitual', 'Online education', 'Forums', 'Discussion', 'Concept map')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/2069","2017-08-23","https://www.repositorio.ufal.br/bitstream/riufal/2069/1/An%c3%a1lise%20da%20utiliza%c3%a7%c3%a3o%20de%20uma%20ferramenta%20de%20f%c3%b3rum%20de%20discuss%c3%a3o%20baseado%20em%20mapas%20conceituais%20-%20um%20experimento%20no%20sistema%20UAB-UFAL.pdf","Analysys of the use a discussion forum based on concept maps: an experiment in the UAB-UFAL system","('Evandro de Barros Costa',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/3190","Campus A.C. Simões","Instituto de Computação","Dissertação","Análise computacional da biomecânica corneal para diagnóstico de ceratocone","('Kempes Jacinto',)","('Aydano Pamponet Machado',)","('João Marcelo de Almeida Gusmão Lyra', 'Jorge Artur Peçanha de Miranda Coelho', 'Renato Ambrósio Júnior')","O objetivo do corrente estudo foi encontrar e modelar representações de características da biomecânica corneal a partir de imagens de exames geradas pelo Corvis ST, a fim de realizar sua aplicação a técnicas de aprendizagem de máquina para o diagnóstico precoce de ceratocone. As imagens foram segmentadas para identificação e conversão em vetores para representação das superfícies anterior, superfície posterior aparente, paquimetria aparente e composição dos dados anteriores. Os vetores foram encadeados (imagens em lote), simplificados com Wavelet e submetidos a MLP, k-NN, Regressão Logística, Naïve Bayes e Fast Large Margin, além do arranjo dos vetores como histogramas 2D para aplicação em rede neural com Deep Learning. A avaliação das classificações foi feita com o escore igual ao produto da sensibilidade multiplicado pela especificidade, com intervalo de confiança entre 0,7843 e 1 e nível de significância 0,0157. Foram usados exames de 686 olhos normais e 406 olhos com ceratocone em graus de I a IV, provindos de bases de exames da Europa e do Brasil, para treinamento e validação dos dados aplicados. Os melhores modelos identificados ocorreram com paquimetria aparente de imagens em lote, com aplicação de wavelet nível 4 e processada com fast large margin na base de dados da Europa, com escore 0,8247, sensibilidade de 89,5% e especifidade de 92,14%; e histograma 2D da paquimetria aparente, com LeNET5, na base do Brasil, com escore 0,8361, sensibilidade de 88,58% e especificidade de 94,39%. Conclui-se que os modelos da biomecânica podem ser usados para diagnosticar ceratocone.","keratoconus. The images were segmented for identification and conversion into vectors for representation of the anterior surface, apparent posterior surfaces, apparent pachymetry and composition of the previous data. The vectors were chained (batch images), simplified with Wavelet and submitted to MLP, k-NN, Logistic Regression, Naïve Bayes and Fast LargeMargin, in addition the vectors were rearranged as 2D histograms for neural network application with Deep Learning. The evaluation of the classifications was done with the score equal to the product of the sensitivity multiplied by the specificity, with confidence interval between 0.7843 and 1 and level of significance 0.0157. Exams of 686 normal eyes and 406 eyes with keratoconus in degrees from I to IV, from exam bases from Europe and Brazil, were used for training and validation of applied data. The best models identified were apparent pachymetry on batch images, with wavelet level 4 and processed with fast large margin in the European database, with a score of 0.8247, sensitivity of 89.5% and specificity of 92.14%; and 2D histogram of apparent pachymetry, with LeNET5, at the Brazilian database, with a score of 0.8361, sensitivity of 88.58% and specificity of 94.39%. It is concluded that biomechanical models can be used to diagnose keratoconus.","('Ceratonone.', 'Biomecânica', 'Diagnóstico', 'Inteligência artificial', 'Segmentação', 'Keratoconus', 'Biomechanics', 'Diagnosis', 'Artificial Intelligence', 'Segmentation')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/3190","2018-04-13","https://www.repositorio.ufal.br/bitstream/riufal/3190/1/An%c3%a1lise%20computacional%20da%20biomec%c3%a2nica%20corneal%20para%20diagn%c3%b3stico%20de%20ceratocone.pdf","Computational analysis of corneal biomechanics for diagnosis of Keratoconus",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/12561","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Modelagem dinâmica de um pêndulo duplo utilizando redes neurais lagrangianas","('Luana Júlia Nunes Ferreira',)","('Ícaro Bezerra Queiroz de Araújo',)","('Tiago Alves de Almeida', 'Glauber Rodrigues Leite')","O presente trabalho tem como objetivo estudar a aplicação de redes neurais na modalagem de um pêndulo duplo, um sistema dinâmico complexo e desafiador. Uma nova classe de Redes Neurais Hamiltonianas (HNN) para modelar o pêndulo duplo foi proposta, porém apresenta falha em muitos sistemas físicos que não podem ser expressos como um sistema Hamiltoniano e, por isso, foi proposto o uso de redes neurais com formulação Lagrangiana (LNN). Logo, este trabalho busca avaliar a eficácia dessa abordagem, reproduzindo o trabalho de Cranmer et al. (2020). Os resultados dessa pesquisa confirmam que a abordagem LNN foi eficaz na obtenção de soluções numéricas próximas à solução analítica. Além disso, o sistema também se mostrou sensível às condições iniciais e a análise da função de loss indicou estabilidade nos resultados após o período de treinamento. A comparação entre as velocidades e acelerações angulares provenientes da solução analítica e previstas mostrou uma relação linear e mínima interferência de outliers. O mapa de calor gerado a partir da análise do espaço de coordenadas mostrou que o modelo se comportou de forma satisfatória.","This work aims to study the application of neural networks in the modeling of the double pendulum, a complex and challenging dynamic system. A new class of Hamiltonian Neural Networks (HNN) was proposed to model the double pendulum, but it fails in many physical systems that cannot be expressed as a Hamiltonian system. Therefore, the use of neural networks with Lagrangian formulation (LNN) was proposed. This work seeks to evaluate the effectiveness of this approach, using the double pendulum as a case study and reproducing the work of Cranmer et al. (2020). The results of this research confirm that the LNN approach was effective in obtaining numerical solutions close to the ideal analytical solution. Furthermore, the system also proved to be sensitive to initial conditions, and the analysis of the loss function indicated stability in the results after the training period. The comparison between real and predicted angular velocities and accelerations showed a linear relationship and minimal interference from outliers. The heat map generated from the analysis of the coordinate space showed that the model behaved satisfactorily.","('Redes neurais (Computação)', 'Lagrange, Funções de', 'Sistemas dinâmicos', 'Controle', 'Pêndulo duplo', 'Neural Networks (Computing)', 'Lagrange, Functions of', 'Dynamic systems', 'Control', 'Double pendulum')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/12561","2023-05-05","https://www.repositorio.ufal.br/bitstream/123456789/12561/1/Modelagem%20din%c3%a2mica%20de%20um%20p%c3%aandulo%20duplo%20utilizando%20redes%20neurais%20lagrangianas.pdf","",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/1853","Campus A.C. Simões","Instituto de Computação","Dissertação","Um ambiente para recuperação semântica de informação em governo eletrônico: um estudo de caso em licitações públicas","('Luiz Frederico Lopes de Oliveira',)","('Evandro de Barros Costa',)","('Frederico Luiz Gonçalves de Freitas', 'Augusto Loureiro da Costa')","O tratamento dado ao grande volume de informações produzidas sob a ótica do governo representa um fator crítico de sucesso para os diversos tipos de relacionamentos que envolvem a administração pública: Governo e Cidadão, Governo e Setor Privado, Governo e outros órgãos e esferas do Governo e Governo e o Servidor Público. Como estamos diante de uma sociedade iminentemente digital, torna-se viável o uso da tecnologia para a divulgação destas informações e, neste caso, o meio bastante apropriado é a Internet. Porém, encontrar a informação desejada na imensidão de documentos existentes na Web é uma tarefa bastante difícil. A fi m de facilitar esta tarefa, a utilização da tecnologia proposta pela Web Semântica surge como uma alternativa bastante promissora. Assim, a arquitetura da Web Semântica facilita o compartilhamento das informações que são geradas continuamente e por diversas fontes de informação, características típicas em um ambiente de e-Gov. Com isto, cidadãos, empresas ou outros órgãos de governo encontram um caminho mais e ciente de relacionamento com o governo. Esta pesquisa aborda a utilização de ontologias e propõe um ambiente baseado em agentes de software para localização de informações na Web. As ontologias facilitam a formatação padronizada dos conteúdos divulgados, enquanto a localização e recomendação das informações é automatizada através de agentes de software. Um catálogo de páginas Web, recurso muito utilizados pelas primeiras ferramenta de busca na Web, também é utilizado pelo protótipo para catalogar ontologias e páginas RDF. Este catálogo é utilizado para orientar a localização de páginas Web, marcadas semanticamente, que atendam a critérios de buscas pré-estabelecidos pelos usuários. O ambiente proposto também contempla a recomendação das informações que são localizadas nas páginas RDF. Neste estudo de caso, as recomendações serão aplicadas em informações sobre licitações públicas. A criação de um ambiente de busca semântica de informação possibilitou a diminuição do esforço necessário para a troca de informações através da Internet, aumentando com isto, de maneira signifi cativa, as chances de sucessos de iniciativas de e-Gov. Além disto, a solução mostrou-se viável para qualquer contexto que, igualmente ao e-Gov, disponibiliza um grande volume de informações de natureza heterogênea e utiliza a Internet como meio de divulgação.","The treatment given to the great volume of information produced under optics of the government represents a critical factor of success for diverse types of relationships that involve the public administration: Government and Citizen, Government and Private Sector, Government e other agencies and spheres of the Government and Government and the Government Employee. As we are facing a digital imminently society, it becomes viable to use the technology to dissemination of this information and, in this case, the Internet is quite appropriate. However, nding the desired information in the immensity of existing documents on the Web is a very hard task. To make this easier, the use of Semantic Web technology appears as a promising alternative. Thus, the SemanticWeb architecture expedites the information sharing that is continuously generated and by all kind of sources of information in a typical e-Gov environment. Therefore, citizens, companies or other government spheres nd a e cient way of relationship with the government. This research is about the use of Ontologies and proposes an environment based in software agents to search for information on the Web. Ontologies make easier having a standard formatting for publish contents, while the searching and the information's recommendation is automated by software agents. A catalog of web pages, widely used in Web search tools from the beginning, is also used by the prototype to catalog Ontologies and RDF pages. This catalog is used to guide the searching of Web pages, semantically marked up, which meet the search preset criteria choosed by the users. The proposed environment also includes the information recommendation found in RDF pages. In this case study, the recommendations will be used in information about public tenders. Creating an environment for semantic search of information made it possible to decrease the e ort required to information exchange on the Internet, increasing, signi cantly, the chances of success of e-Gov initiatives. In addition, the solution proved feasible to any context that, like the e-Gov, provides a great volume of heterogeneous information and uses the Internet as a form of publicizing.","('Agentes inteligentes (Software)', 'Administração pública', 'Licitação pública', 'Ontologia', 'Web semântica', 'Intelligent agents (Software)', 'Public administration', 'Public bidding', 'Ontology', 'Semantic Web')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1853","2006-09-29","https://www.repositorio.ufal.br/bitstream/riufal/1853/1/Um%20ambiente%20para%20recupera%c3%a7%c3%a3o%20sem%c3%a2ntica%20de%20informa%c3%a7%c3%a3o%20em%20governo%20eletr%c3%b4nico%3a%20um%20estudo%20de%20caso%20em%20licita%c3%a7%c3%b5es%20p%c3%bablicas.pdf","An environment for semantic retrieval of information in electronic government: a study case about public bids",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/7474","Campus A.C. Simões","Instituto de Computação","Dissertação","Uma abordagem humano computacional para identificação dos fatores que influenciam o IDEB na rede de ensino básico na visão dos gestores educacionais","('Wanderson Rubian Martins Rodrigues',)","('Evandro de Barros Costa',)","('Marcus de Melo Braga', 'Bruno Almeida Pimentel', 'Olival de Gusmão Freitas Júnior')","A busca pela alocação efetiva dos recursos a fim de alcançar o maior número de pessoas é o desafio constante do gestor público. Desta forma, o presente trabalho tem como objetivo identificar quais fatores, percebido pelos gestores educacionais, impacta no IDEB das escolas municipais de Maceió-Alagoas. Os dados iniciais trabalhados nesta pesquisa já existem, porém precisam ser analisados frente à realidade cotidiana do âmbito escolar, estabelecendo uma relação entre a percepção dos gestores e os resultados divulgados pelo INEP/MEC. Assim, surge a pergunta central que norteia esse estudo: como integrar a visão computacional (máquina) com a visão dos gestores educacionais (humanos) para identificar os fatores que possam influenciar positivamente a melhoria do IDEB, visando apoiar a tomada de decisão dos gestores educacionais? Para tanto, utilizou-se dados do teste SAEB das escolas públicas de Maceió. A presente pesquisa tem caráter descritivo e o desenvolvimento metodológico da investigação advém da revisão da literatura, da análise e compilação dos dados do rendimento dos alunos dos anos iniciais do ensino fundamental da rede de ensino municipal de Maceió-Alagoas no IDEB do ano de 2015, e da realização de entrevistas com os diretores escolares, visando compreender as impressões da gestão escolar sobre os resultados do IDEB, conduzindo um estudo experimental, obtendo resultados na tarefa de identificação dos atributos relevantes, como os extraídos pela visão computacional principalmente nas dimensões: violência na escola; políticas, ações e programas na escola; gestão escolar e recursos financeiros. Na percepção dos gestores escolares, observa-se os seguintes atributos como relevantes para melhoria do IDEB: o nível de escolaridade do gestor, o processo de elaboração do projeto pedagógico da escola, medidas para redução das taxas de reprovação, medidas para minimizar as faltas dos alunos, melhoria na comunicação escola-família, a questão da merenda escolar, apoio das instâncias superiores, recursos financeiros para financiar os gastos, o guia didático do MEC e as escolhas dos livros didáticos pelos professores.","The search for effective resource allocation in order to reach the largest number of people is the constant challenge of the public manager. Thus, this work aims to identify which factors, perceived by educational managers, impact on the IDEB of the municipal schools of Maceió-Alagoas. The initial data worked on in this research already exist, but they need to be analysed in view of the daily reality of the school environment, establishing a relationship between the perception of managers and the results disseminated by INEP/MEC. Thus, the central question that guides this study arises: how to integrate the computational vision (machine) with the vision of educational managers (human) in order to identify the factors that may positively influence the improvement of the IDEB, aiming at supporting the decision making of educational managers? For this, data from the SAEB test of the public schools of Maceió were used. This research has a descriptive character and the methodological development of the research comes from the literature review, the analysis and compilation of data on the performance of students of the initial years of primary schools in the Maceió-Alagoas municipal school network in the IDEB of 2015, and from the carrying out of interviews with school headmasters, in order to understand the impressions of school management on the results of the IDEB, conducting an experimental study, obtaining results in the task of identifying the relevant attributes, such as those extracted by computer vision mainly in the dimensions: violence at school; policies, actions and programs at school; school management and financial resources. In the perception of school managers, the following attributes are observed as relevant for the improvement of IDEB: the level of schooling of the manager, the process of elaboration of the pedagogical project of the school, measures to reduce failure rates, measures to minimise student absences, improvement in school-family communication, the issue of school meals, support from higher levels, financial resources to finance the expenses, the MEC didactic guide and the choices of textbooks by teachers.","('Gestão pública', 'Índice de Desenvolvimento da Educação Básica (IDEB)', 'Mineração de dados educacionais', 'Decision making', 'Data mining', 'IDEB', 'Public management')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/7474","2020-07-15","https://www.repositorio.ufal.br/bitstream/riufal/7474/1/Uma%20abordagem%20humano%20computacional%20para%20identifica%c3%a7%c3%a3o%20dos%20fatores%20que%20influenciam%20o%20IDEB%20na%20rede%20de%20ensino%20b%c3%a1sico%20na%20vis%c3%a3o%20dos%20gestores%20educacionais.pdf","A human computational approach to identifying the factors influencing IDEB in the basic education network from the perspective of educational managers","('João Carlos Cordeiro Barbirato',)"
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/riufal/7514","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Metodologia para análise de mercado de ações com base em técnicas de aprendizado de máquina","('Caio César dos Santos Nunes',)","('André Luiz Lins de Aquino',)","('Rian Gabriel Santos Pinheiro', 'Ivan César Martins')","A predição dos valores de ações é um problema difícil, as séries temporais financeiras possuem comportamento caótico e sendo o “humor” do mercado financeiro uma variável determinante para manobras políticas e econômicas, muitos pesquisadores dedicaram seu tempo para desenvolver meios de prever seu comportamento. Utilizando redes neurais convolucionais e redes neurais de memória a longo prazo construímos modelos capazes de predizer o preço da empresa Apple na bolsa de valores. Os resultados obtidos com a metodologia proposta apontam que redes neurais são capazes de generalizar razoavelmente bem o problema, no entanto os resultados obtidos não são positivos o suficiente para justificar o uso dos modelos em um ambientes competitivos.","Predicting stock values is a difficult problem, financial time series have chaotic behavior and with the “mood” of the financial market being a determining variable for political and economic maneuvers many researchers have devoted their time to developing ways to predict their behavior. Using convolutional neural networks and long-term memory neural networks, we build models capable of predicting the price of the company Apple on the stock exchange. The results obtained with the proposed methodology indicate that neural networks are able to generalize the problem reasonably well, however the results obtained are not positive enough to justify the use of models in a competitive environment.","('Aprendizado do computador', 'Mercado de ações', 'Redes neurais (computação)', 'Seleção de atributos', 'Machine learning', 'Stock market', 'Artificial neural networks', 'Feature selection')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/7514","2020-12-21","https://www.repositorio.ufal.br/bitstream/riufal/7514/1/Metodologia%20para%20an%c3%a1lise%20de%20mercado%20de%20a%c3%a7%c3%b5es%20com%20base%20em%20t%c3%a9cnicas%20de%20aprendizado%20de%20m%c3%a1quina.pdf","Methodology for stock market analysis based on machine learning techniques",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/3200","Campus A.C. Simões","Instituto de Computação","Dissertação","Ambiente computacional para suporte a “Reproducible Research”","('Rodrigo de Lima Pinheiro',)","('Alejandro César Frery Orgambide',)","('Eduardo Nobre Lages', 'Fátima Nelsizeuma Sombra de Medeiros')","Reproducible Research (RR) define boas práticas em metodologia da pesquisa científica para serem aplicadas, em especial à pesquisa computacional quantitativa. Diversos periódicos de prestígio internacional adotam ou exigem o cumprimento dessas práticas. Entretanto, o pleno atendimento às premissas de RR implica em uma carga extra de trabalho. Tal fato compromete seriamente a sua adoção, sendo desejável a utilização de ferramentas computacionais que minimizem esse esforço. Como forma de garantir que as práticas de RR sejam aplicadas de forma transparente a artigos de pesquisa computacional quantitativa, apresentam-se neste trabalho: modelagem, proposta e construção de um ambiente computacional desenvolvido a partir da integração de ferramentas computacionais Free/Libre and Open-Source Software (FLOSS). Tal ambiente computacional é implementado com base na interseção do resultado de três frentes de trabalho: o estudo das principais práticas de Reproducible Research; a análise de soluções computacionais de suporte a RR voltadas especificamente para ciências computacionais; e o levantamento e integração de softwares FLOSS para suporte sustentável a esta iniciativa.","Reproducible Research (RR) defines good practices in scientific research methodology to be applied in special to quantitative computational research. Several prestigious international journals adopt or require the compliance of these practices. However, the full compliance of RR premises implies in extra workload. Such fact seriously compromises its adoption, then it is preferable the usage of computer tools that will minimize this efforts. In order to ensure that the RR practices are transparently applied to papers of quantitative computational research, this paper presents: the modeling, proposal and the development of a computational environment that was developed by the integration of Free/Libre and Open-Source Software (FLOSS) tools. Such computing environment has been implemented based on the intersection of the result of three work fronts: study of the main practices of Reproducible Research, analysis of computational solutions to support RR specifically to computer sciences; survey and FLOSS software integration for sustainable support to this initiative.","('Reproducible Research', 'Software FLOSS', 'Pesquisa Computacional Quantitativa')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/3200","2013-07-31","https://www.repositorio.ufal.br/bitstream/riufal/3200/1/Ambiente%20computacional%20para%20suporte%20a%20%e2%80%9cReproducible%20Research%e2%80%9d.pdf","",""
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/1617","Campus A.C. Simões","Instituto de Computação","Dissertação","Uma abordagem de Workflow na capacitação do CERNE1 para a gestão de incubadoras de empresas","('Josilan Paulino Barbosa',)","('Patrick Henrique da Silva Brito',)","('Evandro de Barros Costa', 'Fernando Álvaro Ostuni Gauthier')","A concepção de incubadora de empresas, como ambiente de inovação e empreendedorismo para empresas nascentes, surgiu nos Estados Unidos, chegando ao Brasil na década de 80. Este habitat de empresas nascentes tem papel de transformar idéias em negócios de sucesso. Desta forma, o processo de incubação de empresas requer condições favoráveis como infraestrutura básica para alocação destes projetos e excelência no gerenciamento dos processos de trabalho. Com base nessa necessidade, SEBRAE e ANPROTEC elaboraram o Centro de Referência para Apoio a Novos Empreendimentos -CERNE. O CERNE é um modelo de trabalho dividido em quatro níveis, a fim de desenvolver 16 processos gerenciais incluindo 62 práticas-chaves que estabelecem a maturidade nos empreendimentos, incubadora, rede de parceiros e melhoria contínua. A implantação do modelo CERNE nas incubadoras tem avançado lentamente na busca da certificação destes ambientes de inovação, em função de dificuldades como rotatividade da equipe, limitação no tocante à assistência externa e pouca interação entre consultores e incubadoras, além da ausência de modelos de documentos no auxílio na gestão dos processos e fluxo de trabalho de cada etapa na implantação. Surge então uma proposta de auxiliar na implantação do CERNE1, através da modelagem dos processos e práticas utilizando uma ferramenta de Workflow, com o uso do editor de fluxo de trabalho Together Worflow Editor -TWE, através da base XPDL e BPMN, com objetivo de proporcionar a representação gráfica das rotinas e etapas do primeiro nível de maturidade, auxiliando na construção de um curso on-line utilizando a plataforma MOODLE voltado para gestores e colaboradores das sete incubadoras de empresas atuantes em Alagoas para um aprendizado interativo, possibilitando a implantação sistemática e gradativa do CERNE1.","The concept of a business incubator as an innovation and entrepreneurship environment for new companies first occured in the United States, arriving in Brazil in the 80's. This habitat has the role of transforming ideas into succesful businesses. In order to do that, the business incubation process require favorable conditions such as: basic infrastructure to place the projects and high excelence on managing work processes. Based on that need, SEBRAE and ANPROTEC formulated the Centre of Reference for Support Newcoming Businesses â€“ CERNE. CERNE is a work model divided in four levels, that aims to develop 16 managerial processes, including 62 key practices that helps to stablish the maturity of the companies, the incubators, their supporting entities and the continuous improvement of all of them. The deploy of CERNE model in the incubators has been advancing slowly in a way to certify this environment, due to difficulties such as employees turnover, limitation when it comes to external aid, low interaction between incubators and consultants and the lack of document samples to aid the processes managing and the workflow of every step of the deployment. From that scenario comes a proposition to deploy CERNE1 using process and pratices modelling through a Workflow tool, with the workflow editor Together Worflow Editor -TWE, using the XPDL and BPMN bases, aiming to represent graphically the routines and stages of the first level of maturity, helping to built an online course using the MOODLE platform for the audience of business incubators managers and coworkers of the 7 main incubators in Alagoas, to generate interactive learning process and making it possible to systematically and gradually deploy CERNE1.","('Incubadoras de empresas', 'Workflow', 'Modelagem', 'Educação à distância', 'CERNE', 'Business incubators', 'Modeling', 'Distance Education')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/1617","2014-12-09","https://www.repositorio.ufal.br/bitstream/riufal/1617/1/Uma%20abordagem%20de%20Workflow%20na%20capacita%c3%a7%c3%a3o%20do%20CERNE1%20para%20a%20gest%c3%a3o%20de%20incubadoras%20de%20empresas.pdf","A Workflow approach in the training of CERNE1 for the management of business incubators","('Marcus de Melo Braga',)"
"PPg Modelagem Computacional de Conhecimento","https://www.repositorio.ufal.br/handle/riufal/7465","Campus A.C. Simões","Instituto de Computação","Dissertação","An information-theoretic approach of network structure and dynamics","('Cristopher Gabriel de Sousa Freitas',)","('André Luiz Lins de Aquino',)","('Rian Gabriel Santos Pinheiro', 'Fabiane da Silva Queiroz')","As redes modernas estão enfrentando os maiores desafios nos últimos anos. A vida está mudando e a Internet se tornou um dos serviços essenciais, como energia, saúde, serviços bancários. A Internet abriu informações globais e, hoje em dia, uma rede estável e eficiente é um direito e um requisito global. As redes legadas herdaram muitos conceitos e infraestrutura das redes de comuta ̧c ̃ao de circuitos, com um design inflexível que depende principalmente do hardware. Outro aspecto crítico da rede ́e a depuração, o que requer pessoal especializado com software projetado adequadamente. Por essas razões -e atual aumento de demanda -os Provedores de Serviços de Internet estão lidando com desafios que exigem inovação e estratégias científicas. Esse cenário levou a novos paradigmas, como redes definidas por software (SDNs) para resolver a maioria dos problemas atuais, trazendo a lógica de rede do design de hardware ao desenvolvimento de software e virtualização. O surgimento de SDNs atraiu a atenção de cientistas e engenheiros de rede para novos caminhos. A Internet é o sistema distribuído mais extenso e depende de dispositivos distribuídos que se comunicam com eficiência por meio de protocolos. Uma rede de computadores é uma coleção sofisticada de dispositivos de rede e sistemas finais. As SDNs permitem uma visão centralizada e agnóstica de protocolo e controle flexível da rede, favorecendo o desenvolvimento de novas estratégias que não são alcançáveis em redes IP legadas. Neste trabalho, estudamos dois aspectos principais das redes de computadores: estrutura e dinâmica. Ao compreender as características da rede e ao modelar seus processos dinâmicos, podemos descobrir como a estrutura e a dinâmica da rede afetam sua robustez. Para alcançar esse entendimento, propomos o uso de quantificadores da teoria da informação para caracterização de redes. Para topologia de rede, apresentamos a Medida de Informa ̧c ̃ao de Fisher para quantificar as características da rede, usando juntamente com a Entropia da Rede em uma representação bidimensional que nos permite identificar se uma rede está mais próxima de uma topologia aleatória, small-world ou scale-free. Avaliamos as séries temporais de tráfego usando a Entropia de Permutação Normalizada e a Complexidade Estatística para tráfego de rede. Observamos que os modelos de geração de tráfego baseados em distribuições de cauda pesada não podem reproduzir a dinâmica real do tráfego. Acreditamos que esse entendimento por meio de quantificadores da teoria da informa ̧c ̃ao pode ajudar a desenvolver soluções de gerenciamento de falhas e automação de rede. Em vez de focar na enorme quantidade de dados disponíveis para as redes, podemos observar como os quantificadores descrevem o comportamento da rede.","Modern networks are facing the most challenges in recent years. Life is changing, and the Internet became one of the essential services such as power, healthcare, banking. The Internet has opened global information, and nowadays, a stable and efficient network is a global right and requirement. Legacy networks inherited many concepts and infrastructure from circuit-switching networks, with inflexible design relying most on hardware. Another critical aspect of networking is debugging it, which requires specialized personnel with properly designed software. For these reasons – and currently increasing demand – Internet Service Providers are dealing with challenges that require innovation and scientific strategies. This scenario led to new paradigms such as software-defined networks (SDNs) to address most of the current issues by bringing the network logic from hardware design to software development and virtualization. The emergence of SDNs has drawn the attention of network scientists and engineers to new roads. The Internet is the most extensive distributed system, and it relies upon distributed devices communicating efficiently through protocols. A computer network is a sophisticated collection of network devices and end-systems. SDNs allow a protocolagnostic, centralized view, and flexible control of the network, favoring the development of new strategies that are not achievable into legacy IP networks. In this work, we study two main aspects of computer networks: structure and dynamics. By understanding the network characteristics and modeling its dynamical processes, we can uncover how network structure and dynamics affect its robustness. To achieve this understanding, we propose the usage of information-theory quantifiers for network characterization. For network topology, we introduce the Fisher Information Measure for quantifying the network characteristics, using alongside the Network Entropy in a bi-dimensional representation that allows us to identify if a network is closer to a random, small-world or scale-free topology.","('Redes de computadores', 'Teoria da informação', 'Redes complexas', 'Software-defined Networks', 'Information theory', 'Complex network')","Ciência da Computação","eng","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/7465","2020-10-26","https://www.repositorio.ufal.br/bitstream/riufal/7465/1/An%20information-theoretic%20approach%20of%20network%20structure%20and%20dynamics.pdf","Uma abordagem de teoria da informação para estrutura e dinâmica de redes",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/9232","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Melhorando a qualidade de código para soluções em sistemas embarcados com o Zeta Middleware","('Lucas Peixoto de Almeida Cavalcante',)","('Rodrigo José Sarmento Peixoto',)","('Erick de Andrade Barboza', 'Baldoíno Fonseca dos Santos Neto')","Contexto: Sistemas Embarcados (SE) são sistemas computacionais desenvolvidos para propósitos específicos e com limitações de memória e processamento. A Internet das Coisas, por exemplo, vem ajudando a disseminar de forma massiva a quantidade de dispositivos ao redor do mundo. Firmware de SE estão crescendo em complexidade e tamanho à medida que a demanda aumenta. Por conta do aumento de complexidade, da minoração do time-to-market e por problemas na aplicação de conceitos de engenharia de software, uma grande quantidade de dispositivos do mercado apresentam um custo alto de manutenção de código ao longo do seu ciclo de vida. Objetivo: A partir de pesquisas do estado da arte, observamos que projetos de SE com diferentes níveis de maturidade apresentam dívida técnica relacionada à arquitetura, código e testes. Portanto, o objetivo é desenvolver uma ferramenta que auxilie novos projetos de SE, a fim de facilitar a implementação e manutenção do firmware, provendo uma arquitetura que facilite testes e reduza a complexidade de código. Método: Esse trabalho apresenta um middleware chamado Zeta que é capaz de fornecer uma arquitetura de software para Sistemas Embarcados, a qual provê em sua essência desacoplamento de tempo, espaço e sincronia. O Zeta conta com uma Command Line Interface que tem a função de gerar o código base do Zeta, através da técnica de Template-Based Code Generation, e de auxiliar o usuário nas suas customizações. Resultados: Os resultados sugerem que o Zeta traz um impacto positivo no desenvolvimento, pois, através de um comparativo entre implementações tradicionalmente utilizadas no mercado, a solução desenvolvida com o Zeta teve um desempenho melhor ou igual em todas as métricas que dizem respeito a qualidade de código. Conclusão: Diante do trabalho desenvolvido e dos resultados obtidos, acreditamos que o Zeta Middleware é capaz de ser utilizado a fim de possibilitar o desenvolvimento de um código com uma qualidade de software maior, o que implica numa velocidade de desenvolvimento e num custo de manutenibilidade menor.","Context: Embedded Systems (ES) are computational systems designed for specific problems using devices with memory and processing limitations. The Internet of Things (IoT) is helping to spread massively the number of devices around the world. So that, ES firmware is growing in complexity and size as demand increases. Due to the increase in complexity, reduction of time-to-market, and problems related to the application of software engineer concepts, a large number of devices in the market have a high maintenance cost throughout their life cycle. Objective: From state-of-art research, we observed that ES projects with different maturity levels present technical debt related to architecture, code, and tests. Thus, the objective of this work is to design a tool to assist new ES projects in order to facilitate the firmware implementation and maintenance, providing an architecture that reduces the code complexity and more suitable for tests. Method: This work presents a middleware named Zeta that provides a software architecture for ES in order to provide time-decoupling, space-decoupling, and synchronizationdecoupling. The Zeta has a Command Line Interface responsible to generate the base code using the Template-Based Code Generation technique and assists the user in customizations for your application. Results: The results suggest that Zeta has a positive impact on the development because, in a comparison between traditional implementations used in the market, the solution developed with Zeta had a performance better or equal in all of the code quality metrics used. Conclusion: In face of the work developed and their results, we believe that the Zeta Middleware is capable to be used in order to provide a code development with a better software quality, which implies in the speed of development and in a lower maintenance cost.","('Sistemas Embarcados (Computadores)', 'Internet das coisas', 'Arquitetura de software', 'Arquitetura de computador', 'Zeta Middleware', 'Embedded Systems (Computers)', 'Internet of Things', 'Software architecture', 'Computer architecture')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/9232","2021-05-05","https://www.repositorio.ufal.br/bitstream/123456789/9232/1/Melhorando%20a%20qualidade%20de%20codigo%20para%20solu%c3%a7%c3%b5es%20em%20sistemas%20embarcados%20com%20o%20Zeta%20Middleware.pdf","Improving the quality of code for solutions in embedded systems with Zeta Middleware",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/11992","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Impacto de fatores socioeconômicos na nota do ENADE: uma investigação usando métodos de aprendizagem de máquina","('Edvonaldo Horácio dos Santos',)","('Bruno Almeida Pimentel',)","('Evandro de Barros Costa', 'Roberta Vilhena Vieira Lopes')","O Enade e um teste aplicado anualmente em graduandos habilitados. Integrando o Sineas, permite, junto com a avaliação institucional e a avaliação de cursos da graduação, medir a qualidade dos cursos no país. Os resultados podem ser consultados no site do Inep e permitem uma análise por meio do uso de técnicas de Aprendizagem de Maquina e Ciência de Dados. A proposta deste trabalho é investigar quais fatores socioeconômicos afetam a nota geral do Enade. São utilizados três algoritmos de regressão: Arvore de Decisão, Floresta Aleatória e Lasso. Para o estudo os dados são separados em dois conjuntos: o primeiro conjunto é formado apenas pelos alunos do estado de Alagoas; enquanto que o segundo é referente aos dos demais estados da federação (excluindo-se os do primeiro). Apresentaram alta influência na nota geral da prova para os dois conjuntos de dados e os três algoritmos os seguintes fatores socioeconômicos: bolsa acadêmica durante a graduação (monitoria, PIBICs, PIBITs e análogos), fonte de financiamento para mensalidade (no caso do curso não ser gratuito) e a renda total familiar. Também se sobressaram a cor do indivíduo, a modalidade do ensino médio realizada pelo aluno e o número de horas de estudo por semana. Além disso, as análises por meio dos gráficos de distribuição mostraram distinções importantes quando comparados em relação ao mesmo dado socioeconômico e também levando em conta a qual conjunto pertence: a media aritmética dos alunos com bolsa acadêmica durante a graduação foi maior que daqueles que não tiveram bolsa; os estudantes de curso gratuito ou com financiamento total pelo ProUni apresentaram media aritmética maior que nos outros casos; e os estudantes com maiores rendas brutas tiveram uma media maior que aqueles que possuem menor poder aquisitivo.","The Enade is a test administered annually to quali_ed graduates. Integrating Sineas, it allows, together with the institutional evaluation and the evaluation of undergraduate courses, to measure the quality of courses in the country. The results can be consulted at Inep's website and allow an analysis through the use of Machine Learning and Data Science techniques. The purpose of this work is to investigate which socioeconomic factors a_ect Enade's overall score. Three regression algorithms are used: Decision Tree, Random Forest and Lasso. For the study, the data are separated into two sets: the _rst set is formed only by students from the state of Alagoas; while the second refers to the other states of the federation (excluding those of the _rst). The following socioeconomic factors had a high inuence on the overall test score for the two datasets and the three algorithms: academic scholarship during graduation (monitoring, PIBICs, PIBITs and the like), source of funding for tuition (in case the course is not free) and the total household income. The individual's color, the type of secondary education performed by the student and the number of hours of study per week also stood out. In addition, the analyzes through the distribution graphs showed important distinctions when compared in relation to the same socioeconomic data and also taking into account which set it belongs: the arithmetic mean of students with academic scholarship during graduation was higher than those who did not have handbag; students taking a free course or with full funding from ProUni had a higher arithmetic mean than in the other cases; and students with higher gross incomes had a higher average than those with lower purchasing power.","('Aprendizado computacional', 'Exame Nacional de Desempenho dos Estudantes', 'Fatores socioeconômicos', 'Algoritmos de regressão', 'Computer learning', 'National Performance Examination of Students', 'Socioeconomic factors', 'Regression algorithms')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/11992","2021-01-20","https://www.repositorio.ufal.br/bitstream/123456789/11992/1/Impacto%20de%20fatores%20socioecon%c3%b4micos%20na%20nota%20do%20ENADE%20Uma%20investiga%c3%a7%c3%a3o%20usando%20m%c3%a9todos%20de%20Aprendizagem%20de%20M%c3%a1quina.pdf","","('Lucas Benevides Viana de Amorim',)"
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/12332","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","A framework for studies of physiological control systems applied to ventricular assist devices","('Roger de Almeida Matos Júnior',)","('Thiago Damasceno Cordeiro',)","('Tiago Alves de Almeida', 'Luís Felipe Vieira Silva')","Dispositivos de assistência ventricular são bombas mecânicas usadas como suporte para pacientes com insuficiência cardíaca. Esses dispositivos são um grande objeto de pesquisa no campo da engenharia biomédica, com foco no control de sistemas fisiológicos com o objetivo de melhorar a performance desses dispositivos. Pesquisadores da Universidade Federal de Alagoas têm investigado diversas estratégias de controle aplicadas a eles há anos. Nessas investigações anteriores, um modelo numérico do coração esquerdo foi utilizado com sucesso para performar simulações de controle. Entretanto, para que se obtenham resultados ainda mais acurados, um modelo mais complexo é necessário. Esse trabalho desenvolve um framework de um modelo do sistema cardiovascular humano que considera ambos os lados do coração e outras variáveis hemodinâmicas. Esse framework permite que um dispositivo de assistência ventricular seja acoplado a ele e controlado. Como prova de conceito, o modelo numérico foi inteiramento simulado utilizando um script em MATLAB® e obteve uma boa performance com um controlador Starling-like, que é uma técnica de controle que usa variáveis do modelo desenvolvido, como o fluxo da bomba e a pressão ventricular esquerda final diastólica. As simulações alcançaram os resultados esperados e o código open source desse framework está disponível para download.","Ventricular assist devices are mechanical pumps used as support to patients with heart failure. These devices are a great object of research in the biomedical engineering field, with focus on physiological control systems in order to improve the performance of these devices. Researchers at the Universidade Federal de Alagoas have investigated several control strategies applied to them for years. In these previous investigations, a left heart numerical model was successfully used to perform control simulations. However, in order to have even more accurate results, a more complex model is necessary. This work develops a human cardiovascular system model framework that considers both sides of the heart and other hemodynamical variables. This framework allows a ventricular assist device to be coupled to it and controlled. As a proof of concept, the entire numerical model was simulated using a script in MATLAB® and performed well with a Starling-like controller, which is a control technique that uses variables from the developed model, such as the pump flow and the left-ventricular end-diastolic pressure. The simulations reached the expected results and the open source code of this framework is available to download.","('Modelo do sistema cardiovascular', 'Dispositivo de assistência ventricular', 'Sistemas fisiológicos', 'Controle starling-like', 'Engenharia biomédica', 'Cardiovascular system model', 'Ventricular assist device', 'Physiological systems', 'Starling-like control', 'Biomedical engineering')","Ciência da Computação","eng","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/12332","2023-01-30","https://www.repositorio.ufal.br/bitstream/123456789/12332/1/A%20framework%20for%20studies%20of%20physiological%20control%20systems%20applied%20to%20ventricular%20assist%20devices.pdf","",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/12645","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Fitting gaussian curves on particle images for density estimation","('Lucas Mendes Massa',)","('Tiago Figueiredo Vieira',)","('Allan de Medeiros Martins',)","No presente trabalho utilizou-se um dispositivo impresso em 3D para medir a densidade de uma micropartícula fazendo uso de acustofluídica, a qual consiste em aplicar ondas sonoras para prender partículas no espaço livre. Inicialmente, a partícula fica presa no plano focal do microscópio (sem desfoque). Em seguida, os transdutores são desligados e a partícula ao longo do fluido, aumentando seu diâmetro devido ao desfoque causado pela distância até a lente. Esse aumento de diâmetro ao longo do tempo fornece sua velocidade, que pode, por sua vez, ser usada para calcular sua densidade. Anotar manualmente o diâmetro nas imagens capturadas é uma tarefa tediosa e sujeita a erros. Isso acontece devido ao alto ruído presente nas imagens, principalmente nos últimos quadros onde o desfoque é alto. Dessa forma, usamos um processo de ajuste de modelo Gaussiano 2D para estimar o diâmetro da partícula em diferentes quadros de profundidade. Para encontrar os diâmetros, inicialmente realizamos o ajuste dos parâmetros Gaussianos com Algoritmo Genético em cada quadro da trajetória da partícula registrada para evitar mínimos locais. Em seguida, refinamos o ajuste com Gradient Descendente usando Tensorflow para compensar qualquer aleatoriedade presente no ajuste do Algoritmo Genético. Validamos o método recuperando a densidade de uma partícula conhecida com desempenho satisfatório.","We use a 3D printed device to measure the density of a micro-particle with acoustofluidics, which consists in using sound waves to trap particles in free space. Initially, the particle is trapped in the microscope’s focal plane (no blur). Then the transducers are shut off and the particle falls inside the fluid, increasing its diameter due to defocus caused by the distance to the lens. This increase in diameter along time provides its velocity, which can, in turn, be used to compute its density. To manually annotate the diameter in the recorded images is a tedious task and is prone to errors. That happens due to the high noise present in the images, specially in the last frames where the defocus is high. Because of that, we use a 2D Gaussian model fitting process to estimate the particle diameter throughout different depth frames. To find the diameters, we initially perform the Gaussian parameters fit with Genetic Algorithm in each frame of the recorded particle trajectory to avoid local minima. Then we refine the fit with Gradient Descent using Tensorflow in order to compensate for any randomness present in the fit of the Genetic Algorithm. We validate the method by retrieving a known particle’s density with acceptable performance.","('Estimação de densidade de partículas', 'Algoritmos genéticos', 'Gradiente descendente', 'Ajuste de gaussiana 2D', 'Acustofluídica', 'Particle density estimation', 'Genetic algorithms', 'Gradient descent', 'Gaussian 2D adjustment', 'Acoustofluidic')","Ciência da Computação","eng","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/12645","2023-03-17","https://www.repositorio.ufal.br/bitstream/123456789/12645/1/Fitting%20gaussian%20curves%20on%20particle%20images%20for%20density%20estimation.pdf","Ajuste de curvas gaussianas em imagens de partículas para estimação de densidade","('Ícaro Bezerra Queiroz de Araújo',)"
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/9092","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Uma ferramenta educativa para o cultivo de plantas utilizando internet das coisas","('Clóvis Gabriel Melo do Nascimento',)","('Roberta Vilhena Vieira Lopes',)","('Evandro de Barros Costa', 'Thiago Damasceno Cordeiro')","Considerada como uma revolução digital, a Internet das Coisas consiste em conectar objetos do cotidiano à internet. Esse advento permite fazer o monitoramento de qualquer situação através da coleta de dados, viabilizada pelo uso de sensores posicionados em locais estratégicos, e também pode permitir a tomada de decisão, através de atuadores que agirão no ambiente. Neste trabalho, será mostrado o desenvolvimento de um sistema em que é possível monitorar a umidade do solo de uma planta em tempo real através de um aplicativo mobile e configurar para regá-la automática ou manualmente. O intuito deste trabalho é fornecer uma ferramenta educativa e tecnológica para desenvolver tanto em crianças quanto em adultos a percepção de quando uma planta precisa ou não de água, auxiliando indivíduos a entender melhor como funciona o mundo ao seu redor e incentivando a prática da sustentabilidade, levando em consideração a importância do cultivo de plantas no planeta e a economia da água, um recurso escasso já em alguns lugares. Além disso, também se deseja verificar neste trabalho se o sistema desenvolvido mantém a planta em umidade aceitável do solo, realizando também a gestão do recurso água.","Regarded as a digital revolution, the Internet of Things consists of connecting everyday objects to the internet. This advent makes it possible to monitor any situation through data collection, made possible by the use of sensors positioned in strategic locations, and it can also allow decision making, through actuators that will act in the environment. In this work, it will be shown the development of a system in which it is possible to monitor the soil moisture of a plant in real time through a mobile application and configure to water it automatically or manually. The aimof this work is to provide an educational and technological tool to develop in both children and adults the perception of when a plant needs water or not, helping individuals to better understand how the world around them works and encouraging the practice of sustainability, taking into account the importance of growing plants on the planet and saving water, a scarce resource already in some places. In addition, it is also desired to verify in this work if the developed system keeps the plant in acceptable soil moisture, also managing the water resource.","('Internet das coisas', 'Sistemas embarcados (Computadores)', 'Computação em nuvem', 'Aplicativo mobile', 'Sustentabilidade', 'Internet of Things', 'Cloud computing', 'Embbeded Systems (Computers)', 'Mobile apps', 'Sustainability')","Sistemas de Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/9092","2020-08-26","https://www.repositorio.ufal.br/bitstream/123456789/9092/1/Uma%20ferramenta%20educativa%20para%20o%20cultivo%20de%20plantas%20utilizando%20internet%20das%20coisas.pdf","",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/10306","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Explorando o efeito de estereótipos na motivação e fluxo em ambientes gamificados na educação","('Jéssica da Silva Mota',)","('Ig Ibert Bittencourt Santana Pinto',)","('Jário José dos Santos Júnior', 'Marcelo Reis')","Como um importante meio de motivação, a gamificação permite ao aluno sensações agradáveis de felicidade e prazer. O trabalho apresenta um sistema de tutoria gamificado com ameaça de estereótipo de gênero, que estuda e analisa os efeitos de ameaça de estereótipo com o constructo motivacional e a experiência de fluxo, utilizando escalas que medem a predisposição de fluxo, o fluxo e a motivação dos participantes. Estudos apontam que a ameaça de estereótipo diminui o desempenho de indivíduos membros dos grupos ameaçados. Foi proposto um sistema de tutoria que avalia o desempenho de estudantes do ensino médio de escolas públicas em diferentes cenários: com estereótipo e sem estereótipo de gênero, com o intuito de se observar o efeito desta ameaça. No experimento, não houve nenhuma diferença significativa no desempenho, na experiência de fluxo e nos quatro aspectos da motivação entre os participantes de gênero masculino e feminino dado o tipo de cenário sem estereótipo e com estereótipo (feminino e masculino). Foram encontrados relações importantes da satisfação, relevância e confiança com o fluxo.","As an important means of motivation, gamification allows the student to feel pleasant feelings of happiness and pleasure. The work presents a gamified mentoring system with gender stereotype threat, which studies and analyzes the effects of stereotype threat with the motivational construct and the flow experience, using scales that measure the predisposition to flow, flow and motivation of participants. Studies show that the threat of stereotyping diminishes the performance of individuals who are members of threatened groups. A tutoring system was proposed that assesses the performance of high school students from public schools in different scenarios: with and without gender stereotype, in order to observe the effect of this threat. In the experiment, there was no significant difference in performance, flow experience, and four aspects of motivation between male and female participants given the non-stereotyped and stereotyped (female and male) type of scenario. Important relationships of satisfaction, relevance and trust with the flow were found.","('Gamificação', 'Educação', 'Motivação na educação', 'Fluxo de dados (Computadores)', 'Gamification', 'Education', 'Motivation', 'Flow', 'Stereotype')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/10306","2021-06-04","https://www.repositorio.ufal.br/bitstream/123456789/10306/1/Explorando%20o%20efeito%20de%20estere%c3%b3tipos%20na%20motiva%c3%a7%c3%a3o%20e%20fluxo%20em.pdf","Exploring the effect of stereotypes on motivation and flow in gamified environments in education","('Geiser Chalco Challco',)"
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/10524","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Controle preditivo aplicado ao manipulador DENSO-VP6242 utilizando quatérnios duais","('Arthur da Costa Vangasse',)","('Glauber Rodrigues Leite',)","('Allan de Medeiros Martins', 'Heitor Judiss Savino')","Este trabalho apresenta uma aplicação de controle preditivo não linear baseado em modelo (NMPC), combinado à modelagem cinemática baseada em quatérnios duais para um manipulador robótico comercial. Foi utilizado o manipulador serial de 6 graus de liberdade VP-6242 fabricado pela Denso Robotics. Tendo desenvolvido o modelo explícito do sistema, são computadas as ações de controle ótimo em um horizonte de predição de acordo com uma função de custo a ser minimizada. Neste problema de otimização, são consideradas as restrições físicas determinadas pelo sistema robótico em uso, garantindo a integridade do mesmo. A álgebra dos quatérnios duais oferece robustez diante de singularidades e vantagens computacionais se comparada ao uso de matrizes de transformações homogêneas. Para o NMPC, é possível lidar com problemas multivariáveis de natureza não linear, cuja solução programada é provida pela MATLAB MPC Toolbox. Resultados de simulações são apresentados, mostrando que a solução implementada gera rotas factíveis e suaves para o sistema de alta complexidade.","This work presents an application of non-linear model predictive control (NMPC), combined to a kinematic model based in dual quaternion of a comercial robotic manipulator. The 6—DOF serial manipulator, VP-6242 by Denso Robotics was used as reference. Having developed the system’s explicit model, optimal control actions are computed in a prediction horizon according to an objective function to be minimized. The optimization problem, considers the structure constraints determined by the robotic system, guaranteeing physical integrity. Dual quaternion algebra adds robustness to the model regarding singularities and computational advantages when compared to traditional homogeneous transformation matrices methods. For NMPC, is possible to deal with multiple variable problems of non-linear nature, which solution is provided by MATLAB MPC Toolbox. Simulation results are presented, showing that the implemented algorithm is capable of generating safe and smooth routes to the highly complex system.","('Controle preditivo -Modelos', 'Quatérnios duais', 'Robótica fixa', 'Sistemas de controle multivariáveis', 'Model Predictive Control', 'Dual Quaternions', 'Fixed Robots', 'MIMO Control Systems')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/10524","2022-02-14","https://www.repositorio.ufal.br/bitstream/123456789/10524/1/Controle%20preditivo%20aplicado%20ao%20manipulador%20DENSO-VP6242%20utilizando%20quat%c3%a9rnios%20duais.pdf","Predictive control applied to the robotic manipulator Denso-VP6242 using dual quaternions","('Ícaro Bezerra Queiroz de Araújo',)"
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/9530","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Estudo de aplicações do controlador ADRC utilizando o laboratório virtual iDymanic","('Leony Oliveira Bernardo',)","('Ícaro Bezerra Queiroz de Araújo',)","('Mário Sérgio Freitas Ferreira Cavalcante', 'Glauber Rodrigues Leite')","Este trabalho apresenta o desenvolvimento detalhado das equações matemáticas da versão linear da técnica de controle Active Disturbance Rejection Control (ADRC), juntamente com sua implementação computacional. É apresentado o desenvolvimento das equações do controlador em suas versões de primeira e segunda ordem, generalizando as mesmas para o controlador em sua n-ésima ordem. A partir da implementação computacional feita, são considerados três sistemas para validação do mesmo: um sistema de controle de posição de um bloco de massa, um sistema de controle de nível de líquido e um sistema de controle de temperatura. Todas as simulações foram executadas no laboratório virtual de sistemas de controle iDynamic. Os resultados das simulações mostram que o ADRC apresenta uma boa suavidade para mudanças de referência no sistema, e menor desgaste e esforço de controle quando bem configurado, além de se adaptar bem à mudanças nas grandezas físicas na planta e apresentar robustez em relação à perturbações.","This work presents the detailed development of the mathematical equations of the Active Disturbance Rejection Control (ADRC) technique in its linear version, followed by an computational implementation of the controller. The development of the controller equations in their first and second order versions is presented, generalizing them to the controller in its N-th order. As from the computational implementation, three systems are considered for its validation: a mass block position control system, a liquid level control system and a temperature control system. All simulations were performed in the virtual laboratory of control systems iDynamic. The simulation results show that ADRC presents good smoothness for system reference changes, less wear and control effort when well configured, in addition, also its good adaptability to changes in plant physical quantities.","('Linear Active Disturbance Rejection Crontrol', 'Sistemas de controle', 'iDynamic', 'Control Systems')","Engenharia de Software","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/9530","2021-07-23","https://www.repositorio.ufal.br/bitstream/123456789/9530/1/Estudo%20de%20aplica%c3%a7%c3%b5es%20do%20controlador%20ADRC%20utilizando%20o%20laborat%c3%b3rio%20virtual%20iDymanic.pdf","Application Study of Linear ADRC Controller using iDynamic virtual laboratory","('Allan de Medeiros Martins',)"
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/10431","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Desagregação de energia baseada em aprendizagem profunda e transformada de wavelet","('Eduardo Gomes dos Santos',)","('André Luiz Lins de Aquino',)","('Heitor Soares Ramos Filho', 'Rian Gabriel Santos Pinheiro')","A desagregação de energia é uma área que busca identificar o consumo individual de diferentes aparelhos usando apenas o sinal agregado medido a partir de um único ponto. Este trabalho propõe uma rede neural treinada com dados reduzidos Wavelets para realizar a desagregação de energia. Além da desagregação, que geralmente apenas obtemos uma resposta binária identificando o momento de ativação do aparelho, também estamos interessados em estimar o valor de consumo do aparelho. Consideramos o conjunto de dados UK-DALE para realizar nossos experimentos, o qual contém dados de diferentes aparelhos de cinco casas da Inglaterra. Usando nossa abordagem, em comparação com outro trabalho bem estabelecido, alcançamos melhorias por aparelho de 27,8% (F1 −score) no processo de desagregação e 11,4% (acurácia estimada) no valor de consumo do aparelho. Nossa principal contribuição foi identificar de forma satisfatória que os coeficientes de aproximação da transformada Wavelet são suficientes para estimar o consumo individual de eletrodomésticos.","Energy disaggregation is a field which seeks to identifying individual consumption of different appliances using only the aggregated signal measured from a single point. This work proposes a neural network trained with Wavelets reduced data to perform energy disaggregation. Besides the disaggregation, usually a binary answer by identifying the appliance activation moment, we are interested in estimating the appliance’s consumption value. We consider the UK-DALE data set to perform our experiments, containing data from different appliances of five houses from England. Using our strategy, compared with another well-established work, we achieved improvements per appliance of 27.8% (F1-score) in the disaggregation process and 11.4% (estimated accuracy) in the appliance’s consumption value. Our main contribution was to identify satisfactorily that the coefficients of approximation of the Wavelet transform are enough to estimate the individual consumption of household appliances.","('Wavelets (Matemática)', 'Energia -Desagregação', 'Non intrusive load monitoring', 'Aprendizagem profunda', 'Energy disaggregation', 'NILM', 'Wavelet transform', 'Deep learning')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/10431","2022-02-22","https://www.repositorio.ufal.br/bitstream/123456789/10431/1/Desagrega%c3%a7%c3%a3o%20de%20energia%20baseada%20em%20aprendizagem%20profunda%20e%20transformada%20de%20wavelet..pdf","","('Geymerson dos Santos Ramos',)"
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/10560","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Controle de um manipulador robótico da série DENSO-VP6242 utilizando quatérnios duais","('Andressa Martins Oliveira',)","('Heitor Judiss Savino',)","('Ícaro Bezerra Queiroz de Araújo', 'José Henrick Viana Ramalho', 'Bruno Judiss Savino')","Este trabalho apresenta o desenvolvimento da implementação da modelagem em quatérnios duais no manipulador robótico de seis graus de liberdade Denso série-VP para o controle cinemático do robô utilizando a cinemática diferencial mapeando as velocidades no espaço operacional nos espaço das juntas para que o efetuador do manipulador seja capaz de chegar a uma posição desejada. A modelagem foi desenvolvida em MATLAB utilizando a biblioteca de quatérnios duais DQ Robotics e a toolbox Robotics toolbox system. Os resultados são apresentados no RViz de maneira visual e em curvas do sistema de controle da posição final do efetuador.","This work presents the development of the implementation of modeling in dual quaternions in the Denso VP series six degrees of freedom robotic manipulator for the kinematic control of the robot using a differential kinematics mapping the velocities in the operational space in the joint spaces so that the manipulator’s effector be able to reach a necessary position. The modeling was developed in MATLAB using a library of dual quaternions DQ Robotics and a toolbox Robotics toolbox system. The results are trained in the RViz visually and in curves of the control system of the final position of the end-efector.","('Quatérnios duais', 'Denso VP6242 (Manipulador robótico)', 'Robótica', 'Dual Quaternions', 'Fixed robotics', 'Denso VP6242', 'ROS', 'Manipulators')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/10560","2021-03-01","https://www.repositorio.ufal.br/bitstream/123456789/10560/1/Controle%20de%20um%20manipulador%20rob%c3%b3tico%20da%20s%c3%a9rie%20DENSO-VP6242%20utilizando.pdf","Control of a DENSO-VP6242 series robotic manipulator using dual quaternions",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/10061","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Controlador RST auto-ajustável: análise e estudo de casos","('Tarcísio Lima Ferreira',)","('Ícaro Bezerra Queiroz de Araújo',)","('Davi Bibiano Brito', 'Glauber Rodrigues Leite')","Este trabalho apresenta o desenvolvimento de um controlador digital RST para entradas dos tipos: degrau, rampa e senoide, combinado com o estimador dos mínimos quadrados recursivos (MQR) para obtenção dos parâmetros do controlador a partir dos parâmetros identificados da planta. O controlador foi aplicado em 2 sistemas simulados, um sistema exemplo e um sistema real. Durante as simulações, foram utilizados índices de desempenho de controladores comumente utilizados na literatura para avaliar os controladores. Os resultados mostram que a estratégia implementada neste trabalho obteve sucesso em controlar os sistemas, mesmo na presença de perturbações e ruídos. Também é demonstrado que o controlador tem resultados satisfatórios em controlar a planta mesmo recebendo uma entrada de referência diferente da qual ele foi projetado.","This work describes the development of a digital controler RST for inputs: step, ramp and sinusoid, combined with least square error estimator (MQR) system identification algorithm to obtain the system model. The controller was applied in two simulated systems, an example system and a real system. Based on the system model, the controller parameters were calculated. During the system simulations, the performance indexes of the developed controller were evaluated. The results show that the self-tuning RST controller was successful in controlling the systems even in the presence of disturbance. It has also been demonstrated that the controller has satisfactory results in controlling the plant even though it receives a different reference input than the one it was designed for.","('Reference Signal Tracking', 'Sistemas de controle digital', 'Identificação de sistemas', 'Single Input Single Output', 'Auto-Tunning RST', 'Digital Control', 'System Identification', 'SISO System', 'Reference Tracking')","Engenharia de Software","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/10061","2021-06-18","https://www.repositorio.ufal.br/bitstream/123456789/10061/1/Controlador%20RST%20auto-ajust%c3%a1vel%20-%20an%c3%a1lise%20e%20estudo%20de%20casos.pdf","",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/9478","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","AutoTF: um ambiente web para modelagem de sistemas físicos","('Marcos Vinícius Santos Costa',)","('Ícaro Bezerra Queiroz de Araújo',)","('Allan de Medeiros Martins', 'Glauber Rodrigues Leite')","Este trabalho apresenta o AutoTF uma solução desenvolvida para modelagem de sistemas físicos lineares, possibilitando que o usuário visualize a função de transferência à partir de uma variável de entrada e uma variável de saída. Elementos elétricos foram considerados para a construção de uma primeira versão do simulador, abrindo portas para elementos de outras naturezas, visto que cada uma possui componentes que influenciam da mesma forma que fontes, resistores, capacitores ou indutores no sistema ao qual está inserido. A solução foi projetada de modo que a comunicação com o usuário através de sua interface gráfica fosse um diferencial na simulação de circuitos, permitindo a construção de um modelo gráfico a partir da ferramenta Canvas e sua API Javascript, garantindo que através de janelas em um navegador Web pudessem ser vistas todas as etapas até a apresentação do resultado final. O sistema utiliza o grafo de ligação como uma alternativa para representação do modelo proposto pelo usuário, transformando-o em um diagrama de fluxo de sinais proveniente das funções lineares geradas pelas matrizes de interconectividade entre os elementos físicos, para que então a regra de Mason fosse aplicada gerando a função de transferência. Os resultados mostram que o AutoTF atende os objetivos propostos garantindo confiabilidade nas funções resultantes, enquanto recursos gráficos desenvolvidos guiam o projetista no início ao fim do processo de modelagem.","This work presents AutoTF, a solution developed for modeling linear physical systems, allowing the user to visualize the transfer function from an input variable and an output variable. Electrical elements were considered for the construction of a first version of the simulator,creating possibilities to future versions implementations with elements of other natures, since each one has components that influence in the same way as sources, resistors, capacitors or inductors in the system to which it is inserted. The solution was designed so that communication with the user through its graphical interface was a di↵erential in circuit simulation, allowing the construction of a graphical model from the Canvas tool and its javascript API, ensuring that using browser Web pages could be useful to show all the steps until the presentation of the final result. The system uses the link graph as an alternative to represent the model proposed by the user, transforming it into a signal-flow graph from the linear functions generated by the interconnectivity matrices between the physical elements, so that Mason’s rule could be applied generating the transfer function. The results show that AutoTF meets the proposed objectives, guaranteeing reliability in the resulting functions, while graphic resources developed guide the designer from the beginning to the end of the modeling process.","('AutoTF (Sistema web)', 'Modelagem de sistemas', 'Função de transferência', 'System modeling', 'Transfer function', 'Control system', 'Mason’s rule')","Engenharia de Software","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/9478","2022-04-22","https://www.repositorio.ufal.br/bitstream/123456789/9478/1/AutoTF-%20um%20ambiente%20web%20para%20modelagem%20de%20sistemas%20f%c3%adsicos.pdf","AutoTF: a web environment for physical systems modeling",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/10250","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Aplicação de Algoritmo Genético para criação de mapas de RPG de mesa","('Marcelo Barandela Abio',)","('Roberta Vilhena Vieira Lopes',)","('Evandro de Barros Costa', 'Marcos Vinícius Carneiro Vital')","Em 1974 o lançamento do jogo Dungeons & Dragons (D&D) por Gary Gygax e Dave Arnenson culminou na criação de um novo gênero de jogo de mesa: o Role-Playing Game (RPG). D&D é um jogo de grupo onde um participante desempenha o papel de mestre do jogo (DM, do inglês Dungeon Master) enquanto os demais participantes interpretam um personagem cada. O mestre possui a tarefa de narrar os acontecimentos do jogo, ser um árbitro das regras e interpretar os personagens que não são interpretados pelos outros jogadores. Caso se deseje jogar o D&D de maneira tática, com miniaturas e tabuleiros, será necessário que o mestre apresente mapas para delimitar o ambiente de jogo, tendo que ou obter os mapas de terceiros ou criá-los por conta própria. Para auxiliar os mestres no processo de preparação das sessões de jogo, este trabalho tem como objetivo apresentar o Mapmaker, uma ferramenta computacional desenvolvida para gerar mapas para os jogos de D&D utilizando algoritmo genético.","The release of the Dungeons & Dragons (D&D) game by Gary Gygax and Dave Arnenson in 1974 resulted in the creation of a new genre of tabletop game: the RolePlaying Game (RPG). D&D is a group game where one participant exert the role of the Dungeon Master (DM) while each of the other participants play a character. It is the DM’s role to narrate the outcomes of the player’s actions, to be a referee of the rules and play the role of others characters the players might encounter. If they wish to play D&D in a tactical manner, with miniatures and a grid, it will be necessary for the DM to present maps that define the game environment, having to obtain the maps by a third-party or create them by themselves. To help Dungeon Masters in the preparation to the game sessions, this paper has as goal present the Mapmaker, a computational tool developed to generate maps for D&D games utilizing genetic algorithm.","('RPG -jogo', 'Algoritmo Genético – jogo', 'Mapmaker', 'Mapas -RPG', 'D&D', 'Genetic algorithm', 'Map', 'RPG')","Engenharia de Software","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/10250","2021-06-07","https://www.repositorio.ufal.br/bitstream/123456789/10250/1/Aplica%c3%a7%c3%a3o%20de%20Algoritmo%20Gen%c3%a9tico%20para%20cria%c3%a7%c3%a3o%20de%20mapas%20de%20RPG%20de%20mesa.pdf","Aplication of Genetic Algorithm for the creation of tabletop RPG maps",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/12591","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Uma análise para sistemas embarcados de modelos de rede neural convolucional para classificação do porte de capacete de segurança","('Derek Nielsen Araújo Alves',)","('Erick de Andrade Barboza',)","('Tiago Figueiredo Vieira', 'Victor Diogho Heuer de Carvalho')","Esta monografia aborda a criação de modelos de aprendizagem de máquina para sistemas embarcados, neste contexto propomos alguns modelos treinados para a classificação do correto uso de capacetes de segurança e fazemos uma análise de viabilidade desses modelos com relação ao seu tamanho, acurácia e perdas, de modo a apontar quais seriam os melhores modelos para se embarcar em algumas placas de desenvolvimento disponíveis. Tal análise de viabilidade foi realizada considerando modelos que utilizaram quatro-mil e oitocentas imagens. Os resultados experimentais obtidos mostram que é possível embarcar esses modelos em diversas placas de desenvolvimento, desde que atentemos as restrições de cada hardware, pouca memória, pouco processamento, baixo consumo de energia, e outros.","This work addresses the creation of machine learning models for embedded systems. In this context, we propose some trained models for classifying the correct use of safety helmets and conduct a feasibility analysis of these models in terms of their size, accuracy and losses, in order to identify the best models to be deployed on various available development boards. Based on this feasibility analysis, our experimental results show that it is possible to deploy these models on different development boards, provided that we pay attention to the constraints of each hardware, such as limited memory, processing power, low energy consumption, and others. Additionally, we created a database containing approximately four thousand images, which we used to train our neural network models.","('Sistemas embarcados', 'TinyML', 'Inteligência artificial', 'Redes neurais', 'Aprendizado de máquina', 'Equipamentos de proteção individual', 'Embedded systems', 'Artificial inteligence', 'Neural networks', 'Machine learning', 'Personal protective equipment')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/12591","2023-06-23","https://www.repositorio.ufal.br/bitstream/123456789/12591/1/Uma%20an%c3%a1lise%20para%20sistemas%20embarcados%20de%20modelos%20de%20rede%20neural%20convolucional%20para%20classifica%c3%a7%c3%a3o%20do%20porte%20de%20capacete%20de%20seguran%c3%a7a.pdf","An analysis for embedded systems of convolutional neural network models for safety helmet usage classification",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/12703","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Análise de evasão baseada em modelos preditivos para o curso de Engenharia de Computação da Universidade Federal de Alagoas","('Igor da Cunha Araújo Theotônio',)","('Thiago Damasceno Cordeiro',)","('Álvaro Alvares de Carvalho César Sobrinho', 'Bruno Almeida Pimentel')","Contexto: Evasão escolar é um problema crítico e crônico presente em diferentes níveis do ensino na educação brasileira. Este problema é extremamente presente nas faculdades públicas, em especial nos cursos de ciências exatas, afetando diretamente o curso de Engenharia de Computação do Instituto de Computação (IC) da Universidade Federal de Alagoas (Ufal). Objetivo: Atualmente não há nenhum recurso sendo utilizado para auxiliar a coordenação do referido curso a mapear alunos com alto risco de evasão. Portanto, o objetivo deste trabalho consistem em avaliar a factibilidade do uso de ferramentas baseadas em modelos preditivos como meio de suporte para diminuição dos índices de evasão escolar. Método: Esse trabalho apresenta a comparação entre dois modelos preditivos, sendo o primeiro baseado em árvores de decisão simples e o segundo baseado no algoritmo Random Forest utilizando a base de dados dos alunos do curso de Engenharia de Computação do IC da Ufal. Estes dados foram fornecidos pelo Núcleo de Tecnologia da Informação (NTI) da própria instituição e contém informações desde o início do curso até o primeiro semestre do ano 2020. Resultados: Os resultados apontam que os modelos gerados possuem acurácia e recall acima de 85% em ambos os modelos, resultados considerados positivos dado o problema de pesquisa apresentado. Além disso, outras métricas e informações relevantes puderam ser extraídas dos dados utilizados. Conclusão: Diante do trabalho desenvolvido e dos resultados obtidos, acreditamos que a utilização de modelos preditivos baseados em árvore de decisão como ferramenta de suporte à redução de evasão do no curso de Engenharia de Computação do IC/Ufal é factível.","Context: School dropout is a critical and chronic problem present at different levels of teaching in Brazilian education. This problem is extremely present in public colleges, especially in exact sciences courses, directly affecting the Computer Engineering course at the Institute of Computing (IC) of the Federal University of Alagoas (Ufal). Objective: Cthere is no resource being used to help the coordination of the referred course to map students with high dropout risk. Therefore, the objective of this work is to evaluate the feasibility of using tools based on predictive models as a means of support for reducing school dropout rates. Method: This work presents the comparison between two predictive models, the first based on simple decision trees and the second based on the Random Forest algorithm using the database of students of the Computer Engineering course at IC/Ufal. These data were provided by the Information Technology Center (NTI) of the institution and contain information from the beginning of the course until the first half of 2020. Results: The results indicate that the generated models have accuracy and recall above 85% in both models, results considered positive given the research problem presented. In addition, other metrics and relevant information could be extracted from the data used. Conclusion: In view of the work carried out and the results obtained, we believe that the use of predictive models based on decision trees as a tool to support the dropout reduction in the Computer Engineering course at IC/Ufal is feasible.","('Engenharia de Computação', 'Evasão universitária', 'Modelo preditivo', 'Árvore de decisão', 'Floresta aleatória (Random forest)', 'Computer Engineering', 'University dropout', 'Predictive model', 'Decision tree')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/12703","2023-05-24","https://www.repositorio.ufal.br/bitstream/123456789/12703/1/An%c3%a1lise%20de%20evas%c3%a3o%20baseada%20em%20modelos%20preditivos%20para%20o%20curso%20de%20Engenharia%20de%20Computa%c3%a7%c3%a3o%20da%20Universidade%20Federal%20de%20Alagoas.pdf","",""
"Engenharia da Computação","https://www.repositorio.ufal.br/handle/123456789/12739","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Adaptação de técnica de interpolação linear para a estimação do sinal de saída de amplificadores ópticos com entrada não plana","('Allan Amaro Bezerra da Silva',)","('Erick de Andrade Barboza',)","('Ícaro Bezerra Queiroz de Araújo', 'Thiago Damasceno Cordeiro')","A Internet tem sido o cenário do aumento no tráfego de dados. Diante desse consumo, as redes ópticas são uma boa opção de uso por conta de sua grande largura de banda. Nelas, os amplificadores ópticos possuem papel fundamental ao compensar perdas de potência que o sinal sofre durante a transmissão, ao mesmo tempo em que o degrada através da adição de distorções e ruídos. É preciso adaptá-los para que seu funcionamento seja autônomo e favoreça a qualidade da transmissão. Assim surge o problema ACOP (Adaptive Control of Operating Point), cujo objetivo é adequar a configuração do amplificador de acordo com o estado da rede. Nas soluções da literatura é fundamental que o conjunto de pontos de operação do amplificador, chamado de máscara de potência, seja conhecido. Para oferecer uma maior granularidade no espaço dos pontos de operação definidos nas máscaras, existem técnicas capazes de estimar o comportamento do amplificador em pontos não definidos, porém nem todas levam em consideração não linearidades nos sinais, comuns em cenários reais. Neste trabalho é proposta uma adaptação de uma das técnicas de estimação de sinais ópticos da literatura, baseada em interpolação linear, de maneira a fazê-la considerar máscaras de potência com sinais não planos. As avaliações mostram que a adaptação foi capaz de aprimorar o desempenho da técnica original, que apresentou medidas de erro muito maiores que as da técnica proposta aqui. Ainda, a adaptação foi capaz de obter resultados semelhantes e, em diversos casos, melhores que uma outra técnica da literatura, baseada em redes neurais artificiais.","The Internet has been the scene of increased data traffic. Given this consumption, optical communication networks are a good option to use because of their large bandwidth. In them, optical amplifiers play a fundamental role in compensating for power losses that the signal suffers during transmission, while degrading it through the addition of distortions and noise. It is necessary to adapt them so that their operation is autonomous and favors transmission quality. Thus, the ACOP (Adaptive Control of Operating Point) problem arises, whose objective is to adapt the amplifier configuration according to the state of the network. In the solutions in the literature, it is essential that the set of amplifier operating points, called the power mask, is known. To offer greater granularity in the space of the operating points defined in the masks, there are techniques capable of estimating the amplifier’s behavior at undefined points, but not all of them take into account non-linearities in the signals, common in real-world scenarios. This work proposes an adaptation of one of the optical signal estimation techniques in the literature, based on linear interpolation, in order to make it consider power masks with non-plane signals. The evaluations show that the adaptation was able to improve the performance of the original technique, which presented error measures much greater than those of the technique proposed here. Furthermore, the adaptation was able to obtain similar results and, in several cases, better than another technique in the literature, based on artificial neural networks.","('Telecomunicações', 'Redes ópticas', 'Sinal óptico -Amplificador óptico', 'Interpolação linear', 'Telecommunications', 'Optical networks', 'Optical amplifier', 'Optical signal', 'Linear interpolation')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/12739","2021-06-04","https://www.repositorio.ufal.br/bitstream/123456789/12739/1/Adapta%c3%a7%c3%a3o%20de%20t%c3%a9cnica%20de%20interpola%c3%a7%c3%a3o%20linear%20para%20a%20estima%c3%a7%c3%a3o%20do%20sinal%20de%20sa%c3%adda%20de%20amplificadores%20%c3%b3pticos%20com%20entrada%20n%c3%a3o%20plana.pdf","Adaptation of linear interpolation technique for estimating the output signal of optical amplifiers with non-flat input",""
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/12594","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Estudo e desenvolvimento de um detector automático de comportamento Gaming the System em resolução de problemas de programação","('Julios Suruagil Lins da Rocha',)","('Evandro de Barros Costa',)","('Hemilis Joyse Barbosa Rocha', 'Roberta Vilhena Vieira Lopes', 'Emanuele Tuane Silva')","Este trabalho está relacionado a um estudo sobre um tipo de comportamento, considerado indesejável, identificado em alguns estudantes, diante de situação de resolução de problemas de programação. Assim, foi investido no desenvolvimento de uma solução para detectar automaticamente a presença do mencionado comportamento. Deste modo, primeiramente foi desenvolvido um ambiente apropriado para coleta de dados, seguindo-se pela preparação desses dados para serem utilizados por algoritmos de aprendizagem de máquina supervisionada, considerando uma tarefa de classificação, permitindo a detecção do comportamento. O desenvolvimento do detector envolveu explorar, avaliar e comparar diferentes algoritmos classificadores. Como um dos resultados, verificamos que o algoritmo MLP apresentou um melhor desempenho, com uma acurácia de 0.84.","This work is related to a study on a type of behavior, considered undesirable, identified in some students, when faced with a situation of solving programming problems. Thus, we invested in the development of a solution to automatically detect the presence of the mentioned behavior. Thus, firstly, an appropriate environment for data collection was developed, followed by the preparation of these data to be used by supervised machine learning algorithms, considering a classificationtask,allowingthedetectionofbehavior. The development of the detector involved exploring, evaluating and comparing different classification algorithms. As one of the results, we found that the MLP algorithm performed better, with an accuracy of 0.84.","('Programação (Computadores)', 'Resolução de problemas', 'Algoritmos de aprendizagem', 'Aprendizagem de máquina', 'Mineração de dados', 'Programming (Computers)', 'Problem solving', 'Learning Algorithms', 'Machine Learning', 'Data mining')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/12594","2022-12-19","https://www.repositorio.ufal.br/bitstream/123456789/12594/1/Estudo%20e%20desenvolvimento%20de%20um%20detector%20autom%c3%a1tico%20de%20comportamento%20Gaming%20the%20System%20em%20resolu%c3%a7%c3%a3o%20de%20problemas%20de%20programa%c3%a7%c3%a3o.pdf","",""
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/12656","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Bayesian inference for uncertainty quantification in binary classification tasks with limited data","('Wagner da Silva Fontes',)","('Bruno Almeida Pimentel',)","('Rafael de Amorim Silva', 'Diego Carvalho do Nascimento')","Nos últimos anos, a Quantificação de Incerteza emergiu como um componente essencial dos modelos de Aprendizado de Máquina, particularmente no contexto de tomada de decisões e avaliação de riscos. Neste trabalho, realizamos uma investigação abrangente sobre o desempenho da Inferência Bayesiana para a Quantificação de Incerteza em problemas de classificação binária com dados limitados. Aplicamos modelos de regressão logística bayesiana, bem como os outros dois métodos, a diversos conjuntos de dados pequenos e amplamente conhecidos. A performance dessas abordagens é avaliada utilizando a métrica F1S core e comparada em diferentes níveis de incerteza preditos por cada método. Nossos resultados demonstram que a abordagem de Inferência Bayesiana não apenas exibe um desempenho competitivo, mas também fornece uma saída mais flexível na forma de uma distribuição, que viabiliza uma análise mais completa dos resultados e pode ser utilizada de diversas maneiras para capturar diferentes níveis de incerteza. Apesar dos desafios de convergência associados a conjuntos de dados pequenos e espaços paramétricos complexos, os modelos bayesianos conseguem capturar tanto as incertezas epistêmicas quanto as aleatórias, oferecendo uma estrutura robusta para a compreensão dos fenômenos subjacentes. Em contrapartida, os métodos de região de incerteza e Inferência Conformal apresentam certas limitações, como o tamanho reduzido do conjunto de treinamento para Inferência Conformal e inflexibilidade na saída, que podem potencialmente dificultar suas aplicações práticas. Nossas descobertas destacam o potencial da Inferência Bayesiana como uma abordagem eficaz para a Quantificação de Incerteza em problemas de classificação binária, mesmo quando confrontada com a limitação de dados, com performance equiparável aos métodos frequentistas especialmente com a escolha de distribuições priori não informativas.","In recent years, Uncertainty Quantification has gained significant attention as an essential aspect of Machine Learning models, particularly in the context of decision-making and risk assessment. In this study, we provide a comprehensive investigation of the performance of Bayesian Inference for Uncertainty Quantification in binary classification problems with limited data, and we compare its effectiveness with alternative approaches, such as the uncertainty region and Conformal Inference methods. We apply Bayesian logistic regression models, as well as the other two methods, to various well-known small datasets. The performance of these approaches is evaluated using F1 scores at different levels of the uncertainty predicted by each method. Our results demonstrate that the Bayesian Inference approach not only exhibits competitive performance, particularly when using non-informative priors, but also provides a more flexible output in the form of a distribution, this adaptability enables a more comprehensive analysis of the results and can be leveraged in various ways to capture different levels of uncertainty. Despite the convergence challenges associated with small data sets and high-dimensional parameter spaces, the Bayesian models capture both epistemic and aleatoric uncertainties, offering a robust framework for understanding the underlying phenomena. In contrast, the uncertainty region and Conformal Inference methods display certain limitations, such as reduced training set size for Conformal Inference and inflexibility in the out put, which could potentially hinder their practical applications. Our findings highlight the potential of Bayesian Inference as an effective approach for Uncertainty Quantification in binary classification problems, even when faced with limited data.","('Inferência bayesiana', 'Classificação binária', 'Quantificação de incerteza', 'Bayesian Inference', 'Binary classification', 'Quantification of uncertainty')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/12656","2023-05-31","https://www.repositorio.ufal.br/bitstream/123456789/12656/1/Bayesian%20inference%20for%20uncertainty%20quantification%20in%20binary%20classification%20tasks%20%20with%20limited%20data.pdf","",""
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/10161","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Compilação de Recomendações para Auxiliar no Desenvolvimento de Novas Soluções para Problemas de Visão Computacional","('Nelson Gomes Neto',)","('Rodrigo de Barros Paes',)","('Tiago Figueiredo Vieira', 'Bruno Georgevich Ferreira')","O objetivo deste trabalho é ser um guia para quem busca alavancar seus conhecimentos em Visão Computacional através da Aprendizagem de Máquina. Com este objetivo, foi realizada uma pesquisa em problemas de Visão Computacional da plataforma Kaggle; onde foram coletadas diversas estatísticas dos problemas e suas melhores soluções. Neste trabalho de monograﬁa, foram exempliﬁcados e explicados bons direcionamentos para criação de novas soluções para problemas de Visão Computacional utilizando Aprendizagem de Máquina. Por ﬁm, através de testes práticos, foi possível concluir a relevância desta monograﬁa.","TheobjectiveofthisworkistobeaguidetowhoseekstoelevateyourknowledgeinComputer Vision through Machine Learning. With this objective, a survey was done on Computer Vision problems from Kaggle’s website. Through it, various features from the problems and their best solutions were extracted. In this monography: examples and good directions were given to the creation of new Machine Learning solutions to Computer Vision problems. Lastly, through practical tests, it was possible to conclude the relevance of this monography","('Inteligência Artiﬁcial', 'Visão Computacional', 'Kaggle', 'Artiﬁcial Intelligence', 'Computer Vision')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/10161","2021-03-22","https://www.repositorio.ufal.br/bitstream/123456789/10161/1/Compila%c3%a7%c3%a3o%20de%20Recomenda%c3%a7%c3%b5es%20para%20Auxiliar%20no%20Desenvolvimento%20de%20Novas%20Solu%c3%a7%c3%b5es%20para%20Problemas%20de%20Vis%c3%a3o%20Computacional.pdf","Compilation of Recomendations to Auxiliate the Development of New Solutions on Computer Vision Problems","('Willy Carvalho Tiengo',)"
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/10357","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Comparação de técnicas para aumentar a eficácia e eficiência de análise de sentimento por meio da redução do número de features","('Gabriel Fabrício Batista Freire',)","('Bruno Almeida Pimentel',)","('Lucas Benevides Viana de Amorim', 'Roberta Vilhena Vieira Lopes')","Análise de sentimentos é uma das mais prevalentes áreas do Aprendizado de Máquina, por conseguir converter textos em classes. Porém essa conversão vem com alguns inconvenientes, dentre eles estão o alto tempo de treinamento e a baixa acurácia em geral, os quais são agravados por conta dos modelos de deﬁnição de features mais comuns, que geram features baseadas em cada uma das palavras contidas no conjunto de dados. Assim, esse trabalho tem por objetivo comparar meios de reduzir o número de features considerando tanto o aumento de eﬁciência, na forma de tempo de treinamento e predição, quanto o aumento de eﬁcácia, na forma de melhores parâmetros e resultados para as predições.","Sentiment Analysis is one of the most prevalent areas of Machine Learning, for being able to convert texts into classes. Though that conversion comes with its own drawbacks, among them are the high training cost and low general accuracy, which are compounded by the most common feature deﬁnition models, that generate features based on every word contained in the training datasets. Thus, this research has the goal of comparing means of reducing the number of features to considering both the increase efﬁciency, in the form of shorter training and prediction times, and the increase in efﬁcacy, in the form of better parameters and results for predictions","('Aprendizado do computador', 'Modelo de sentimento', 'Processamento de linguagem natural (Computação)', 'MachineLearning', 'Sentiment Analysis', 'Natural Language Processing', 'Dimensionality Reduction')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/10357","2021-06-09","https://www.repositorio.ufal.br/bitstream/123456789/10357/1/Compara%c3%a7%c3%a3o%20de%20t%c3%a9cnicas%20para%20aumentar%20a%20efic%c3%a1cia%20e%20efici%c3%aancia%20de.pdf","","('Rafael de Amorim Silva',)"
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/10441","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Classificação de textos de decisões judiciais","('Brunno Moreira Gêda',)","('André Lages Freitas',)","('Fábio José Coutinho da Silva', 'José de Jesus Filho')","Neste trabalho, fazemos uso de técnicas de aprendizado de máquina e processamento de linguagem natural (NLP) para automatizar a classificação textual no contexto de decisões judiciais e, assim, tornar esse processo mais rápido. A importância e relevância deste trabalho se devem à grande quantidade de textos jurídicos produzidos em tribunais, o que torna ineficiente e lenta a avaliação humana. Assim, este trabalho consiste em treinar e avaliar uma base de dados de textos oriundos de Acórdãos (decisões judiciais) obtidos do Tribunal de Justiça de Alagoas para classificá-los de acordo com três possíveis resultados: recurso provido, recurso não provido, ou recurso parcialmente provido. Para isso, avaliamos o desempenho de cinco modelos de aprendizado de máquina supervisionado: Gaussian Naive Bayes, Árvore de Decisão, Máquina de Vetores de Suporte, Random Forest e XGBoost. Destacaram-se os modelos Árvore de Decisão, Máquina de Vetores de Suporte e XGBoost, que atingiram aproximadamente precisão de 99% (f1-score).","The great amount of legal documents produced in law courts makes it very inefficient and slow to be reviewed by humans. For example, courts produce millions of legal decisions per year in Brazil. In this paper, we propose an approach to automate the classification of court decisions. Specifically, we address the classification of sentences that contains judge decisions. We use machine learning and natural language processing (NLP) techniques to classify appeal decisions as granted, not granted, and partially granted. As a result, legal professionals do not need to read the case decisions – or even their summary (Ementa) – to know its decision. The data set used in this paper has 1,596 legal decisions from the State Supreme Court of Alagoas (Tribunal de Justiça de Alagoas). Moreover, we assessed the performance of five supervised machine learning models: Gaussian Naive Bayes, Decision Tree, Support Vector Machine, Random Forest, and XGBoost. The Decision Tree, Support Vector Machine, and XGBoost models achieved standout results with approximately an F1-score of 99%.","('Inteligência artificial', 'Aprendizado do computador', 'Direito', 'Decisão judicial', 'Processamento de linguagem natural (Computação)', 'Artificial intelligence', 'Machine learning', 'Law', 'Legal', 'Case outcome', 'Legal decisions')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/10441","2021-04-09","https://www.repositorio.ufal.br/bitstream/123456789/10441/1/Classifica%c3%a7%c3%a3o%20de%20textos%20de%20decis%c3%b5es%20judiciais.pdf","","('Leonardo Viana Pereira',)"
"Ciências da Computação","https://www.repositorio.ufal.br/handle/riufal/6995","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Desagregação de energia utilizando GSP (Graph Signal Processing)","('Bruno Marques Barbosa',)","('André Luiz Lins de Aquino',)","('Leonardo Viana Pereira', 'Randy Ambrósio Quindai João')","O uso de dispositivos computacionais acabou gerando, com o passar do tempo, um grande acúmulo de dados. Esses dados vão desde recibos de compras a processos judiciais. Sendo assim, há um grande interesse comercial e acadêmico em saber o que fazer com tais dados, de forma a extrair informação importante deles. Trabalhos relacionados ao problema da desagregação de energia e do monitoramento não-intrusivo de cargas envolvem criação de conjuntos de dados para o estudo do problema, criação de dispositivos para a coleta de dados, entre outros. O problema da desagregação de energia consiste em coletar dados dos quadros gerais das casas, que é onde a energia elétrica vinda dos postes é distribuída para a casa, e dos eletrodomésticos individualmente e, utilizando algoritmos, obter dados que se aproximam muito dos dados coletados dos eletrodomésticos, ou seja, dados os dados de energia de uma casa, verificar quais eletrodomésticos estão utilizando aquelas cargas em determinada hora do dia. Este problema faz parte do NILM (Non-intrusive Load Monitoring), que é um conjunto de técnicas, que envolvem hardware e software, para monitoramento de energia elétrica, a fim de que a energia possa ser melhor utilizada pelos moradores. A solução utilizada envolve um algoritmo chamado GSP (Graph Signal Monitoring), que utiliza processamento de sinais para a construção de grafos com dados de sinais (no caso da desagregação de energia, os sinais são a energia elétrica) e, a partir desses grafos, verificar quais dados são mais similares e, assim, agrupá-los para formar os eletrodomésticos que consumiram a energia elétrica da casa. Este método é uma forma de se desagregar energia sem utilizar treinamento, como os métodos que usam Deep Learning, por exemplo. A aplicação do algoritmo utilizou bases de dados públizas, como o REDD (Reference Energy Disaggregation Dataset) e o REFIT, a fim de implementar as soluções apresentadas pelo artigo que publicou o algoritmo baseado em GSP. A desagregação foi realizada, os dados desagregados obtidos se aproximam dos resultados coletados individualmente, porém, é necessário melhorar a acurácia.","The use of computational devices eventually generated a large accumulation of data. This data ranges from purchase receipts to lawsuits. Therefore, there is a strong business and academic interest in what to do with such data in order to extract important information from them. Work related to the problem of energy disaggregation and non-intrusive load monitoring involves creating data sets to study the problem, creating devices for data collection, among others. The problem of power disaggregation is to collect data from the house overviews, which is where the electric power coming from the poles is distributed to the house, and from the individual appliances and, using algorithms, to get data that comes very close to the data collected from the appliances, ie given the energy data of a home, check which appliances are using those loads at a particular time of day. This problem is part of Non-intrusive Load Monitoring (NILM), which is a set of techniques that involve hardware and software for monitoring power so that energy can be better utilized by residents. The solution used involves an algorithm called GSP (Graph Signal Monitoring), which uses signal processing to construct graphs with signal data (in the case of energy breakdown, the signals are electrical energy) and from these graphs, check which data are most similar and thus group them together to form the appliances that have consumed the electricity of the house. This method is a way of disaggregating energy without training, such as Deep Learning methods, for example. The application of the algorithm used public databases, such as REDD (Reference Energy Disaggregation Dataset) and REFIT, in order to implement the solutions presented by the article that published the GSP-based algorithm. The disaggregation was performed, the disaggregated data obtained approximate the results collected individually, but it is necessary to improve the accuracy.","('Desagregação de energia', 'Processamento de sinal gráfico', 'Energy Disaggregation', 'GSP', 'Python')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/6995","2020-03-27","https://www.repositorio.ufal.br/bitstream/riufal/6995/1/Desagrega%c3%a7%c3%a3o%20de%20energia%20utilizando%20GSP%20%28Graph%20Signal%20Processing%29.pdf","Energy Disaggregation Using GSP (Graph Signal Processing)",""
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/12563","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Avaliação de métodos clássicos de detecção de características no auxílio à identificação de amastigotas de leishmaniose","('Eduardo Antônio de Lucena Lisboa',)","('Fabiane da Silva Queiroz',)","('Raquel da Silva Cabral', 'Eliana Silva de Almeida')","A Leishmaniose Visceral (LV) é uma antropozoonose, de alta letalidade, transmitida pelo popularmente conhecido mosquito palha. Atualmente, o diagnóstico dessa doença é complexo devido à similaridade de seus sintomas com outras enfermidades, sendo o padrão ouro do diagnóstico o exame parasitológico que trata da análise visual do parasita leishmania em material de biópsia, sendo esta análise passível de erros devido a fatores como o tamanho minúsculo do parasita a ser observado (cerca 2–4 µm de diâmetro) e a expertise médico no diagnóstico dessa doença. Neste estudo, a partir de um método patch-based, avaliamos diversos descritores de textura e algoritmos de classificação que possam auxiliar na identificação destes parasitas. Mais precisamente, um conjunto de fragmentos (patches), extraídos de imagens microscópicas de aspirado de medula óssea, foram submetidos a algoritmos de pré-processamento, extração de características e classificação. Os algoritmos SIFT, ORB e Haralick foram empregados na extração de características, considerando sua detecção, descrição e análise de textura. Os classificadores SVM e KNN foram utilizados para classificar as imagens, identificando a presença ou ausência de leishmania. Os resultados obtidos demonstraram a eficácia dessas técnicas no diagnóstico da LV, com acurácia satisfatória na identificação dos parasitas. Portanto, este estudo destaca o potencial das técnicas de processamento de imagens e algoritmos de aprendizagem de máquina como ferramentas auxiliares no diagnóstico preciso e rápido dessa doença grave, possibilitando um tratamento eficaz e melhores resultados para os pacientes afetados.","Visceral leishmaniasis (VL) is an anthropozoonosis, of high lethality, transmited by the popularly known sand flies. Currently, the diagnosis of this disease is complex due to the similarity of its symptoms with other diseases, the gold standard of diagnosis being the parasitological examination that deals with the visual analysis of the parasite leishmania in biopsy material, this analysis being subject to errors due to factors such as the minuscule size of the parasite to be observed (about 2–4 µm in diameter) and the medical expertise in diagnosing this disease. In this study, from a patch-based method, we evaluated several texture descriptors and classification algorithms that can help identify these parasites. More precisely, a set of fragments (patches), extracted from microscopic images of bone marrow aspirates, were submitted to pre-processing, feature extraction and classification algorithms. The algorithms SIFT, ORB and Haralick were employed in the feature extraction, considering their detection, description and texture analysis. The classifiers SVM and KNN were used to classify the images, identifying the presence or absence of leishmania. The results obtained demonstrated the effectiveness of these techniques in the diagnosis of VL, with satisfactory accuracy in the identification of parasites. Therefore, this study highlights the potential of image processing techniques and machine learning algorithms as auxiliary tools in the accurate and rapid diagnosis of this serious disease, enabling effective treatment and better outcomes for affected patients.","('Leishmaniose visceral', 'Aprendizagem de máquina', 'Diagnóstico médico', 'Visceral leishmaniasis', 'Machine learning', 'Medical diagnosis')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/12563","2023-06-07","https://www.repositorio.ufal.br/bitstream/123456789/12563/1/Avalia%c3%a7%c3%a3o%20de%20m%c3%a9todos%20cl%c3%a1ssicos%20de%20detec%c3%a7%c3%a3o%20de%20caracter%c3%adsticas%20no%20aux%c3%adlio%20%c3%a0%20identifica%c3%a7%c3%a3o%20de%20amastigotas%20de%20leishmaniose.pdf","Evaluation of classical characteristic detection methods in aiding the identification of leishmaniasis amastigotes",""
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/12685","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Detecção de smells em testes automatizados em diferentes linguagens de programação","('Gustavo Augusto Calazans Lopes',)","('Márcio de Medeiros Ribeiro',)","('Ivan do Carmo Machado', 'Erick de Andrade Barboza')","Testes de software são importantes para qualquer produto digital em desenvolvimento ou já em uso. Eles servem como garantia que o sistema está funcionando conforme o esperado e que em eventuais manutenções ou criação de novas funcionalidades, não irão interferir no atual funcionamento do sistema. Os testes automatizados e desenvolvimentos de scripts de teste são predominantes na indústria de software. Contudo, assim como códigos de produção, a escrita dos testes automatizados também podem conter problemas no projeto ou na implementação, afetando negativamente a qualidade, os denominados tests smells. A identificação desses smells por parte dos desenvolvedores não é trivial, o que leva a utilização de ferramentas para isso. Na pesquisa realizada foi visto que, apesar de existirem muitas ferramentas para identificação de smells, não existe uma certa diversidade quanto as linguagens suportadas, além da necessidade de desenvolvimento de novas ferramentas para cada linguagem ou framework de testes automatizados. O presente trabalho de conclusão de curso tem por objetivo apresentar uma única ferramenta para identificação de tests smells com suporte para diferentes linguagens e frameworks de desenvolvimento de testes automatizados. Com isso, intenta-se sanar a necessidade de falta de suporte e retrabalho com a criação de novas ferramentas para um mesmo propósito.","Software testing is important for any digital product under development or already in use. It serve as a guarantee that the system is working as expected and that any maintenance or creation of new functionalities will not interfere with the current system operation. Automated tests and test script development are very common in the software industry. However, just like production codes, the writing of automated tests can also contain bad design, negatively affecting quality, as known as test smells. The identification of these smells by developers is not trivial, which leads to the use of tools for this. In the research conducted, it was seen that, although there are many tools for identifying smells, there is not a certain diversity in terms of supported languages, besides to the need to develop new tools for each language or automated test frameworks. The present work aims to present a single tool for identifying test smells with support for different languages and frameworks for developing automated tests. With this, it is intended to remedy the need for lack of support and rework with the creation of new tools for the same goal.","('Software – Testes', 'Testes automatizados', 'Code smells', 'Software – Tests', 'Automated testing', 'Smell detection tools')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/12685","2023-06-12","https://www.repositorio.ufal.br/bitstream/123456789/12685/1/Detec%c3%a7%c3%a3o%20de%20smells%20em%20testes%20automatizados%20em%20diferentes%20linguagens%20de%20programa%c3%a7%c3%a3o.pdf","Detection of smells in automated tests in different programming languages","('Elvys Alves Soares',)"
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/9205","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Desenvolvimento de modelos para estimar principais características socioeconômicas para as notas de redação e matemática para ENEM 2018","('Manoela Cassia Santos',)","('Bruno Almeida Pimentel',)","('Rafael de Amorim Silva', 'Lucas Benevides Viana de Amorim')","Análise preditiva é uma técnica analítica avançada que usa dados, algoritmos e Aprendizagem de Máquina para antecipar tendências e fazer projeções nos negócios. Utilizando como base os dados coletados pelo Exame Nacional do Ensino Médio (ENEM) do ano de 2018, esse trabalho tem como proposta analisar os dados socioeconômicos dos participantes, a ﬁm de aprimorar modelos regressores para prever as notas de Redação e de Matemática dos participantes. Foram desenvolvidos modelos preditivos utilizando algoritmos de Aprendizagem de Máquina (Rede Neural, Random Forest, Árvore de Decisão, Regressão Linear). Após aplicação métricas de avaliação de modelos preditivos, foi constatado que o modelo Rede Neural teve melhor desempenho na predição das notas de Matemática, enquanto Regressão Linear na predição das nota de Redação. Destacaram-se algumas características socioeconômicas sobre tipo de escola, sexo, computador, ocupação do pai, renda familiar mensal, inﬂuentes na predição das notas de Redação e Matemática.","Predictive analytics is na advanced analytical technique that uses data, algorithms and Machine Learning to anticipate trends and make business projections. Using the data collected by the Exame Nacional do Ensino Médio (ENEM) in 2018, this work aims to analyze the socioeconomic data of the participants, in order to improve regression models to predict the Writing and Mathematics scores of the participants. Predictive models were developed using Machine Learning algorithms (Neural Network, Random Forest, Decision Tree, Linear Regression). After applying metrics to evaluate predictive models, it was found that the Neural Network model performed better in predicting math scores, while Linear Regression in predicting writing scores. Some socioeconomic features on type of school, sex, computer, father’s occupation, monthly family income, which are inﬂuential in the prediction of Writing and Mathematics scores, stood out.","('Análise Preditiva', 'Análise de Dados', 'Aprendizado de Máquina', 'Mineração de Dados (Computação)', 'Ciência de Dados', 'Exame Nacional do Ensino Médio (Brasil)', 'Data analysis', 'Predictive analysis', 'Machine Learning', 'Data Mining (Computing)', 'Data Science', 'National High School Exam (Brazil)')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/9205","2020-08-18","https://www.repositorio.ufal.br/bitstream/123456789/9205/3/Desenvolvimento%20de%20modelos%20para%20estimar%20principais%20caracter%c3%adsticas%20socioecon%c3%b4micas%20para%20as%20notas%20de%20reda%c3%a7%c3%a3o%20e%20matem%c3%a1tica%20para%20ENEM%202018.pdf","",""
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/10200","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Uma abordagem de fusão de dados multisensores em dispositivos IoT para jogos sérios","('Erivaldo Lourenço Mariano',)","('Rafael de Amorim Silva',)","('Ranilson Oscar Araújo Paiva', 'Bruno Almeida Pimentel')","Este trabalho apresenta uma abordagem de fusão de sensores no âmbito dos jogos sérios e Internet das Coisas. Para tal, buscou-se usar sensores importantes que estão presentes em um smartphone (acelerômetro e giroscópio). Foi criado um app que captura os dados destes sensores no smartphone. A metodologia é dividida em: entrada, processamento e resultado. Na entrada, o usuário simula o movimento de uma jogada de tênis, os dados do giroscópio e acelerômetro são armazenados em um arquivo com layout pré-definido, estes dados são usados na etapa de processamento. Durante o processamento, o arquivo com os dados dos sensores é processado, retirando informações desnecessárias e é executado a fusão das informações dos sensores, por um filtro complementar, e as informações de dois sensores se tornam uma. Nos resultados, os dados do movimento do usuário são submetidos a um classificador KNN que já tem uma base com movimentos da jogada de profissionais, e é feita uma classificação para cada ponto gerado. Em seguida, uma estimativa da proximidade do movimento do usuário amador para o profissional é apresentada.","This work presents a sensor fusion approach in the realm of serious games and internet of things. For this I tried to use important sensors that are present in a smartphone (accelerometer and gyroscope). For this, an app was created that captures the data of these sensors on the smartphone. The methodology is divided into: input, processing and result. At the entrance, the user simulates the movement of a tennis move, the data from the gyroscope and accelerometer are stored in a file with a predefined layout, these data are used in the processing step. During processing, the file with the sensor data is processed, removing unnecessary information and the sensor information is merged by a complementary filter, and the information from two sensors becomes one. In the results, the user’s movement data is submitted to a KNN classifier that already has a base with professional movement movements, and a classification is made for each point generated. Then, an estimate of the proximity of the movement of the amateur user to the professional is presented.","('Fusão de sensores', 'Jogos sérios', 'Internet das coisas', 'Sensor Fusion', 'Serius Games', 'Internet of Things')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/10200","2020-06-29","https://www.repositorio.ufal.br/bitstream/123456789/10200/1/Uma%20abordagem%20de%20fus%c3%a3o%20de%20dados%20multisensores%20em%20dispositivos%20IoT%20para%20jogos%20s%c3%a9rios.pdf","",""
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/8155","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Acessibilidade de portais web para pessoas com deficiência visual: o caso do Portal de Arquitetura Alagoana","('Juliana de Carvalho Cavalcanti',)","('Fábio José Coutinho da Silva',)","('Roberta Vilhena Vieira Lopes', 'Patrick Henrique da Silva Brito')","Quase tudo que fazemos diariamente depende da nossa visão, do contato visual com uma pessoa ou objeto. De acordo com Kim et al. (2016), estima-se que no mundo inteiro mais de 285 milhões de pessoas possuem algum tipo de deficiência visual e, dentre elas, 39 milhões são cegas. Pesquisas como a realizada pela instituição Movimento Web para Todos–MWPT em parceria com a BigData Corp (CORP. (2019)) evidenciam o problema da falta de acessibilidade em sites brasileiros. O estudo desenvolvido avaliou o nível de acessibilidade de cerca de 14 milhões de sites brasileiros ativos, apontando que 99% dos sites estudados apresentaram erros nas verificações realizadas. Um outro estudo, desenvolvido por Acosta-Vargas et al. (2016), analisou a acessibilidade do conteúdo dos websites das 20 melhores universidades do mundo e constatou que a maioria deles não está em conformidade com os padrões de acessibilidade. Diante dessa necessidade, este trabalho tem como objetivo analisar o website chamado Portal de Arquitetura Alagoana e apontar quais as principais lacunas existentes que impedem a experiência completa por parte do público alvo deste trabalho, para que então seja possível refatorá-lo de forma que ele fique acessível para este público. O Portal de Arquitetura Alagoana é um projeto com objetivo de fornecer uma educação patrimonial com interesse histórico. Sendo assim, para a solução do problema foi feito um estudo de recursos e ferramentas disponíveis para pessoas cegas; pesquisas e entrevistas com usuários cegos visando coletar dados sobre suas necessidades e experiências no uso de sites e aplicativos; um estudo das diretrizes de acessibilidade WCAG 2.1 do consórcioW3C, identificando quais são destinadas à acessibilidade das pessoas cegas; utilização de um verificador de acessibilidade automático para testar as páginas do portal; especificação e implementação de requisitos para melhorar a acessibilidade do mesmo. Em seguida, foi utilizado o verificador novamente depois de realizar as devidas mudanças e, por último, foi realizado um teste de usabilidade com usuários cegos para aferir o nível de acessibilidade do portal. Antes de implementar os requisitos especificados, a média das notas emitidas pelo verificador nas páginas do portal foi 7,67. Depois de aplicar as correções necessárias e fazendo uma segunda avaliação como mesmo verificador, a média de notas apresentadas foi 9,97. Já com relação ao teste de usabilidade aplicado, verificou-se que pelo menos 60% dos usuários acharam as tarefas neutras, fáceis ou muito fáceis de serem realizadas, chegando até em 90% em determinadas tarefas. De modo geral, o resultado obtido foi satisfatório, visto que o feedback recebido refletiu que a implementação dos requisitos especificados contribuiu para elevar o nível de acessibilidade do Portal de Arquitetura Alagoana.","Almost everything we do daily depends on our vision, on eye contact with a person or object. According to Kim et al. (2016), it is estimated that more than 285 million people worldwide have some type of visual impairment and, among them, 39 million are blind. Researches such as that carried out by the Movimento Web para Todos institution – MWPT, in partnership with BigData Corp, (CORP. (2019)) highlight the problem of the lack of accessibility on Brazilian websites. The developed study evaluated the accessibility level of about 14 million active Brazilian sites, pointing out that 99% of the studied sites had errors in their evaluation. Another study, developed by Acosta-Vargas et al. (2016), analyzed the accessibility of the contents concerning the websites of 20 universities from all around the world and found that most of them do not comply with accessibility standards. Given this need, this work aims to analyze the website called Portal de Arquitetura Alagoana and point out the main existing gaps that prevent the complete experience on the part of this work’s target audience, so that it’s possible to refactor it andmade it accessible to this audience. The Portal de Arquitetura Alagoana is a project with the objective of providing patrimonial education with historical interest. Thus, to solve the problem, a study of resources and tools available to blind people was made; surveys and interviews with blind users in order to collect data about their needs and experiences in the use of websites and applications; a study of the W3C consortium’s accessibility guidelines, identifying which ones are intended for the accessibility of blind people; use of an automatic accessibility checker to test the portal pages; specification and implementation of requirements to improve accessibility. Then, the verifier was used again after making the necessary changes and, lastly, a usability test was carried out with blind users to measure the accessibility level of the portal. Before implementing the specified requirements, the average of the scores issued by the verifier on the portal pages was 7.67. After applying the necessary corrections and making a second assessment with the same verifier, the average of the scores presented was 9.97. Regarding the usability test applied, it was found that at least 60% of users found the tasks neutral, easy or very easy to be performed, reaching up to 90% in certain tasks. In general, the result obtained was satisfactory, since the feedback received reflected that the implementation of the specified requirements contributed to raising the level of accessibility of the Portal de Arquitetura Alagoana.","('Portal de Arquitetura Alagoana', 'Tecnologia assistiva', 'Acessibilidade para cegos', 'Assistive technology,', 'Accessibility for blind people')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/8155","2020-08-18","https://www.repositorio.ufal.br/bitstream/123456789/8155/3/Acessibilidade%20de%20portais%20web%20para%20pessoas%20com%20defici%c3%aancia%20visual%3a%20o%20caso%20do%20Portal%20de%20Arquitetura%20Alagoana.pdf","Accessibility of web portals for people with visual impairments: the case of Portal de Arquitetura Alagoana","('Floripes Teixeira Santos',)"
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/10561","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Uma aplicação do aprendizado por transferência na detecção de Code Smells","('André Moabson da Silva Ramos',)","('Baldoíno Fonseca dos Santos Neto',)","('Ícaro Bezerra Queiroz de Araújo', 'Rafael Maiani de Mello')","Durante o desenvolvimento de um software, a presença de code smells tem sido relacionada com a degradação na qualidade do software. Diversos estudos mostram a importância de detectar os smells no código fonte e aplicar refatoração. No entanto, as abordagens existentes para a detecção de code smells são limitadas para determinadas linguagens de programação. Nesse contexto, este trabalho visa ampliar os métodos para detecção de code smells utilizando o aprendizado por transferência para construir um grande conjunto de dados para treinamento e validação dos modelos de aprendizagem de máquina, utilizando as regras catalogadas e thresholds extraídos da ferramenta Designite. Coletando, assim, um total 22.687, 8.501 e 5.953 smells detectados em projetos das respectivas linguagens de programação, C++, Java e C#. Em seguida, nós obtivemos 72 modelos pré-treinados, e realizamos o aprendizado por transferência, que consistiu em avaliar o modelo pré-treinado para smells no conjunto de dados entre linguagens de programação. Nossos resultados revelaram que se escolhermos o smell de design, Unecessary Abstraction, e a linguagem alvo for C#, então o modelo mais apropriado para detectar esse code smell é o baseado no RandomForest, pois foi melhor dentre os outros modelos treinados no conjunto de dados da linguagem C++ para o mesmo smell. Esses resultados podem ajudar a desenvolvedores e pesquisadores a aplicar as mesmas estratégias de detecção de code smells em diferentes linguagens de programação, e utilizar modelos de treinamentos que sejam mais apropriados para cada tipo de code smell e linguagens de programação.","During the software development, the presence of code smells has been related to the degradation of the software quality. Several studies present the relevance to detect smells in the source code and to apply refactoring. However, the existing approaches to detect code smells are limited to specific programming languages. In this context, this work aims to extend the techniques of code smell detection using learning transfer to build a large dataset for training and validation of machine learning models, using cataloged rules and extracted thresholds of the Designite tool. Collecting, then, a total of total 22,687, 8,501 e 5,953 detected smells in software projects of the respective programming languages, C++, Java e C#. In a sequence, we obtained 72 pretrained models and performed the transfer learning to evaluate the pre-trained model for smells in the dataset between programming languages. Our results revealed that the model RandomForest is the most appropriate to detect code smells like the Unecessary Abstraction design smell for the C# programming language. These results can help developers and researchers to apply the same code smell detection strategies for different programming languages and to apply the most appropriate training models for each code smell type and programming language.","('Code smells -Detecção', 'Aprendizagem de máquina', 'Aprendizagem por transferência', 'Code smells', 'Detection', 'Transfer learning', 'Machine learning')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/10561","2021-03-02","https://www.repositorio.ufal.br/bitstream/123456789/10561/1/Uma%20aplica%c3%a7%c3%a3o%20do%20aprendizado%20por%20transfer%c3%aancia%20na%20detec%c3%a7%c3%a3o%20de%20Code%20Smells.pdf","","('Ana Carla Gomes Bibiano',)"
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/10476","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Análises de competições presentes na Plataforma Kaggle para auxiliar no desenvolvimento de novas soluções para problemas de visão computacional","('Daniel Humberto Cavalcante Vassalo',)","('Rodrigo de Barros Paes',)","('Tiago Figueiredo Vieira', 'Bruno Georgevich Ferreira')","Este trabalho visa analisar e discutir os dados coletados sobre problemas de visão computacional e suas melhores soluções encontradas na plataforma Kaggle. O objetivo destas discussões é tentar entender quais são as abordagens mais utilizadas em certos tipos de problemas e porquê elas são mais recorrentes do que outras. Para isso, antes do desenvolvimento desta monografia foi feito um trabalho de pesquisa para coletar os dados referentes às características de algumas competições de visão computacional presentes na plataforma Kaggle. Para este trabalho foram levantados questionamentos acerca do desenvolvimento de novas soluções para problemas de visão computacional. Cada questionamento foi amplamente discutido e embasado com análises sobre os dados coletados na pesquisa e conceitos presentes na literatura. Por fim, concluiu-se a importância da análise de soluções já existentes para auxiliar na discussão de certas etapas do desenvolvimento de soluções de novos problemas.","This work aims to analyze and discuss previously collected data regarding computer vision problems and their best solutions on the Kaggle platform. The purpose of these discussions was to try to understand what are the most used approaches in some types of problems and why they are used more often than others. To accomplish that, before the development of this monography, a research project was carried out to collect data about the main characteristics of some computer vision competitions on Kaggle’s platform. For this work, relevant questions were raised about the development of new solutions to computer vision problems. Each question was widely discussed and substantiated with an analysis of the data collected in the research project and concepts found in the literature. Finally, it concludes the importance of the analysis of existing solutions to assist in the discussion of certain steps of the process of development of solutions to new problems.","('Aprendizagem de Máquina', 'Visão Computacional', 'Ciência de Dados', 'Plataforma Kaggle', 'Machine learning', 'Computer vision', 'Data science', 'Kaggle')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/10476","2021-03-22","https://www.repositorio.ufal.br/bitstream/123456789/10476/1/An%c3%a1lises%20de%20competi%c3%a7%c3%b5es%20presentes%20na%20Plataforma%20Kaggle%20para%20auxiliar%20no%20%20desenvolvimento%20de%20novas%20solu%c3%a7%c3%b5es%20para%20problemas%20de%20vis%c3%a3o%20computacional.pdf","Analysis of Competitions from Kaggle's Platform to assist in the development of future solutions to computer vision problems","('Willy Carvalho Tiengo',)"
"Sistema de Informação","https://www.repositorio.ufal.br/handle/123456789/10078","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Sistemas de informação e gestão do conhecimento: uma revisão bibliográfica dos ambientes virtuais de aprendizagem","('Tahinan Wilena Barbosa Araújo',)","('Natallya de Almeida Levino',)","('Ibsen Mateus Bittencourt Santana Pinto', 'Petrúcio Antônio Medeiros Barros')","Os crescentes avanços tecnológicos e o processo de globalização da economia, cultura, conhecimento e informação têm permitido que novos recursos e tecnologias se aperfeiçoem para incentivar a construção de novas formas e práticas de ensino. O objetivo deste trabalho é analisar a importância dos sistemas de informação e de gestão do conhecimento nos Ambientes Virtuais de Aprendizagem (AVA). Para isso, foi realizada uma revisão sistemática da literatura, nos principais periódicos nacionais nos anos de 1997 a 2019. Verificou-se que as mudanças nos processos de ensino, durante as últimas décadas, causadas pela revolução tecnológica e pela chamada Sociedade do Conhecimento têm incentivado a aplicação de tecnologias de informação e comunicação como instrumentos de aprimoramento do processo de ensino/aprendizagem, assim, novas possibilidades de ensino a distância podem ser consideradas, até mesmo como estratégias de suporte para a educação presencial. No entanto, o uso de recursos tecnológicos não garante a aprendizagem dos alunos, o que exige o incentivo, interação e interlocução entre aprendizes e docentes. Nesse contexto, entende-se que é necessário fornecer ferramentas aos aprendizes para que eles consigam articular seu conhecimento prévio com as informações adquiridas durante o processo e, ao mesmo tempo, se aproximar dos saberes e de outros indivíduos.","The growing technological advances and the globalization process of economy, culture, knowledge, and information have allowed new resources and technologies to be improved to encourage the construction of new forms and practices of teaching. The objective of this paper is to analyze the importance of information and knowledge management systems in Virtual Learning Environments (VLE). For this, a systematic literature review was conducted in the main national journals in the years 1997 to 2019. It was verified that the changes in the teaching processes, during the last decades, caused by the technological revolution and the socalled Knowledge Society have encouraged the application of information and communication technologies as instruments for the improvement of the teaching/learning process, thus, new possibilities of distance education can be considered, even as support strategies for face-to-face education. However, the use of technological resources does not guarantee student learning, which requires encouragement, interaction, and interlocution between learners and teachers. In this context, it is understood that it is necessary to provide tools to learners so that they can articulate their prior knowledge with the information acquired during the process and, at the same time, get closer to the knowledge and other individuals.","('Sistemas de informação', 'Gestão do conhecimento', 'Ambientes virtuais de aprendizagem', 'Knowledge Management', 'Information Systems', 'Virtual Learning Environments', 'VLE')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/10078","2021-03-10","https://www.repositorio.ufal.br/bitstream/123456789/10078/1/Sistemas%20de%20informa%c3%a7%c3%a3o%20e%20gest%c3%a3o%20do%20conhecimento%20-%20uma%20revis%c3%a3o%20bibliogr%c3%a1fica%20dos%20ambientes%20virtuais%20de%20aprendizagem.pdf","",""
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/9772","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","An empirical study on the frequency of disciplined and undisciplined annotations in preprocessor –based systems in C and C++","('José Carlos Viana Filho',)","('Márcio de Medeiros Ribeiro',)","('Baldoíno Fonseca dos Santos Neto', 'Thiago Damasceno Cordeiro')","As linguagens de programação C e C++ permitem uma ferramenta de preprocessador para escrever anotações condicionais. Comunidades de software relevantes tais como Linux e Apache tem usado anotações condicionais em seus projetos. No entanto, desenvolvedores escrevem estas anotações condicionais de uma forma indisciplinada muitas vezes. A aplicação de anotações condicionais indisciplinadas ou anotações indisciplinadas pode ter um efeito negativo sobre a legibilidade do código e o aumento da propensão de erros. Ao longo desses últimos 10 anos, estudos empíricos tem investigado como o uso de anotações indisciplinada tem afetado a qualidade do software e como disciplinar essas anotações. Uma estratégia proposta para resolver anotações indisciplinadas é aplicar refatorações. Refatoração é uma transformação de código que almeja melhorar a qualidade do código preservando o comportamento do programa. No contexto de anotações disciplinadas, uma refatoração almeja disciplinar uma anotação indisciplinada. No entanto, não existem evidências empíricas sobre até que ponto o número de anotações disciplinadas tem aumentado e/ou diminuído ao longo desses últimos dez anos. Principalmente, se desenvolvedores aplicam refatorações sobre anotações disciplinadas e se essas refatorações disciplinam essas anotações. Baseado nessas limitações da literatura, esse estudo almeja verifica se a frequência de anotações indisciplinadas e disciplinadas ao longo desses últimos dez anos, e se desenvolvedores aplicam refatorações sobre anotações indisciplinadas na prática. Nós investigamos 23 projetos de software que foram investigados dez anos atrás sobre anotações indisciplinadas. Nossos resultados apresentam que somente 10 projetos de sobre tiveram um aumento significativo no número de anotações disciplinadas nesses últimos dez anos, nós também apresentamos 19 refatorações que foram aplicadas na prática. Nós observamos que desenvolvedores refatoram não sobre anotações disciplinadas, mas também anotações indisciplinadas. Esses resultados podem motivar estudos futuros para investigar se contribuições e recomendações de refatorações existentes tem ajudado desenvolvedores para disciplinar anotações ou se os desenvolvedores tem usado o conhecimento empírico existente para resolver anotações disciplinadas.","The C and C++ programming languages allow a preprocessor tool to write conditional annotations. Relevant software communities such as Linux and Apache have used conditional annotations in their software projects. However, developers write these conditional annotations in an undisciplined way. The application of undisciplined conditional annotations or undisciplined annotations can have a negative effect on code readability and increasing the error proneness. Over the last ten years, empirical studies have investigated how the use of undisciplined annotations can affect the software quality and how to discipline these annotations. A proposed strategy to solve undisciplined annotation is to apply refactorings. Refactoring is a code transformation that aims to improve the code quality, preserving the program behavior. In the context of undisciplined annotations, one refactoring aims to discipline it. However, there is no empirical evidence on to what extent the number of disciplined annotations increased and/or decreased over the last ten years. Mainly, if developers applied refactorings on undisciplined annotations and these refactorings disciplined these annotations. Based on those literature limitations, our study aims to verify if the frequency of disciplined and undisciplined annotations during the last ten years, if developers apply refactorings on undisciplined annotations in the practice. We investigated 23 software projects that were investigated ten years ago on undisciplined annotations. Our results presented that only ten software projects had an increase in the number of disciplined annotations over the last ten years, and we presented 19 refactorings that were applied in practice. We observed that developers refactor not only undisciplined annotations but also disciplined ones. These results can motivate future studies to investigate if existing findings and recommendations of refactorings have helped developers to discipline annotations or if developers have used the existing empirical knowledge to solve undisciplined annotations.","('C e C++ (linguagens de computador)', 'Software', 'Refatoração', 'Anotações Condicionais', 'Conditional Annotations', 'Disciplined Annotations', 'Undisciplined Annotations', 'Refactoring', 'Mining Software Repositories')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/9772","2021-10-01","https://www.repositorio.ufal.br/bitstream/123456789/9772/1/An%20empirical%20study%20on%20the%20frequency%20of%20disciplined%20and%20undisciplined%20annotations%20in%20preprocessor%20%e2%80%93based%20systems%20in%20C%20and%20C%2b%2b.pdf","","('Ana Carla Gomes Bibiano',)"
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/12125","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Um algoritmo genético auto adaptável pela fuzzificação da taxa de mutação","('João Victor Ribeiro Ferro',)","('Roberta Vilhena Vieira Lopes',)","('Evandro de Barros Costa', 'Andrilene Ferreira Maciel')","Neste trabalho será apresentado uma variação de um algoritmo genético de Holland para o problema de otimização com o foco no ajuste do parâmetro da taxa de mutação por meio da fuzzificação da diversidade da população e do valor da adaptação do indivíduo e, em paralelo, compreender como é o comportamento dos métodos de seleção e substituição. Uma vez que esses parâmetros interferem diretamente na convergência e na qualidade da solução encontrada pelo algoritmo genético. Para avaliar o desempenho do algoritmo proposto foram realizados experimentos com problema de otimização combinatorial, em que foram analisados a convergência, a qualidade da solução encontrada, a diversidade da população e o número de indivíduos avaliados.","In this work, a variation of Holland's genetic algorithm will be presented for the optimization problem, focusing on the adjustment of the mutation rate parameter, by means of the population diversity and the adaptation value of the individual and, in parallel, understanding how the selection and substitution methods behave. Since these parameters directly interfere with the convergence and quality of the solution found by the genetic algorithm. To evaluate the performance of the proposed algorithm, experiments were conducted with combinatorial optimization problems, in which the convergence, the quality of the solution found,","('Algoritmos genéticos -Taxa de mutação', 'Algoritmos genéticos -Seleção', 'Algoritmos genéticos -Substituição', 'Lógica difusa', 'Genetic algorithm -Selection', 'Mutation rate', 'Fuzzy logic', 'Substitution')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/12125","2022-07-14","https://www.repositorio.ufal.br/bitstream/123456789/12125/1/Um%20algoritmo%20gen%c3%a9tico%20auto%20adapt%c3%a1vel%20pela%20fuzzifica%c3%a7%c3%a3o%20da%20taxa%20de%20muta%c3%a7%c3%a3o.pdf","A Self-adaptive genetic algorithm by mutation rate fuzzification",""
"Ciências da Computação","https://www.repositorio.ufal.br/handle/123456789/9798","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Uma abordagem para extrair relatos de agressões contra mulheres no Twitter e enquadrar na Lei Maria da Penha","('Júlia Albuquerque Aguiar',)","('André Lages Freitas',)","('Mônica de Sá Dantas Paz', 'Pablo Bravo Hurtado')","A violência de gênero é uma violência de repetição que causa não só danos físicos, mas também psicológicos a uma quantidade razoável de mulheres ao redor do mundo. No Brasil, a Lei Maria da Penha, com seus 15 anos de existência, continua sendo um símbolo nacional de luta contra a violência de gênero e acumula milhões de processos na justiça. Com a pandemia da COVID-19, aumentou-se consideravelmente a quantidade de casos de violência devido ao isolamento social e à carência de projetos de apoio a este público. Como um canal alternativo às mídias tradicionais de conteúdo, as redes sociais deram voz às mulheres nesta busca por justiça e criaram frentes de discussões sobre uma possível modernização da aplicação da legislação brasileira. Por exemplo, a literatura da área de Ciências Sociais fala sobre conceitos importantes como tecnopolítica, ciberfeminismo e ciberespaço e também traz um debate essencial sobre teoria do afeto nas redes sociais. Já outros trabalhos analisam manifestações online como o movimento #MeToo, “Não mereço ser estuprada” e dezenas de outras hashtags que viralizaram nas mídias sociais, e para além desta análise, estudam formas de classificações destes relatos. O objetivo do nosso trabalho é investigar se os relatos de violência doméstica postadas em redes sociais podem ser enquadrados na Lei Maria da Penha assim como analisar a frequência nesses relatos dos tipos de violência descritos na Lei Maria da Penha. Assim, desenvolvemos uma metodologia para a coleta de relatos de redes sociais e classificação dos relatos de acordo com os cinco tipos de violência doméstica descritos na Lei Maria da Penha: Moral, Sexual, Psicológica, Física e Patrimonial. Essa metodologia foi validada através da implementação de um protótipo de pesquisa que automatiza toda a abordagem proposta. Esse protótipo, que foi implementado na linguagem de programação Python, utiliza técnicas de Aprendizado de Máquina e Processamento de Linguagem Natural. Utilizamos o protótipo desenvolvido para coletar e analisar dados do Twitter. Percebemos que o tipo de violência contra mulher que apareceu com mais frequência nesses relatos é a Violência Moral, seguida da Violência Sexual. Assim, validamos parcialmente nossa hipótese de pesquisa que afirmava que a maioria dos relatos seriam de Violência Sexual. Uma consequência importante dessa conclusão é sobre a atenção que deve ser dada também às violências não físicas contra mulher. Por fim, a abordagem proposta neste trabalho oferece um arcabouço para o auxílio à elaboração, fiscalização e fomento de políticas públicas para o combate à violência de gênero. Ou seja, instituições privadas ou o próprio Poder Público – seja através do Executivo, Legislativo, Judiciário, Ministério Público ou Defensoria Pública – podem utilizar o conceito ou a tecnologia propostos neste trabalho para combater as agressões contra mulheres.","Gender violence is a repeated violence that causes both physical and psychological damages in a fair amount of women around the world. In Brazil the Maria da Penha law through its 15 years of existence remains a national symbol in the fight against gender violence and accumulates millions of lawsuits at court. The COVID-19 pandemic increased considerably the number of violent cases in social isolation and there is a lack of support projects for this group. As an alternative channel to traditional media, the social networks gave women voice in this search for justice and created various research groups who are approaching possible law enforcement from innovative perspectives. For instance, literature in this field highlights key concepts as technopolitics, cyberfeminism, cyberspace and also brings into discussion the theory about the affect of social networks. Other projects analyze online movements such as #MeToo movement, “Não mereço ser estuprada” and dozens of other hashtags that went viral on social media and study ways about how to classify these reports. The goal of our project is to investigate if the reporting of aggression posted on social networks can be covered by Maria da Penha law and to analyze the frequency which type of violence described in the Maria da Penha law. So we developed a methodology to collect posts from social networks and classify them according to the five types of domestic violence covered by Maria da Penha law, i.e., Moral, Sexual, Psychological, Physical, and Property. We validated this methodology by implementing a working prototype that automates the overall proposed approach and takes advantage of Artificial Intelligence and Natural Language Processing techniques. This prototype is implemented in Python programming language and uses the social network Twitter. Moreover, we used the prototype to collect posts from Twitter and concluded that moral violence is the most common type of violence against women followed by sexual violence So, our research hypothesis was partially validated as we had assumed that most posts would refer to sexual violence. An important consequence of this conclusion is that we must also pay attention to non-physical violence against women. In conclusion, the approach proposed here provides a framework for elaboration, supervision, and promotion of public policy for the fight against gender violence. In other words, private institutions or Public Power -whether through the Executive, Legislative, Judicial, Public Ministry or Public Defenders -may use the concept or the technology proposed in this work to fight against gender violence.","('Twitter (Rede social on-line)', 'Violência contra as mulheres', 'Violência doméstica', 'Brasil. Lei n. 11.340, de 7 de agosto de 2006', 'Processamento de linguagem natural (Computação)', 'Direito', 'Aprendizado do computador', 'Inteligência artificial')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/9798","2021-09-30","https://www.repositorio.ufal.br/bitstream/123456789/9798/1/Uma%20abordagem%20para%20extrair%20relatos%20de%20agress%c3%b5es%20contra%20mulheres%20no%20Twitter%20e%20enquadrar%20na%20Lei%20Maria%20da%20Penha.pdf","An approach for extracting violence reports against women from Twitter and frame into Maria da Penha law",""
"Sistema de Informação","https://www.repositorio.ufal.br/handle/123456789/9668","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Uma proposta de sistema de informação para apoiar a compra de material didático para escolas da rede municipal de Olivença – AL","('Marcelo Ferreira Siqueira',)","('Ranilson Oscar Araújo Paiva',)","('Diego Dermeval de Medeiros da Cunha Matos', 'Rafael de Amorim Silva')","Devido à dificuldade encontrada no processo de compra e reposição de material escolar na cidade de Olivença/AL, das escolas públicas da Zona Urbana e Rural, é gerado desperdício de tempo dos funcionários públicos na Secretaria Municipal de Educação do município, de professores, diretores e secretários. O presente documento, com base em entrevistas e estudos observatórios realizados em campo real, propõe melhorias no processo de compra e reposição de materiais, custos e tempo, através de uma proposta pautada a utilização de um Sistema da Informação desenvolvido para a situação, minimizando a ocorrência de erros e garantindo agilidade no processo. Processos manuais na administração pública podem ser motivos de prejuízos financeiros e de tempo, e os Sistemas de Informações são ferramentas importantes para auxiliar no processamento de dados, gerando informações fundamentais para administradores. Este trabalho por sua vez, apresentará os benefícios de um sistema da informação e apresentará o sistema proposto para a compra de material letivo.","Due to the difficulty encountered in the process of buying and replacing school supplies in the city of Olivença/AL, public schools in urban and Rural areas, it is generated waste of time of public officials in the Municipal secretariat of Education of the municipality, Teachers, directors and secretaries. This document, based on interviews and observational studies conducted in the real field, proposes improvements in the process of buying and replenishing materials, costs and time, through a proposal based on the use of an information system developed To the situation, minimizing the occurrence of errors and ensuring agility in the process. Manual processes in public administration may be reasons for financial and time losses, and information systems are important tools to assist in data processing, generating key information for administrators. This work in turn will present the benefits of an information system and will present the proposed system for the purchase of school material.","('Sistemas de informação', 'Tecnologia', 'Gestão pública', 'Apoio à tomada de decisões', 'Information system', 'Administration', 'Technology')","Sistemas de Informação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/9668","2019-10-09","https://www.repositorio.ufal.br/bitstream/123456789/9668/1/Uma%20proposta%20de%20sistema%20de%20informa%c3%a7%c3%a3o%20para%20apoiar%20a%20compra%20de%20material%20did%c3%a1tico%20para%20escolas%20da%20rede%20municipal%20de%20Oliven%c3%a7a%20%e2%80%93%20AL.pdf","","('Randerson Douglas Ribeiro dos Santos',)"
"Sistema de Informação","https://www.repositorio.ufal.br/handle/123456789/9710","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Monitoramento de temperatura e umidade em racks simples de telecomunicação com plataforma arduino","('Washington Júnior Ferreira',)","('Lucas Benevides Viana de Amorim',)","('Petrúcio Antônio Medeiros Barros', 'Almir Pereira Guimarães', 'Everton Cleiton de Oliveira')","Os racks de telecomunicações, onde são instalados os equipamentos de rede, na maioria das vezes ficam isolados em salas sem circulação de pessoas, e estão sujeitos a sofrer as mais diversas variações de temperatura e humidade, fazendo com que, de acordo com os manuais dos fabricantes, a vida útil desses equipamentos possivelmente seja reduzida, e consequentemente, dependendo do grau dessa variação, pode prejudicar os serviços de rede (internet e intranet) que dependem desses aparelhos. Foi vivenciando uma dessas variações de umidade, que danificou um switch, parando alguns serviços web de um hospital, a partir daí surgiu a ideia para resolução desse problema. O trabalho apresentado descreveu os passos executados para a construção de uma solução de baixo custo para o monitoramento de temperatura e umidade, direcionada para as pequenas empresas ou instituições que não dispõem de um capital financeiro mais elevado, para compra de uma solução mais robusta. Utilizou-se como base o Arduino, que é uma plataforma open-source de prototipagem eletrônica com hardware e software flexíveis e fáceis de usar, juntamente com um sensor e um shield ethernet. A solução foi testada em um ambiente de produção, instalada num rack simples de telecomunicação. O monitoramento foi feito através do software Zabbix, que é uma ferramenta de monitoramento distribuído e Open Source, que recebeu e armazenou as informações, gerando alertas aos usuários quando uma destas grandezas ultrapassou os limites estabelecidos, desta forma, assistindo o ambiente monitorado e observando se as condições do ambiente estão adequadas para o bom funcionamento dos equipamentos instalados no rack. Ao final do teste no ambiente de produção, a solução mostrou-se eficiente, cumprindo o objetivo do projeto, que seria uma solução barata e eficaz, desenvolvida valendo-se dos conceitos e tecnologias da plataforma Arduino.","Telecommunications racks, where network equipment is installed, are most often isolated in rooms with no circulation of people, and are subject to the most diverse variations in temperature and humidity, making it, according to the user manuals. manufacturers, the useful life of this equipment is likely to be reduced, and consequently, depending on the degree of this variation, it may harm the network services (internet and intranet) that depend on these devices. It was experiencing one of these humidity variations, which damaged a switch, stopping some hospital web services, that's where the idea for solving this problem came from. The work presented described the steps taken to build a low-cost solution for monitoring temperature and humidity, aimed at small companies or institutions that do not have a higher financial capital, to purchase a more robust solution. Arduino was used as a base, which is an open-source electronic prototyping platform with flexible and easy to use hardware and software, together with a sensor and an ethernet shield. The solution was tested in a production environment, installed in a simple telecommunication rack. The monitoring was done through the Zabbix software, which is a distributed and Open Source monitoring tool, which received and stored the information, generating alerts to users when one of these quantities exceeded the established limits, thus, watching the monitored environment and observing if the environmental conditions are adequate for the proper functioning of the equipment installed in the rack. At the end of the test in the production environment, the solution proved to be efficient, fulfilling the objective of the project, which would be a cheap and effective solution, developed using the concepts and technologies of the Arduino platform.","('Arduino', 'Zabbix', 'Temperatura e Umidade', 'Rack', 'Temperature and Humidity')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/9710","2021-02-01","https://www.repositorio.ufal.br/bitstream/123456789/9710/1/Monitoramento%20de%20temperatura%20e%20umidade%20em%20racks%20simples%20de%20telecomunica%c3%a7%c3%a3o%20com%20plataforma%20arduino.pdf","Temperature and humidity monitoring in simple telecommunication racks with arduino platform",""
"Sistema de Informação","https://www.repositorio.ufal.br/handle/123456789/8934","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","O impacto das novas tecnologias sobre o mercado de trabalho no setor bancário brasileiro.","('William Nascimento da Oliveira',)","('Natallya de Almeida Levino',)","('Ibsen Mateus Bittencourt Santana Pinto', 'Cristiano da Silva Santos')","Em um contexto amplo, as novas tecnologias têm sido precursoras de transformações culturais, sociais e econômicas em toda a sociedade, inclusive possibilitando alterações que tem impactado diretamente o mercado de trabalho nas mais diversas áreas. Este trabalho busca analisar o impacto das novas tecnologias sobre o mercado de trabalho no setor bancário brasileiro. Assim, diante da observação da quantidade de postos de trabalho que ano após ano vem sendo suprimidas no setor bancário, surgiu o interesse para o desenvolvimento desta pesquisa, visando buscar uma relação entre os avanços tecnológicos vividos no setor bancário e o seu impacto no mercado de trabalho bancário, levando-se em consideração uma janela temporal de cinco anos. A metodologia utilizada neste trabalho é do tipo pesquisa bibliográfica com enfoque qualitativo e de natureza exploratória. Os dados aqui presentes foram coletados em diversas fontes, dente estes: Banco Central do Brasil (BACEN), da Federação Brasileiras de Bancos (FEBRABAN) e do Departamento Intersindical de Estatísticas e Estudos Socieconômicos (DIEESE), além de consultas a dados e informações disponibilizadas pelos bancos em seus relatórios anuais e/ou balanços financeiros. A partir da compilação destas informações, verificou-se que as funções relacionadas ao back office nos bancos tendem a ser esvaziadas, dando espaço a processos de automação baseados nas novas tecnologias recém-surgidas no setor, bem como mudança no perfil profissional dos bancários. Diante das observações e dados levantados no setor, verificou-se que o setor bancário vem passando por um processo de digitalização em decorrência do aumento concorrência da fintechs bem com pelo aparecimento de novas tecnologias, o que vem ocasionando redução de agências e postos de trabalho.","In a broad context, new technologies have been precursors of cultural, social and economic transformations across society, including enabling changes that have directly impacted the labor market in the most diverse areas. This paper seeks to analyze the impact of new technologies on the labor market in the Brazilian banking sector. Thus, in view of the observation of the number of jobs that are being eliminated in the banking sector year after year, interest for the development of this research arose, aiming to search for a relationship between the technological advances experienced in the banking sector and its impact on the banking market. banking work, taking into account a time window of five years. The methodology used in this work is of the type bibliographic research with qualitative focus and exploratory nature. The data presented here were collected from several sources, including: Banco Central do Brasil (BACEN), Federação Brasileira de Bancos (FEBRABAN) and the Departamento Intersindical de Estatísticas e Estudos Socieconômicos (DIEESE), in addition to consultations with data and information made available banks in their annual reports and / or financial statements. From the compilation of this information, it was found that the functions related to the back office in banks tend to be emptied, giving space to automation processes based on new technologies newly emerged in the sector, as well as change the professional profile of bank employees. In view of the magazines and data collected in the sector, it was found that the banking sector has been going through a process of digitization due to the increase in competition from fintechs as well as the appearance of new technologies, which has been causing a reduction in branches and jobs.","('Bancos – Automação', 'Bancários', 'Tecnologias', 'Mercado de trabalho', 'Desemprego', 'Fintechs', 'PIX', 'Open banking', 'Banks', 'Bank Officer', 'Technologies', 'Unemployment', 'Labor Market')","Sistemas de Informação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/8934","2020-09-23","https://www.repositorio.ufal.br/bitstream/123456789/8934/1/O%20impacto%20das%20novas%20tecnologias%20sobre%20o%20mercado%20de%20trabalho%20no%20setor%20bancario%20brasileiro.pdf","",""
"Sistema de Informação","https://www.repositorio.ufal.br/handle/123456789/8719","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Uma proposta metodológica simplificada de implantação do Lean Six Sigma em pequenas e médias empresas","('Jadson Sousa da Silva',)","('Petrúcio Antônio Medeiros Barros',)","('Wanderson Rubian Martins Rodrigues', 'Olival de Gusmão Freitas Júnior')","O presente estudo teve como objetivo propor uma proposta metodológica simplificada de implantação do Lean Six Sigma para pequenas e médias empresas. Trata-se de uma pesquisa descritiva e quantitativa, onde para levantamento dos dados utilizou-se a pesquisa bibliográfica. O Lean Six Sigma integra a metodologia do Lean Manufacturing com as técnicas utilizadas no Six Sigma, utilizando os pontos fortes de cada metodologia para juntos, atingirem melhores resultados do que se forem implantados individualmente. Os benefícios do Lean Six Sigma incluem a remoção de etapas sem valor agregado, redução do custo de baixa qualidade, diminuir o tempo do ciclo e entrega do produto. A implantação do Lean Six Sigma deve seguir uma metodologia, o qual envolve a identificação dos processos a serem melhorados, a descrição e classificação desses processos, estabelecendo as prioridades de melhoria para os processos avaliados, o uso da metodologia DMAIC, a qual define o problema, mede as melhorias, analisa o que deve ser melhorado, apresenta a melhoria e, por fim, controla as melhorias que serão implementadas. Através de um roteiro, como o sugerido, as empresas podem utilizar o LSS em seus processos para minimizar perdas e melhorar seus processos, atingindo assim, melhores resultados organizacionais.","The present study aimed to propose a simplified methodological proposal for the implementation of Lean Six Sigma for small and medium-sized companies. It is a descriptive and quantitative research, where for data collection we used the bibliographic research. Lean Six Sigma integrates the Lean Manufacturing methodology with the techniques used in Six Sigma, using the strengths of each methodology to achieve better results together than if they were implemented individually. The benefits of Lean Six Sigma include removing steps with no added value, reducing low quality costs, shortening cycle times and delivering the product. The implementation of Lean Six Sigma must follow a methodology, which involves the identification of the processes to be improved, the description and classification of these processes, establishing the improvement priorities for the evaluated processes, the use of the DMAIC methodology, which defines the problem, measures improvements, analyzes what should be improved, presents the improvement and, finally, controls the improvements that will be implemented. Through a script, as suggested, companies can use LSS in their processes to minimize losses and improve their processes, thus achieving better organizational results.","('Pequenas e médias empresas', 'DMAIC -Metodologia', 'Lean Six Sigma', 'Lean manufacturing', 'Small and medium companies', 'DMAIC -Methodology')","Sistemas de Informação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/8719","2020-09-23","https://www.repositorio.ufal.br/bitstream/123456789/8719/3/Uma%20proposta%20metodol%c3%b3gica%20simplificada%20de%20implanta%c3%a7%c3%a3o%20do%20Lean%20Six%20Sigma%20em%20pequenas%20e%20m%c3%a9dias%20empresas.pdf","",""
"Sistema de Informação","https://www.repositorio.ufal.br/handle/123456789/12668","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","A gestão de TI em uma unidade hospitalar em tempos de Covid-19: estudo de caso em um hospital regional de Santana do Ipanema – Alagoas","('Mychel Silva Santos',)","('Olival de Gusmão Freitas Júnior',)","('Giseldo da Silva Néo', 'Arturo Hernández-Domínguez')","Diante da Covid-19, os processos de trabalho no setor de Tecnologia da Informação (TI) da unidade hospitalar regional em Santana do Ipanema, sofreram impactos consideráveis que possibilitaram a aplicação da gestão de processos para superá-los. Este trabalho tem como objetivo remodelar os processos de trabalho do setor de TI em uma unidade hospitalar, utilizando a modelagem de processos. Trata-se de uma pesquisa de cunho qualitativa com estudo de caso. No estudo foi identificado que o processo de utilização do sistema estava em um modo positivo e que durante a pandemia e após sua remodelagem trouxeram ganhos de eficiência, otimização de tempo bem como eliminando anomalias. Considerando os resultados apresentados, podemos afirmar que remodelagem de processos na unidade no setor de TI durante a pandemia se mostrou eficiente e contribuiu para uma gestão mais eficaz.","Given the Covid-19, the work processes in the Information Technology (IT) sector of the regional hospital unit in Santana do Ipanema, suffered considerable impacts that enabled the application of process management to overcome them. This work aims to remodel the work processes of the IT sector in a hospital unit, using process modeling. This is a qualitative research with a case study. In the study it was identified that the process of using the system was in a positive mode and that during the pandemic and after its remodeling brought gains in efficiency, time optimization as well as eliminating anomalies. Considering the results presented, we can state that remodeling processes in the unit in the IT sector during the pandemic proved to be efficient and contributed to a more effective management.","('Tecnologia da informação -Administração', 'Hospitais -Gestão da informação', 'COVID-19', 'Information technology -Administration', 'Hospitals -Information management')","Sistemas de Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/12668","2021-08-25","https://www.repositorio.ufal.br/bitstream/123456789/12668/1/A%20gest%c3%a3o%20de%20TI%20em%20uma%20unidade%20hospitalar%20em%20tempos%20de%20Covid-19%3a%20estudo%20de%20caso%20em%20um%20hospital%20regional%20de%20Santana%20do%20Ipanema%20%e2%80%93%20Alagoas.pdf","","('Wanderson Rubian Martins Rodrigues',)"
"Sistema de Informação","https://www.repositorio.ufal.br/handle/riufal/7763","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Otimização do desempenho de redes sem fio de pequeno porte: um estudo de caso baseado em redes domésticas e de pequenos negócios","('Paulo Gustavo de Amorim Leandro',)","('Almir Pereira Guimarães',)","('Marcus de Melo Braga', 'Petrúcio Antônio Medeiros Barros')","A utilização das redes sem fio passou a ser um elemento comum nos lares e também nos pequenos empreendimentos. Pesquisas demostram o crescimento continuo no uso desse modelo de rede. Aliado a isso, um número cada vez maior de dispositivos que utilizam diferentes tipos de conexões sem fio, tais como videogames, Smart TVs, Smartphones, vem surgindo nos últimos anos. Com esse cenário, aumentaram possibilidades de problemas, como aumento na densidade de canais, interferências e obstrução de sinais, comprometendo a qualidade das conexões das redes sem fio. Assim, administrar uma rede, mesmo em equipamentos aonde seu funcionamento não exige maior complexidade, pode tornar-se uma atividade complexa. Diante disso, esse trabalho tem o objetivo de prover orientações para configuração de redes sem fio de pequeno porte voltadas para utilização doméstica e de empresas de pequeno porte, em situações adversas para a instalação. Realizamos dois estudos de caso, numa rede sem fio doméstica e outra de um pequeno negócio. Através de diagnósticos, utilizando um aplicativo de monitoramento, detectamos os problemas e propusemos soluções a partir de pequenos ajustes em ambas configurações dos pontos de acesso dessas redes. Como resultado, observamos que as redes sem fio, apesar da existência de obstáculos físicos, são passiveis de serem otimizadas, melhorando a estabilidade e a potência dos sinais por meio das soluções aplicadas.","The use of wireless networks has become a common element in homes as well as in small businesses. Research shows the continued growth in the use of this network model. Allied to this, an increasing number of devices that use different types of wireless connection, such as video games, Smart TVs, Smartphones, have been emerging in recent years. With this scenario, greater possibilities of problems, such as increased channel density, interference and signal obstruction, compromising the quality of connections in wireless networks. Thus, managing a network, the same in equipment where its operation does not require greater complexity, it can become a complex activity. For this reason, this work aims to provide guidelines for configuring small wireless networks for home and small business use, in adverse situations for installation. We conducted two case studies, one on a home wireless network and one on a small business. Through diagnostics, using a monitoring application, we detected the problems and proposed solutions from minor adjustments to the access point settings of these networks. As a result, we observed that wireless networks, despite the existence of physical obstacles, are liable to be optimized, improving the stability and strength of the signals through the applied solutions.","('Redes sem fio', 'Ondas eletromagnéticas', 'IEEE 802.11', 'WPA2', 'Interferências', 'Wireless networks', 'Electromagnetic waves', 'Interference')","Sistemas de Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/7763","2020-02-19","https://www.repositorio.ufal.br/bitstream/riufal/7763/1/Otimiza%c3%a7%c3%a3o%20do%20desempenho%20de%20redes%20sem%20fio%20de%20pequeno%20porte%20-%20um%20estudo%20de%20caso%20baseado%20em%20redes%20dom%c3%a9sticas%20e%20de%20pequenos%20neg%c3%b3cios.pdf","",""
"Sistema de Informação","https://www.repositorio.ufal.br/handle/123456789/9656","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Implantação de uma solução open source na gestão de uma rede de computadores em uma média empresa com as ferramentas Zabbix e Grafana","('Raul Sales Cansanção Chaves',)","('Almir Pereira Guimarães',)","('Petrúcio Antônio Medeiros Barros', 'Rômulo Nunes de Oliveira')","As redes de computadores nas últimas décadas tornaram-se um elemento de importância fundamental e vital para qualquer órgão ou empresa. É indispensável que a infraestrutura destas redes apresente requisitos de confiabilidade, segurança e desempenho de maneira satisfatória, a fim de oferecer suporte total às aplicações críticas para o bom funcionamento dos processos envolvidos nas organizações públicas ou privadas. Diante desse cenário, o monitoramento da rede é um serviço fundamental para obter uma resposta rápida e precisa sobre o funcionamento da infraestrutura computacional presente. Uma rede é o coração de uma infraestrutura de Informática, de maneira que quando uma rede falha, o fluxo de informações necessárias para os aplicativos e operações de negócios é interrompido. Levando em consideração todos esses pontos, a proposta deste trabalho é a implantação de um sistema de monitoramento de redes de computadores, integrado a um painel visual, permitindo a visão de informações centralizadas, que serão obtidas para a tomada de decisões assertivas e imediatas, com o objetivo de manter a sustentação dos serviços das redes de computadores de uma empresa na área de saúde. O sistema de gerenciamento utilizado neste trabalho foi o Zabbix, que é um software de código aberto que permite o monitoramento de todos os recursos de uma infraestrutura de informática, garantindo a manutenção de sua integridade, disponibilidade e desempenho. Para exibir as informações colhidas pelo Zabbix, foi utilizado o Grafana que também é uma plataforma de código aberto para monitoramento, análise e visualização de dados. De uma maneira geral, a solução integrada das duas ferramentas se mostrou bastante eficiente, dando à equipe de informática, proatividade na resolução de problemas, deixando-os quase sempre, transparentes aos colaboradores. Além disso, as ferramentas contribuíram de forma satisfatória na solução de dois problemas propostos neste trabalho. Foram eles: o cuidado com o espaço disponível em disco nos servidores de imagens de exames, a fim de evitar a interrupção na realização dos exames; bem como auxiliando a gestão de informática, através da possibilidade de elaboração de relatórios técnicos detalhados.","Computer networks in recent decades have become an element of fundamental and vital importance for any organ or company. It is essential that the infrastructure of these networks present requirements for reliability, security and performance in a satisfactory manner, in order to offer full support to applications critical to the proper functioning of the processes involved in public or private organizations. In view of this scenario, network monitoring is a fundamental service to obtain a quick and accurate response on the functioning of the present computational infrastructure. A network is the heart of an IT infrastructure, in a way that when a network fails, the flow of information necessary for applications and business operations is interrupted. Taking into account all these points, the purpose of this work is the implementation of a computer network monitoring system, integrated with a visual panel, allowing the centralized information view, which will be obtained for assertive and immediate decisions , in order to maintain the sustainability of a company's computer network services in the health area. The management system used in this work was Zabbix, which is open source software that allows the monitoring of all the resources of an IT infrastructure, ensuring the maintenance of its integrity, availability and performance. To display the information collected by Zabbix, Grafana was used, which is also an open source platform for monitoring, analyzing and visualizing data. In general, the integrated solution of the two tools proved to be very efficient, giving the IT team proactivity in solving problems, making them almost always transparent to employees. In addition, the tools contributed satisfactorily to the solution of two problems posed in this work. They were: the care with the available disk space in the exam image servers, in order to avoid interruption in the exams; as well as assisting computer management, through the possibility of preparing detailed technical reports.","('Redes de computadores – Gerência', 'Zabbix (Software)', 'Grafana (Software)', 'Protocolo de Rede de Computador', 'Simple Network Management Protocol – SNMP', 'Base de Informações de Gerenciamento', 'Management Information Base – MIB', 'Network Management')","Sistemas de Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/9656","2020-12-10","https://www.repositorio.ufal.br/bitstream/123456789/9656/1/Implanta%c3%a7%c3%a3o%20de%20uma%20solu%c3%a7%c3%a3o%20open%20source%20na%20gest%c3%a3o%20de%20uma%20rede%20de%20computadores%20em%20uma%20m%c3%a9dia%20empresa%20com%20as%20ferramentas%20Zabbix%20e%20Grafana.pdf","",""
"Sistema de Informação","https://www.repositorio.ufal.br/handle/123456789/9612","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Gamificação na area de marketing digital","('Zulmira Ramos de Oliveira',)","('Alan Pedro da Silva',)","('Luiz Claúdio Ferreira da Silva Júnior', 'Petrúcio Antônio Medeiros Barros')","A Gamificação é uma abordagem que dispõe de técnicas, dinâmicas e elementos de jogos capazes de instruir e influenciar o comportamento das pessoas. Enquanto isso, Marketing Digital vem utilizando essa técnica com a missão de atrair clientes e aumentar as vendas, visando construir uma marca de qualidade e colocando a empresa na mídia. Dado isto, este trabalho tem como objetivo, conduzir uma revisão sistemática da literatura nacional, para compreender como a gamificação vem sendo utilizada na área de Marketing Digital. Para a condução deste trabalho, foram selecionados seis artigos da literatura nacional e foram extraídos desses artigos incluídos informações sobre seus objetivos, as formas que os elementos da gamificação foram aplicados na área de marketing digital e os resultados reportados.","Gamification is an approach that uses techniques, dynamics, and game elements that are capable of instructing and influencing people's behaviour. Meanwhile, Digital Marketing has been using this approach to attract customers and increase sales, aiming to build a quality brand and put the company in the media. Based on it, this paper aims to conduct a systematic literature review of the national literature to understand how gamification has been used in Digital Marketing. To conduct this work, six articles were selected from the national literature, and information concerning their objectives, how the elements of gamification were applied in the area of digital marketing, and the results reported were extracted from these articles.","('Gamificação', 'Marketing Digital', 'Gamification', 'Digital Marketing')","Sistemas de Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/9612","2021-02-05","https://www.repositorio.ufal.br/bitstream/123456789/9612/1/Gamifica%c3%a7%c3%a3o%20na%20%c3%a1rea%20de%20marketing%20digital.pdf","","('Kamilla Kemilly Tenório Alves dos Santos',)"
"Sistema de Informação","https://www.repositorio.ufal.br/handle/123456789/10408","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Avaliação de dependabilidade em redes de computadores utilizando os mecanismos de modelagem analítica e análise de sensibilidade: um estudo de caso baseado em uma pequena empresa","('Flávio Pereira da Silva',)","('Almir Pereira Guimarães',)","('Petrúcio Antônio Medeiros Barros', 'Ranilson Oscar Araújo Paiva')","Com a crescente dependência das atividades sociais e econômicas em sistemas de informação, existe grande expectativa quanto à disponibilidade, confiabilidade e robustez para as redes de computadores subjacentes a estes sistemas. Essa expectativa é devido à possibilidade de falhas sobre estas redes que podem ser originadas de diversas fontes, tais como: falhas de hardware, bugs de software, ataques mal-intencionados, erros humanos de operação/manutenção e desastres naturais. Justifica-se a relevância deste tema em virtude da grande importância que as redes de computadores desempenham para o funcionamento dos sistemas vitais das empresas. O presente trabalho possui por objetivo proporcionar modelos analíticos, utilizando o mecanismo de modelagem diagrama de blocos de confiabilidade, para analisar o nível de disponibilidade de redes de computadores considerando a implantação de redundância em componentes críticos para o funcionamento destas redes. Além disso, é utilizado o índice de análise de sensibilidade para determinar quais parâmetros, relacionados aos seus componentes, possuem maior impacto sobre sua disponibilidade a fim de direcionar as estratégias para o incremento desta métrica. Foi analisada a infraestrutura da rede de computadores original (arquitetura base) e também foram propostas duas arquiteturas adicionais com um incremento no nível de redundância a fim de analisar o impacto de cada um de seus parâmetros sobre a disponibilidade do sistema. O tempo de reparo relacionado ao enlace na arquitetura base, o tempo de reparo relacionado ao servidor na arquitetura 2 e o tempo de reparo relacionado ao host na arquitetura 3 são os parâmetros que mais impactam sobre a disponibilidade de todo o sistema.","With the growing dependence on social and economic activities in information systems, there is great expectation regarding the availability, reliability and robustness for the computer networks underlying these systems. This expectation is due to the possibility of failures on these networks that can originate from several sources, such as: hardware failures, software bugs, malicious attacks, human operation / maintenance errors and natural disasters. The relevance of this topic is justified in view of the great importance that computer networks play for the functioning of companies' vital systems. The present work aims to provide analytical models, using the reliability block diagram modeling mechanism, to analyze the level of availability of computer networks considering the implementation of redundancy in critical components for the functioning of these networks. In addition, the sensitivity analysis index is used to determine which parameters, related to their components, have the greatest impact on their availability in order to direct strategies for increasing this metric. The infrastructure of the original computer network (base architecture) was analyzed and two additional architectures were proposed with an increase in the level of redundancy in order to analyze the impact of each of its parameters on the availability of the system. The repair time related to the link in the base architecture, the repair time related to the server in architecture 2 and the repair time related to the host in architecture 3 are the parameters that most impact on the availability of the entire system.","('Redes de computadores', 'Diagrama de blocos de confiabilidade', 'Análise de sensibilidade', 'Dependability', 'Sensitivity Analysis', 'Reliability Block diagram', 'Corporate Networks')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/10408","2020-12-17","https://www.repositorio.ufal.br/bitstream/123456789/10408/1/Avalia%c3%a7%c3%a3o%20de%20dependabilidade%20em%20redes%20de%20computadores%20utilizando%20os.pdf","",""
"Sistema de Informação","https://www.repositorio.ufal.br/handle/123456789/8616","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","O comércio eletrônico, as formas de pagamentos e as dicas de segurança da informação","('José Weseles Alves da Santos',)","('Ibsen Mateus Bittencourt Santana Pinto',)","('Ana Paula Lima Marques Fernandes', 'Petrúcio Antônio Medeiros Barros')","Esse estudo teve como objetivo compreender a inter-relação entre Comércio Eletrônico ou E-commerce, em inglês, suas formas de pagamentos e a segurança da informação, tendo como pano de fundo o papel fundamental da Internet. Inicialmente, falou-se sobre as tecnologias que marcaram a evolução da Internet para em seguida contextualizar uma análise de indicadores de acesso à Grande Rede pela população e o atual estágio de desenvolvimento do ambiente de compra online nacional. Em seguida, almejou-se saber quais conclusões seriam extraídas das comparações dos seguintes indicadores: acesso à Internet pela população vs. crescimento do E-commerce brasileiro e crescimento do E-commerce brasileiro vs. Produto Interno Bruto -PIB brasileiro. Dando continuidade, foram apresentados conceitos e as principais características do Comércio Eletrônico. Da mesma forma foram descritas suas transações mais usuais, observando como critério mais relevante de classificação neste trabalho a qualidade da relação entre seus participantes, dos quais, no mercado brasileiro, destacam-se os consumidores e as empresas. Dando sequência, pretendeu-se estabelecer um panorama através da análise dos principais índices do E-commerce nacional, do importante papel dos motivadores de compra tendo como destaques os sites de buscas e as redes sociais, dos desafios a serem vencidos e das principais estratégias – sendo o uso cada vez mais massivo das TICs móveis em especial o smartphone a mais relevante para o futuro deste segmento de mercado. Além disso, foram apresentadas as modalidades de pagamentos mais praticadas e as precauções nos sistemas eletrônicos dos portais, bem como as dicas de segurança da informação para os consumidores. Enfim, juntadas todas essas partes -agora interdependentes – tem-se um panorama do Comércio Eletrônico brasileiro e, portanto, ficam menos árduas as tarefas de identificar vantagens competitivas para quem deseja empreender neste segmento de mercado e também vislumbrar num futuro -não muito distante -tendências que mudarão o comportamento do consumidor de produtos e serviços virtuais como as elencadas nas considerações futuras ao final.","This study aimed to understand the interrelationship between Electronic Commerce or E-commerce, in English, its forms of payments and information security, against the background of the fundamental role of the Internet. Initially, there was talk about the technologies that marked the evolution of the Internet and then contextualize an analysis of indicators of access to the Grande Rede by the population and the current stage of development of the national online shopping environment. Then, the aim was to know which conclusions would be drawn from comparisons of the following indicators: Internet access by the population vs. growth of Brazilian E-commerce and growth of Brazilian E-commerce vs. Gross Domestic Product -Brazilian GDP. Continuing, concepts and the main characteristics of Electronic Commerce were presented. Likewise, their most usual transactions were described, observing the quality of the relationship between their participants as the most relevant classification criterion in this work, of which, in the Brazilian market, consumers and companies stand out. Continuing, it was intended to establish a panorama through the analysis of the main national E-commerce indexes, the important role of purchase motivators, with search engine and social network highlights, the challenges to be overcome and the main strategies -with the increasingly massive use of mobile ICTs in particular the smartphone being the most relevant for the future of this market segment. In addition, the most popular payment methods and precautions in the electronic systems of the portals were presented, as well as information security tips for consumers. Anyway, all these parts -now interdependent -together have a panorama of the Brazilian Electronic Commerce and, therefore, the tasks of identifying competitive advantages for those who wish to undertake in this market segment and also envision in the future -not too distant -are less arduous -trends that will change the behavior of consumers of virtual products and services such as those listed in the future considerations at the end.","('Comércio Eletrônico', 'Produto Interno Bruto', 'Redes sociais', 'Comércio virtual', 'E-commerce', 'Electronic Commerce', 'Gross Domestic Product', 'M-commerce', 'Social network')","Sistemas de Informação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/8616","2020-09-10","https://www.repositorio.ufal.br/bitstream/123456789/8616/1/O%20com%c3%a9rcio%20eletr%c3%b4nico%2c%20as%20formas%20de%20pagamentos%20e%20as%20dicas%20de%20seguran%c3%a7a%20da%20informa%c3%a7%c3%a3o.pdf","Electronic commerce, payment methods and information security tips",""
"Sistema de Informação","https://www.repositorio.ufal.br/handle/123456789/12118","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Avanços da legislação brasileira na segurança da informação: uma pesquisa documental na plataforma Jusbrasil","('Claudevan Cardoso da Silva',)","('Andrea Marques Vanderlei Fregadolli',)","('Rômulo Nunes de Oliveira', 'Petrúcio Antônio Medeiros Barros')","A referida pesquisa teve por objetivo analisar como vem sendo tratado a segurança da informação na Internet, onde para isso realizou-se uma pesquisa documental sistemática nas plataformas digitais, entre um determinado período de tempo, que foi de 15 de janeiro de 2020 a 15 de fevereiro de 2020. Através dos dados coletados se tornou possível compreender que a grande preocupação destacada na maioria das vezes, era de como os dados pessoas estavam sendo usados pelas mais diversas entidades. Vale ressaltar ainda que muito vem sendo feito para sanar o problema envolvendo a segurança da informação da Internet, como leis implantadas e estratégias de prevenção e combate a estes tipos de crimes sendo criadas constantemente, garantindo assim que aos usuários mantenham uma vida social mais protegida, com a sensação de estar com seus dados protegidos ao acessar a rede mundial de computadores. Entretanto, a busca por um ambiente seguro ainda está longe de ter um fim, mas com as devidas precauções o uso da Internet esteja mais seguro.","This research aimed to analyze how information security on the Internet has been treated, where a systematic documentary research was carried out on digital platforms, for a certain period of time, which was from January 15, 2020 to January 15, February 2020. Through the data collected, it became possible to understand that the main concern highlighted most of the time was how personal data was being used by the most diverse entities. It is also worth mentioning that much has been done to solve the problem involving the security of information on the Internet, such as implemented laws and strategies to prevent and combat these types of crimes being constantly created, thus ensuring that users maintain a more protected social life, with the feeling of having your data protected when accessing the world wide web. However, the search for a safe environment is still far from having an end, but with the proper precautions, the use of the Internet is safer","('Internet – Legislação -Brasil', 'Proteção de dados', 'Internet -Legislation -Brazil', 'data protection')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/12118","2021-06-22","https://www.repositorio.ufal.br/bitstream/123456789/12118/1/Avan%c3%a7os%20da%20legisla%c3%a7%c3%a3o%20brasileira%20na%20seguran%c3%a7a%20da%20informa%c3%a7%c3%a3o%20uma%20pesquisa%20documental%20na%20plataforma%20Jusbrasil.pdf","Advances in Brazilian legislation on information security: a documentary research on the Jusbrasil platform",""
"Sistema de Informação","https://www.repositorio.ufal.br/handle/riufal/7789","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Fatores críticos de sucesso em empresas digitais: estudos de casos em municípios do sertão alagoano","('Thiago José dos Santos Barbosa',)","('Olival de Gusmão Freitas Júnior',)","('Petrúcio Antônio Medeiros Barros', 'Marcus de Melo Braga')","O crescimento da competitividade no mundo dos negócios exige das empresas estratégias como inovação e empreendedorismo, estratégia esta que pode levá-las a se destacar no mercado. O empreendedorismo busca a visualização de oportunidades de negócios, onde existe uma busca incessante por inovações, assumindo riscos calculados com a intenção de obter renda, reconhecimento e crescimento no mercado. Empreendedorismo digital é o tipo de empreendedorismo que aborda os meios e serviços digitais que possam gerar lucro. Este trabalho é uma pesquisa aplicada em três cidades do sertão alagoano (Delmiro Gouveia, Piranhas e Santana do Ipanema), visando identificar os fatores críticos de sucesso em empresas digitais. Essa pesquisa ajuda também a traçar o perfil do empreendedor digital do sertão alagoano, observando as características das empresas digitais.","Increasing competitiveness in the business world requires companies such as innovation and entrepreneurship, a strategy that can make them stand out in the marketplace. Entrepreneurship seeks the visualization of business opportunities, where there is an incessant search for innovations, taking calculated risks with the intention of earning income, recognition and growth in the market. Digital entrepreneurship is the type of entrepreneurship that addresses digital media and services that can generate profit. This work is a research applied in three cities of the Alagoas backlands (Delmiro Gouveia, Piranhas and Santana do Ipanema), aiming to identify the critical success factors in digital companies. This research also helps to profile the digital entrepreneur of the sertão of Alagoas, observing the characteristics of digital companies.","('Empreendedorismo', 'Empreendedorismo digital', 'Fatores críticos de sucesso', 'Entrepreneurship', 'Digital entrepreneurship', 'Critical success factors')","Sistemas de Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/handle/riufal/7789","2019-09-19","https://www.repositorio.ufal.br/bitstream/riufal/7789/1/Fatores%20cr%c3%adticos%20de%20sucesso%20em%20empresas%20digitais%20-%20estudos%20de%20casos%20em%20munic%c3%adpios%20do%20sert%c3%a3o%20alagoano.pdf","Critical success factors in digital companies: case studies in municipalities in the sertão alagoano","('Wanderson Rubian Martins Rodrigues',)"
"Sistema de Informação","https://www.repositorio.ufal.br/handle/123456789/10174","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Avaliando a implantação de um software de gestão","('Moézio Leivas Silva Lino',)","('Petrúcio Antônio Medeiros Barros',)","('Marcus de Melo Braga', 'Almir Pereira Guimarães')","Diante de uma cobrança por maior transparência, governança, compliance, eficiência e efetividade a administração pública brasileira passou a adotar sistemas integrados de gestão. É possível avaliar a implantação de sistemas computacionais através de fatores críticos de sucesso. O objetivo deste trabalho é investigar entre os fatores chave quais os mais relevantes para avaliação de um software de gestão. Foi estudado então um método de avaliação da implantação sendo o objetivo a melhoria dos serviços. Vários autores já escreveram sobre o assunto, é possível entender em seus artigos que podemos desenvolver modelos, os quais reúnem fatores críticos de sucesso que se combinam para amplificação dos resultados; podem ser desenvolvidos filtros de acordo com o ramo de atuação da instituição. Um questionário foi montado objetivando avaliar dois dos quatro sistemas integrados de gestão implantados pela UFAL, SIPAC -Sistema Integrado de Gestão de Patrimônio -é um sistema que oferece operações fundamentais para a gestão das unidades responsáveis pelas finanças, patrimônio e contratos; SIGRH -Sistema Integrado de Gestão de Recursos Humanos -informatiza os procedimentos de recursos humanos, tais como: marcação/alteração de férias, cálculos de aposentadoria, avaliação funcional, dimensionamento de força de trabalho, dentre outros. A fim de expor como é feita a escolha do sistema e como o sucesso da implantação é influenciado por fatores críticos, o questionário desenvolvido se utilizou de estatística descritiva fornecida de forma automática pelo Google Forms. Este questionário foi enviado aos setores que estiveram presentes na reunião que marcou a mudança do sistema na UFAL. Ao final concluímos que um dos fatores críticos de sucesso mais importantes encontrados nesse estudo é a participação dos gestores no processo de aquisição e implementação do sistema; e que os benefícios passaram a ser mais percebidos em setores que não possuíam software de gestão, no entanto, foi balanceado pelos setores que já utilizavam sistemas e possivelmente não perceberam tantos benefícios quanto os demais. Ainda é importante mencionar que a avaliação dos resultados e benefícios do sistema atual nos leva a considerar o resultado como bom, mesmo diante de muitos fatores críticos de sucesso que nos possibilitam várias perspectivas.","Faced with a demand for greater transparency, governance, compliance, efficiency and effectiveness, the Brazilian public administration started to adopt integrated management systems. Is possible to evaluate the implementation of computer systems through critical success factors, the objective of this work is to investigate what key factors are the most relevant for evaluating a management software. Then, a method of evaluation of the implantation was studied with the objective to improve the services. Many authors have already written about the subject, is possible to understand in their articles that we can develop models that bring together critical success factors that combine to amplify the results; filters can be developed according to the institution's field of activity. Was assemble a questionnaire aiming to evaluate two of the four integrated management systems implemented by UFAL, SIPAC -Integrated Wealth Management System -is a system that offers fundamental operations for the management of units responsible for finance, equity and contracts; SIGRH -Integrated Human Resources Management System -computerizes human resources procedures, such as: scheduling/changing vacations, retirement calculations, functional evaluation, workforce sizing, among others. In order to expose how the choice of the system is made and how the success of the implementation is influenced by critical factors, a questionnaire was developed that uses descriptive statistics provided automatically by Google Forms. This questionnaire was sent to the sectors that were present at the meeting that marked the change of the system at UFAL. In the end, we conclude that one of the most important critical success factors found in this study is the participation of managers in the process of acquiring and implementing the system; and that the benefits started to be more perceived in sectors that did not have management software, however, it was balanced by the sectors that already used systems and possibly did not realize as many benefits as the others sectors. Is also important to mention that the evaluation of the results and benefits of the current system leads us to consider the result as good, even in the face of many critical success factors that allow us to have several perspectives.","('Software de gestão', 'Fatores críticos de sucesso', 'Satisfação', 'Administração pública', 'Critical factors', 'Success', 'Satisfaction')","Sistemas de Informação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/10174","2021-10-18","https://www.repositorio.ufal.br/bitstream/123456789/10174/1/Avaliando%20a%20implanta%c3%a7%c3%a3o%20de%20um%20software%20de%20gest%c3%a3o.pdf","Evaluating the Implementation of a Management Software",""
"Sistema de Informação","https://www.repositorio.ufal.br/handle/123456789/9394","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Análise do grau de maturidade de inovação em TVs públicas educativas brasileiras: estudo de casos","('Robson de Oliveira Bispo',)","('Olival de Gusmão Freitas Júnior',)","('Giseldo da Silva Néo', 'Arturo Hernández-Domínguez')","O presente trabalho tem como objetivo avaliar o nível de maturidade de inovação em emissoras de TVs educativas públicas do território nacional, onde 3 empresas concordaram em participar da avaliação. As emissoras de TVs educativas públicas são organizações geridas pelo poder público, não tendo por finalidade a geração de lucros, consequentemente, sua programação não se encontra atrelada ao modelo das emissoras comerciais que usam seus índices de audiência para obtenção de lucros. Enquanto as TVs comerciais veem seus telespectadores como consumidores, as TVs pública educativa os veem como cidadãos, visando transmitir através de sua grade uma programação que leve educação com ética e responsabilidade social ambiental. Nesse estudo, utilizou-se um questionário que foi desenvolvido para estimar o grau de maturidade em inovação das emissoras de TVs. A metodologia adotada nesse estudo está classificada, preponderantemente quanto aos fins como exploratório, e quanto aos meios como bibliográfico, qualitativo e suportado por estudo de casos, de forma a permitir a análise aplicada dos resultados esperados. Após a análise dos dados, observou-se que a emissora A possui 44% do nível I, necessitando de 3 competências da dimensão gestão de pessoas para inovação, 2 competências da dimensão gestão estratégica da tecnologia para consolidar o nível I. Já a emissora B preencheu todas as competências do nível I do modelo proposto, faltando uma competência na dimensão intenção estratégica de inovar para consolidar o nível II. A emissora C possui apenas 33,3% do nível I precisando de três competências de gestão de pessoas para inovação, uma competência em gestão estratégica da tecnologia e dois itens em organicidade da estrutura organizacional para consolidar o nível I. A metodologia utilizada possibilitou a avaliação do grau de maturidade de inovação nas emissoras de TVs públicas educativas, apresentando ações que os gestores devem promover em suas instituições na busca do desenvolvimento de uma cultura inovadora.","The present work aims to assess the level of innovation maturity in public educational TV stations in the national territory, where 3 companies agreed to participate in the assessment. Public educational TV broadcasters are organizations managed by the government, not having the purpose of generating profits. Consequently, their programming is not linked to the model of commercial broadcasters that use their audience ratings to obtain profits. While commercial TVs see their viewers as consumers, public educational TVs see them as citizens, aiming to transmit through their grid a program that brings education with ethics and environmental social responsibility. In this study, a questionnaire was used that was developed to estimate the degree of maturity in innovation of TV stations. The methodology adopted in this study is classified, mainly as to the purposes as exploratory, and as to the means as bibliographic, qualitative and supported by case studies, in order to allow the applied analysis of the expected results. After analyzing the data, it was observed that broadcaster A has 44% of level I, requiring 3 skills in the people management dimension for innovation, 2 skills in the strategic management dimension of technology to consolidate level I. fulfilled all the competences of level I of the proposed model, lacking a competence in the dimension of strategic intention to innovate to consolidate level II. Issuer C has only 33.3% of level I needing three people management skills for innovation, one competence in strategic technology management and two items in organicity of the organizational structure to consolidate level I. The methodology used enabled the evaluation the degree of maturity of innovation in educational public TV stations, presenting actions that managers must promote in their institutions in the search for the development of an innovative culture.","('Maturidade (Inovação)', 'Gestão da inovação', 'Televisão pública', 'Maturity', 'Innovation', 'Innovation Management', 'Educational TV')","Sistemas de Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/9394","2021-02-24","https://www.repositorio.ufal.br/bitstream/123456789/9394/1/An%c3%a1lise%20do%20grau%20de%20maturidade%20de%20inova%c3%a7%c3%a3o%20em%20TVs%20p%c3%bablicas%20educativas%20brasileiras%3a%20estudo%20de%20casos.pdf","","('Wanderson Rubian Martins Rodrigues',)"
"Sistema de Informação","https://www.repositorio.ufal.br/handle/123456789/9028","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Crimes informáticos: um breve estudo acerca da legislação brasileira atual","('Marcos Valerio da Almeida',)","('Petrúcio Antônio Medeiros Barros',)","('Almir Pereira Guimarães', 'Marcus de Melo Braga')","O presente trabalho tem como escopo verificar se existe proteção adequada para as vítimas de crimes cibernéticos. Trata-se de uma pesquisa de natureza essencialmente bibliográfica, realizada através de literaturas publicadas em livros, artigos de revistas impressas e/ou eletrônicas, bem como de natureza qualitativa, consistente na interpretação e análise crítica da temática proposta, capaz de atender os objetivos da pesquisa. O estudo evidenciou que o Brasil tem uma lei que trata da Política Cibernética de Defesa no âmbito nacional, além de uma série de normas legais que visam amparar as vítimas de crimes cibernéticos. Para além das sanções no âmbito penal, existem medidas sancionatórias cabíveis na esfera jurídica civil, normalmente consistentes em pagamento de indenizações por danos morais e/ou materiais suportados pela vítima, assim como a obrigatoriedade dos provedores de internet de retirar da rede as páginas ou notícias ensejadoras de situações vexatórias e de consequentes danos morais. Porém, há necessidade de uma melhor aplicação da legislação, para melhor sucesso na autuação e punição de casos cometidos.","This current work has as its objective identify whether there’s adequares protection for victims of cybernetic crimes. This work is essentially bibliographic, done through research from literatures published in books, articles from magazines and/or electronic magazines, as well as qualitative, based on interpreting and critically analysing the proposed theme, capable of meeting the requirements of the research. The study showed that Brazil has a law that deals with Cyber Defense Policy at the national level, in addition to a series of legal rules that aim to protect victims of cybercrimes. In addition to the penalties in the criminal sanctions, there are sanctioning measures applicable in the legal sphere, usually consisting of the payment of indemnities for moral/material damage, as well as the internet providers responsibility of taking down the pages of unwanted news and consequent moral damage. However, there’s need of a better application of the legislation, for success in assessment and punishment of committed crimes.","('Crimes cibernéticos', 'Segurança cibernética', 'Legislação Processual Penal -Brasil', 'Cybercrimes', 'Cyber security', 'Criminal Procedural Legislation -Brazil')","Sistemas de Informação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/9028","2020-07-23","https://www.repositorio.ufal.br/bitstream/123456789/9028/1/Crimes%20inform%c3%a1ticos%3a%20um%20breve%20estudo%20acerca%20da%20legisla%c3%a7%c3%a3o%20brasileira%20atual..pdf","Crimes computers: a brief study about current brazilian legislation","('Maria Regina Ferreira da Silva Lima',)"
"Sistema de Informação","https://www.repositorio.ufal.br/handle/123456789/12449","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Classifying vascular age based on brazilian reference values a bayes’ theorem and least squares approach","('Rodrigo Santos da Silva',)","('Thiago Damasceno Cordeiro',)","('Rodrigo Lisbôa Pereira', 'Álvaro Alvares de Carvalho César Sobrinho')","Doenças cardiovasculares, de acordo com a (Organização Mundial da Saúde) OMS, são as principais responsáveis pelos casos de morte na última década. Como uma prova disso, em 2019 um total de 17.9 milhões foram em decorrência de problemas cardiovasculares, o que representa 32% das mortes no mundo. Além disso, tais doenças têm um papel crucial em casos de morte nas populações de países de baixa e média renda. Assim, um dos métodos aplicados para avaliar as condições de cardiovasculares de um indivíduo é o cálculo da idade cardiovascular. Hoje, existem técnicas que realizam esse cálculo, como o dispositivo Mobil-O-Graph que consegue calcular a idade cardiovascular com base em 5 variáveis hemodinâmicas (as mesmas usadas nesse trabalho). Porém, tal dispositivo foi desenvolvido e calibrado utilizando populações europeias, que possuem estilos de vida diferentes de outras populações, o que torna difícil a identificação da idade vascular de indivíduos brasileiros, por exemplo. Assim, mediante ao estudo que levanta valores de referência para a população brasileira, torna-se possível desenvolver métodos de classificação de idade cardiovascular para outras populações, como o caso da população brasileira nesse trabalho. Assim, esse estudo tem como objetivo desenvolver um método de classificação de idade cardiovascular, utilizando o método do Teorema de Bayes, baseado na distribuição da população brasileira de 2010, via a não publicação de dados novos em decorrência da pandemia da Covid-19, de acordo com o Instituto Brasileiro de Geografia e Estatística (IBGE), para realizar os cálculos de probabilidade da idade cardiovascular de um indivíduo. Além disso, utiliza-se o método de mínimos quadrados para minimizar o erro entre os dados previstos e as funções acumulativas calculadas com base nos valores de referência. Os resultados mostram que foi possível calcular classes de idades cardiovasculares com base nos valores das variáveis hemodinâmicas informadas. Além disso, foi desenvolvida uma aplicação web com o intuito de testar a técnica, utilizando dados de pacientes reais.","Cardiovascular diseases, according to the World Health Organization (WHO), have been the leading cause of death in the last decade. As evidence of this, in 2019 a total of 17.9 million deaths were due to cardiovascular problems, representing 32% of global deaths. Furthermore, such diseases play a crucial role in mortality cases among populations in low-and middle income countries. Therefore, one of the methods applied to assess an individual’s cardiovascular conditions is the calculation of cardiovascular age. Nowadays, there are techniques that perform this calculation, such as the Mobil-O-Graph device, which can calculate cardiovascular age based on 5 hemodynamic variables (the same variables used in this study). However, this device was developed and calibrated using European populations, which have different lifestyles compared to other populations, making it difficult to identify the vascular age of individuals from, for example, Brazil. Thus, through a study that establishes reference values for the Brazilian population, it becomes possible to develop methods for classifying cardiovascular age for other populations, such as the Brazilian population in this study. Therefore, the objective of this study is to develop a method for classifying cardiovascular age using Bayes’ Theorem, based on the distribution of the Brazilian population in 2010, due to then on-publicationofnew data as a result of the Covid-19 pandemic, according to the Brazilian Institute of Geography and Statistics (IBGE), to calculate the probability of an individual’s cardiovascular age. In addition, the least squares method is used to minimize the error between the predicted data and the cumulative functions calculated based on reference values. The results show that it was possible to calculate cardiovascular age classes based on the provided hemodynamic variable values. Furthermore, a web application was developed to test the technique using data from real patients.","('Mobil-O-Graph', 'Teorema de Bayes', 'Pressão Sistólica Central', 'Pressão Diastólica Central', 'Bayes’ Theorem', 'Central Systolic Pressure', 'Central Diastolic Pressure')","Ciência da Computação","eng","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/12449","2023-05-10","https://www.repositorio.ufal.br/bitstream/123456789/12449/1/Classifying%20vascular%20age%20based%20on%20brazilian%20reference%20%20values%20a%20bayes%e2%80%99%20theorem%20and%20least%20squares%20approach.pdf","","('Glauco Estácio Gonçalves',)"
"Sistema de Informação","https://www.repositorio.ufal.br/handle/123456789/9658","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Análise de vulnerabilidades em protocolos de segurança em redes sem fio domésticas e comerciais de pequeno porte","('Rodolfo José de Paula Santos',)","('Almir Pereira Guimarães',)","('Petrúcio Antônio Medeiros Barros', 'Rômulo Nunes de Oliveira')","O uso da tecnologia wireless com o passar dos anos tem sido cada vez maior e fica cada vez mais clara a sua evolução através de dispositivos portáteis e eletrônicos como notebook, smartphones, tablets, Smartv, sistemas residenciais inteligentes, dispositivos de assistência pessoal, e até eletrodomésticos que antes eram impensáveis em ter alguma conexão com a Internet. Hoje é possível ter conexões para eletrodomésticos tais como geladeira, fogão, entre outros. As redes sem fio, tem sido amplamente difundidas em ambientes domésticos e corporativos tanto com a finalidade de economia em infraestrutura de cabeamento, quanto ao fato de permitir maior portabilidade e flexibilidade para redes locais. Porém, em contrapartida exige algumas preocupações adicionais em segurança que são intrínsecas a um meio de comunicação sem fio. Devido à importância dos dados que circulam em redes sem fio, a segurança da informação é uma questão de grande relevância para essas redes, sejam elas domésticas ou corporativas. Nosso trabalho busca analisar determinados protocolos e até mesmo configurações utilizadas neste tipo de rede com o propósito de exibir alguns tipos de ataques e fragilidades relativas à segurança de redes sem fio, dando ênfase ao padrão IEEE 802.11 (IEEE 802.11b, IEEE 802.11g, IEEE 802.11n). Nos testes realizados foram feitos ataques do tipo sniffer, desautenticação, dicionário, captura de handshake, PMKID, força bruta, dentre outros, que obtiveram êxito com a utilização de ferramentas como AirCrack-ng, Wifite2, Bettercap, Hashcat para explorar suas respectivas vulnerabilidades.","The use of wireless technology over the years has been increasingly greater and its evolution is increasingly clear through portable and electronic devices such as notebooks, smartphones, tablets, Smartv, smart home systems, personal assistance devices, and even appliances that were previously unthinkable to have an internet connection. Today it is possible to have connections for appliances such as refrigerator, stove, and others. Wireless networks have been widely used in domestic and corporate environments, both for the purpose of saving cabling infrastructure and allowing greater portability and flexibility for local networks. However, in return, it requires some additional security concerns that are intrinsic to a wireless medium. Due to the importance of data circulating on wireless networks, information security is an issue of great relevance for these networks, whether they are domestic or corporate. Our work seeks to analyze certain protocols and even configurations used in this type of network with the purpose of showing some types of attacks and weaknesses related to the security of wireless networks, emphasizing the IEEE 802.11 standard (IEEE 802.11b, IEEE 802.11g, IEEE 802.11n). In the tests carried out, sniffer, deauthentication, dictionary, handshake capture, PMKID, brute force attacks were performed, among others, which were successful with the use of tools such as AirCrack-ng, Wifite2, Bettercap, Hashcat to exploit their respective vulnerabilities.","('Redes locais sem fio', 'Segurança de redes', 'IEEE 802.11 (Normas)', 'Ataque de PMKID', 'AirCrack-ng (Suíte)', 'Wireless networks', 'Network security', 'PMKID attack')","Sistemas de Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/9658","2020-12-01","https://www.repositorio.ufal.br/bitstream/123456789/9658/1/An%c3%a1lise%20de%20vulnerabilidades%20em%20protocolos%20de%20seguran%c3%a7a%20em%20redes%20sem%20fio%20dom%c3%a9sticas%20e%20comerciais%20de%20pequeno%20porte.pdf","",""
"Sistema de Informação","https://www.repositorio.ufal.br/handle/123456789/8233","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Análise de sentimentos em narrativas de gestores educacionais com ênfase no IDEB","('Samuel Feitosa Batista',)","('Olival de Gusmão Freitas Júnior',)","('Giseldo da Silva Néo', 'Bruno Almeida Pimentel')","No presente trabalho foi analisado a taxa de aprovação de alunos nas escolas públicas municipais de Maceió. O trabalho tem como objetivo principal analisar de que forma a opinião dos gestores escolares se correlaciona com essa taxa de aprovação através da Análise de Sentimentos. A Taxa de aprovação e o índice de evasão escolar comprovado pelo censo da educação básica publicado pelo Instituto Nacional de Estudos e Pesquisas Educacionais Anísio Teixeira (INEP) nos últimos anos, foi objeto de motivação da pesquisa. Este trabalho apresenta uma abordagem de análise de sentimentos que começa na coleta de opiniões através de um questionário aplicado a 12 gestores de escolas públicas municipais de Maceió. A pesquisa caracteriza-se como exploratória com abordagem quantitativa. Após a coleta de dados fazendo uso de técnicas de analises estatísticas a hipótese levantada foi testada e verificou-se uma correlação linear negativa para os dados apresentados, resultando numa inversão acerca da taxa de aprovação e sentimento do gestor.","In the present work, the approval rate of students in the municipal public schools of Maceió was analyzed. The main objective of the work is to analyze how the opinion of school managers correlates with this approval rate through Sentiment Analysis. The approval rate and the school dropout rate proven by the basic education census published by the National Institute of Educational Studies and Research Anísio Teixeira (INEP) in recent years, was the object of motivation for the research. This work presents a sentiment analysis approach that begins with the collection of opinions through a questionnaire applied to 12 managers of municipal public schools in Maceió. The research is characterized as exploratory with a quantitative approach. After collecting data using statistical analysis techniques, the hypothesis was tested and a negative linear correlation was found for the data presented, resulting in an inversion of the approval rate and the manager's feelings.","('Análise de Sentimentos', 'Estatística descritiva', 'Taxa de aprovação', 'Sentiment Analysis', 'Descriptive Statistics', 'Approval Rate')","Ciência da Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/8233","2021-08-10","https://www.repositorio.ufal.br/bitstream/123456789/8233/1/An%c3%a1lise%20de%20sentimentos%20em%20narrativas%20de%20gestores%20educacionais%20com%20%c3%aanfase%20no%20IDEB.pdf","Analysis of feelings in narratives of educational managers with emphasis on IDEB","('Wanderson Rubian Martins Rodrigues',)"
"Sistemas de Informação","https://www.repositorio.ufal.br/handle/123456789/14489","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Análise da governança de TI em uma prefeitura do Nordeste do Brasil","('Joclean Albuquerque dos Lima',)","('Ibsen Mateus Bittencourt Santana Pinto',)","('Ranilson Oscar Araújo Paiva', 'Petrúcio Antônio Medeiros Barros')","O estudo em pauta analisou a existência ou não de algum modelo de governança de TI em uma prefeitura de uma capital no Nordeste do Brasil, investigando as práticas de governança de TI, levando em consideração as características culturais e ambientais da organização. O estudo examinou os diferentes níveis de maturidade da tecnologia da informação dentro da prefeitura, bem como a influência de órgãos de controle e a compreensão do conceito de governança por parte dos gestores municipais. O artigo abordou as origens e evolução do conceito de governança, bem como a relação entre os frameworks COBIT e ITIL. Através de questionários e entrevistas, foram coletados dados sobre a estrutura de TI da prefeitura, o planejamento estratégico e a aplicação de práticas de governança. Os resultados revelam, a falta de percepção da importância da TI na gestão estratégica municipal, a necessidade de melhorias na área de governança de TI, incluindo a falta de instrumentos de planejamento e o baixo nível de aplicação de práticas de governança. Conclui-se que a TI ainda não é totalmente reconhecida como uma função estratégica na gestão pública municipal, e são necessários esforços para fortalecer a governança de TI e melhorar a prestação de serviços à comunidade.","The study in question analyzed the existence or not of some IT governance model in a city hall of a capital in the Northeast of Brazil, investigating IT administration practices, taking into account the cultural and environmental characteristics of the organization. The study examined the different levels of information technology maturity within the city politics, as well as the influence of control institutions and the understanding of the concept of governance by municipal managers. The article addressed the origins and development of the concept of governance, as well as the relationship between the COBIT and ITIL frameworks. Through surveys and interviews, data were collected on the city politic's IT structure, strategic planning and the application of governance practices. The results show the lack of perception of the importance of IT in the municipal strategic management, the need for improvements in the area of IT administration, including the lack of planning instruments and the low level of application of governance practices. It is concluded that IT is not yet fully recognized as a strategic function in municipal public management, and efforts are needed to strengthen IT governance and improve service provision to the community.","('Governança', 'Tecnologia da informação', 'Administração pública', 'Governance', 'Information technology', 'Management')","Sistemas de Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/14489","2023-12-21","https://www.repositorio.ufal.br/bitstream/123456789/14489/1/An%c3%a1lise%20da%20governan%c3%a7a%20de%20TI%20em%20uma%20prefeitura%20do%20Nordeste%20do%20Brasil.pdf","Analysis of IT governance in a city hall in the Northeast of Brazil",""
"Sistemas de Informação","https://www.repositorio.ufal.br/handle/123456789/15970","Campus A.C. Simões","Instituto de Computação","Trabalho de Conclusão de Curso","Uma análise correlacional da capacidade de autorregulação e o desempenho de estudantes da educação online","('Rosana Alves de Santos',)","('Ranilson Oscar Araújo Paiva',)","('Diego Dermeval de Medeiros da Cunha Matos', 'Dalgoberto Miquilino Pinho Júnior')","No presente trabalho, abordamos o tema autorregulação da aprendizagem no ensino superior na modalidade a distância. Este trabalho tem como objetivo avaliar a capacidade de autorregulação de estudantes de cursos à distância, identificar os impactos socioeconômicos e culturais na capacidade de autorregulação da aprendizagem, bem como avaliar a correlação com o resultado acadêmico. Um total de 26 estudantes responderam a um questionário constituído de três partes: na primeira, solicitamos dados pessoais do estudante para uma análise socioeconômica demográfica; a segunda parte foi composta por 21 questões, onde obtivemos informações a respeito da sua experiência com cursos EaD e; Na terceira parte, utilizamos o questionário QIAR (Questionário de Instrumentalidade da Autorregulação da Aprendizagem) para avaliar a capacidade de autorregulação dos participantes. A coleta de dados foi realizada on-line, por meio de um Formulário do Google. Os resultados comprovaram que há uma correlação moderada entre a capacidade de autorregular sua aprendizagem e o desempenho dos estudantes nos seus respectivos cursos. Isso evidencia uma influência entre a capacidade de se autorregular e o coeficiente (nota global do estudante no curso, ou seja, seu desempenho acadêmico no curso). Dentro do contexto desta pesquisa, os resultados nos permitem afirmar que autorregular contribui para o desempenho do estudante no curso. A partir dos resultados apresentados, espera-se contribuir para aprofundar o conhecimento sobre a autorregulação da aprendizagem no ensino a distância e que as universidades promovam e motivem os alunos a desenvolver estratégias para autorregular a sua própria aprendizagem.","In the present work, we approach the topic of self-regulation of learning in higher education in the distance modality. This work aims to evaluate the selfregulation capacity of students in distance learning courses, to identify the socioeconomic and cultural impacts on the self-regulation capacity of learning, as well as to assess the correlation with academic results. A total of 26 students responded to a questionnaire consisting of three parts: in the first, we requested personal data from the student for a demographic socioeconomic analysis; the second part consisted of 21 questions, where we obtained information about their experience with distance education courses and; In the third part, we used the QIAR questionnaire (Questionnaire of Instrumentality of Self-Regulation of Learning) to assess the self-regulation capacity of the participants. Data collection was performed online, using a Google Form. The results showed that there is a moderate correlation between the ability to self-regulate their learning and students' performance in their respective courses. This shows an influence between the ability to self-regulate and the coefficient (student's overall grade in the course, that is, their academic performance in the course). Within the context of this research, the results allow us to affirm that self-regulation contributes to student performance in the course. Based on the results presented, it is expected to contribute to deepening knowledge about the self-regulation of learning in distance learning and that universities promote and motivate students to develop strategies to self-regulate their own learning.","('Autoregulação da aprendizagem', 'Ensino superior', 'Educação à distância', 'Desempenho estudantil', 'Educação Online', 'Estratégias de Autorregulação', 'Online Education', 'Higher Education', 'Self-Regulation of Learning', 'SelfRegulation Strategies')","Sistemas de Computação","por","Universidade Federal de Alagoas","UFAL","Acesso Aberto","http://www.repositorio.ufal.br/jspui/handle/123456789/15970","2021-08-19","https://www.repositorio.ufal.br/bitstream/123456789/15970/1/Uma%20an%c3%a1lise%20correlacional%20da%20capacidade%20de%20autorregula%c3%a7%c3%a3o%20e%20o%20desempenho%20de%20estudantes%20da%20educa%c3%a7%c3%a3o%20online.pdf","",""
